[0m[2025-01-21T18:27:19.435875] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T18:27:19.435928] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T18:27:21.319088] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T18:27:23.191374] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T18:27:23.191440] [SCALING] Setting up experiment.


[0m[2025-01-21T18:27:23.191452] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T18:27:23.200745] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T18:27:23.216890] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T18:27:23.233814] [SCALING] Statefulset name to scale : flink-1000m-1024
[0m[2025-01-21T18:27:23.244560] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 1 replica.
[0m[2025-01-21T18:27:28.252867] [FLK_MGR] Running job.
[0m[2025-01-21T18:27:28.252898] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T18:27:28.666171] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-tj8lw
[0m[2025-01-21T18:27:33.630613] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID ca9223dee6f043fdbec135e9cd225ea3

[0m[2025-01-21T18:27:33.630781] [FLK_MGR] Running job id: ca9223dee6f043fdbec135e9cd225ea3
[0m[2025-01-21T18:27:33.630792] [FLK_MGR] Getting job info.
[0m[2025-01-21T18:27:33.648677] [FLK_MGR] Job plan response: {"plan":{"jid":"ca9223dee6f043fdbec135e9cd225ea3","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T18:27:33.648820] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T18:27:34.082175] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-tj8lw
[0m[2025-01-21T18:27:35.520723] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 18:27:32 : ca9223dee6f043fdbec135e9cd225ea3 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T18:27:35.520865] [FLK_MGR] Running jobs: ['ca9223dee6f043fdbec135e9cd225ea3']
[0m[2025-01-21T18:27:35.520874] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T18:27:35.520880] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T18:31:35.544555] [SCALING] Scaling started.
[0m[2025-01-21T18:31:35.544653] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T18:31:35.557189] [SCALING] Scaling finished.
[0m[2025-01-21T18:31:35.557221] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T18:31:35.573274] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T18:31:35.588662] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T18:31:35.606604] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 0 replica.
[0m[2025-01-21T18:31:35.622906] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T18:31:35.634619] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T18:31:35.647042] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T18:31:35.658549] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T18:31:35.669485] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T18:31:35.687493] [POD_MGR] Pod flink-jobmanager-7d7c784b74-tj8lw deleted
[0m[2025-01-21T18:31:37.562646] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T18:31:39.453178] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T18:31:39.453249] Reloading playbook: application/kafka
[0m[2025-01-21T18:31:45.349371] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T18:32:51.270186] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T18:32:51.270313] [EXPERIMENT] Run 1 completed. Start: 1737484039, End: 1737484371
[0m[2025-01-21T18:32:51.270319] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T18:33:01.271380] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-21T18:33:03.166716] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T18:33:05.013291] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T18:33:05.013360] [SCALING] Setting up experiment.


[0m[2025-01-21T18:33:05.013375] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T18:33:05.019009] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T18:33:05.033767] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T18:33:05.048768] [SCALING] Statefulset name to scale : flink-1000m-1024
[0m[2025-01-21T18:33:05.058064] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 1 replica.
[0m[2025-01-21T18:33:10.066911] [FLK_MGR] Running job.
[0m[2025-01-21T18:33:10.066935] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T18:33:10.535282] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-7h7b9
[0m[2025-01-21T18:33:14.620900] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 750d32cae4cab54a6604f40641d4f948

[0m[2025-01-21T18:33:14.620945] [FLK_MGR] Running job id: 750d32cae4cab54a6604f40641d4f948
[0m[2025-01-21T18:33:14.620953] [FLK_MGR] Getting job info.
[0m[2025-01-21T18:33:14.637926] [FLK_MGR] Job plan response: {"plan":{"jid":"750d32cae4cab54a6604f40641d4f948","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T18:33:14.638070] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T18:33:15.077209] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-7h7b9
[0m[2025-01-21T18:33:16.541503] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 18:33:13 : 750d32cae4cab54a6604f40641d4f948 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T18:33:16.541551] [FLK_MGR] Running jobs: ['750d32cae4cab54a6604f40641d4f948']
[0m[2025-01-21T18:33:16.541559] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T18:33:16.541566] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T18:37:16.565300] [SCALING] Scaling started.
[0m[2025-01-21T18:37:16.565354] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T18:37:16.583130] [SCALING] Scaling finished.
[0m[2025-01-21T18:37:16.583183] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T18:37:16.601567] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T18:37:16.617727] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T18:37:16.638535] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 0 replica.
[0m[2025-01-21T18:37:26.663481] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T18:37:26.674962] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T18:37:26.686621] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T18:37:26.698323] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T18:37:26.710049] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T18:37:26.731810] [POD_MGR] Pod flink-jobmanager-7d7c784b74-7h7b9 deleted
[0m[2025-01-21T18:37:28.598144] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T18:37:30.482302] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T18:37:30.482527] Reloading playbook: application/kafka
[0m[2025-01-21T18:37:36.385689] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T18:38:22.341118] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T18:38:22.341416] [EXPERIMENT] Run 2 completed. Start: 1737484381, End: 1737484702
[0m[2025-01-21T18:38:22.341425] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T18:38:32.342550] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-21T18:38:34.237474] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T18:38:36.095731] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T18:38:36.095812] [SCALING] Setting up experiment.


[0m[2025-01-21T18:38:36.095821] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T18:38:36.101143] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T18:38:36.116217] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T18:38:36.131373] [SCALING] Statefulset name to scale : flink-1000m-1024
[0m[2025-01-21T18:38:36.142251] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 1 replica.
[0m[2025-01-21T18:38:41.150164] [FLK_MGR] Running job.
[0m[2025-01-21T18:38:41.150192] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T18:38:41.656832] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-tfbcn
[0m[2025-01-21T18:38:45.719819] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6e7630991467945a6a702dda99b74515

[0m[2025-01-21T18:38:45.719863] [FLK_MGR] Running job id: 6e7630991467945a6a702dda99b74515
[0m[2025-01-21T18:38:45.719870] [FLK_MGR] Getting job info.
[0m[2025-01-21T18:38:45.738319] [FLK_MGR] Job plan response: {"plan":{"jid":"6e7630991467945a6a702dda99b74515","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T18:38:45.738465] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T18:38:46.117326] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-tfbcn
[0m[2025-01-21T18:38:47.557722] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 18:38:44 : 6e7630991467945a6a702dda99b74515 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T18:38:47.557781] [FLK_MGR] Running jobs: ['6e7630991467945a6a702dda99b74515']
[0m[2025-01-21T18:38:47.557789] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T18:38:47.557809] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T18:42:47.582013] [SCALING] Scaling started.
[0m[2025-01-21T18:42:47.582160] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T18:42:47.595638] [SCALING] Scaling finished.
[0m[2025-01-21T18:42:47.595683] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T18:42:47.613003] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T18:42:47.629203] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T18:42:47.649514] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 0 replica.
[0m[2025-01-21T18:42:52.669022] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T18:42:52.681365] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T18:42:52.693930] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T18:42:52.706127] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T18:42:52.717848] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T18:42:52.739601] [POD_MGR] Pod flink-jobmanager-7d7c784b74-tfbcn deleted
[0m[2025-01-21T18:42:54.637588] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T18:42:56.528517] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T18:42:56.528590] Reloading playbook: application/kafka
[0m[2025-01-21T18:43:02.448088] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T18:43:48.391050] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T18:43:48.391469] [EXPERIMENT] Run 3 completed. Start: 1737484712, End: 1737485028
[0m[2025-01-21T18:43:48.391476] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T18:43:58.392456] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-21T18:44:00.242410] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T18:44:02.127370] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T18:44:02.127434] [SCALING] Setting up experiment.


[0m[2025-01-21T18:44:02.127442] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T18:44:02.140497] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T18:44:02.168623] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T18:44:02.185959] [SCALING] Statefulset name to scale : flink-1000m-1024
[0m[2025-01-21T18:44:02.195878] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 1 replica.
[0m[2025-01-21T18:44:07.205337] [FLK_MGR] Running job.
[0m[2025-01-21T18:44:07.205365] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T18:44:07.633133] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jh8v9
[0m[2025-01-21T18:44:11.779159] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 35eb55de37d31ce819290ede6fb88948

[0m[2025-01-21T18:44:11.779212] [FLK_MGR] Running job id: 35eb55de37d31ce819290ede6fb88948
[0m[2025-01-21T18:44:11.779219] [FLK_MGR] Getting job info.
[0m[2025-01-21T18:44:11.796918] [FLK_MGR] Job plan response: {"plan":{"jid":"35eb55de37d31ce819290ede6fb88948","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T18:44:11.797068] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T18:44:12.218228] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jh8v9
[0m[2025-01-21T18:44:13.662638] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 18:44:10 : 35eb55de37d31ce819290ede6fb88948 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T18:44:13.662702] [FLK_MGR] Running jobs: ['35eb55de37d31ce819290ede6fb88948']
[0m[2025-01-21T18:44:13.662710] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T18:44:13.662721] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T18:48:13.686822] [SCALING] Scaling started.
[0m[2025-01-21T18:48:13.686933] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T18:48:13.700584] [SCALING] Scaling finished.
[0m[2025-01-21T18:48:13.700642] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T18:48:13.716814] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T18:48:13.732264] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T18:48:13.752925] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 0 replica.
[0m[2025-01-21T18:48:13.771676] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T18:48:13.785046] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T18:48:13.797130] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T18:48:13.809328] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T18:48:13.821199] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T18:48:13.840589] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jh8v9 deleted
[0m[2025-01-21T18:48:15.729982] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T18:48:17.642999] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T18:48:17.643065] Reloading playbook: application/kafka
[0m[2025-01-21T18:48:23.569650] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T18:49:09.540965] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T18:49:09.541127] [EXPERIMENT] Run 4 completed. Start: 1737485038, End: 1737485349
[0m[2025-01-21T18:49:09.541134] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T18:49:19.542077] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-21T18:49:21.421701] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T18:49:23.296554] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T18:49:23.296615] [SCALING] Setting up experiment.


[0m[2025-01-21T18:49:23.296624] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T18:49:23.301952] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T18:49:23.317960] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T18:49:23.336020] [SCALING] Statefulset name to scale : flink-1000m-1024
[0m[2025-01-21T18:49:23.346122] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 1 replica.
[0m[2025-01-21T18:49:28.354973] [FLK_MGR] Running job.
[0m[2025-01-21T18:49:28.355003] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T18:49:28.790222] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-vgwjk
[0m[2025-01-21T18:49:32.956837] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a3007f786ade4015553b17e8a3bd98f9

[0m[2025-01-21T18:49:32.956885] [FLK_MGR] Running job id: a3007f786ade4015553b17e8a3bd98f9
[0m[2025-01-21T18:49:32.956892] [FLK_MGR] Getting job info.
[0m[2025-01-21T18:49:32.975317] [FLK_MGR] Job plan response: {"plan":{"jid":"a3007f786ade4015553b17e8a3bd98f9","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T18:49:32.975450] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T18:49:33.418305] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-vgwjk
[0m[2025-01-21T18:49:34.869700] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 18:49:31 : a3007f786ade4015553b17e8a3bd98f9 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T18:49:34.869758] [FLK_MGR] Running jobs: ['a3007f786ade4015553b17e8a3bd98f9']
[0m[2025-01-21T18:49:34.869765] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T18:49:34.869771] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T18:53:34.892745] [SCALING] Scaling started.
[0m[2025-01-21T18:53:34.892848] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T18:53:34.904928] [SCALING] Scaling finished.
[0m[2025-01-21T18:53:34.904953] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T18:53:34.923334] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T18:53:34.940154] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T18:53:34.962075] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 0 replica.
[0m[2025-01-21T18:53:44.989399] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T18:53:45.001509] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T18:53:45.013554] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T18:53:45.025880] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T18:53:45.037855] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T18:53:45.060834] [POD_MGR] Pod flink-jobmanager-7d7c784b74-vgwjk deleted
[0m[2025-01-21T18:53:46.951898] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T18:53:48.861726] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T18:53:48.861787] Reloading playbook: application/kafka
[0m[2025-01-21T18:53:54.804278] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T18:54:40.693126] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T18:54:40.693277] [EXPERIMENT] Run 5 completed. Start: 1737485359, End: 1737485680
[0m[2025-01-21T18:54:40.693283] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T18:54:52.956628] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-21T18:54:52.956697] [RESOURCE_E] Running experiment with 1000m cores and 2048 memory.
[0m[2025-01-21T18:55:00.214849] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T18:55:00.215022] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T18:55:02.076887] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T18:55:03.960655] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T18:55:03.960720] [SCALING] Setting up experiment.


[0m[2025-01-21T18:55:03.960728] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T18:55:03.966758] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T18:55:03.982206] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T18:55:03.998633] [SCALING] Statefulset name to scale : flink-1000m-2048
[0m[2025-01-21T18:55:04.009891] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 1 replica.
[0m[2025-01-21T18:55:09.018266] [FLK_MGR] Running job.
[0m[2025-01-21T18:55:09.018293] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T18:55:09.446953] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-wh7s4
[0m[2025-01-21T18:55:13.633178] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 890e1b7ab8e1d65820ff5fed46e0e713

[0m[2025-01-21T18:55:13.633222] [FLK_MGR] Running job id: 890e1b7ab8e1d65820ff5fed46e0e713
[0m[2025-01-21T18:55:13.633230] [FLK_MGR] Getting job info.
[0m[2025-01-21T18:55:13.651103] [FLK_MGR] Job plan response: {"plan":{"jid":"890e1b7ab8e1d65820ff5fed46e0e713","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T18:55:13.651242] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T18:55:14.032735] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-wh7s4
[0m[2025-01-21T18:55:15.470125] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 18:55:12 : 890e1b7ab8e1d65820ff5fed46e0e713 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T18:55:15.470188] [FLK_MGR] Running jobs: ['890e1b7ab8e1d65820ff5fed46e0e713']
[0m[2025-01-21T18:55:15.470196] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T18:55:15.470208] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T18:59:15.494714] [SCALING] Scaling started.
[0m[2025-01-21T18:59:15.494826] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T18:59:15.509024] [SCALING] Scaling finished.
[0m[2025-01-21T18:59:15.509063] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T18:59:15.527071] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T18:59:15.545399] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T18:59:15.566656] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 0 replica.
[0m[2025-01-21T18:59:20.585595] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T18:59:20.674689] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T18:59:20.688532] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T18:59:20.700834] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T18:59:20.713127] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T18:59:20.741101] [POD_MGR] Pod flink-jobmanager-7d7c784b74-wh7s4 deleted
[0m[2025-01-21T18:59:22.620739] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T18:59:24.521518] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T18:59:24.521588] Reloading playbook: application/kafka
[0m[2025-01-21T18:59:30.527834] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T19:00:16.458547] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T19:00:16.458653] [EXPERIMENT] Run 1 completed. Start: 1737485700, End: 1737486016
[0m[2025-01-21T19:00:16.458658] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T19:00:26.459686] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-21T19:00:28.321378] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:00:30.221111] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:00:30.221179] [SCALING] Setting up experiment.


[0m[2025-01-21T19:00:30.221195] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:00:30.226413] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:00:30.252285] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T19:00:30.269047] [SCALING] Statefulset name to scale : flink-1000m-2048
[0m[2025-01-21T19:00:30.278997] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 1 replica.
[0m[2025-01-21T19:00:35.290073] [FLK_MGR] Running job.
[0m[2025-01-21T19:00:35.290102] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T19:00:35.666009] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-ncm9b
[0m[2025-01-21T19:00:39.846483] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 63fea5262b755605803e2ecb59559326

[0m[2025-01-21T19:00:39.846544] [FLK_MGR] Running job id: 63fea5262b755605803e2ecb59559326
[0m[2025-01-21T19:00:39.846553] [FLK_MGR] Getting job info.
[0m[2025-01-21T19:00:39.861475] [FLK_MGR] Job plan response: {"plan":{"jid":"63fea5262b755605803e2ecb59559326","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T19:00:39.861630] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T19:00:40.300087] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-ncm9b
[0m[2025-01-21T19:00:41.712679] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 19:00:38 : 63fea5262b755605803e2ecb59559326 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T19:00:41.712737] [FLK_MGR] Running jobs: ['63fea5262b755605803e2ecb59559326']
[0m[2025-01-21T19:00:41.712743] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T19:00:41.712749] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T19:04:41.738045] [SCALING] Scaling started.
[0m[2025-01-21T19:04:41.738149] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T19:04:41.752111] [SCALING] Scaling finished.
[0m[2025-01-21T19:04:41.752130] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:04:41.772213] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:04:41.789599] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T19:04:41.810452] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 0 replica.
[0m[2025-01-21T19:04:51.835483] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T19:04:51.847875] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T19:04:51.860246] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T19:04:51.872697] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T19:04:51.885093] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T19:04:51.907022] [POD_MGR] Pod flink-jobmanager-7d7c784b74-ncm9b deleted
[0m[2025-01-21T19:04:53.794783] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:04:55.699347] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:04:55.699417] Reloading playbook: application/kafka
[0m[2025-01-21T19:05:01.632948] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T19:05:47.564475] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T19:05:47.564599] [EXPERIMENT] Run 2 completed. Start: 1737486026, End: 1737486347
[0m[2025-01-21T19:05:47.564605] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T19:05:57.565840] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-21T19:05:59.451974] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:06:01.298929] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:06:01.298991] [SCALING] Setting up experiment.


[0m[2025-01-21T19:06:01.298999] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:06:01.304168] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:06:01.318840] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T19:06:01.333310] [SCALING] Statefulset name to scale : flink-1000m-2048
[0m[2025-01-21T19:06:01.342019] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 1 replica.
[0m[2025-01-21T19:06:06.350763] [FLK_MGR] Running job.
[0m[2025-01-21T19:06:06.350791] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T19:06:06.796458] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jbgjq
[0m[2025-01-21T19:06:10.908546] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6afecdef91150c77f0e09ea0bf65779f

[0m[2025-01-21T19:06:10.908631] [FLK_MGR] Running job id: 6afecdef91150c77f0e09ea0bf65779f
[0m[2025-01-21T19:06:10.908641] [FLK_MGR] Getting job info.
[0m[2025-01-21T19:06:10.927299] [FLK_MGR] Job plan response: {"plan":{"jid":"6afecdef91150c77f0e09ea0bf65779f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T19:06:10.927438] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T19:06:11.358460] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jbgjq
[0m[2025-01-21T19:06:12.785242] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 19:06:09 : 6afecdef91150c77f0e09ea0bf65779f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T19:06:12.785306] [FLK_MGR] Running jobs: ['6afecdef91150c77f0e09ea0bf65779f']
[0m[2025-01-21T19:06:12.785314] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T19:06:12.785322] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T19:10:12.808259] [SCALING] Scaling started.
[0m[2025-01-21T19:10:12.808354] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T19:10:12.821747] [SCALING] Scaling finished.
[0m[2025-01-21T19:10:12.821767] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:10:12.841391] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:10:12.857994] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T19:10:12.878156] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 0 replica.
[0m[2025-01-21T19:10:17.899268] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T19:10:17.912093] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T19:10:17.925543] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T19:10:17.939219] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T19:10:17.953802] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T19:10:17.990834] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jbgjq deleted
[0m[2025-01-21T19:10:19.879204] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:10:21.803015] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:10:21.803074] Reloading playbook: application/kafka
[0m[2025-01-21T19:10:27.731451] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T19:11:13.691698] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T19:11:13.691830] [EXPERIMENT] Run 3 completed. Start: 1737486357, End: 1737486673
[0m[2025-01-21T19:11:13.691836] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T19:11:23.692889] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-21T19:11:25.580132] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:11:27.462537] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:11:27.462595] [SCALING] Setting up experiment.


[0m[2025-01-21T19:11:27.462603] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:11:27.467910] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:11:27.484151] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T19:11:27.499158] [SCALING] Statefulset name to scale : flink-1000m-2048
[0m[2025-01-21T19:11:27.508913] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 1 replica.
[0m[2025-01-21T19:11:32.519114] [FLK_MGR] Running job.
[0m[2025-01-21T19:11:32.519142] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T19:11:32.941158] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-f9ntz
[0m[2025-01-21T19:11:37.150369] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 637265aab60dfeca3280afc7caba3031

[0m[2025-01-21T19:11:37.150421] [FLK_MGR] Running job id: 637265aab60dfeca3280afc7caba3031
[0m[2025-01-21T19:11:37.150432] [FLK_MGR] Getting job info.
[0m[2025-01-21T19:11:37.167707] [FLK_MGR] Job plan response: {"plan":{"jid":"637265aab60dfeca3280afc7caba3031","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T19:11:37.167852] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T19:11:37.600838] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-f9ntz
[0m[2025-01-21T19:11:39.038904] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 19:11:36 : 637265aab60dfeca3280afc7caba3031 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T19:11:39.038960] [FLK_MGR] Running jobs: ['637265aab60dfeca3280afc7caba3031']
[0m[2025-01-21T19:11:39.038967] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T19:11:39.038972] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T19:15:39.061810] [SCALING] Scaling started.
[0m[2025-01-21T19:15:39.061908] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T19:15:39.075593] [SCALING] Scaling finished.
[0m[2025-01-21T19:15:39.075610] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:15:39.095733] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:15:39.113711] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T19:15:39.134742] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 0 replica.
[0m[2025-01-21T19:15:44.155808] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T19:15:44.169539] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T19:15:44.186590] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T19:15:44.202269] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T19:15:44.217098] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T19:15:44.250007] [POD_MGR] Pod flink-jobmanager-7d7c784b74-f9ntz deleted
[0m[2025-01-21T19:15:46.140311] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:15:48.024543] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:15:48.024605] Reloading playbook: application/kafka
[0m[2025-01-21T19:15:54.000875] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T19:16:39.973506] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T19:16:39.973630] [EXPERIMENT] Run 4 completed. Start: 1737486683, End: 1737486999
[0m[2025-01-21T19:16:39.973636] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T19:16:49.974651] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-21T19:16:51.851932] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:16:53.727602] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:16:53.727746] [SCALING] Setting up experiment.


[0m[2025-01-21T19:16:53.727755] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:16:53.733137] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:16:53.748788] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T19:16:53.767461] [SCALING] Statefulset name to scale : flink-1000m-2048
[0m[2025-01-21T19:16:53.778628] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 1 replica.
[0m[2025-01-21T19:16:58.787802] [FLK_MGR] Running job.
[0m[2025-01-21T19:16:58.787830] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T19:16:59.161971] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-nccqn
[0m[2025-01-21T19:17:03.338774] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c1557b137cbb804dde121cc3ee925c5a

[0m[2025-01-21T19:17:03.338831] [FLK_MGR] Running job id: c1557b137cbb804dde121cc3ee925c5a
[0m[2025-01-21T19:17:03.338841] [FLK_MGR] Getting job info.
[0m[2025-01-21T19:17:03.356815] [FLK_MGR] Job plan response: {"plan":{"jid":"c1557b137cbb804dde121cc3ee925c5a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T19:17:03.356954] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T19:17:03.779961] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-nccqn
[0m[2025-01-21T19:17:05.227410] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 19:17:02 : c1557b137cbb804dde121cc3ee925c5a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T19:17:05.227465] [FLK_MGR] Running jobs: ['c1557b137cbb804dde121cc3ee925c5a']
[0m[2025-01-21T19:17:05.227473] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T19:17:05.227478] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T19:21:05.251282] [SCALING] Scaling started.
[0m[2025-01-21T19:21:05.251379] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T19:21:05.263445] [SCALING] Scaling finished.
[0m[2025-01-21T19:21:05.263467] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:21:05.282602] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:21:05.300965] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T19:21:05.320712] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 0 replica.
[0m[2025-01-21T19:21:10.340912] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T19:21:10.354941] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T19:21:10.368255] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T19:21:10.381500] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T19:21:10.393857] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T19:21:10.412463] [POD_MGR] Pod flink-jobmanager-7d7c784b74-nccqn deleted
[0m[2025-01-21T19:21:12.296029] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:21:14.185970] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:21:14.186030] Reloading playbook: application/kafka
[0m[2025-01-21T19:21:20.174000] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T19:22:06.104490] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T19:22:06.104814] [EXPERIMENT] Run 5 completed. Start: 1737487009, End: 1737487326
[0m[2025-01-21T19:22:06.104821] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T19:22:18.335694] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-21T19:22:18.335747] [RESOURCE_E] Running experiment with 1000m cores and 4096 memory.
[0m[2025-01-21T19:22:25.569103] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T19:22:25.569168] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T19:22:27.462960] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:22:29.327560] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:22:29.327616] [SCALING] Setting up experiment.


[0m[2025-01-21T19:22:29.327624] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:22:29.332524] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:22:29.347698] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T19:22:29.363525] [SCALING] Statefulset name to scale : flink-1000m-4096
[0m[2025-01-21T19:22:29.375044] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 1 replica.
[0m[2025-01-21T19:22:34.386476] [FLK_MGR] Running job.
[0m[2025-01-21T19:22:34.386506] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T19:22:34.837019] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-trftv
[0m[2025-01-21T19:22:38.926068] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 4f3150d1fca132245d4bdc9e59ec80a9

[0m[2025-01-21T19:22:38.926122] [FLK_MGR] Running job id: 4f3150d1fca132245d4bdc9e59ec80a9
[0m[2025-01-21T19:22:38.926131] [FLK_MGR] Getting job info.
[0m[2025-01-21T19:22:38.943933] [FLK_MGR] Job plan response: {"plan":{"jid":"4f3150d1fca132245d4bdc9e59ec80a9","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T19:22:38.944078] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T19:22:39.368846] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-trftv
[0m[2025-01-21T19:22:40.829315] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 19:22:37 : 4f3150d1fca132245d4bdc9e59ec80a9 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T19:22:40.829374] [FLK_MGR] Running jobs: ['4f3150d1fca132245d4bdc9e59ec80a9']
[0m[2025-01-21T19:22:40.829381] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T19:22:40.829386] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T19:26:40.853879] [SCALING] Scaling started.
[0m[2025-01-21T19:26:40.853935] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T19:26:40.868285] [SCALING] Scaling finished.
[0m[2025-01-21T19:26:40.868316] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:26:40.885327] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:26:40.902760] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T19:26:40.922504] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 0 replica.
[0m[2025-01-21T19:26:45.944842] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T19:26:45.958512] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T19:26:45.971632] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T19:26:45.986300] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T19:26:45.999771] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T19:26:46.025027] [POD_MGR] Pod flink-jobmanager-7d7c784b74-trftv deleted
[0m[2025-01-21T19:26:47.890351] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:26:49.802358] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:26:49.802425] Reloading playbook: application/kafka
[0m[2025-01-21T19:26:55.837961] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T19:27:41.780645] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T19:27:41.780770] [EXPERIMENT] Run 1 completed. Start: 1737487345, End: 1737487661
[0m[2025-01-21T19:27:41.780776] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T19:27:51.781910] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-21T19:27:53.660714] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:27:55.527889] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:27:55.527953] [SCALING] Setting up experiment.


[0m[2025-01-21T19:27:55.527962] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:27:55.533354] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:27:55.548446] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T19:27:55.564393] [SCALING] Statefulset name to scale : flink-1000m-4096
[0m[2025-01-21T19:27:55.574984] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 1 replica.
[0m[2025-01-21T19:28:00.583859] [FLK_MGR] Running job.
[0m[2025-01-21T19:28:00.583887] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T19:28:01.018595] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xgphs
[0m[2025-01-21T19:28:05.069469] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 996a90b0f6c52c5a761d7c4fc5ba830a

[0m[2025-01-21T19:28:05.069518] [FLK_MGR] Running job id: 996a90b0f6c52c5a761d7c4fc5ba830a
[0m[2025-01-21T19:28:05.069525] [FLK_MGR] Getting job info.
[0m[2025-01-21T19:28:05.086225] [FLK_MGR] Job plan response: {"plan":{"jid":"996a90b0f6c52c5a761d7c4fc5ba830a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T19:28:05.086382] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T19:28:05.511009] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xgphs
[0m[2025-01-21T19:28:06.933724] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 19:28:04 : 996a90b0f6c52c5a761d7c4fc5ba830a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T19:28:06.933779] [FLK_MGR] Running jobs: ['996a90b0f6c52c5a761d7c4fc5ba830a']
[0m[2025-01-21T19:28:06.933789] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T19:28:06.933796] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T19:32:06.956322] [SCALING] Scaling started.
[0m[2025-01-21T19:32:06.956376] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T19:32:06.968812] [SCALING] Scaling finished.
[0m[2025-01-21T19:32:06.968833] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:32:06.986038] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:32:07.003733] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T19:32:07.025343] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 0 replica.
[0m[2025-01-21T19:32:12.045588] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T19:32:12.060228] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T19:32:12.074438] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T19:32:12.089224] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T19:32:12.103634] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T19:32:12.125205] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xgphs deleted
[0m[2025-01-21T19:32:13.990600] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:32:15.867090] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:32:15.867155] Reloading playbook: application/kafka
[0m[2025-01-21T19:32:21.727386] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T19:33:07.720049] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T19:33:07.720184] [EXPERIMENT] Run 2 completed. Start: 1737487671, End: 1737487987
[0m[2025-01-21T19:33:07.720191] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T19:33:17.721225] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-21T19:33:19.582418] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:33:21.435522] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:33:21.435581] [SCALING] Setting up experiment.


[0m[2025-01-21T19:33:21.435590] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:33:21.440808] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:33:21.456620] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T19:33:21.474474] [SCALING] Statefulset name to scale : flink-1000m-4096
[0m[2025-01-21T19:33:21.484018] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 1 replica.
[0m[2025-01-21T19:33:26.499957] [FLK_MGR] Running job.
[0m[2025-01-21T19:33:26.499988] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T19:33:26.934205] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-hplm9
[0m[2025-01-21T19:33:31.063542] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a80a08d54ad8a3936e66ca307dd8b888

[0m[2025-01-21T19:33:31.063592] [FLK_MGR] Running job id: a80a08d54ad8a3936e66ca307dd8b888
[0m[2025-01-21T19:33:31.063599] [FLK_MGR] Getting job info.
[0m[2025-01-21T19:33:31.080141] [FLK_MGR] Job plan response: {"plan":{"jid":"a80a08d54ad8a3936e66ca307dd8b888","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T19:33:31.080277] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T19:33:31.473570] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-hplm9
[0m[2025-01-21T19:33:32.914558] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 19:33:30 : a80a08d54ad8a3936e66ca307dd8b888 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T19:33:32.914612] [FLK_MGR] Running jobs: ['a80a08d54ad8a3936e66ca307dd8b888']
[0m[2025-01-21T19:33:32.914620] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T19:33:32.914627] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T19:37:32.938232] [SCALING] Scaling started.
[0m[2025-01-21T19:37:32.938284] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T19:37:32.951404] [SCALING] Scaling finished.
[0m[2025-01-21T19:37:32.951421] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:37:32.970214] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:37:32.987179] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T19:37:33.008001] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 0 replica.
[0m[2025-01-21T19:37:38.028360] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T19:37:38.041386] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T19:37:38.054178] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T19:37:38.066965] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T19:37:38.080330] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T19:37:38.108247] [POD_MGR] Pod flink-jobmanager-7d7c784b74-hplm9 deleted
[0m[2025-01-21T19:37:40.007508] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:37:41.906157] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:37:41.906220] Reloading playbook: application/kafka
[0m[2025-01-21T19:37:47.871254] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T19:38:33.832421] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T19:38:33.832564] [EXPERIMENT] Run 3 completed. Start: 1737487997, End: 1737488313
[0m[2025-01-21T19:38:33.832571] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T19:38:43.833730] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-21T19:38:45.688520] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:38:47.538292] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:38:47.538350] [SCALING] Setting up experiment.


[0m[2025-01-21T19:38:47.538359] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:38:47.544252] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:38:47.560940] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T19:38:47.582598] [SCALING] Statefulset name to scale : flink-1000m-4096
[0m[2025-01-21T19:38:47.592443] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 1 replica.
[0m[2025-01-21T19:38:52.603745] [FLK_MGR] Running job.
[0m[2025-01-21T19:38:52.603772] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T19:38:53.015420] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-42hk2
[0m[2025-01-21T19:38:57.117889] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8e2b89a7f8149a73a86084ec96d11a32

[0m[2025-01-21T19:38:57.117947] [FLK_MGR] Running job id: 8e2b89a7f8149a73a86084ec96d11a32
[0m[2025-01-21T19:38:57.117957] [FLK_MGR] Getting job info.
[0m[2025-01-21T19:38:57.136193] [FLK_MGR] Job plan response: {"plan":{"jid":"8e2b89a7f8149a73a86084ec96d11a32","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T19:38:57.136339] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T19:38:57.555491] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-42hk2
[0m[2025-01-21T19:38:58.970003] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 19:38:56 : 8e2b89a7f8149a73a86084ec96d11a32 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T19:38:58.970059] [FLK_MGR] Running jobs: ['8e2b89a7f8149a73a86084ec96d11a32']
[0m[2025-01-21T19:38:58.970066] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T19:38:58.970071] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T19:42:58.992877] [SCALING] Scaling started.
[0m[2025-01-21T19:42:58.992977] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T19:42:59.006407] [SCALING] Scaling finished.
[0m[2025-01-21T19:42:59.006423] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:42:59.024816] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:42:59.042464] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T19:42:59.063958] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 0 replica.
[0m[2025-01-21T19:43:09.089667] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T19:43:09.102574] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T19:43:09.115441] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T19:43:09.128410] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T19:43:09.140900] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T19:43:09.176630] [POD_MGR] Pod flink-jobmanager-7d7c784b74-42hk2 deleted
[0m[2025-01-21T19:43:11.102159] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:43:12.951281] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:43:12.951350] Reloading playbook: application/kafka
[0m[2025-01-21T19:43:18.915522] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T19:44:04.865190] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T19:44:04.865349] [EXPERIMENT] Run 4 completed. Start: 1737488323, End: 1737488644
[0m[2025-01-21T19:44:04.865357] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T19:44:14.866371] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-21T19:44:16.739793] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:44:18.596706] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:44:18.596765] [SCALING] Setting up experiment.


[0m[2025-01-21T19:44:18.596773] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:44:18.602017] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:44:18.617920] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T19:44:18.637566] [SCALING] Statefulset name to scale : flink-1000m-4096
[0m[2025-01-21T19:44:18.647784] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 1 replica.
[0m[2025-01-21T19:44:23.657820] [FLK_MGR] Running job.
[0m[2025-01-21T19:44:23.657848] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T19:44:24.085995] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-8c687
[0m[2025-01-21T19:44:28.222207] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 21156c36aad5a061315131d68b7abaa0

[0m[2025-01-21T19:44:28.222256] [FLK_MGR] Running job id: 21156c36aad5a061315131d68b7abaa0
[0m[2025-01-21T19:44:28.222262] [FLK_MGR] Getting job info.
[0m[2025-01-21T19:44:28.239220] [FLK_MGR] Job plan response: {"plan":{"jid":"21156c36aad5a061315131d68b7abaa0","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T19:44:28.239418] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T19:44:28.652347] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-8c687
[0m[2025-01-21T19:44:30.075983] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 19:44:27 : 21156c36aad5a061315131d68b7abaa0 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T19:44:30.076039] [FLK_MGR] Running jobs: ['21156c36aad5a061315131d68b7abaa0']
[0m[2025-01-21T19:44:30.076046] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T19:44:30.076053] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T19:48:30.099283] [SCALING] Scaling started.
[0m[2025-01-21T19:48:30.099377] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T19:48:30.113200] [SCALING] Scaling finished.
[0m[2025-01-21T19:48:30.113219] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:48:30.134500] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:48:30.151535] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T19:48:30.173622] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 0 replica.
[0m[2025-01-21T19:48:35.195908] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T19:48:35.210739] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T19:48:35.225310] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T19:48:35.239924] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T19:48:35.254541] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T19:48:35.278763] [POD_MGR] Pod flink-jobmanager-7d7c784b74-8c687 deleted
[0m[2025-01-21T19:48:37.151262] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:48:39.068571] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:48:39.068638] Reloading playbook: application/kafka
[0m[2025-01-21T19:48:44.997486] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T19:49:30.970049] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T19:49:30.970172] [EXPERIMENT] Run 5 completed. Start: 1737488654, End: 1737488970
[0m[2025-01-21T19:49:30.970178] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T19:49:43.208407] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-21T19:49:43.208458] [RESOURCE_E] Running experiment with 1000m cores and 8192 memory.
[0m[2025-01-21T19:49:50.465734] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T19:49:50.465797] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T19:49:52.293428] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:49:54.174860] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:49:54.174913] [SCALING] Setting up experiment.


[0m[2025-01-21T19:49:54.174921] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:49:54.180141] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:49:54.197395] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T19:49:54.213699] [SCALING] Statefulset name to scale : flink-1000m-8192
[0m[2025-01-21T19:49:54.225073] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 1 replica.
[0m[2025-01-21T19:49:59.234402] [FLK_MGR] Running job.
[0m[2025-01-21T19:49:59.234430] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T19:49:59.674109] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-zvp4w
[0m[2025-01-21T19:50:03.822217] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 2849f3faca6313c10c4bf8e77fe70d29

[0m[2025-01-21T19:50:03.822267] [FLK_MGR] Running job id: 2849f3faca6313c10c4bf8e77fe70d29
[0m[2025-01-21T19:50:03.822274] [FLK_MGR] Getting job info.
[0m[2025-01-21T19:50:03.839729] [FLK_MGR] Job plan response: {"plan":{"jid":"2849f3faca6313c10c4bf8e77fe70d29","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T19:50:03.839883] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T19:50:04.226130] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-zvp4w
[0m[2025-01-21T19:50:05.674304] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 19:50:02 : 2849f3faca6313c10c4bf8e77fe70d29 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T19:50:05.674364] [FLK_MGR] Running jobs: ['2849f3faca6313c10c4bf8e77fe70d29']
[0m[2025-01-21T19:50:05.674371] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T19:50:05.674377] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T19:54:05.697873] [SCALING] Scaling started.
[0m[2025-01-21T19:54:05.697973] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T19:54:05.712546] [SCALING] Scaling finished.
[0m[2025-01-21T19:54:05.712568] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:54:05.731867] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:54:05.759767] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T19:54:05.786253] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 0 replica.
[0m[2025-01-21T19:54:10.807982] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T19:54:10.822997] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T19:54:10.837293] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T19:54:10.853552] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T19:54:10.918486] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T19:54:10.942587] [POD_MGR] Pod flink-jobmanager-7d7c784b74-zvp4w deleted
[0m[2025-01-21T19:54:12.814868] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:54:14.720844] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:54:14.720908] Reloading playbook: application/kafka
[0m[2025-01-21T19:54:20.739153] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T19:55:06.659737] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T19:55:06.659874] [EXPERIMENT] Run 1 completed. Start: 1737488990, End: 1737489306
[0m[2025-01-21T19:55:06.659880] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T19:55:16.660861] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-21T19:55:18.572301] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:55:20.438822] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T19:55:20.438883] [SCALING] Setting up experiment.


[0m[2025-01-21T19:55:20.438891] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:55:20.444829] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:55:20.464386] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T19:55:20.481476] [SCALING] Statefulset name to scale : flink-1000m-8192
[0m[2025-01-21T19:55:20.492693] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 1 replica.
[0m[2025-01-21T19:55:25.505423] [FLK_MGR] Running job.
[0m[2025-01-21T19:55:25.505453] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T19:55:25.886721] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jlbkf
[0m[2025-01-21T19:55:29.974138] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 073f75b859f1d68017417029318652ab

[0m[2025-01-21T19:55:29.974200] [FLK_MGR] Running job id: 073f75b859f1d68017417029318652ab
[0m[2025-01-21T19:55:29.974207] [FLK_MGR] Getting job info.
[0m[2025-01-21T19:55:29.992264] [FLK_MGR] Job plan response: {"plan":{"jid":"073f75b859f1d68017417029318652ab","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T19:55:29.992436] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T19:55:30.428426] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jlbkf
[0m[2025-01-21T19:55:31.870647] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 19:55:28 : 073f75b859f1d68017417029318652ab : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T19:55:31.870698] [FLK_MGR] Running jobs: ['073f75b859f1d68017417029318652ab']
[0m[2025-01-21T19:55:31.870705] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T19:55:31.870711] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T19:59:31.893947] [SCALING] Scaling started.
[0m[2025-01-21T19:59:31.894039] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T19:59:31.907000] [SCALING] Scaling finished.
[0m[2025-01-21T19:59:31.907023] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T19:59:31.925886] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T19:59:31.944385] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T19:59:31.964407] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 0 replica.
[0m[2025-01-21T19:59:41.989279] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T19:59:42.002308] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T19:59:42.016962] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T19:59:42.032162] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T19:59:42.046667] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T19:59:42.069939] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jlbkf deleted
[0m[2025-01-21T19:59:44.004270] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:59:45.893917] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T19:59:45.893988] Reloading playbook: application/kafka
[0m[2025-01-21T19:59:51.894402] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T20:00:37.862533] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T20:00:37.862669] [EXPERIMENT] Run 2 completed. Start: 1737489316, End: 1737489637
[0m[2025-01-21T20:00:37.862675] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T20:00:47.863697] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-21T20:00:49.726227] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:00:51.609655] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:00:51.609714] [SCALING] Setting up experiment.


[0m[2025-01-21T20:00:51.609734] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:00:51.616761] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:00:51.632644] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T20:00:51.649945] [SCALING] Statefulset name to scale : flink-1000m-8192
[0m[2025-01-21T20:00:51.660461] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 1 replica.
[0m[2025-01-21T20:00:56.670815] [FLK_MGR] Running job.
[0m[2025-01-21T20:00:56.670845] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T20:00:57.106871] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-nglc6
[0m[2025-01-21T20:01:01.273158] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 476eace15a0d54b5d8bae6685574015b

[0m[2025-01-21T20:01:01.273214] [FLK_MGR] Running job id: 476eace15a0d54b5d8bae6685574015b
[0m[2025-01-21T20:01:01.273221] [FLK_MGR] Getting job info.
[0m[2025-01-21T20:01:01.291544] [FLK_MGR] Job plan response: {"plan":{"jid":"476eace15a0d54b5d8bae6685574015b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T20:01:01.291698] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T20:01:01.712194] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-nglc6
[0m[2025-01-21T20:01:03.166083] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 20:01:00 : 476eace15a0d54b5d8bae6685574015b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T20:01:03.166137] [FLK_MGR] Running jobs: ['476eace15a0d54b5d8bae6685574015b']
[0m[2025-01-21T20:01:03.166144] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T20:01:03.166149] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T20:05:03.189861] [SCALING] Scaling started.
[0m[2025-01-21T20:05:03.189913] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T20:05:03.201415] [SCALING] Scaling finished.
[0m[2025-01-21T20:05:03.201436] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:05:03.218526] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:05:03.236783] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T20:05:03.258586] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 0 replica.
[0m[2025-01-21T20:05:08.277771] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T20:05:08.290872] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T20:05:08.304123] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T20:05:08.317252] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T20:05:08.330798] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T20:05:08.366263] [POD_MGR] Pod flink-jobmanager-7d7c784b74-nglc6 deleted
[0m[2025-01-21T20:05:10.291522] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:05:12.215519] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:05:12.215588] Reloading playbook: application/kafka
[0m[2025-01-21T20:05:18.186527] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T20:06:04.117393] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T20:06:04.117645] [EXPERIMENT] Run 3 completed. Start: 1737489647, End: 1737489964
[0m[2025-01-21T20:06:04.117653] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T20:06:14.118807] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-21T20:06:16.001476] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:06:17.855678] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:06:17.855756] [SCALING] Setting up experiment.


[0m[2025-01-21T20:06:17.855774] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:06:17.863250] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:06:17.880085] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T20:06:17.896769] [SCALING] Statefulset name to scale : flink-1000m-8192
[0m[2025-01-21T20:06:17.921612] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 1 replica.
[0m[2025-01-21T20:06:22.932080] [FLK_MGR] Running job.
[0m[2025-01-21T20:06:22.932119] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T20:06:23.412926] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-2xblj
[0m[2025-01-21T20:06:27.568811] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 72ed27bd6a5d1d45ed14c6adeb1e5296

[0m[2025-01-21T20:06:27.568862] [FLK_MGR] Running job id: 72ed27bd6a5d1d45ed14c6adeb1e5296
[0m[2025-01-21T20:06:27.568869] [FLK_MGR] Getting job info.
[0m[2025-01-21T20:06:27.588193] [FLK_MGR] Job plan response: {"plan":{"jid":"72ed27bd6a5d1d45ed14c6adeb1e5296","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T20:06:27.588335] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T20:06:27.959880] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-2xblj
[0m[2025-01-21T20:06:29.395657] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 20:06:26 : 72ed27bd6a5d1d45ed14c6adeb1e5296 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T20:06:29.395711] [FLK_MGR] Running jobs: ['72ed27bd6a5d1d45ed14c6adeb1e5296']
[0m[2025-01-21T20:06:29.395718] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T20:06:29.395725] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T20:10:29.417919] [SCALING] Scaling started.
[0m[2025-01-21T20:10:29.417971] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T20:10:29.430011] [SCALING] Scaling finished.
[0m[2025-01-21T20:10:29.430032] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:10:29.482026] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:10:29.500434] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T20:10:29.523631] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 0 replica.
[0m[2025-01-21T20:10:34.546207] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T20:10:34.564286] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T20:10:34.578186] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T20:10:34.593363] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T20:10:34.608087] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T20:10:34.643316] [POD_MGR] Pod flink-jobmanager-7d7c784b74-2xblj deleted
[0m[2025-01-21T20:10:36.521155] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:10:38.455738] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:10:38.455801] Reloading playbook: application/kafka
[0m[2025-01-21T20:10:44.376866] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T20:11:40.352762] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T20:11:40.353004] [EXPERIMENT] Run 4 completed. Start: 1737489974, End: 1737490300
[0m[2025-01-21T20:11:40.353011] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T20:11:50.353960] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-21T20:11:52.234924] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:11:54.104126] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:11:54.104190] [SCALING] Setting up experiment.


[0m[2025-01-21T20:11:54.104201] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:11:54.109640] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:11:54.124115] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T20:11:54.142984] [SCALING] Statefulset name to scale : flink-1000m-8192
[0m[2025-01-21T20:11:54.154688] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 1 replica.
[0m[2025-01-21T20:11:59.165850] [FLK_MGR] Running job.
[0m[2025-01-21T20:11:59.165879] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T20:11:59.542914] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-h9t94
[0m[2025-01-21T20:12:03.665174] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 7579616fff46d388d1d865502e84edf0

[0m[2025-01-21T20:12:03.665241] [FLK_MGR] Running job id: 7579616fff46d388d1d865502e84edf0
[0m[2025-01-21T20:12:03.665250] [FLK_MGR] Getting job info.
[0m[2025-01-21T20:12:03.684340] [FLK_MGR] Job plan response: {"plan":{"jid":"7579616fff46d388d1d865502e84edf0","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T20:12:03.684496] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T20:12:04.108235] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-h9t94
[0m[2025-01-21T20:12:05.537283] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 20:12:02 : 7579616fff46d388d1d865502e84edf0 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T20:12:05.537340] [FLK_MGR] Running jobs: ['7579616fff46d388d1d865502e84edf0']
[0m[2025-01-21T20:12:05.537347] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T20:12:05.537354] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T20:16:05.561353] [SCALING] Scaling started.
[0m[2025-01-21T20:16:05.561404] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T20:16:05.575042] [SCALING] Scaling finished.
[0m[2025-01-21T20:16:05.575064] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:16:05.594411] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:16:05.611066] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T20:16:05.631922] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 0 replica.
[0m[2025-01-21T20:16:15.656466] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T20:16:15.669065] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T20:16:15.684157] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T20:16:15.696936] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T20:16:15.709606] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T20:16:15.737082] [POD_MGR] Pod flink-jobmanager-7d7c784b74-h9t94 deleted
[0m[2025-01-21T20:16:17.605659] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:16:19.551685] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:16:19.551879] Reloading playbook: application/kafka
[0m[2025-01-21T20:16:25.519292] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T20:17:11.480617] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T20:17:11.480826] [EXPERIMENT] Run 5 completed. Start: 1737490310, End: 1737490631
[0m[2025-01-21T20:17:11.480833] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T20:17:23.729545] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-21T20:17:23.729605] [RESOURCE_E] Running experiment with 1000m cores and 16384 memory.
[0m[2025-01-21T20:17:31.009024] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T20:17:31.009112] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T20:17:32.915388] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:17:34.792609] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:17:34.792732] [SCALING] Setting up experiment.


[0m[2025-01-21T20:17:34.792758] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:17:34.801092] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:17:34.816552] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T20:17:34.838587] [SCALING] Statefulset name to scale : flink-1000m-16384
[0m[2025-01-21T20:17:34.854825] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 1 replica.
[0m[2025-01-21T20:17:39.868771] [FLK_MGR] Running job.
[0m[2025-01-21T20:17:39.868820] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T20:17:40.329121] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-rdmlt
[0m[2025-01-21T20:17:44.466276] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a38e3fd5634213185475cfb900e8801b

[0m[2025-01-21T20:17:44.466326] [FLK_MGR] Running job id: a38e3fd5634213185475cfb900e8801b
[0m[2025-01-21T20:17:44.466334] [FLK_MGR] Getting job info.
[0m[2025-01-21T20:17:44.482651] [FLK_MGR] Job plan response: {"plan":{"jid":"a38e3fd5634213185475cfb900e8801b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T20:17:44.482789] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T20:17:44.908513] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-rdmlt
[0m[2025-01-21T20:17:46.371704] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 20:17:43 : a38e3fd5634213185475cfb900e8801b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T20:17:46.371764] [FLK_MGR] Running jobs: ['a38e3fd5634213185475cfb900e8801b']
[0m[2025-01-21T20:17:46.371771] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T20:17:46.371780] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T20:21:46.396637] [SCALING] Scaling started.
[0m[2025-01-21T20:21:46.396696] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T20:21:46.409249] [SCALING] Scaling finished.
[0m[2025-01-21T20:21:46.409278] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:21:46.428183] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:21:46.444701] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T20:21:46.467312] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 0 replica.
[0m[2025-01-21T20:21:51.486471] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T20:21:51.499562] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T20:21:51.512292] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T20:21:51.524996] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T20:21:51.537882] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T20:21:51.567675] [POD_MGR] Pod flink-jobmanager-7d7c784b74-rdmlt deleted
[0m[2025-01-21T20:21:53.484640] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:21:55.370209] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:21:55.370308] Reloading playbook: application/kafka
[0m[2025-01-21T20:22:01.382212] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T20:23:02.356549] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T20:23:02.356695] [EXPERIMENT] Run 1 completed. Start: 1737490651, End: 1737490982
[0m[2025-01-21T20:23:02.356702] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T20:23:12.357776] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-21T20:23:14.253349] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:23:16.137014] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:23:16.137092] [SCALING] Setting up experiment.


[0m[2025-01-21T20:23:16.137104] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:23:16.143707] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:23:16.162514] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T20:23:16.179358] [SCALING] Statefulset name to scale : flink-1000m-16384
[0m[2025-01-21T20:23:16.189350] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 1 replica.
[0m[2025-01-21T20:23:21.202480] [FLK_MGR] Running job.
[0m[2025-01-21T20:23:21.202508] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T20:23:21.631444] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-m5mxg
[0m[2025-01-21T20:23:25.732972] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f5f55ce97ae70ad23e9013c36fe58954

[0m[2025-01-21T20:23:25.733022] [FLK_MGR] Running job id: f5f55ce97ae70ad23e9013c36fe58954
[0m[2025-01-21T20:23:25.733030] [FLK_MGR] Getting job info.
[0m[2025-01-21T20:23:25.750850] [FLK_MGR] Job plan response: {"plan":{"jid":"f5f55ce97ae70ad23e9013c36fe58954","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T20:23:25.750997] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T20:23:26.192502] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-m5mxg
[0m[2025-01-21T20:23:27.637277] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 20:23:24 : f5f55ce97ae70ad23e9013c36fe58954 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T20:23:27.637336] [FLK_MGR] Running jobs: ['f5f55ce97ae70ad23e9013c36fe58954']
[0m[2025-01-21T20:23:27.637342] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T20:23:27.637348] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T20:27:27.662111] [SCALING] Scaling started.
[0m[2025-01-21T20:27:27.662167] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T20:27:27.675760] [SCALING] Scaling finished.
[0m[2025-01-21T20:27:27.675783] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:27:27.695413] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:27:27.725445] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T20:27:27.750124] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 0 replica.
[0m[2025-01-21T20:27:32.770061] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T20:27:32.783971] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T20:27:32.796671] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T20:27:32.810213] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T20:27:32.824820] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T20:27:32.859343] [POD_MGR] Pod flink-jobmanager-7d7c784b74-m5mxg deleted
[0m[2025-01-21T20:27:34.727915] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:27:36.637610] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:27:36.637677] Reloading playbook: application/kafka
[0m[2025-01-21T20:27:42.574194] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T20:28:28.532667] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T20:28:28.532802] [EXPERIMENT] Run 2 completed. Start: 1737490992, End: 1737491308
[0m[2025-01-21T20:28:28.532809] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T20:28:38.533719] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-21T20:28:40.384568] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:28:42.236466] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:28:42.236522] [SCALING] Setting up experiment.


[0m[2025-01-21T20:28:42.236531] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:28:42.241715] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:28:42.259480] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T20:28:42.275104] [SCALING] Statefulset name to scale : flink-1000m-16384
[0m[2025-01-21T20:28:42.284257] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 1 replica.
[0m[2025-01-21T20:28:47.294103] [FLK_MGR] Running job.
[0m[2025-01-21T20:28:47.294130] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T20:28:47.729091] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-lq5jn
[0m[2025-01-21T20:28:51.808720] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a9ce1ef9442d4f503f8025d29f6de4a4

[0m[2025-01-21T20:28:51.808776] [FLK_MGR] Running job id: a9ce1ef9442d4f503f8025d29f6de4a4
[0m[2025-01-21T20:28:51.808785] [FLK_MGR] Getting job info.
[0m[2025-01-21T20:28:51.826240] [FLK_MGR] Job plan response: {"plan":{"jid":"a9ce1ef9442d4f503f8025d29f6de4a4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T20:28:51.826388] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T20:28:52.220685] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-lq5jn
[0m[2025-01-21T20:28:53.673961] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 20:28:50 : a9ce1ef9442d4f503f8025d29f6de4a4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T20:28:53.674024] [FLK_MGR] Running jobs: ['a9ce1ef9442d4f503f8025d29f6de4a4']
[0m[2025-01-21T20:28:53.674031] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T20:28:53.674041] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T20:32:53.698482] [SCALING] Scaling started.
[0m[2025-01-21T20:32:53.698584] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T20:32:53.711754] [SCALING] Scaling finished.
[0m[2025-01-21T20:32:53.711776] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:32:53.730234] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:32:53.749706] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T20:32:53.771676] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 0 replica.
[0m[2025-01-21T20:33:03.797400] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T20:33:03.813001] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T20:33:03.828104] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T20:33:03.843783] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T20:33:03.858834] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T20:33:03.885251] [POD_MGR] Pod flink-jobmanager-7d7c784b74-lq5jn deleted
[0m[2025-01-21T20:33:05.722216] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:33:07.617471] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:33:07.617542] Reloading playbook: application/kafka
[0m[2025-01-21T20:33:13.544214] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T20:33:59.475133] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T20:33:59.475278] [EXPERIMENT] Run 3 completed. Start: 1737491318, End: 1737491639
[0m[2025-01-21T20:33:59.475285] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T20:34:09.476229] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-21T20:34:11.342875] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:34:13.235717] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:34:13.235781] [SCALING] Setting up experiment.


[0m[2025-01-21T20:34:13.235790] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:34:13.242485] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:34:13.260084] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T20:34:13.276088] [SCALING] Statefulset name to scale : flink-1000m-16384
[0m[2025-01-21T20:34:13.285653] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 1 replica.
[0m[2025-01-21T20:34:18.295808] [FLK_MGR] Running job.
[0m[2025-01-21T20:34:18.295836] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T20:34:18.723622] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-8crgf
[0m[2025-01-21T20:34:22.813946] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f3f55ffe7b53cd7f6b5e02c0bac45aaa

[0m[2025-01-21T20:34:22.813995] [FLK_MGR] Running job id: f3f55ffe7b53cd7f6b5e02c0bac45aaa
[0m[2025-01-21T20:34:22.814002] [FLK_MGR] Getting job info.
[0m[2025-01-21T20:34:22.835504] [FLK_MGR] Job plan response: {"plan":{"jid":"f3f55ffe7b53cd7f6b5e02c0bac45aaa","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T20:34:22.835653] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T20:34:23.284570] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-8crgf
[0m[2025-01-21T20:34:24.726377] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 20:34:21 : f3f55ffe7b53cd7f6b5e02c0bac45aaa : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T20:34:24.726436] [FLK_MGR] Running jobs: ['f3f55ffe7b53cd7f6b5e02c0bac45aaa']
[0m[2025-01-21T20:34:24.726443] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T20:34:24.726455] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T20:38:24.749582] [SCALING] Scaling started.
[0m[2025-01-21T20:38:24.749634] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T20:38:24.766333] [SCALING] Scaling finished.
[0m[2025-01-21T20:38:24.766372] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:38:24.785005] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:38:24.801175] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T20:38:24.823840] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 0 replica.
[0m[2025-01-21T20:38:29.845020] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T20:38:29.859514] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T20:38:29.872608] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T20:38:29.885469] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T20:38:29.900945] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T20:38:29.920696] [POD_MGR] Pod flink-jobmanager-7d7c784b74-8crgf deleted
[0m[2025-01-21T20:38:31.800288] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:38:33.700557] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:38:33.700630] Reloading playbook: application/kafka
[0m[2025-01-21T20:38:39.653047] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T20:39:25.637683] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T20:39:25.637837] [EXPERIMENT] Run 4 completed. Start: 1737491649, End: 1737491965
[0m[2025-01-21T20:39:25.637843] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T20:39:35.638917] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-21T20:39:37.517796] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:39:39.387824] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:39:39.387891] [SCALING] Setting up experiment.


[0m[2025-01-21T20:39:39.387900] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:39:39.393540] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:39:39.409528] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T20:39:39.426665] [SCALING] Statefulset name to scale : flink-1000m-16384
[0m[2025-01-21T20:39:39.437843] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 1 replica.
[0m[2025-01-21T20:39:44.448242] [FLK_MGR] Running job.
[0m[2025-01-21T20:39:44.448322] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T20:39:44.874879] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-sw4q4
[0m[2025-01-21T20:39:48.945794] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6260eef630b1c2f1487a3078ddfba331

[0m[2025-01-21T20:39:48.945843] [FLK_MGR] Running job id: 6260eef630b1c2f1487a3078ddfba331
[0m[2025-01-21T20:39:48.945850] [FLK_MGR] Getting job info.
[0m[2025-01-21T20:39:48.963555] [FLK_MGR] Job plan response: {"plan":{"jid":"6260eef630b1c2f1487a3078ddfba331","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T20:39:48.963699] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T20:39:49.404922] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sw4q4
[0m[2025-01-21T20:39:50.843561] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 20:39:47 : 6260eef630b1c2f1487a3078ddfba331 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T20:39:50.843616] [FLK_MGR] Running jobs: ['6260eef630b1c2f1487a3078ddfba331']
[0m[2025-01-21T20:39:50.843622] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T20:39:50.843628] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T20:43:50.867894] [SCALING] Scaling started.
[0m[2025-01-21T20:43:50.867990] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T20:43:50.881252] [SCALING] Scaling finished.
[0m[2025-01-21T20:43:50.881278] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:43:50.899751] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:43:50.918082] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T20:43:50.939968] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 0 replica.
[0m[2025-01-21T20:43:55.962561] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T20:43:55.977628] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T20:43:55.992787] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T20:43:56.006983] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T20:43:56.022674] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T20:43:56.046315] [POD_MGR] Pod flink-jobmanager-7d7c784b74-sw4q4 deleted
[0m[2025-01-21T20:43:57.950467] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:43:59.864229] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:43:59.864294] Reloading playbook: application/kafka
[0m[2025-01-21T20:44:05.882564] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T20:44:51.746808] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T20:44:51.746933] [EXPERIMENT] Run 5 completed. Start: 1737491975, End: 1737492291
[0m[2025-01-21T20:44:51.746939] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T20:45:04.000923] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-21T20:45:04.000973] [RESOURCE_E] Running experiment with 1000m cores and 32768 memory.
[0m[2025-01-21T20:45:11.218375] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T20:45:11.218434] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T20:45:13.090931] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:45:14.942845] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:45:14.942901] [SCALING] Setting up experiment.


[0m[2025-01-21T20:45:14.942909] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:45:14.948442] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:45:14.964294] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T20:45:14.981186] [SCALING] Statefulset name to scale : flink-1000m-32768
[0m[2025-01-21T20:45:14.991772] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 1 replica.
[0m[2025-01-21T20:45:20.002862] [FLK_MGR] Running job.
[0m[2025-01-21T20:45:20.002891] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T20:45:20.448440] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-gl5nj
[0m[2025-01-21T20:45:24.537732] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f2db168903560aab7c7b6a0797fe42aa

[0m[2025-01-21T20:45:24.537781] [FLK_MGR] Running job id: f2db168903560aab7c7b6a0797fe42aa
[0m[2025-01-21T20:45:24.537788] [FLK_MGR] Getting job info.
[0m[2025-01-21T20:45:24.559377] [FLK_MGR] Job plan response: {"plan":{"jid":"f2db168903560aab7c7b6a0797fe42aa","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T20:45:24.559518] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T20:45:24.939420] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-gl5nj
[0m[2025-01-21T20:45:26.385418] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 20:45:23 : f2db168903560aab7c7b6a0797fe42aa : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T20:45:26.385489] [FLK_MGR] Running jobs: ['f2db168903560aab7c7b6a0797fe42aa']
[0m[2025-01-21T20:45:26.385501] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T20:45:26.385531] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T20:49:26.408389] [SCALING] Scaling started.
[0m[2025-01-21T20:49:26.408458] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T20:49:26.422063] [SCALING] Scaling finished.
[0m[2025-01-21T20:49:26.422098] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:49:26.439605] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:49:26.457332] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T20:49:26.481291] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 0 replica.
[0m[2025-01-21T20:49:36.508581] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T20:49:36.521964] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T20:49:36.536194] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T20:49:36.550516] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T20:49:36.566571] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T20:49:36.595237] [POD_MGR] Pod flink-jobmanager-7d7c784b74-gl5nj deleted
[0m[2025-01-21T20:49:38.440575] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:49:40.342761] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:49:40.342804] Reloading playbook: application/kafka
[0m[2025-01-21T20:49:46.306426] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T20:50:32.263278] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T20:50:32.263418] [EXPERIMENT] Run 1 completed. Start: 1737492311, End: 1737492632
[0m[2025-01-21T20:50:32.263424] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T20:50:42.264511] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-21T20:50:44.131307] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:50:46.002553] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:50:46.002621] [SCALING] Setting up experiment.


[0m[2025-01-21T20:50:46.002631] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:50:46.008126] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:50:46.024523] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T20:50:46.039787] [SCALING] Statefulset name to scale : flink-1000m-32768
[0m[2025-01-21T20:50:46.050583] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 1 replica.
[0m[2025-01-21T20:50:51.060618] [FLK_MGR] Running job.
[0m[2025-01-21T20:50:51.060646] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T20:50:51.430763] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-86qd8
[0m[2025-01-21T20:50:55.515037] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 56eb8069523ac743798e5d0b5eb05720

[0m[2025-01-21T20:50:55.515093] [FLK_MGR] Running job id: 56eb8069523ac743798e5d0b5eb05720
[0m[2025-01-21T20:50:55.515102] [FLK_MGR] Getting job info.
[0m[2025-01-21T20:50:55.530874] [FLK_MGR] Job plan response: {"plan":{"jid":"56eb8069523ac743798e5d0b5eb05720","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T20:50:55.531025] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T20:50:55.966968] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-86qd8
[0m[2025-01-21T20:50:57.425170] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 20:50:54 : 56eb8069523ac743798e5d0b5eb05720 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T20:50:57.425249] [FLK_MGR] Running jobs: ['56eb8069523ac743798e5d0b5eb05720']
[0m[2025-01-21T20:50:57.425266] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T20:50:57.425277] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T20:54:57.450499] [SCALING] Scaling started.
[0m[2025-01-21T20:54:57.450600] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T20:54:57.465103] [SCALING] Scaling finished.
[0m[2025-01-21T20:54:57.465120] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:54:57.483825] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:54:57.502627] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T20:54:57.526635] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 0 replica.
[0m[2025-01-21T20:55:02.547837] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T20:55:02.564452] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T20:55:02.577999] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T20:55:02.591850] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T20:55:02.606268] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T20:55:02.638558] [POD_MGR] Pod flink-jobmanager-7d7c784b74-86qd8 deleted
[0m[2025-01-21T20:55:04.538340] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:55:06.443415] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T20:55:06.443480] Reloading playbook: application/kafka
[0m[2025-01-21T20:55:12.413472] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T20:55:58.390641] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T20:55:58.390772] [EXPERIMENT] Run 2 completed. Start: 1737492642, End: 1737492958
[0m[2025-01-21T20:55:58.390778] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T20:56:08.391796] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-21T20:56:10.252463] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:56:12.122992] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T20:56:12.123052] [SCALING] Setting up experiment.


[0m[2025-01-21T20:56:12.123061] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T20:56:12.128381] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T20:56:12.145099] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T20:56:12.171695] [SCALING] Statefulset name to scale : flink-1000m-32768
[0m[2025-01-21T20:56:12.186738] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 1 replica.
[0m[2025-01-21T20:56:17.196464] [FLK_MGR] Running job.
[0m[2025-01-21T20:56:17.196493] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T20:56:17.607003] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-pfcnj
[0m[2025-01-21T20:56:21.768642] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 3526bc1df7a25795062a6cc64a430e0d

[0m[2025-01-21T20:56:21.768714] [FLK_MGR] Running job id: 3526bc1df7a25795062a6cc64a430e0d
[0m[2025-01-21T20:56:21.768727] [FLK_MGR] Getting job info.
[0m[2025-01-21T20:56:21.785059] [FLK_MGR] Job plan response: {"plan":{"jid":"3526bc1df7a25795062a6cc64a430e0d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T20:56:21.785206] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T20:56:22.218021] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-pfcnj
[0m[2025-01-21T20:56:23.666451] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 20:56:20 : 3526bc1df7a25795062a6cc64a430e0d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T20:56:23.666510] [FLK_MGR] Running jobs: ['3526bc1df7a25795062a6cc64a430e0d']
[0m[2025-01-21T20:56:23.666517] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T20:56:23.666524] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T21:00:23.691356] [SCALING] Scaling started.
[0m[2025-01-21T21:00:23.691412] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T21:00:23.703075] [SCALING] Scaling finished.
[0m[2025-01-21T21:00:23.703092] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:00:23.722324] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:00:23.742533] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T21:00:23.764346] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 0 replica.
[0m[2025-01-21T21:00:28.786775] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T21:00:28.801055] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T21:00:28.817493] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T21:00:28.833476] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T21:00:28.848201] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T21:00:28.883537] [POD_MGR] Pod flink-jobmanager-7d7c784b74-pfcnj deleted
[0m[2025-01-21T21:00:30.813022] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:00:32.719218] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:00:32.719283] Reloading playbook: application/kafka
[0m[2025-01-21T21:00:38.700591] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T21:01:24.655771] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T21:01:24.655909] [EXPERIMENT] Run 3 completed. Start: 1737492968, End: 1737493284
[0m[2025-01-21T21:01:24.655917] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T21:01:34.656941] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-21T21:01:36.535838] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:01:38.370562] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:01:38.370618] [SCALING] Setting up experiment.


[0m[2025-01-21T21:01:38.370626] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:01:38.375849] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:01:38.391641] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T21:01:38.409040] [SCALING] Statefulset name to scale : flink-1000m-32768
[0m[2025-01-21T21:01:38.418692] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 1 replica.
[0m[2025-01-21T21:01:43.427976] [FLK_MGR] Running job.
[0m[2025-01-21T21:01:43.428005] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T21:01:43.851844] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-7ftjl
[0m[2025-01-21T21:01:48.038148] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b3e4322a763f12f2d4fc14577acf36bb

[0m[2025-01-21T21:01:48.038202] [FLK_MGR] Running job id: b3e4322a763f12f2d4fc14577acf36bb
[0m[2025-01-21T21:01:48.038213] [FLK_MGR] Getting job info.
[0m[2025-01-21T21:01:48.055598] [FLK_MGR] Job plan response: {"plan":{"jid":"b3e4322a763f12f2d4fc14577acf36bb","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T21:01:48.055743] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T21:01:48.427124] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-7ftjl
[0m[2025-01-21T21:01:49.876757] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 21:01:47 : b3e4322a763f12f2d4fc14577acf36bb : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T21:01:49.876820] [FLK_MGR] Running jobs: ['b3e4322a763f12f2d4fc14577acf36bb']
[0m[2025-01-21T21:01:49.876828] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T21:01:49.876838] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T21:05:49.900678] [SCALING] Scaling started.
[0m[2025-01-21T21:05:49.900741] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T21:05:49.913613] [SCALING] Scaling finished.
[0m[2025-01-21T21:05:49.913659] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:05:49.932035] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:05:49.949953] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T21:05:50.026529] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 0 replica.
[0m[2025-01-21T21:06:00.052551] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T21:06:00.067065] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T21:06:00.080356] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T21:06:00.095030] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T21:06:00.109658] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T21:06:00.142300] [POD_MGR] Pod flink-jobmanager-7d7c784b74-7ftjl deleted
[0m[2025-01-21T21:06:01.990733] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:06:03.924449] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:06:03.924513] Reloading playbook: application/kafka
[0m[2025-01-21T21:06:09.908831] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T21:07:15.844763] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T21:07:15.844902] [EXPERIMENT] Run 4 completed. Start: 1737493294, End: 1737493635
[0m[2025-01-21T21:07:15.844908] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T21:07:25.846198] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-21T21:07:27.701446] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:07:29.558611] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:07:29.558668] [SCALING] Setting up experiment.


[0m[2025-01-21T21:07:29.558676] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:07:29.567028] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:07:29.584426] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T21:07:29.604692] [SCALING] Statefulset name to scale : flink-1000m-32768
[0m[2025-01-21T21:07:29.614640] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 1 replica.
[0m[2025-01-21T21:07:34.628407] [FLK_MGR] Running job.
[0m[2025-01-21T21:07:34.628438] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T21:07:35.016590] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-lfxw8
[0m[2025-01-21T21:07:39.070847] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID d9222743cb040309e5c79801a8997848

[0m[2025-01-21T21:07:39.070898] [FLK_MGR] Running job id: d9222743cb040309e5c79801a8997848
[0m[2025-01-21T21:07:39.070908] [FLK_MGR] Getting job info.
[0m[2025-01-21T21:07:39.087239] [FLK_MGR] Job plan response: {"plan":{"jid":"d9222743cb040309e5c79801a8997848","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T21:07:39.087406] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T21:07:39.506169] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-lfxw8
[0m[2025-01-21T21:07:40.949427] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 21:07:38 : d9222743cb040309e5c79801a8997848 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T21:07:40.949481] [FLK_MGR] Running jobs: ['d9222743cb040309e5c79801a8997848']
[0m[2025-01-21T21:07:40.949488] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T21:07:40.949494] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T21:11:40.972574] [SCALING] Scaling started.
[0m[2025-01-21T21:11:40.972668] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T21:11:40.986913] [SCALING] Scaling finished.
[0m[2025-01-21T21:11:40.986935] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:11:41.008280] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:11:41.027315] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T21:11:41.049997] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 0 replica.
[0m[2025-01-21T21:11:46.070963] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T21:11:46.085298] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T21:11:46.099739] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T21:11:46.115289] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T21:11:46.129808] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T21:11:46.161706] [POD_MGR] Pod flink-jobmanager-7d7c784b74-lfxw8 deleted
[0m[2025-01-21T21:11:48.028157] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:11:49.964540] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:11:49.964601] Reloading playbook: application/kafka
[0m[2025-01-21T21:11:55.991588] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T21:12:41.995561] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T21:12:41.995694] [EXPERIMENT] Run 5 completed. Start: 1737493645, End: 1737493961
[0m[2025-01-21T21:12:41.995701] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T21:12:54.118376] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-21T21:12:54.118432] [RESOURCE_E] Running experiment with 2000m cores and 1024 memory.
[0m[2025-01-21T21:13:01.355791] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T21:13:01.355848] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T21:13:03.221196] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:13:05.082540] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:13:05.082595] [SCALING] Setting up experiment.


[0m[2025-01-21T21:13:05.082603] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:13:05.088845] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:13:05.104567] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T21:13:05.121043] [SCALING] Statefulset name to scale : flink-2000m-1024
[0m[2025-01-21T21:13:05.132002] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 1 replica.
[0m[2025-01-21T21:13:10.143173] [FLK_MGR] Running job.
[0m[2025-01-21T21:13:10.143200] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T21:13:10.573196] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-hrpj8
[0m[2025-01-21T21:13:14.665543] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID e0d3272e24b44a4a3f63d5073700cd52

[0m[2025-01-21T21:13:14.665598] [FLK_MGR] Running job id: e0d3272e24b44a4a3f63d5073700cd52
[0m[2025-01-21T21:13:14.665608] [FLK_MGR] Getting job info.
[0m[2025-01-21T21:13:14.684591] [FLK_MGR] Job plan response: {"plan":{"jid":"e0d3272e24b44a4a3f63d5073700cd52","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T21:13:14.684734] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T21:13:15.125940] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-hrpj8
[0m[2025-01-21T21:13:16.549680] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 21:13:13 : e0d3272e24b44a4a3f63d5073700cd52 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T21:13:16.549733] [FLK_MGR] Running jobs: ['e0d3272e24b44a4a3f63d5073700cd52']
[0m[2025-01-21T21:13:16.549740] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T21:13:16.549747] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T21:17:16.573087] [SCALING] Scaling started.
[0m[2025-01-21T21:17:16.573137] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T21:17:16.585864] [SCALING] Scaling finished.
[0m[2025-01-21T21:17:16.585884] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:17:16.602248] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:17:16.619239] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T21:17:16.638811] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 0 replica.
[0m[2025-01-21T21:17:16.653701] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T21:17:16.668775] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T21:17:16.681700] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T21:17:16.694519] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T21:17:16.707419] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T21:17:16.741319] [POD_MGR] Pod flink-jobmanager-7d7c784b74-hrpj8 deleted
[0m[2025-01-21T21:17:18.622115] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:17:20.488152] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:17:20.488217] Reloading playbook: application/kafka
[0m[2025-01-21T21:17:26.431190] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T21:18:12.404823] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T21:18:12.404959] [EXPERIMENT] Run 1 completed. Start: 1737493981, End: 1737494292
[0m[2025-01-21T21:18:12.404964] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T21:18:22.405921] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-21T21:18:24.300451] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:18:26.160383] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:18:26.160441] [SCALING] Setting up experiment.


[0m[2025-01-21T21:18:26.160450] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:18:26.166249] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:18:26.182137] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T21:18:26.199168] [SCALING] Statefulset name to scale : flink-2000m-1024
[0m[2025-01-21T21:18:26.210619] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 1 replica.
[0m[2025-01-21T21:18:31.220865] [FLK_MGR] Running job.
[0m[2025-01-21T21:18:31.220896] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T21:18:31.659144] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jrqvq
[0m[2025-01-21T21:18:35.868280] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0b5ba2763f623ec4da0c9f051ea90ecb

[0m[2025-01-21T21:18:35.868333] [FLK_MGR] Running job id: 0b5ba2763f623ec4da0c9f051ea90ecb
[0m[2025-01-21T21:18:35.868340] [FLK_MGR] Getting job info.
[0m[2025-01-21T21:18:35.885417] [FLK_MGR] Job plan response: {"plan":{"jid":"0b5ba2763f623ec4da0c9f051ea90ecb","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T21:18:35.885546] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T21:18:36.309281] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jrqvq
[0m[2025-01-21T21:18:37.755423] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 21:18:34 : 0b5ba2763f623ec4da0c9f051ea90ecb : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T21:18:37.755481] [FLK_MGR] Running jobs: ['0b5ba2763f623ec4da0c9f051ea90ecb']
[0m[2025-01-21T21:18:37.755488] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T21:18:37.755494] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T21:22:37.778806] [SCALING] Scaling started.
[0m[2025-01-21T21:22:37.778860] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T21:22:37.790539] [SCALING] Scaling finished.
[0m[2025-01-21T21:22:37.790557] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:22:37.808175] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:22:37.827163] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T21:22:37.848015] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 0 replica.
[0m[2025-01-21T21:22:37.866243] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T21:22:37.880367] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T21:22:37.893944] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T21:22:37.908094] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T21:22:37.922182] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T21:22:37.957680] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jrqvq deleted
[0m[2025-01-21T21:22:39.887853] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:22:41.790974] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:22:41.791033] Reloading playbook: application/kafka
[0m[2025-01-21T21:22:47.753561] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T21:23:33.763965] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T21:23:33.764099] [EXPERIMENT] Run 2 completed. Start: 1737494302, End: 1737494613
[0m[2025-01-21T21:23:33.764105] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T21:23:43.765073] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-21T21:23:45.664275] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:23:47.540287] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:23:47.540345] [SCALING] Setting up experiment.


[0m[2025-01-21T21:23:47.540353] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:23:47.545667] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:23:47.562486] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T21:23:47.578141] [SCALING] Statefulset name to scale : flink-2000m-1024
[0m[2025-01-21T21:23:47.587676] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 1 replica.
[0m[2025-01-21T21:23:52.596578] [FLK_MGR] Running job.
[0m[2025-01-21T21:23:52.596608] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T21:23:53.041082] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-9vrbw
[0m[2025-01-21T21:23:57.093235] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0aef85cd429b4a16af274801bb09b9bd

[0m[2025-01-21T21:23:57.093301] [FLK_MGR] Running job id: 0aef85cd429b4a16af274801bb09b9bd
[0m[2025-01-21T21:23:57.093310] [FLK_MGR] Getting job info.
[0m[2025-01-21T21:23:57.112093] [FLK_MGR] Job plan response: {"plan":{"jid":"0aef85cd429b4a16af274801bb09b9bd","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T21:23:57.112240] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T21:23:57.486225] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-9vrbw
[0m[2025-01-21T21:23:58.948975] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 21:23:56 : 0aef85cd429b4a16af274801bb09b9bd : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T21:23:58.949030] [FLK_MGR] Running jobs: ['0aef85cd429b4a16af274801bb09b9bd']
[0m[2025-01-21T21:23:58.949037] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T21:23:58.949044] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T21:27:58.971564] [SCALING] Scaling started.
[0m[2025-01-21T21:27:58.971615] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T21:27:58.985115] [SCALING] Scaling finished.
[0m[2025-01-21T21:27:58.985135] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:27:59.004557] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:27:59.021987] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T21:27:59.044458] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 0 replica.
[0m[2025-01-21T21:28:04.066714] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T21:28:04.081888] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T21:28:04.097653] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T21:28:04.114318] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T21:28:04.127379] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T21:28:04.163348] [POD_MGR] Pod flink-jobmanager-7d7c784b74-9vrbw deleted
[0m[2025-01-21T21:28:06.061913] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:28:07.976003] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:28:07.976068] Reloading playbook: application/kafka
[0m[2025-01-21T21:28:13.946341] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T21:28:59.967026] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T21:28:59.967170] [EXPERIMENT] Run 3 completed. Start: 1737494623, End: 1737494939
[0m[2025-01-21T21:28:59.967177] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T21:29:09.968191] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-21T21:29:11.850487] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:29:13.713904] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:29:13.713968] [SCALING] Setting up experiment.


[0m[2025-01-21T21:29:13.713975] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:29:13.719525] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:29:13.735912] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T21:29:13.753489] [SCALING] Statefulset name to scale : flink-2000m-1024
[0m[2025-01-21T21:29:13.764640] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 1 replica.
[0m[2025-01-21T21:29:18.776697] [FLK_MGR] Running job.
[0m[2025-01-21T21:29:18.776726] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T21:29:19.191800] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-hfzvc
[0m[2025-01-21T21:29:23.347825] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c562f0f9502e777bdb9d281744550b9b

[0m[2025-01-21T21:29:23.347884] [FLK_MGR] Running job id: c562f0f9502e777bdb9d281744550b9b
[0m[2025-01-21T21:29:23.347894] [FLK_MGR] Getting job info.
[0m[2025-01-21T21:29:23.366054] [FLK_MGR] Job plan response: {"plan":{"jid":"c562f0f9502e777bdb9d281744550b9b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T21:29:23.366201] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T21:29:23.790419] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-hfzvc
[0m[2025-01-21T21:29:25.228848] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 21:29:22 : c562f0f9502e777bdb9d281744550b9b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T21:29:25.228905] [FLK_MGR] Running jobs: ['c562f0f9502e777bdb9d281744550b9b']
[0m[2025-01-21T21:29:25.228911] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T21:29:25.228916] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T21:33:25.252628] [SCALING] Scaling started.
[0m[2025-01-21T21:33:25.252685] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T21:33:25.265084] [SCALING] Scaling finished.
[0m[2025-01-21T21:33:25.265105] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:33:25.282984] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:33:25.303128] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T21:33:25.325446] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 0 replica.
[0m[2025-01-21T21:33:25.342427] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T21:33:25.355788] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T21:33:25.368552] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T21:33:25.382084] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T21:33:25.394763] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T21:33:25.417854] [POD_MGR] Pod flink-jobmanager-7d7c784b74-hfzvc deleted
[0m[2025-01-21T21:33:27.306473] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:33:29.196946] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:33:29.197013] Reloading playbook: application/kafka
[0m[2025-01-21T21:33:35.163518] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T21:34:21.155540] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T21:34:21.155769] [EXPERIMENT] Run 4 completed. Start: 1737494949, End: 1737495261
[0m[2025-01-21T21:34:21.155776] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T21:34:31.156877] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-21T21:34:33.069399] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:34:34.953966] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:34:34.954028] [SCALING] Setting up experiment.


[0m[2025-01-21T21:34:34.954036] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:34:34.959756] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:34:34.976047] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T21:34:34.992620] [SCALING] Statefulset name to scale : flink-2000m-1024
[0m[2025-01-21T21:34:35.003144] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 1 replica.
[0m[2025-01-21T21:34:40.013998] [FLK_MGR] Running job.
[0m[2025-01-21T21:34:40.014028] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T21:34:40.461905] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-m6s99
[0m[2025-01-21T21:34:44.630924] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c54921ac8f80a0d681bc406e4cbf4602

[0m[2025-01-21T21:34:44.630973] [FLK_MGR] Running job id: c54921ac8f80a0d681bc406e4cbf4602
[0m[2025-01-21T21:34:44.630980] [FLK_MGR] Getting job info.
[0m[2025-01-21T21:34:44.647209] [FLK_MGR] Job plan response: {"plan":{"jid":"c54921ac8f80a0d681bc406e4cbf4602","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T21:34:44.647341] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T21:34:45.073302] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-m6s99
[0m[2025-01-21T21:34:46.501299] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 21:34:43 : c54921ac8f80a0d681bc406e4cbf4602 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T21:34:46.501356] [FLK_MGR] Running jobs: ['c54921ac8f80a0d681bc406e4cbf4602']
[0m[2025-01-21T21:34:46.501363] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T21:34:46.501369] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T21:38:46.525152] [SCALING] Scaling started.
[0m[2025-01-21T21:38:46.525249] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T21:38:46.540435] [SCALING] Scaling finished.
[0m[2025-01-21T21:38:46.540458] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:38:46.559949] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:38:46.587430] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T21:38:46.614669] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 0 replica.
[0m[2025-01-21T21:38:46.629964] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T21:38:46.644992] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T21:38:46.658432] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T21:38:46.673965] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T21:38:46.688025] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T21:38:46.721822] [POD_MGR] Pod flink-jobmanager-7d7c784b74-m6s99 deleted
[0m[2025-01-21T21:38:48.622322] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:38:50.544340] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:38:50.544406] Reloading playbook: application/kafka
[0m[2025-01-21T21:38:56.528195] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T21:39:42.479618] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T21:39:42.479753] [EXPERIMENT] Run 5 completed. Start: 1737495271, End: 1737495582
[0m[2025-01-21T21:39:42.479760] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T21:39:54.619447] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-21T21:39:54.619585] [RESOURCE_E] Running experiment with 2000m cores and 2048 memory.
[0m[2025-01-21T21:40:01.851860] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T21:40:01.851921] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T21:40:03.735750] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:40:05.651798] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:40:05.651859] [SCALING] Setting up experiment.


[0m[2025-01-21T21:40:05.651866] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:40:05.659490] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:40:05.676198] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T21:40:05.693040] [SCALING] Statefulset name to scale : flink-2000m-2048
[0m[2025-01-21T21:40:05.707585] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 1 replica.
[0m[2025-01-21T21:40:10.718141] [FLK_MGR] Running job.
[0m[2025-01-21T21:40:10.718168] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T21:40:11.150806] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-wdw77
[0m[2025-01-21T21:40:15.316903] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5d79a912fc406b048cd2990d6c021eec

[0m[2025-01-21T21:40:15.316955] [FLK_MGR] Running job id: 5d79a912fc406b048cd2990d6c021eec
[0m[2025-01-21T21:40:15.316961] [FLK_MGR] Getting job info.
[0m[2025-01-21T21:40:15.335184] [FLK_MGR] Job plan response: {"plan":{"jid":"5d79a912fc406b048cd2990d6c021eec","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T21:40:15.335311] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T21:40:15.716363] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-wdw77
[0m[2025-01-21T21:40:17.137773] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 21:40:14 : 5d79a912fc406b048cd2990d6c021eec : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T21:40:17.137827] [FLK_MGR] Running jobs: ['5d79a912fc406b048cd2990d6c021eec']
[0m[2025-01-21T21:40:17.137834] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T21:40:17.137840] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T21:44:17.160394] [SCALING] Scaling started.
[0m[2025-01-21T21:44:17.160445] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T21:44:17.171887] [SCALING] Scaling finished.
[0m[2025-01-21T21:44:17.171909] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:44:17.189633] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:44:17.206083] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T21:44:17.227547] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 0 replica.
[0m[2025-01-21T21:44:22.248601] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T21:44:22.263089] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T21:44:22.277098] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T21:44:22.292415] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T21:44:22.306242] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T21:44:22.341305] [POD_MGR] Pod flink-jobmanager-7d7c784b74-wdw77 deleted
[0m[2025-01-21T21:44:24.244492] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:44:26.131357] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:44:26.131432] Reloading playbook: application/kafka
[0m[2025-01-21T21:44:32.131016] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T21:45:18.090984] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T21:45:18.091062] [EXPERIMENT] Run 1 completed. Start: 1737495601, End: 1737495918
[0m[2025-01-21T21:45:18.091067] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T21:45:28.092177] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-21T21:45:29.955836] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:45:31.823358] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:45:31.823426] [SCALING] Setting up experiment.


[0m[2025-01-21T21:45:31.823435] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:45:31.830483] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:45:31.847194] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T21:45:31.869067] [SCALING] Statefulset name to scale : flink-2000m-2048
[0m[2025-01-21T21:45:31.878874] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 1 replica.
[0m[2025-01-21T21:45:36.889514] [FLK_MGR] Running job.
[0m[2025-01-21T21:45:36.889542] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T21:45:37.274332] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-t72wm
[0m[2025-01-21T21:45:41.405630] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 07db794b0e947292979a13ccbd721ffa

[0m[2025-01-21T21:45:41.405686] [FLK_MGR] Running job id: 07db794b0e947292979a13ccbd721ffa
[0m[2025-01-21T21:45:41.405696] [FLK_MGR] Getting job info.
[0m[2025-01-21T21:45:41.423249] [FLK_MGR] Job plan response: {"plan":{"jid":"07db794b0e947292979a13ccbd721ffa","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T21:45:41.423392] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T21:45:41.852677] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-t72wm
[0m[2025-01-21T21:45:43.296098] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 21:45:40 : 07db794b0e947292979a13ccbd721ffa : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T21:45:43.296159] [FLK_MGR] Running jobs: ['07db794b0e947292979a13ccbd721ffa']
[0m[2025-01-21T21:45:43.296165] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T21:45:43.296172] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T21:49:43.320171] [SCALING] Scaling started.
[0m[2025-01-21T21:49:43.320274] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T21:49:43.333102] [SCALING] Scaling finished.
[0m[2025-01-21T21:49:43.333122] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:49:43.350442] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:49:43.367984] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T21:49:43.389342] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 0 replica.
[0m[2025-01-21T21:49:48.410051] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T21:49:48.422745] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T21:49:48.435487] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T21:49:48.448068] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T21:49:48.460848] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T21:49:48.486815] [POD_MGR] Pod flink-jobmanager-7d7c784b74-t72wm deleted
[0m[2025-01-21T21:49:50.374112] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:49:52.252293] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:49:52.252356] Reloading playbook: application/kafka
[0m[2025-01-21T21:49:58.293743] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T21:50:44.269224] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T21:50:44.269365] [EXPERIMENT] Run 2 completed. Start: 1737495928, End: 1737496244
[0m[2025-01-21T21:50:44.269373] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T21:50:54.270376] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-21T21:50:56.161487] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:50:58.034836] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:50:58.034891] [SCALING] Setting up experiment.


[0m[2025-01-21T21:50:58.034900] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:50:58.040471] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:50:58.057352] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T21:50:58.073669] [SCALING] Statefulset name to scale : flink-2000m-2048
[0m[2025-01-21T21:50:58.083325] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 1 replica.
[0m[2025-01-21T21:51:03.092353] [FLK_MGR] Running job.
[0m[2025-01-21T21:51:03.092383] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T21:51:03.527967] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-sb6zz
[0m[2025-01-21T21:51:07.748974] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 3c861a2634db1cceb8d5e78bf1a13753

[0m[2025-01-21T21:51:07.749020] [FLK_MGR] Running job id: 3c861a2634db1cceb8d5e78bf1a13753
[0m[2025-01-21T21:51:07.749028] [FLK_MGR] Getting job info.
[0m[2025-01-21T21:51:07.766613] [FLK_MGR] Job plan response: {"plan":{"jid":"3c861a2634db1cceb8d5e78bf1a13753","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T21:51:07.766749] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T21:51:08.198284] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sb6zz
[0m[2025-01-21T21:51:09.622736] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 21:51:06 : 3c861a2634db1cceb8d5e78bf1a13753 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T21:51:09.622791] [FLK_MGR] Running jobs: ['3c861a2634db1cceb8d5e78bf1a13753']
[0m[2025-01-21T21:51:09.622798] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T21:51:09.622805] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T21:55:09.646808] [SCALING] Scaling started.
[0m[2025-01-21T21:55:09.646903] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T21:55:09.661112] [SCALING] Scaling finished.
[0m[2025-01-21T21:55:09.661135] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:55:09.678971] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:55:09.697880] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T21:55:09.719143] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 0 replica.
[0m[2025-01-21T21:55:19.746344] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T21:55:19.761225] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T21:55:19.775078] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T21:55:19.790177] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T21:55:19.804263] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T21:55:19.839831] [POD_MGR] Pod flink-jobmanager-7d7c784b74-sb6zz deleted
[0m[2025-01-21T21:55:21.748230] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:55:23.637010] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T21:55:23.637072] Reloading playbook: application/kafka
[0m[2025-01-21T21:55:29.629542] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T21:56:15.557842] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T21:56:15.558049] [EXPERIMENT] Run 3 completed. Start: 1737496254, End: 1737496575
[0m[2025-01-21T21:56:15.558057] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T21:56:25.559149] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-21T21:56:27.445849] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:56:29.317801] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T21:56:29.317864] [SCALING] Setting up experiment.


[0m[2025-01-21T21:56:29.317875] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T21:56:29.323591] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T21:56:29.338419] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T21:56:29.355726] [SCALING] Statefulset name to scale : flink-2000m-2048
[0m[2025-01-21T21:56:29.375318] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 1 replica.
[0m[2025-01-21T21:56:34.385588] [FLK_MGR] Running job.
[0m[2025-01-21T21:56:34.385615] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T21:56:34.826763] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-t6dhb
[0m[2025-01-21T21:56:38.947272] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 062aef947a3243b33b48c6221c8c1863

[0m[2025-01-21T21:56:38.947326] [FLK_MGR] Running job id: 062aef947a3243b33b48c6221c8c1863
[0m[2025-01-21T21:56:38.947333] [FLK_MGR] Getting job info.
[0m[2025-01-21T21:56:38.965908] [FLK_MGR] Job plan response: {"plan":{"jid":"062aef947a3243b33b48c6221c8c1863","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T21:56:38.966053] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T21:56:39.336937] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-t6dhb
[0m[2025-01-21T21:56:40.775695] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 21:56:37 : 062aef947a3243b33b48c6221c8c1863 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T21:56:40.775752] [FLK_MGR] Running jobs: ['062aef947a3243b33b48c6221c8c1863']
[0m[2025-01-21T21:56:40.775760] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T21:56:40.775766] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T22:00:40.799234] [SCALING] Scaling started.
[0m[2025-01-21T22:00:40.799331] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T22:00:40.812226] [SCALING] Scaling finished.
[0m[2025-01-21T22:00:40.812248] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:00:40.831839] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:00:40.850968] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T22:00:40.908824] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 0 replica.
[0m[2025-01-21T22:00:45.931208] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T22:00:45.945152] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T22:00:45.958558] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T22:00:45.971607] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T22:00:45.984734] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T22:00:46.022971] [POD_MGR] Pod flink-jobmanager-7d7c784b74-t6dhb deleted
[0m[2025-01-21T22:00:47.901981] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:00:49.819823] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:00:49.819892] Reloading playbook: application/kafka
[0m[2025-01-21T22:00:55.820988] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T22:01:41.821807] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T22:01:41.821985] [EXPERIMENT] Run 4 completed. Start: 1737496585, End: 1737496901
[0m[2025-01-21T22:01:41.821991] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T22:01:51.823094] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-21T22:01:53.703497] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:01:55.579495] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:01:55.579549] [SCALING] Setting up experiment.


[0m[2025-01-21T22:01:55.579561] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:01:55.586843] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:01:55.603028] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T22:01:55.627143] [SCALING] Statefulset name to scale : flink-2000m-2048
[0m[2025-01-21T22:01:55.637625] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 1 replica.
[0m[2025-01-21T22:02:00.648175] [FLK_MGR] Running job.
[0m[2025-01-21T22:02:00.648203] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T22:02:01.016661] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-zlw64
[0m[2025-01-21T22:02:05.153320] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 339b6f88d04c274441a3dad1045f851b

[0m[2025-01-21T22:02:05.153378] [FLK_MGR] Running job id: 339b6f88d04c274441a3dad1045f851b
[0m[2025-01-21T22:02:05.153386] [FLK_MGR] Getting job info.
[0m[2025-01-21T22:02:05.171935] [FLK_MGR] Job plan response: {"plan":{"jid":"339b6f88d04c274441a3dad1045f851b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T22:02:05.172079] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T22:02:05.606078] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-zlw64
[0m[2025-01-21T22:02:07.039492] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 22:02:04 : 339b6f88d04c274441a3dad1045f851b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T22:02:07.039553] [FLK_MGR] Running jobs: ['339b6f88d04c274441a3dad1045f851b']
[0m[2025-01-21T22:02:07.039560] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T22:02:07.039566] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T22:06:07.064483] [SCALING] Scaling started.
[0m[2025-01-21T22:06:07.064541] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T22:06:07.077675] [SCALING] Scaling finished.
[0m[2025-01-21T22:06:07.077700] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:06:07.096468] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:06:07.113975] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T22:06:07.137145] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 0 replica.
[0m[2025-01-21T22:06:12.158564] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T22:06:12.171845] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T22:06:12.184835] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T22:06:12.197339] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T22:06:12.209979] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T22:06:12.239307] [POD_MGR] Pod flink-jobmanager-7d7c784b74-zlw64 deleted
[0m[2025-01-21T22:06:14.119895] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:06:15.974573] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:06:15.974632] Reloading playbook: application/kafka
[0m[2025-01-21T22:06:21.898241] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T22:07:07.882504] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T22:07:07.882705] [EXPERIMENT] Run 5 completed. Start: 1737496911, End: 1737497227
[0m[2025-01-21T22:07:07.882712] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T22:07:20.120473] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-21T22:07:20.120525] [RESOURCE_E] Running experiment with 2000m cores and 4096 memory.
[0m[2025-01-21T22:07:27.365371] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T22:07:27.365435] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T22:07:29.227946] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:07:31.087321] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:07:31.087380] [SCALING] Setting up experiment.


[0m[2025-01-21T22:07:31.087390] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:07:31.093097] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:07:31.122123] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T22:07:31.142484] [SCALING] Statefulset name to scale : flink-2000m-4096
[0m[2025-01-21T22:07:31.152994] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 1 replica.
[0m[2025-01-21T22:07:36.162614] [FLK_MGR] Running job.
[0m[2025-01-21T22:07:36.162653] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T22:07:36.599560] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-d565m
[0m[2025-01-21T22:07:40.736992] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 7b43e9ccc1ede0cda1a69e1159076aea

[0m[2025-01-21T22:07:40.737043] [FLK_MGR] Running job id: 7b43e9ccc1ede0cda1a69e1159076aea
[0m[2025-01-21T22:07:40.737050] [FLK_MGR] Getting job info.
[0m[2025-01-21T22:07:40.755829] [FLK_MGR] Job plan response: {"plan":{"jid":"7b43e9ccc1ede0cda1a69e1159076aea","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T22:07:40.755981] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T22:07:41.184195] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-d565m
[0m[2025-01-21T22:07:42.621266] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 22:07:39 : 7b43e9ccc1ede0cda1a69e1159076aea : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T22:07:42.621323] [FLK_MGR] Running jobs: ['7b43e9ccc1ede0cda1a69e1159076aea']
[0m[2025-01-21T22:07:42.621330] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T22:07:42.621335] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T22:11:42.645732] [SCALING] Scaling started.
[0m[2025-01-21T22:11:42.645831] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T22:11:42.662681] [SCALING] Scaling finished.
[0m[2025-01-21T22:11:42.662723] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:11:42.684014] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:11:42.701006] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T22:11:42.721648] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 0 replica.
[0m[2025-01-21T22:11:47.743538] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T22:11:47.759161] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T22:11:47.774362] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T22:11:47.788261] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T22:11:47.801121] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T22:11:47.832856] [POD_MGR] Pod flink-jobmanager-7d7c784b74-d565m deleted
[0m[2025-01-21T22:11:49.743340] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:11:51.674902] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:11:51.674971] Reloading playbook: application/kafka
[0m[2025-01-21T22:11:57.636623] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T22:12:43.625691] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T22:12:43.626169] [EXPERIMENT] Run 1 completed. Start: 1737497247, End: 1737497563
[0m[2025-01-21T22:12:43.626193] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T22:12:53.627318] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-21T22:12:55.520656] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:12:57.372333] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:12:57.372390] [SCALING] Setting up experiment.


[0m[2025-01-21T22:12:57.372398] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:12:57.379350] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:12:57.395119] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T22:12:57.412054] [SCALING] Statefulset name to scale : flink-2000m-4096
[0m[2025-01-21T22:12:57.430633] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 1 replica.
[0m[2025-01-21T22:13:02.442831] [FLK_MGR] Running job.
[0m[2025-01-21T22:13:02.442859] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T22:13:02.890402] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-w6p7r
[0m[2025-01-21T22:13:07.052700] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID d4c8b5e37a074009f708804ac7f393da

[0m[2025-01-21T22:13:07.052750] [FLK_MGR] Running job id: d4c8b5e37a074009f708804ac7f393da
[0m[2025-01-21T22:13:07.052758] [FLK_MGR] Getting job info.
[0m[2025-01-21T22:13:07.069526] [FLK_MGR] Job plan response: {"plan":{"jid":"d4c8b5e37a074009f708804ac7f393da","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T22:13:07.069680] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T22:13:07.526789] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-w6p7r
[0m[2025-01-21T22:13:08.961779] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 22:13:06 : d4c8b5e37a074009f708804ac7f393da : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T22:13:08.961833] [FLK_MGR] Running jobs: ['d4c8b5e37a074009f708804ac7f393da']
[0m[2025-01-21T22:13:08.961840] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T22:13:08.961846] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T22:17:08.986529] [SCALING] Scaling started.
[0m[2025-01-21T22:17:08.986587] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T22:17:08.999988] [SCALING] Scaling finished.
[0m[2025-01-21T22:17:09.000005] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:17:09.017992] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:17:09.033797] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T22:17:09.055039] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 0 replica.
[0m[2025-01-21T22:17:19.080291] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T22:17:19.093041] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T22:17:19.105728] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T22:17:19.118638] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T22:17:19.131409] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T22:17:19.163606] [POD_MGR] Pod flink-jobmanager-7d7c784b74-w6p7r deleted
[0m[2025-01-21T22:17:21.062260] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:17:22.947110] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:17:22.947180] Reloading playbook: application/kafka
[0m[2025-01-21T22:17:28.906116] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T22:18:14.899548] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T22:18:14.899691] [EXPERIMENT] Run 2 completed. Start: 1737497573, End: 1737497894
[0m[2025-01-21T22:18:14.899698] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T22:18:24.900640] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-21T22:18:26.781603] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:18:28.656478] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:18:28.656538] [SCALING] Setting up experiment.


[0m[2025-01-21T22:18:28.656547] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:18:28.661970] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:18:28.679023] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T22:18:28.696742] [SCALING] Statefulset name to scale : flink-2000m-4096
[0m[2025-01-21T22:18:28.706721] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 1 replica.
[0m[2025-01-21T22:18:33.716464] [FLK_MGR] Running job.
[0m[2025-01-21T22:18:33.716493] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T22:18:34.100351] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-28wxl
[0m[2025-01-21T22:18:38.225614] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8c1ac6657e79214bf7e918e9b4a7c9d4

[0m[2025-01-21T22:18:38.225664] [FLK_MGR] Running job id: 8c1ac6657e79214bf7e918e9b4a7c9d4
[0m[2025-01-21T22:18:38.225672] [FLK_MGR] Getting job info.
[0m[2025-01-21T22:18:38.243103] [FLK_MGR] Job plan response: {"plan":{"jid":"8c1ac6657e79214bf7e918e9b4a7c9d4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T22:18:38.243249] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T22:18:38.675731] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-28wxl
[0m[2025-01-21T22:18:40.125985] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 22:18:37 : 8c1ac6657e79214bf7e918e9b4a7c9d4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T22:18:40.126044] [FLK_MGR] Running jobs: ['8c1ac6657e79214bf7e918e9b4a7c9d4']
[0m[2025-01-21T22:18:40.126052] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T22:18:40.126061] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T22:22:40.151395] [SCALING] Scaling started.
[0m[2025-01-21T22:22:40.151503] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T22:22:40.164192] [SCALING] Scaling finished.
[0m[2025-01-21T22:22:40.164213] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:22:40.184210] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:22:40.201369] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T22:22:40.223033] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 0 replica.
[0m[2025-01-21T22:22:45.244408] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T22:22:45.259026] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T22:22:45.274907] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T22:22:45.288842] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T22:22:45.303728] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T22:22:45.324663] [POD_MGR] Pod flink-jobmanager-7d7c784b74-28wxl deleted
[0m[2025-01-21T22:22:47.168098] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:22:49.063223] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:22:49.063288] Reloading playbook: application/kafka
[0m[2025-01-21T22:22:54.985139] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T22:23:40.918148] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T22:23:40.918276] [EXPERIMENT] Run 3 completed. Start: 1737497904, End: 1737498220
[0m[2025-01-21T22:23:40.918285] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T22:23:50.919314] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-21T22:23:52.807701] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:23:54.677218] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:23:54.677289] [SCALING] Setting up experiment.


[0m[2025-01-21T22:23:54.677298] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:23:54.683937] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:23:54.701363] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T22:23:54.722551] [SCALING] Statefulset name to scale : flink-2000m-4096
[0m[2025-01-21T22:23:54.733243] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 1 replica.
[0m[2025-01-21T22:23:59.743719] [FLK_MGR] Running job.
[0m[2025-01-21T22:23:59.743754] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T22:24:00.172239] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-6d4pq
[0m[2025-01-21T22:24:04.323992] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID e04754eb717479f0827bed2f028bc27e

[0m[2025-01-21T22:24:04.324042] [FLK_MGR] Running job id: e04754eb717479f0827bed2f028bc27e
[0m[2025-01-21T22:24:04.324050] [FLK_MGR] Getting job info.
[0m[2025-01-21T22:24:04.341621] [FLK_MGR] Job plan response: {"plan":{"jid":"e04754eb717479f0827bed2f028bc27e","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T22:24:04.341774] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T22:24:04.772189] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-6d4pq
[0m[2025-01-21T22:24:06.226069] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 22:24:03 : e04754eb717479f0827bed2f028bc27e : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T22:24:06.226131] [FLK_MGR] Running jobs: ['e04754eb717479f0827bed2f028bc27e']
[0m[2025-01-21T22:24:06.226138] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T22:24:06.226149] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T22:28:06.250899] [SCALING] Scaling started.
[0m[2025-01-21T22:28:06.251002] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T22:28:06.263084] [SCALING] Scaling finished.
[0m[2025-01-21T22:28:06.263107] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:28:06.281957] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:28:06.298770] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T22:28:06.321449] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 0 replica.
[0m[2025-01-21T22:28:11.343300] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T22:28:11.356519] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T22:28:11.370005] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T22:28:11.384215] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T22:28:11.398317] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T22:28:11.431305] [POD_MGR] Pod flink-jobmanager-7d7c784b74-6d4pq deleted
[0m[2025-01-21T22:28:13.295315] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:28:15.206884] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:28:15.206946] Reloading playbook: application/kafka
[0m[2025-01-21T22:28:21.195775] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T22:29:07.184139] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T22:29:07.184300] [EXPERIMENT] Run 4 completed. Start: 1737498230, End: 1737498547
[0m[2025-01-21T22:29:07.184307] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T22:29:17.185362] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-21T22:29:19.064220] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:29:20.939516] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:29:20.939573] [SCALING] Setting up experiment.


[0m[2025-01-21T22:29:20.939580] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:29:20.944898] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:29:20.959745] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T22:29:20.977125] [SCALING] Statefulset name to scale : flink-2000m-4096
[0m[2025-01-21T22:29:20.989411] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 1 replica.
[0m[2025-01-21T22:29:25.999862] [FLK_MGR] Running job.
[0m[2025-01-21T22:29:25.999908] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T22:29:26.428730] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-qwwfn
[0m[2025-01-21T22:29:30.537678] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fd2c41fd06e14787327da87abe07c8fe

[0m[2025-01-21T22:29:30.537726] [FLK_MGR] Running job id: fd2c41fd06e14787327da87abe07c8fe
[0m[2025-01-21T22:29:30.537734] [FLK_MGR] Getting job info.
[0m[2025-01-21T22:29:30.555250] [FLK_MGR] Job plan response: {"plan":{"jid":"fd2c41fd06e14787327da87abe07c8fe","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T22:29:30.555408] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T22:29:30.998046] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-qwwfn
[0m[2025-01-21T22:29:32.457022] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 22:29:29 : fd2c41fd06e14787327da87abe07c8fe : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T22:29:32.457081] [FLK_MGR] Running jobs: ['fd2c41fd06e14787327da87abe07c8fe']
[0m[2025-01-21T22:29:32.457088] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T22:29:32.457094] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T22:33:32.480965] [SCALING] Scaling started.
[0m[2025-01-21T22:33:32.481017] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T22:33:32.496211] [SCALING] Scaling finished.
[0m[2025-01-21T22:33:32.496228] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:33:32.514580] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:33:32.532062] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T22:33:32.553409] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 0 replica.
[0m[2025-01-21T22:33:37.576858] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T22:33:37.591203] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T22:33:37.606323] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T22:33:37.619917] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T22:33:37.633040] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T22:33:37.653943] [POD_MGR] Pod flink-jobmanager-7d7c784b74-qwwfn deleted
[0m[2025-01-21T22:33:39.529114] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:33:41.454787] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:33:41.454955] Reloading playbook: application/kafka
[0m[2025-01-21T22:33:47.401761] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T22:34:33.348031] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T22:34:33.348156] [EXPERIMENT] Run 5 completed. Start: 1737498557, End: 1737498873
[0m[2025-01-21T22:34:33.348162] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T22:34:45.591857] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-21T22:34:45.591913] [RESOURCE_E] Running experiment with 2000m cores and 8192 memory.
[0m[2025-01-21T22:34:52.831796] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T22:34:52.831859] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T22:34:54.670259] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:34:56.530100] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:34:56.530157] [SCALING] Setting up experiment.


[0m[2025-01-21T22:34:56.530165] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:34:56.535661] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:34:56.551689] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T22:34:56.571654] [SCALING] Statefulset name to scale : flink-2000m-8192
[0m[2025-01-21T22:34:56.581448] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 1 replica.
[0m[2025-01-21T22:35:01.591339] [FLK_MGR] Running job.
[0m[2025-01-21T22:35:01.591368] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T22:35:02.023263] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-gb6g7
[0m[2025-01-21T22:35:06.040842] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 366eda7a9fd8255788f4b54c86fa4356

[0m[2025-01-21T22:35:06.040891] [FLK_MGR] Running job id: 366eda7a9fd8255788f4b54c86fa4356
[0m[2025-01-21T22:35:06.040899] [FLK_MGR] Getting job info.
[0m[2025-01-21T22:35:06.058032] [FLK_MGR] Job plan response: {"plan":{"jid":"366eda7a9fd8255788f4b54c86fa4356","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T22:35:06.058182] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T22:35:06.440842] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-gb6g7
[0m[2025-01-21T22:35:07.879756] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 22:35:05 : 366eda7a9fd8255788f4b54c86fa4356 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T22:35:07.879818] [FLK_MGR] Running jobs: ['366eda7a9fd8255788f4b54c86fa4356']
[0m[2025-01-21T22:35:07.879825] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T22:35:07.879838] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T22:39:07.902921] [SCALING] Scaling started.
[0m[2025-01-21T22:39:07.903020] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T22:39:07.917634] [SCALING] Scaling finished.
[0m[2025-01-21T22:39:07.917672] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:39:07.937760] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:39:07.958106] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T22:39:07.979793] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 0 replica.
[0m[2025-01-21T22:39:13.000386] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T22:39:13.013634] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T22:39:13.026660] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T22:39:13.039310] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T22:39:13.051901] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T22:39:13.073834] [POD_MGR] Pod flink-jobmanager-7d7c784b74-gb6g7 deleted
[0m[2025-01-21T22:39:14.962646] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:39:16.883590] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:39:16.883657] Reloading playbook: application/kafka
[0m[2025-01-21T22:39:22.848095] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T22:40:08.767807] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T22:40:08.768077] [EXPERIMENT] Run 1 completed. Start: 1737498892, End: 1737499208
[0m[2025-01-21T22:40:08.768106] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T22:40:18.769177] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-21T22:40:20.655063] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:40:22.507735] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:40:22.507781] [SCALING] Setting up experiment.


[0m[2025-01-21T22:40:22.507789] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:40:22.512863] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:40:22.529496] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T22:40:22.555647] [SCALING] Statefulset name to scale : flink-2000m-8192
[0m[2025-01-21T22:40:22.573692] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 1 replica.
[0m[2025-01-21T22:40:27.583519] [FLK_MGR] Running job.
[0m[2025-01-21T22:40:27.583546] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T22:40:27.955907] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-ps9mx
[0m[2025-01-21T22:40:32.058064] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8bd3872d04e043e2ffb4471a66432a0b

[0m[2025-01-21T22:40:32.058119] [FLK_MGR] Running job id: 8bd3872d04e043e2ffb4471a66432a0b
[0m[2025-01-21T22:40:32.058126] [FLK_MGR] Getting job info.
[0m[2025-01-21T22:40:32.075142] [FLK_MGR] Job plan response: {"plan":{"jid":"8bd3872d04e043e2ffb4471a66432a0b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T22:40:32.075283] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T22:40:32.495484] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-ps9mx
[0m[2025-01-21T22:40:33.938584] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 22:40:31 : 8bd3872d04e043e2ffb4471a66432a0b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T22:40:33.938640] [FLK_MGR] Running jobs: ['8bd3872d04e043e2ffb4471a66432a0b']
[0m[2025-01-21T22:40:33.938647] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T22:40:33.938656] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T22:44:33.962076] [SCALING] Scaling started.
[0m[2025-01-21T22:44:33.962179] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T22:44:33.976812] [SCALING] Scaling finished.
[0m[2025-01-21T22:44:33.976843] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:44:33.995490] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:44:34.014685] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T22:44:34.034788] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 0 replica.
[0m[2025-01-21T22:44:39.054527] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T22:44:39.067591] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T22:44:39.080512] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T22:44:39.093204] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T22:44:39.106806] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T22:44:39.138753] [POD_MGR] Pod flink-jobmanager-7d7c784b74-ps9mx deleted
[0m[2025-01-21T22:44:41.037940] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:44:42.979373] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:44:42.979438] Reloading playbook: application/kafka
[0m[2025-01-21T22:44:48.918263] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T22:45:34.876501] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T22:45:34.876788] [EXPERIMENT] Run 2 completed. Start: 1737499218, End: 1737499534
[0m[2025-01-21T22:45:34.876816] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T22:45:44.877832] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-21T22:45:46.725639] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:45:48.597233] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:45:48.597414] [SCALING] Setting up experiment.


[0m[2025-01-21T22:45:48.597444] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:45:48.603538] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:45:48.619726] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T22:45:48.649339] [SCALING] Statefulset name to scale : flink-2000m-8192
[0m[2025-01-21T22:45:48.660322] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 1 replica.
[0m[2025-01-21T22:45:53.669754] [FLK_MGR] Running job.
[0m[2025-01-21T22:45:53.669784] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T22:45:54.101650] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-94znn
[0m[2025-01-21T22:45:58.244384] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c7a15e4db8ed13cd97b512bc892e4920

[0m[2025-01-21T22:45:58.244434] [FLK_MGR] Running job id: c7a15e4db8ed13cd97b512bc892e4920
[0m[2025-01-21T22:45:58.244442] [FLK_MGR] Getting job info.
[0m[2025-01-21T22:45:58.262397] [FLK_MGR] Job plan response: {"plan":{"jid":"c7a15e4db8ed13cd97b512bc892e4920","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T22:45:58.262540] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T22:45:58.697591] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-94znn
[0m[2025-01-21T22:46:00.141298] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 22:45:57 : c7a15e4db8ed13cd97b512bc892e4920 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T22:46:00.141358] [FLK_MGR] Running jobs: ['c7a15e4db8ed13cd97b512bc892e4920']
[0m[2025-01-21T22:46:00.141366] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T22:46:00.141372] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T22:50:00.166885] [SCALING] Scaling started.
[0m[2025-01-21T22:50:00.166991] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T22:50:00.181720] [SCALING] Scaling finished.
[0m[2025-01-21T22:50:00.181742] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:50:00.200060] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:50:00.218653] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T22:50:00.240822] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 0 replica.
[0m[2025-01-21T22:50:10.268940] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T22:50:10.285107] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T22:50:10.300742] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T22:50:10.314772] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T22:50:10.330620] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T22:50:10.372627] [POD_MGR] Pod flink-jobmanager-7d7c784b74-94znn deleted
[0m[2025-01-21T22:50:12.291236] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:50:14.165111] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:50:14.165179] Reloading playbook: application/kafka
[0m[2025-01-21T22:50:20.203357] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T22:51:06.187022] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T22:51:06.187152] [EXPERIMENT] Run 3 completed. Start: 1737499544, End: 1737499866
[0m[2025-01-21T22:51:06.187159] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T22:51:16.188219] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-21T22:51:18.055006] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:51:19.919567] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:51:19.919625] [SCALING] Setting up experiment.


[0m[2025-01-21T22:51:19.919633] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:51:19.925169] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:51:19.941756] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T22:51:19.959867] [SCALING] Statefulset name to scale : flink-2000m-8192
[0m[2025-01-21T22:51:19.980522] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 1 replica.
[0m[2025-01-21T22:51:24.990354] [FLK_MGR] Running job.
[0m[2025-01-21T22:51:24.990381] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T22:51:25.449659] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-2pvqr
[0m[2025-01-21T22:51:29.460113] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a058c00a8277604dc146bf255487ada5

[0m[2025-01-21T22:51:29.460168] [FLK_MGR] Running job id: a058c00a8277604dc146bf255487ada5
[0m[2025-01-21T22:51:29.460176] [FLK_MGR] Getting job info.
[0m[2025-01-21T22:51:29.476828] [FLK_MGR] Job plan response: {"plan":{"jid":"a058c00a8277604dc146bf255487ada5","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T22:51:29.476965] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T22:51:29.862154] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-2pvqr
[0m[2025-01-21T22:51:31.312410] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 22:51:28 : a058c00a8277604dc146bf255487ada5 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T22:51:31.312476] [FLK_MGR] Running jobs: ['a058c00a8277604dc146bf255487ada5']
[0m[2025-01-21T22:51:31.312483] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T22:51:31.312505] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T22:55:31.336227] [SCALING] Scaling started.
[0m[2025-01-21T22:55:31.336291] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T22:55:31.349649] [SCALING] Scaling finished.
[0m[2025-01-21T22:55:31.349687] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:55:31.369588] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:55:31.388440] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T22:55:31.411668] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 0 replica.
[0m[2025-01-21T22:55:41.510514] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T22:55:41.527332] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T22:55:41.544209] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T22:55:41.559315] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T22:55:41.574674] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T22:55:41.608356] [POD_MGR] Pod flink-jobmanager-7d7c784b74-2pvqr deleted
[0m[2025-01-21T22:55:43.493979] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:55:45.401164] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T22:55:45.401265] Reloading playbook: application/kafka
[0m[2025-01-21T22:55:51.406515] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T22:56:37.349077] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T22:56:37.349219] [EXPERIMENT] Run 4 completed. Start: 1737499876, End: 1737500197
[0m[2025-01-21T22:56:37.349226] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T22:56:47.350255] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-21T22:56:49.192119] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:56:51.100820] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T22:56:51.100875] [SCALING] Setting up experiment.


[0m[2025-01-21T22:56:51.100883] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T22:56:51.105856] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T22:56:51.121804] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T22:56:51.137926] [SCALING] Statefulset name to scale : flink-2000m-8192
[0m[2025-01-21T22:56:51.150629] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 1 replica.
[0m[2025-01-21T22:56:56.160621] [FLK_MGR] Running job.
[0m[2025-01-21T22:56:56.160652] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T22:56:56.531879] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-glkgp
[0m[2025-01-21T22:57:00.687002] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fda47eb2434feade082dae60d86df235

[0m[2025-01-21T22:57:00.687125] [FLK_MGR] Running job id: fda47eb2434feade082dae60d86df235
[0m[2025-01-21T22:57:00.687139] [FLK_MGR] Getting job info.
[0m[2025-01-21T22:57:00.706541] [FLK_MGR] Job plan response: {"plan":{"jid":"fda47eb2434feade082dae60d86df235","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T22:57:00.706713] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T22:57:01.151755] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-glkgp
[0m[2025-01-21T22:57:02.605497] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 22:56:59 : fda47eb2434feade082dae60d86df235 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T22:57:02.605562] [FLK_MGR] Running jobs: ['fda47eb2434feade082dae60d86df235']
[0m[2025-01-21T22:57:02.605571] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T22:57:02.605579] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T23:01:02.630014] [SCALING] Scaling started.
[0m[2025-01-21T23:01:02.630074] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T23:01:02.644286] [SCALING] Scaling finished.
[0m[2025-01-21T23:01:02.644305] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:01:02.663123] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:01:02.680288] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T23:01:02.700465] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 0 replica.
[0m[2025-01-21T23:01:07.720824] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T23:01:07.734578] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T23:01:07.747638] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T23:01:07.761404] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T23:01:07.775740] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T23:01:07.799232] [POD_MGR] Pod flink-jobmanager-7d7c784b74-glkgp deleted
[0m[2025-01-21T23:01:09.694352] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:01:11.596964] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:01:11.597030] Reloading playbook: application/kafka
[0m[2025-01-21T23:01:17.610780] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T23:02:03.584790] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T23:02:03.584919] [EXPERIMENT] Run 5 completed. Start: 1737500207, End: 1737500523
[0m[2025-01-21T23:02:03.584925] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T23:02:15.815317] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-21T23:02:15.815380] [RESOURCE_E] Running experiment with 2000m cores and 16384 memory.
[0m[2025-01-21T23:02:23.073725] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T23:02:23.073797] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T23:02:24.943206] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:02:26.827521] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:02:26.827578] [SCALING] Setting up experiment.


[0m[2025-01-21T23:02:26.827587] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:02:26.833451] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:02:26.849744] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T23:02:26.868018] [SCALING] Statefulset name to scale : flink-2000m-16384
[0m[2025-01-21T23:02:26.878534] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 1 replica.
[0m[2025-01-21T23:02:31.888024] [FLK_MGR] Running job.
[0m[2025-01-21T23:02:31.888050] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T23:02:32.337214] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-f69tl
[0m[2025-01-21T23:02:36.529312] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c84d1ee2790a131cbea275907cbdf7f7

[0m[2025-01-21T23:02:36.529367] [FLK_MGR] Running job id: c84d1ee2790a131cbea275907cbdf7f7
[0m[2025-01-21T23:02:36.529378] [FLK_MGR] Getting job info.
[0m[2025-01-21T23:02:36.550285] [FLK_MGR] Job plan response: {"plan":{"jid":"c84d1ee2790a131cbea275907cbdf7f7","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T23:02:36.550439] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T23:02:36.990341] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-f69tl
[0m[2025-01-21T23:02:38.436397] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 23:02:35 : c84d1ee2790a131cbea275907cbdf7f7 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T23:02:38.436458] [FLK_MGR] Running jobs: ['c84d1ee2790a131cbea275907cbdf7f7']
[0m[2025-01-21T23:02:38.436465] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T23:02:38.436472] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T23:06:38.460325] [SCALING] Scaling started.
[0m[2025-01-21T23:06:38.460425] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T23:06:38.473511] [SCALING] Scaling finished.
[0m[2025-01-21T23:06:38.473529] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:06:38.492303] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:06:38.509872] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T23:06:38.531840] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 0 replica.
[0m[2025-01-21T23:06:48.557348] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T23:06:48.570125] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T23:06:48.583767] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T23:06:48.597511] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T23:06:48.611188] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T23:06:48.635236] [POD_MGR] Pod flink-jobmanager-7d7c784b74-f69tl deleted
[0m[2025-01-21T23:06:50.578526] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:06:52.467824] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:06:52.467895] Reloading playbook: application/kafka
[0m[2025-01-21T23:06:58.448140] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T23:07:44.427540] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T23:07:44.427669] [EXPERIMENT] Run 1 completed. Start: 1737500543, End: 1737500864
[0m[2025-01-21T23:07:44.427674] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T23:07:54.428786] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-21T23:07:56.305906] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:07:58.159574] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:07:58.159636] [SCALING] Setting up experiment.


[0m[2025-01-21T23:07:58.159645] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:07:58.165571] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:07:58.181834] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T23:07:58.196801] [SCALING] Statefulset name to scale : flink-2000m-16384
[0m[2025-01-21T23:07:58.207988] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 1 replica.
[0m[2025-01-21T23:08:03.218700] [FLK_MGR] Running job.
[0m[2025-01-21T23:08:03.218725] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T23:08:03.691746] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-8pk9k
[0m[2025-01-21T23:08:07.794170] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID df9475169ef9217b162f94e3f03e6399

[0m[2025-01-21T23:08:07.794227] [FLK_MGR] Running job id: df9475169ef9217b162f94e3f03e6399
[0m[2025-01-21T23:08:07.794234] [FLK_MGR] Getting job info.
[0m[2025-01-21T23:08:07.811191] [FLK_MGR] Job plan response: {"plan":{"jid":"df9475169ef9217b162f94e3f03e6399","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T23:08:07.811330] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T23:08:08.252107] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-8pk9k
[0m[2025-01-21T23:08:09.730547] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 23:08:06 : df9475169ef9217b162f94e3f03e6399 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T23:08:09.730601] [FLK_MGR] Running jobs: ['df9475169ef9217b162f94e3f03e6399']
[0m[2025-01-21T23:08:09.730610] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T23:08:09.730617] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T23:12:09.754421] [SCALING] Scaling started.
[0m[2025-01-21T23:12:09.754471] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T23:12:09.769284] [SCALING] Scaling finished.
[0m[2025-01-21T23:12:09.769308] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:12:09.788308] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:12:09.805486] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T23:12:09.826788] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 0 replica.
[0m[2025-01-21T23:12:19.855976] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T23:12:19.869986] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T23:12:19.882991] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T23:12:19.896355] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T23:12:19.910153] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T23:12:19.936117] [POD_MGR] Pod flink-jobmanager-7d7c784b74-8pk9k deleted
[0m[2025-01-21T23:12:21.836166] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:12:23.736907] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:12:23.736970] Reloading playbook: application/kafka
[0m[2025-01-21T23:12:29.671409] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T23:13:15.643843] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T23:13:15.643983] [EXPERIMENT] Run 2 completed. Start: 1737500874, End: 1737501195
[0m[2025-01-21T23:13:15.643989] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T23:13:25.645042] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-21T23:13:27.523400] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:13:29.383159] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:13:29.383222] [SCALING] Setting up experiment.


[0m[2025-01-21T23:13:29.383231] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:13:29.388860] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:13:29.410813] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T23:13:29.431832] [SCALING] Statefulset name to scale : flink-2000m-16384
[0m[2025-01-21T23:13:29.442572] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 1 replica.
[0m[2025-01-21T23:13:34.453581] [FLK_MGR] Running job.
[0m[2025-01-21T23:13:34.453609] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T23:13:34.824140] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-65v5b
[0m[2025-01-21T23:13:38.950443] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c1a0472918ba348261595b7f0d12406f

[0m[2025-01-21T23:13:38.950495] [FLK_MGR] Running job id: c1a0472918ba348261595b7f0d12406f
[0m[2025-01-21T23:13:38.950503] [FLK_MGR] Getting job info.
[0m[2025-01-21T23:13:38.969291] [FLK_MGR] Job plan response: {"plan":{"jid":"c1a0472918ba348261595b7f0d12406f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T23:13:38.969439] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T23:13:39.394100] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-65v5b
[0m[2025-01-21T23:13:40.842381] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 23:13:37 : c1a0472918ba348261595b7f0d12406f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T23:13:40.842434] [FLK_MGR] Running jobs: ['c1a0472918ba348261595b7f0d12406f']
[0m[2025-01-21T23:13:40.842441] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T23:13:40.842448] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T23:17:40.866584] [SCALING] Scaling started.
[0m[2025-01-21T23:17:40.866633] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T23:17:40.879273] [SCALING] Scaling finished.
[0m[2025-01-21T23:17:40.879293] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:17:40.898195] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:17:40.916630] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T23:17:40.937650] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 0 replica.
[0m[2025-01-21T23:17:45.958201] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T23:17:45.973585] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T23:17:45.988558] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T23:17:46.002421] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T23:17:46.017602] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T23:17:46.056630] [POD_MGR] Pod flink-jobmanager-7d7c784b74-65v5b deleted
[0m[2025-01-21T23:17:47.954748] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:17:49.877713] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:17:49.877775] Reloading playbook: application/kafka
[0m[2025-01-21T23:17:55.847382] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T23:18:41.800199] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T23:18:41.800577] [EXPERIMENT] Run 3 completed. Start: 1737501205, End: 1737501521
[0m[2025-01-21T23:18:41.800600] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T23:18:51.801522] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-21T23:18:53.669651] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:18:55.507042] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:18:55.507100] [SCALING] Setting up experiment.


[0m[2025-01-21T23:18:55.507108] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:18:55.514470] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:18:55.529883] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T23:18:55.548159] [SCALING] Statefulset name to scale : flink-2000m-16384
[0m[2025-01-21T23:18:55.559224] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 1 replica.
[0m[2025-01-21T23:19:00.571117] [FLK_MGR] Running job.
[0m[2025-01-21T23:19:00.571147] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T23:19:01.029422] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-m7hjz
[0m[2025-01-21T23:19:05.108994] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a6e36a504a9c177913961be692a8c884

[0m[2025-01-21T23:19:05.109051] [FLK_MGR] Running job id: a6e36a504a9c177913961be692a8c884
[0m[2025-01-21T23:19:05.109058] [FLK_MGR] Getting job info.
[0m[2025-01-21T23:19:05.126059] [FLK_MGR] Job plan response: {"plan":{"jid":"a6e36a504a9c177913961be692a8c884","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T23:19:05.126202] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T23:19:05.551252] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-m7hjz
[0m[2025-01-21T23:19:07.003998] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 23:19:04 : a6e36a504a9c177913961be692a8c884 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T23:19:07.004054] [FLK_MGR] Running jobs: ['a6e36a504a9c177913961be692a8c884']
[0m[2025-01-21T23:19:07.004061] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T23:19:07.004068] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T23:23:07.026751] [SCALING] Scaling started.
[0m[2025-01-21T23:23:07.026801] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T23:23:07.039206] [SCALING] Scaling finished.
[0m[2025-01-21T23:23:07.039229] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:23:07.057769] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:23:07.075010] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T23:23:07.095795] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 0 replica.
[0m[2025-01-21T23:23:12.115151] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T23:23:12.129611] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T23:23:12.144691] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T23:23:12.158082] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T23:23:12.171684] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T23:23:12.203768] [POD_MGR] Pod flink-jobmanager-7d7c784b74-m7hjz deleted
[0m[2025-01-21T23:23:14.090245] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:23:15.959806] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:23:15.959871] Reloading playbook: application/kafka
[0m[2025-01-21T23:23:21.927688] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T23:24:07.871116] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T23:24:07.871244] [EXPERIMENT] Run 4 completed. Start: 1737501531, End: 1737501847
[0m[2025-01-21T23:24:07.871250] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T23:24:17.872187] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-21T23:24:19.724928] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:24:21.586585] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:24:21.586639] [SCALING] Setting up experiment.


[0m[2025-01-21T23:24:21.586647] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:24:21.595187] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:24:21.611772] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T23:24:21.627739] [SCALING] Statefulset name to scale : flink-2000m-16384
[0m[2025-01-21T23:24:21.636905] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 1 replica.
[0m[2025-01-21T23:24:26.646770] [FLK_MGR] Running job.
[0m[2025-01-21T23:24:26.646799] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T23:24:27.091538] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-4ksdd
[0m[2025-01-21T23:24:31.155652] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID bc730fd93cc1126b1014f6216a9def8c

[0m[2025-01-21T23:24:31.155701] [FLK_MGR] Running job id: bc730fd93cc1126b1014f6216a9def8c
[0m[2025-01-21T23:24:31.155708] [FLK_MGR] Getting job info.
[0m[2025-01-21T23:24:31.172778] [FLK_MGR] Job plan response: {"plan":{"jid":"bc730fd93cc1126b1014f6216a9def8c","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T23:24:31.172924] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T23:24:31.602475] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-4ksdd
[0m[2025-01-21T23:24:33.029475] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 23:24:30 : bc730fd93cc1126b1014f6216a9def8c : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T23:24:33.029530] [FLK_MGR] Running jobs: ['bc730fd93cc1126b1014f6216a9def8c']
[0m[2025-01-21T23:24:33.029537] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T23:24:33.029543] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T23:28:33.052202] [SCALING] Scaling started.
[0m[2025-01-21T23:28:33.052251] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T23:28:33.066551] [SCALING] Scaling finished.
[0m[2025-01-21T23:28:33.066577] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:28:33.084072] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:28:33.099996] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T23:28:33.123174] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 0 replica.
[0m[2025-01-21T23:28:38.144801] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T23:28:38.159944] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T23:28:38.175342] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T23:28:38.191559] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T23:28:38.205672] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T23:28:38.240759] [POD_MGR] Pod flink-jobmanager-7d7c784b74-4ksdd deleted
[0m[2025-01-21T23:28:40.150852] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:28:42.016020] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:28:42.016086] Reloading playbook: application/kafka
[0m[2025-01-21T23:28:47.936062] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T23:29:33.884913] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T23:29:33.885053] [EXPERIMENT] Run 5 completed. Start: 1737501857, End: 1737502173
[0m[2025-01-21T23:29:33.885058] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T23:29:46.131998] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-21T23:29:46.132104] [RESOURCE_E] Running experiment with 2000m cores and 32768 memory.
[0m[2025-01-21T23:29:53.383599] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T23:29:53.383667] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T23:29:55.237780] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:29:57.113186] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:29:57.113246] [SCALING] Setting up experiment.


[0m[2025-01-21T23:29:57.113266] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:29:57.119418] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:29:57.135789] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T23:29:57.152646] [SCALING] Statefulset name to scale : flink-2000m-32768
[0m[2025-01-21T23:29:57.162744] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 1 replica.
[0m[2025-01-21T23:30:02.177315] [FLK_MGR] Running job.
[0m[2025-01-21T23:30:02.177346] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T23:30:02.625780] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-59hw7
[0m[2025-01-21T23:30:06.733434] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6dbe8867b32511ab7ddc1e7106ea5508

[0m[2025-01-21T23:30:06.733483] [FLK_MGR] Running job id: 6dbe8867b32511ab7ddc1e7106ea5508
[0m[2025-01-21T23:30:06.733490] [FLK_MGR] Getting job info.
[0m[2025-01-21T23:30:06.755169] [FLK_MGR] Job plan response: {"plan":{"jid":"6dbe8867b32511ab7ddc1e7106ea5508","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T23:30:06.755304] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T23:30:07.121687] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-59hw7
[0m[2025-01-21T23:30:08.577279] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 23:30:05 : 6dbe8867b32511ab7ddc1e7106ea5508 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T23:30:08.577331] [FLK_MGR] Running jobs: ['6dbe8867b32511ab7ddc1e7106ea5508']
[0m[2025-01-21T23:30:08.577338] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T23:30:08.577345] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T23:34:08.600857] [SCALING] Scaling started.
[0m[2025-01-21T23:34:08.600950] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T23:34:08.613478] [SCALING] Scaling finished.
[0m[2025-01-21T23:34:08.613494] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:34:08.631029] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:34:08.648191] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T23:34:08.669643] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 0 replica.
[0m[2025-01-21T23:34:18.696518] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T23:34:18.711378] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T23:34:18.726718] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T23:34:18.741234] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T23:34:18.754082] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T23:34:18.780922] [POD_MGR] Pod flink-jobmanager-7d7c784b74-59hw7 deleted
[0m[2025-01-21T23:34:20.671692] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:34:22.586682] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:34:22.586741] Reloading playbook: application/kafka
[0m[2025-01-21T23:34:28.540992] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T23:35:14.521098] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T23:35:14.521266] [EXPERIMENT] Run 1 completed. Start: 1737502193, End: 1737502514
[0m[2025-01-21T23:35:14.521273] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T23:35:24.522252] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-21T23:35:26.410516] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:35:28.276896] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:35:28.276951] [SCALING] Setting up experiment.


[0m[2025-01-21T23:35:28.276962] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:35:28.284993] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:35:28.301685] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T23:35:28.320255] [SCALING] Statefulset name to scale : flink-2000m-32768
[0m[2025-01-21T23:35:28.387988] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 1 replica.
[0m[2025-01-21T23:35:33.397612] [FLK_MGR] Running job.
[0m[2025-01-21T23:35:33.397637] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T23:35:33.764665] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-2qmpl
[0m[2025-01-21T23:35:37.910314] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID d0119ceeb60aa7e5b0d778ec259cdaf5

[0m[2025-01-21T23:35:37.910360] [FLK_MGR] Running job id: d0119ceeb60aa7e5b0d778ec259cdaf5
[0m[2025-01-21T23:35:37.910367] [FLK_MGR] Getting job info.
[0m[2025-01-21T23:35:37.927825] [FLK_MGR] Job plan response: {"plan":{"jid":"d0119ceeb60aa7e5b0d778ec259cdaf5","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T23:35:37.927955] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T23:35:38.343541] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-2qmpl
[0m[2025-01-21T23:35:39.795727] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 23:35:36 : d0119ceeb60aa7e5b0d778ec259cdaf5 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T23:35:39.795778] [FLK_MGR] Running jobs: ['d0119ceeb60aa7e5b0d778ec259cdaf5']
[0m[2025-01-21T23:35:39.795785] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T23:35:39.795791] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T23:39:39.819278] [SCALING] Scaling started.
[0m[2025-01-21T23:39:39.819329] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T23:39:39.831832] [SCALING] Scaling finished.
[0m[2025-01-21T23:39:39.831851] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:39:39.851896] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:39:39.869351] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T23:39:39.892631] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 0 replica.
[0m[2025-01-21T23:39:44.914574] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T23:39:44.929042] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T23:39:44.943273] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T23:39:44.956641] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T23:39:44.970131] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T23:39:45.011036] [POD_MGR] Pod flink-jobmanager-7d7c784b74-2qmpl deleted
[0m[2025-01-21T23:39:46.903026] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:39:48.798964] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:39:48.799048] Reloading playbook: application/kafka
[0m[2025-01-21T23:39:54.773773] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T23:41:00.711691] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T23:41:00.711829] [EXPERIMENT] Run 2 completed. Start: 1737502524, End: 1737502860
[0m[2025-01-21T23:41:00.711836] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T23:41:10.712978] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-21T23:41:12.584653] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:41:14.447430] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:41:14.447492] [SCALING] Setting up experiment.


[0m[2025-01-21T23:41:14.447500] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:41:14.453767] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:41:14.471246] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T23:41:14.489932] [SCALING] Statefulset name to scale : flink-2000m-32768
[0m[2025-01-21T23:41:14.500656] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 1 replica.
[0m[2025-01-21T23:41:19.512465] [FLK_MGR] Running job.
[0m[2025-01-21T23:41:19.512492] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T23:41:19.929184] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-sqw7p
[0m[2025-01-21T23:41:24.029052] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 03c3dc2f747c9af431b829bc32f5e4dc

[0m[2025-01-21T23:41:24.029104] [FLK_MGR] Running job id: 03c3dc2f747c9af431b829bc32f5e4dc
[0m[2025-01-21T23:41:24.029113] [FLK_MGR] Getting job info.
[0m[2025-01-21T23:41:24.048135] [FLK_MGR] Job plan response: {"plan":{"jid":"03c3dc2f747c9af431b829bc32f5e4dc","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T23:41:24.048301] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T23:41:24.476789] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sqw7p
[0m[2025-01-21T23:41:25.894809] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 23:41:23 : 03c3dc2f747c9af431b829bc32f5e4dc : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T23:41:25.894863] [FLK_MGR] Running jobs: ['03c3dc2f747c9af431b829bc32f5e4dc']
[0m[2025-01-21T23:41:25.894870] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T23:41:25.894877] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T23:45:25.921569] [SCALING] Scaling started.
[0m[2025-01-21T23:45:25.921620] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T23:45:25.935386] [SCALING] Scaling finished.
[0m[2025-01-21T23:45:25.935409] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:45:25.955799] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:45:25.975014] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T23:45:25.997433] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 0 replica.
[0m[2025-01-21T23:45:31.020072] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T23:45:31.037976] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T23:45:31.053336] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T23:45:31.066531] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T23:45:31.079803] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T23:45:31.102658] [POD_MGR] Pod flink-jobmanager-7d7c784b74-sqw7p deleted
[0m[2025-01-21T23:45:32.993546] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:45:34.855676] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:45:34.855763] Reloading playbook: application/kafka
[0m[2025-01-21T23:45:40.875534] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T23:46:26.856980] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T23:46:26.857689] [EXPERIMENT] Run 3 completed. Start: 1737502870, End: 1737503186
[0m[2025-01-21T23:46:26.857719] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T23:46:36.858810] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-21T23:46:38.711239] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:46:40.617978] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:46:40.618046] [SCALING] Setting up experiment.


[0m[2025-01-21T23:46:40.618056] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:46:40.623933] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:46:40.640251] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T23:46:40.655784] [SCALING] Statefulset name to scale : flink-2000m-32768
[0m[2025-01-21T23:46:40.666343] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 1 replica.
[0m[2025-01-21T23:46:45.678251] [FLK_MGR] Running job.
[0m[2025-01-21T23:46:45.678277] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T23:46:46.117765] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-77m5m
[0m[2025-01-21T23:46:50.211805] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 51a00ded2ee54a5fd46b4101e4aec18a

[0m[2025-01-21T23:46:50.211856] [FLK_MGR] Running job id: 51a00ded2ee54a5fd46b4101e4aec18a
[0m[2025-01-21T23:46:50.211863] [FLK_MGR] Getting job info.
[0m[2025-01-21T23:46:50.227446] [FLK_MGR] Job plan response: {"plan":{"jid":"51a00ded2ee54a5fd46b4101e4aec18a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T23:46:50.227577] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T23:46:50.620834] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-77m5m
[0m[2025-01-21T23:46:52.060407] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 23:46:49 : 51a00ded2ee54a5fd46b4101e4aec18a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T23:46:52.060471] [FLK_MGR] Running jobs: ['51a00ded2ee54a5fd46b4101e4aec18a']
[0m[2025-01-21T23:46:52.060479] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T23:46:52.060485] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T23:50:52.082767] [SCALING] Scaling started.
[0m[2025-01-21T23:50:52.082818] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T23:50:52.095562] [SCALING] Scaling finished.
[0m[2025-01-21T23:50:52.095589] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:50:52.113095] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:50:52.135181] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T23:50:52.158373] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 0 replica.
[0m[2025-01-21T23:50:57.180261] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T23:50:57.193000] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T23:50:57.205777] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T23:50:57.272639] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T23:50:57.290062] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T23:50:57.317544] [POD_MGR] Pod flink-jobmanager-7d7c784b74-77m5m deleted
[0m[2025-01-21T23:50:59.175232] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:51:01.093092] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:51:01.093160] Reloading playbook: application/kafka
[0m[2025-01-21T23:51:07.059954] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T23:51:53.046749] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T23:51:53.047122] [EXPERIMENT] Run 4 completed. Start: 1737503196, End: 1737503513
[0m[2025-01-21T23:51:53.047186] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T23:52:03.048328] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-21T23:52:04.913882] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:52:06.771545] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:52:06.771600] [SCALING] Setting up experiment.


[0m[2025-01-21T23:52:06.771609] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:52:06.778003] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:52:06.792860] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T23:52:06.808479] [SCALING] Statefulset name to scale : flink-2000m-32768
[0m[2025-01-21T23:52:06.819085] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 1 replica.
[0m[2025-01-21T23:52:11.827838] [FLK_MGR] Running job.
[0m[2025-01-21T23:52:11.827868] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T23:52:12.206806] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-j2tjs
[0m[2025-01-21T23:52:16.319911] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 15328ac896feefc1c453dd92341bc71b

[0m[2025-01-21T23:52:16.319961] [FLK_MGR] Running job id: 15328ac896feefc1c453dd92341bc71b
[0m[2025-01-21T23:52:16.319969] [FLK_MGR] Getting job info.
[0m[2025-01-21T23:52:16.336618] [FLK_MGR] Job plan response: {"plan":{"jid":"15328ac896feefc1c453dd92341bc71b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T23:52:16.336760] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T23:52:16.753599] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-j2tjs
[0m[2025-01-21T23:52:18.207347] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 23:52:15 : 15328ac896feefc1c453dd92341bc71b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T23:52:18.207412] [FLK_MGR] Running jobs: ['15328ac896feefc1c453dd92341bc71b']
[0m[2025-01-21T23:52:18.207423] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T23:52:18.207435] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-21T23:56:18.231892] [SCALING] Scaling started.
[0m[2025-01-21T23:56:18.231959] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-21T23:56:18.247329] [SCALING] Scaling finished.
[0m[2025-01-21T23:56:18.247365] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:56:18.267011] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:56:18.284298] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-21T23:56:18.305316] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 0 replica.
[0m[2025-01-21T23:56:28.334047] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-21T23:56:28.350242] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-21T23:56:28.363682] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-21T23:56:28.377752] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-21T23:56:28.391742] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-21T23:56:28.420462] [POD_MGR] Pod flink-jobmanager-7d7c784b74-j2tjs deleted
[0m[2025-01-21T23:56:30.261217] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:56:32.130563] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-21T23:56:32.130638] Reloading playbook: application/kafka
[0m[2025-01-21T23:56:38.154291] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-21T23:57:24.125668] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-21T23:57:24.125860] [EXPERIMENT] Run 5 completed. Start: 1737503523, End: 1737503844
[0m[2025-01-21T23:57:24.125867] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-21T23:57:36.259134] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-21T23:57:36.259212] [RESOURCE_E] Running experiment with 4000m cores and 1024 memory.
[0m[2025-01-21T23:57:43.542748] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-21T23:57:43.542828] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-21T23:57:45.415222] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:57:47.265595] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-21T23:57:47.265662] [SCALING] Setting up experiment.


[0m[2025-01-21T23:57:47.265670] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-21T23:57:47.271277] [NODE_MGR] Resetting state labels.
[0m[2025-01-21T23:57:47.288691] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-21T23:57:47.304632] [SCALING] Statefulset name to scale : flink-4000m-1024
[0m[2025-01-21T23:57:47.315738] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 1 replica.
[0m[2025-01-21T23:57:52.326237] [FLK_MGR] Running job.
[0m[2025-01-21T23:57:52.326264] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-21T23:57:52.748269] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-nhjqp
[0m[2025-01-21T23:57:56.821622] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fdb7f3a64ffd458d29b668157bf066ae

[0m[2025-01-21T23:57:56.821670] [FLK_MGR] Running job id: fdb7f3a64ffd458d29b668157bf066ae
[0m[2025-01-21T23:57:56.821678] [FLK_MGR] Getting job info.
[0m[2025-01-21T23:57:56.838669] [FLK_MGR] Job plan response: {"plan":{"jid":"fdb7f3a64ffd458d29b668157bf066ae","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-21T23:57:56.838799] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-21T23:57:57.262883] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-nhjqp
[0m[2025-01-21T23:57:58.711197] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
21.01.2025 23:57:55 : fdb7f3a64ffd458d29b668157bf066ae : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-21T23:57:58.711256] [FLK_MGR] Running jobs: ['fdb7f3a64ffd458d29b668157bf066ae']
[0m[2025-01-21T23:57:58.711263] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-21T23:57:58.711275] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T00:01:58.736387] [SCALING] Scaling started.
[0m[2025-01-22T00:01:58.736447] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T00:01:58.749767] [SCALING] Scaling finished.
[0m[2025-01-22T00:01:58.749801] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:01:58.766493] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:01:58.784637] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T00:01:58.807112] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 0 replica.
[0m[2025-01-22T00:02:03.826113] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T00:02:03.838812] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T00:02:03.851709] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T00:02:03.864571] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T00:02:03.877317] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T00:02:03.909067] [POD_MGR] Pod flink-jobmanager-7d7c784b74-nhjqp deleted
[0m[2025-01-22T00:02:05.770045] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:02:07.666795] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:02:07.666870] Reloading playbook: application/kafka
[0m[2025-01-22T00:02:13.630401] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T00:02:59.600114] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T00:02:59.600426] [EXPERIMENT] Run 1 completed. Start: 1737503863, End: 1737504179
[0m[2025-01-22T00:02:59.600433] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T00:03:09.601470] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T00:03:11.469585] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:03:13.339432] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:03:13.339492] [SCALING] Setting up experiment.


[0m[2025-01-22T00:03:13.339501] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:03:13.345408] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:03:13.360977] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T00:03:13.376862] [SCALING] Statefulset name to scale : flink-4000m-1024
[0m[2025-01-22T00:03:13.387797] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 1 replica.
[0m[2025-01-22T00:03:18.398621] [FLK_MGR] Running job.
[0m[2025-01-22T00:03:18.398651] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T00:03:18.845567] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-488f6
[0m[2025-01-22T00:03:22.921539] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID ac2cf5d6f541dc2626ecf811ec16547d

[0m[2025-01-22T00:03:22.921590] [FLK_MGR] Running job id: ac2cf5d6f541dc2626ecf811ec16547d
[0m[2025-01-22T00:03:22.921597] [FLK_MGR] Getting job info.
[0m[2025-01-22T00:03:22.938827] [FLK_MGR] Job plan response: {"plan":{"jid":"ac2cf5d6f541dc2626ecf811ec16547d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T00:03:22.938956] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T00:03:23.388627] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-488f6
[0m[2025-01-22T00:03:24.828822] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 00:03:21 : ac2cf5d6f541dc2626ecf811ec16547d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T00:03:24.828880] [FLK_MGR] Running jobs: ['ac2cf5d6f541dc2626ecf811ec16547d']
[0m[2025-01-22T00:03:24.828886] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T00:03:24.828892] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T00:07:24.853267] [SCALING] Scaling started.
[0m[2025-01-22T00:07:24.853340] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T00:07:24.865840] [SCALING] Scaling finished.
[0m[2025-01-22T00:07:24.865860] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:07:24.883309] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:07:24.899151] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T00:07:24.919842] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 0 replica.
[0m[2025-01-22T00:07:24.935445] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T00:07:24.949799] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T00:07:24.962440] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T00:07:24.974869] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T00:07:24.987443] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T00:07:25.019475] [POD_MGR] Pod flink-jobmanager-7d7c784b74-488f6 deleted
[0m[2025-01-22T00:07:26.910670] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:07:28.813882] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:07:28.813943] Reloading playbook: application/kafka
[0m[2025-01-22T00:07:34.803958] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T00:08:20.775318] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T00:08:20.775442] [EXPERIMENT] Run 2 completed. Start: 1737504189, End: 1737504500
[0m[2025-01-22T00:08:20.775449] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T00:08:30.776477] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T00:08:32.671608] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:08:34.519750] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:08:34.519805] [SCALING] Setting up experiment.


[0m[2025-01-22T00:08:34.519814] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:08:34.525023] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:08:34.539981] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T00:08:34.555773] [SCALING] Statefulset name to scale : flink-4000m-1024
[0m[2025-01-22T00:08:34.567607] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 1 replica.
[0m[2025-01-22T00:08:39.578561] [FLK_MGR] Running job.
[0m[2025-01-22T00:08:39.578593] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T00:08:39.954508] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-lcd25
[0m[2025-01-22T00:08:44.027867] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 078f603670c5b17fe62c6b77527420a2

[0m[2025-01-22T00:08:44.027918] [FLK_MGR] Running job id: 078f603670c5b17fe62c6b77527420a2
[0m[2025-01-22T00:08:44.027925] [FLK_MGR] Getting job info.
[0m[2025-01-22T00:08:44.047463] [FLK_MGR] Job plan response: {"plan":{"jid":"078f603670c5b17fe62c6b77527420a2","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T00:08:44.047610] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T00:08:44.490385] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-lcd25
[0m[2025-01-22T00:08:45.932255] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 00:08:43 : 078f603670c5b17fe62c6b77527420a2 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T00:08:45.932312] [FLK_MGR] Running jobs: ['078f603670c5b17fe62c6b77527420a2']
[0m[2025-01-22T00:08:45.932320] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T00:08:45.932331] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T00:12:45.955544] [SCALING] Scaling started.
[0m[2025-01-22T00:12:45.955656] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T00:12:45.969727] [SCALING] Scaling finished.
[0m[2025-01-22T00:12:45.969768] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:12:45.987990] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:12:46.005433] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T00:12:46.027520] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 0 replica.
[0m[2025-01-22T00:12:46.043872] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T00:12:46.056702] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T00:12:46.069845] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T00:12:46.082290] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T00:12:46.094851] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T00:12:46.127834] [POD_MGR] Pod flink-jobmanager-7d7c784b74-lcd25 deleted
[0m[2025-01-22T00:12:48.034005] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:12:49.935046] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:12:49.935109] Reloading playbook: application/kafka
[0m[2025-01-22T00:12:55.913771] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T00:13:41.898069] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T00:13:41.898208] [EXPERIMENT] Run 3 completed. Start: 1737504510, End: 1737504821
[0m[2025-01-22T00:13:41.898214] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T00:13:51.899258] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T00:13:53.782958] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:13:55.685879] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:13:55.686181] [SCALING] Setting up experiment.


[0m[2025-01-22T00:13:55.686269] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:13:55.692365] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:13:55.708097] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T00:13:55.726157] [SCALING] Statefulset name to scale : flink-4000m-1024
[0m[2025-01-22T00:13:55.736362] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 1 replica.
[0m[2025-01-22T00:14:00.746499] [FLK_MGR] Running job.
[0m[2025-01-22T00:14:00.746582] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T00:14:01.180560] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-dmvrd
[0m[2025-01-22T00:14:05.389709] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 3ba0862cfa899a79807e791121bd7249

[0m[2025-01-22T00:14:05.389762] [FLK_MGR] Running job id: 3ba0862cfa899a79807e791121bd7249
[0m[2025-01-22T00:14:05.389773] [FLK_MGR] Getting job info.
[0m[2025-01-22T00:14:05.411669] [FLK_MGR] Job plan response: {"plan":{"jid":"3ba0862cfa899a79807e791121bd7249","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T00:14:05.411850] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T00:14:05.842157] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-dmvrd
[0m[2025-01-22T00:14:07.284375] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 00:14:04 : 3ba0862cfa899a79807e791121bd7249 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T00:14:07.284430] [FLK_MGR] Running jobs: ['3ba0862cfa899a79807e791121bd7249']
[0m[2025-01-22T00:14:07.284437] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T00:14:07.284442] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T00:18:07.308862] [SCALING] Scaling started.
[0m[2025-01-22T00:18:07.308921] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T00:18:07.322960] [SCALING] Scaling finished.
[0m[2025-01-22T00:18:07.322990] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:18:07.342325] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:18:07.359466] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T00:18:07.381564] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 0 replica.
[0m[2025-01-22T00:18:12.402102] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T00:18:12.415001] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T00:18:12.427836] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T00:18:12.440699] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T00:18:12.453937] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T00:18:12.475297] [POD_MGR] Pod flink-jobmanager-7d7c784b74-dmvrd deleted
[0m[2025-01-22T00:18:14.343208] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:18:16.231113] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:18:16.231181] Reloading playbook: application/kafka
[0m[2025-01-22T00:18:22.150277] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T00:19:08.109851] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T00:19:08.109976] [EXPERIMENT] Run 4 completed. Start: 1737504831, End: 1737505148
[0m[2025-01-22T00:19:08.109983] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T00:19:18.111093] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T00:19:20.001957] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:19:21.882998] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:19:21.883058] [SCALING] Setting up experiment.


[0m[2025-01-22T00:19:21.883066] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:19:21.889498] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:19:21.905402] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T00:19:21.930135] [SCALING] Statefulset name to scale : flink-4000m-1024
[0m[2025-01-22T00:19:21.940243] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 1 replica.
[0m[2025-01-22T00:19:26.950827] [FLK_MGR] Running job.
[0m[2025-01-22T00:19:26.950854] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T00:19:27.391447] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-9hhn6
[0m[2025-01-22T00:19:31.506657] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 07203a41bd71b197a9264fed42535273

[0m[2025-01-22T00:19:31.506709] [FLK_MGR] Running job id: 07203a41bd71b197a9264fed42535273
[0m[2025-01-22T00:19:31.506718] [FLK_MGR] Getting job info.
[0m[2025-01-22T00:19:31.520716] [FLK_MGR] Job plan response: {"plan":{"jid":"07203a41bd71b197a9264fed42535273","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T00:19:31.520856] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T00:19:31.960309] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-9hhn6
[0m[2025-01-22T00:19:33.406507] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 00:19:30 : 07203a41bd71b197a9264fed42535273 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T00:19:33.406561] [FLK_MGR] Running jobs: ['07203a41bd71b197a9264fed42535273']
[0m[2025-01-22T00:19:33.406568] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T00:19:33.406574] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T00:23:33.431011] [SCALING] Scaling started.
[0m[2025-01-22T00:23:33.431113] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T00:23:33.445341] [SCALING] Scaling finished.
[0m[2025-01-22T00:23:33.445366] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:23:33.464976] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:23:33.484389] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T00:23:33.509059] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 0 replica.
[0m[2025-01-22T00:23:38.531045] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T00:23:38.545228] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T00:23:38.560839] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T00:23:38.575248] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T00:23:38.589735] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T00:23:38.612123] [POD_MGR] Pod flink-jobmanager-7d7c784b74-9hhn6 deleted
[0m[2025-01-22T00:23:40.460831] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:23:42.380704] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:23:42.380770] Reloading playbook: application/kafka
[0m[2025-01-22T00:23:48.287910] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T00:24:49.255150] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T00:24:49.255530] [EXPERIMENT] Run 5 completed. Start: 1737505158, End: 1737505489
[0m[2025-01-22T00:24:49.255574] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T00:25:01.496811] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T00:25:01.496861] [RESOURCE_E] Running experiment with 4000m cores and 2048 memory.
[0m[2025-01-22T00:25:08.760598] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T00:25:08.760654] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T00:25:10.632786] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:25:12.488151] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:25:12.488204] [SCALING] Setting up experiment.


[0m[2025-01-22T00:25:12.488212] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:25:12.495146] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:25:12.514757] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T00:25:12.530673] [SCALING] Statefulset name to scale : flink-4000m-2048
[0m[2025-01-22T00:25:12.541088] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 1 replica.
[0m[2025-01-22T00:25:17.552299] [FLK_MGR] Running job.
[0m[2025-01-22T00:25:17.552329] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T00:25:17.980659] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-8b452
[0m[2025-01-22T00:25:22.135927] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9dccd9139b1f4b12b6a46c1ee69dc29d

[0m[2025-01-22T00:25:22.135980] [FLK_MGR] Running job id: 9dccd9139b1f4b12b6a46c1ee69dc29d
[0m[2025-01-22T00:25:22.135989] [FLK_MGR] Getting job info.
[0m[2025-01-22T00:25:22.154434] [FLK_MGR] Job plan response: {"plan":{"jid":"9dccd9139b1f4b12b6a46c1ee69dc29d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T00:25:22.154592] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T00:25:22.535413] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-8b452
[0m[2025-01-22T00:25:23.985456] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 00:25:21 : 9dccd9139b1f4b12b6a46c1ee69dc29d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T00:25:23.985518] [FLK_MGR] Running jobs: ['9dccd9139b1f4b12b6a46c1ee69dc29d']
[0m[2025-01-22T00:25:23.985526] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T00:25:23.985537] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T00:29:24.008925] [SCALING] Scaling started.
[0m[2025-01-22T00:29:24.008984] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T00:29:24.022801] [SCALING] Scaling finished.
[0m[2025-01-22T00:29:24.022845] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:29:24.041763] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:29:24.073822] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T00:29:24.096467] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 0 replica.
[0m[2025-01-22T00:29:29.116513] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T00:29:29.129450] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T00:29:29.143576] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T00:29:29.156561] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T00:29:29.169331] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T00:29:29.205043] [POD_MGR] Pod flink-jobmanager-7d7c784b74-8b452 deleted
[0m[2025-01-22T00:29:31.104151] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:29:32.998432] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:29:32.998496] Reloading playbook: application/kafka
[0m[2025-01-22T00:29:38.966087] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T00:30:24.907249] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T00:30:24.907613] [EXPERIMENT] Run 1 completed. Start: 1737505508, End: 1737505824
[0m[2025-01-22T00:30:24.907620] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T00:30:34.908743] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T00:30:36.792972] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:30:38.672825] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:30:38.672887] [SCALING] Setting up experiment.


[0m[2025-01-22T00:30:38.672894] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:30:38.678221] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:30:38.693008] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T00:30:38.708937] [SCALING] Statefulset name to scale : flink-4000m-2048
[0m[2025-01-22T00:30:38.719291] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 1 replica.
[0m[2025-01-22T00:30:43.729828] [FLK_MGR] Running job.
[0m[2025-01-22T00:30:43.729916] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T00:30:44.150827] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-j4dc5
[0m[2025-01-22T00:30:48.357650] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6ac23f001bfbe7639d3eb32c924ebec9

[0m[2025-01-22T00:30:48.357698] [FLK_MGR] Running job id: 6ac23f001bfbe7639d3eb32c924ebec9
[0m[2025-01-22T00:30:48.357706] [FLK_MGR] Getting job info.
[0m[2025-01-22T00:30:48.374288] [FLK_MGR] Job plan response: {"plan":{"jid":"6ac23f001bfbe7639d3eb32c924ebec9","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T00:30:48.374437] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T00:30:48.804718] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-j4dc5
[0m[2025-01-22T00:30:50.244486] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 00:30:47 : 6ac23f001bfbe7639d3eb32c924ebec9 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T00:30:50.244544] [FLK_MGR] Running jobs: ['6ac23f001bfbe7639d3eb32c924ebec9']
[0m[2025-01-22T00:30:50.244552] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T00:30:50.244558] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T00:34:50.269559] [SCALING] Scaling started.
[0m[2025-01-22T00:34:50.269664] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T00:34:50.282609] [SCALING] Scaling finished.
[0m[2025-01-22T00:34:50.282628] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:34:50.300591] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:34:50.316253] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T00:34:50.336472] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 0 replica.
[0m[2025-01-22T00:34:55.358419] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T00:34:55.372236] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T00:34:55.386017] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T00:34:55.399076] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T00:34:55.412087] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T00:34:55.436328] [POD_MGR] Pod flink-jobmanager-7d7c784b74-j4dc5 deleted
[0m[2025-01-22T00:34:57.297380] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:34:59.198419] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:34:59.198483] Reloading playbook: application/kafka
[0m[2025-01-22T00:35:05.217523] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T00:35:51.165869] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T00:35:51.165999] [EXPERIMENT] Run 2 completed. Start: 1737505834, End: 1737506151
[0m[2025-01-22T00:35:51.166005] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T00:36:01.167056] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T00:36:03.024075] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:36:04.877487] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:36:04.877538] [SCALING] Setting up experiment.


[0m[2025-01-22T00:36:04.877546] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:36:04.882964] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:36:04.900775] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T00:36:04.918842] [SCALING] Statefulset name to scale : flink-4000m-2048
[0m[2025-01-22T00:36:04.929670] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 1 replica.
[0m[2025-01-22T00:36:09.939945] [FLK_MGR] Running job.
[0m[2025-01-22T00:36:09.939971] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T00:36:10.365055] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-x78fm
[0m[2025-01-22T00:36:14.480021] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5b4a97f3ce5d171e34c9e7a16fd7917f

[0m[2025-01-22T00:36:14.480138] [FLK_MGR] Running job id: 5b4a97f3ce5d171e34c9e7a16fd7917f
[0m[2025-01-22T00:36:14.480155] [FLK_MGR] Getting job info.
[0m[2025-01-22T00:36:14.499511] [FLK_MGR] Job plan response: {"plan":{"jid":"5b4a97f3ce5d171e34c9e7a16fd7917f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T00:36:14.499682] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T00:36:14.982064] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-x78fm
[0m[2025-01-22T00:36:16.428419] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 00:36:13 : 5b4a97f3ce5d171e34c9e7a16fd7917f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T00:36:16.428472] [FLK_MGR] Running jobs: ['5b4a97f3ce5d171e34c9e7a16fd7917f']
[0m[2025-01-22T00:36:16.428479] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T00:36:16.428486] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T00:40:16.450885] [SCALING] Scaling started.
[0m[2025-01-22T00:40:16.450978] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T00:40:16.464031] [SCALING] Scaling finished.
[0m[2025-01-22T00:40:16.464052] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:40:16.484488] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:40:16.503686] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T00:40:16.524982] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 0 replica.
[0m[2025-01-22T00:40:21.548266] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T00:40:21.562477] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T00:40:21.576744] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T00:40:21.593076] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T00:40:21.608046] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T00:40:21.644920] [POD_MGR] Pod flink-jobmanager-7d7c784b74-x78fm deleted
[0m[2025-01-22T00:40:23.513771] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:40:25.404151] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:40:25.404227] Reloading playbook: application/kafka
[0m[2025-01-22T00:40:31.410745] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T00:41:17.381969] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T00:41:17.382105] [EXPERIMENT] Run 3 completed. Start: 1737506161, End: 1737506477
[0m[2025-01-22T00:41:17.382112] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T00:41:27.383161] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T00:41:29.264847] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:41:31.138181] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:41:31.138240] [SCALING] Setting up experiment.


[0m[2025-01-22T00:41:31.138249] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:41:31.143887] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:41:31.158967] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T00:41:31.179280] [SCALING] Statefulset name to scale : flink-4000m-2048
[0m[2025-01-22T00:41:31.190566] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 1 replica.
[0m[2025-01-22T00:41:36.200311] [FLK_MGR] Running job.
[0m[2025-01-22T00:41:36.200338] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T00:41:36.651256] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-fnpjn
[0m[2025-01-22T00:41:40.747068] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b9c2717f9b2f71a05eed4132b1917c79

[0m[2025-01-22T00:41:40.747117] [FLK_MGR] Running job id: b9c2717f9b2f71a05eed4132b1917c79
[0m[2025-01-22T00:41:40.747124] [FLK_MGR] Getting job info.
[0m[2025-01-22T00:41:40.763403] [FLK_MGR] Job plan response: {"plan":{"jid":"b9c2717f9b2f71a05eed4132b1917c79","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T00:41:40.763541] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T00:41:41.140420] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-fnpjn
[0m[2025-01-22T00:41:42.566006] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 00:41:39 : b9c2717f9b2f71a05eed4132b1917c79 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T00:41:42.566060] [FLK_MGR] Running jobs: ['b9c2717f9b2f71a05eed4132b1917c79']
[0m[2025-01-22T00:41:42.566068] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T00:41:42.566074] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T00:45:42.589601] [SCALING] Scaling started.
[0m[2025-01-22T00:45:42.589695] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T00:45:42.604521] [SCALING] Scaling finished.
[0m[2025-01-22T00:45:42.604540] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:45:42.622851] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:45:42.642896] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T00:45:42.666699] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 0 replica.
[0m[2025-01-22T00:45:47.688791] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T00:45:47.702955] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T00:45:47.717158] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T00:45:47.732924] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T00:45:47.749517] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T00:45:47.840003] [POD_MGR] Pod flink-jobmanager-7d7c784b74-fnpjn deleted
[0m[2025-01-22T00:45:49.724060] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:45:51.648287] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:45:51.648357] Reloading playbook: application/kafka
[0m[2025-01-22T00:45:57.587016] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T00:46:43.552200] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T00:46:43.552338] [EXPERIMENT] Run 4 completed. Start: 1737506487, End: 1737506803
[0m[2025-01-22T00:46:43.552345] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T00:46:53.553405] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T00:46:55.415933] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:46:57.313742] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:46:57.313805] [SCALING] Setting up experiment.


[0m[2025-01-22T00:46:57.313814] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:46:57.319681] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:46:57.336786] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T00:46:57.358918] [SCALING] Statefulset name to scale : flink-4000m-2048
[0m[2025-01-22T00:46:57.369981] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 1 replica.
[0m[2025-01-22T00:47:02.379536] [FLK_MGR] Running job.
[0m[2025-01-22T00:47:02.379568] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T00:47:02.762245] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-z9fvg
[0m[2025-01-22T00:47:06.849924] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 018f8a0294dd869e31273c7342ed23c9

[0m[2025-01-22T00:47:06.849985] [FLK_MGR] Running job id: 018f8a0294dd869e31273c7342ed23c9
[0m[2025-01-22T00:47:06.850009] [FLK_MGR] Getting job info.
[0m[2025-01-22T00:47:06.867818] [FLK_MGR] Job plan response: {"plan":{"jid":"018f8a0294dd869e31273c7342ed23c9","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T00:47:06.867955] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T00:47:07.308761] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-z9fvg
[0m[2025-01-22T00:47:08.747300] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 00:47:05 : 018f8a0294dd869e31273c7342ed23c9 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T00:47:08.747358] [FLK_MGR] Running jobs: ['018f8a0294dd869e31273c7342ed23c9']
[0m[2025-01-22T00:47:08.747366] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T00:47:08.747372] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T00:51:08.771120] [SCALING] Scaling started.
[0m[2025-01-22T00:51:08.771213] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T00:51:08.783987] [SCALING] Scaling finished.
[0m[2025-01-22T00:51:08.784011] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:51:08.802574] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:51:08.820104] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T00:51:08.839842] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 0 replica.
[0m[2025-01-22T00:51:13.859781] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T00:51:13.872660] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T00:51:13.885521] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T00:51:13.898026] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T00:51:13.910772] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T00:51:13.933854] [POD_MGR] Pod flink-jobmanager-7d7c784b74-z9fvg deleted
[0m[2025-01-22T00:51:15.821242] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:51:17.731959] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:51:17.732022] Reloading playbook: application/kafka
[0m[2025-01-22T00:51:23.668107] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T00:52:09.700208] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T00:52:09.700333] [EXPERIMENT] Run 5 completed. Start: 1737506813, End: 1737507129
[0m[2025-01-22T00:52:09.700340] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T00:52:21.942524] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T00:52:21.942588] [RESOURCE_E] Running experiment with 4000m cores and 4096 memory.
[0m[2025-01-22T00:52:29.115415] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T00:52:29.115480] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T00:52:30.984101] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:52:32.848104] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:52:32.848164] [SCALING] Setting up experiment.


[0m[2025-01-22T00:52:32.848172] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:52:32.853567] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:52:32.868671] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T00:52:32.885664] [SCALING] Statefulset name to scale : flink-4000m-4096
[0m[2025-01-22T00:52:32.897374] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 1 replica.
[0m[2025-01-22T00:52:37.907497] [FLK_MGR] Running job.
[0m[2025-01-22T00:52:37.907525] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T00:52:38.348450] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-5l5ft
[0m[2025-01-22T00:52:42.449468] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c87e49a5b47d6ba0a46068036f358226

[0m[2025-01-22T00:52:42.449519] [FLK_MGR] Running job id: c87e49a5b47d6ba0a46068036f358226
[0m[2025-01-22T00:52:42.449526] [FLK_MGR] Getting job info.
[0m[2025-01-22T00:52:42.469335] [FLK_MGR] Job plan response: {"plan":{"jid":"c87e49a5b47d6ba0a46068036f358226","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T00:52:42.469473] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T00:52:42.894045] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-5l5ft
[0m[2025-01-22T00:52:44.356308] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 00:52:41 : c87e49a5b47d6ba0a46068036f358226 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T00:52:44.356364] [FLK_MGR] Running jobs: ['c87e49a5b47d6ba0a46068036f358226']
[0m[2025-01-22T00:52:44.356372] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T00:52:44.356378] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T00:56:44.379309] [SCALING] Scaling started.
[0m[2025-01-22T00:56:44.379364] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T00:56:44.390506] [SCALING] Scaling finished.
[0m[2025-01-22T00:56:44.390527] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:56:44.409908] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:56:44.427834] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T00:56:44.451137] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 0 replica.
[0m[2025-01-22T00:56:54.479697] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T00:56:54.495681] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T00:56:54.511581] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T00:56:54.526123] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T00:56:54.541800] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T00:56:54.566358] [POD_MGR] Pod flink-jobmanager-7d7c784b74-5l5ft deleted
[0m[2025-01-22T00:56:56.480767] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:56:58.410116] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T00:56:58.410175] Reloading playbook: application/kafka
[0m[2025-01-22T00:57:04.358105] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T00:57:50.302220] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T00:57:50.302345] [EXPERIMENT] Run 1 completed. Start: 1737507149, End: 1737507470
[0m[2025-01-22T00:57:50.302351] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T00:58:00.303421] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T00:58:02.176148] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:58:04.052463] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T00:58:04.052521] [SCALING] Setting up experiment.


[0m[2025-01-22T00:58:04.052529] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T00:58:04.057945] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T00:58:04.074122] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T00:58:04.090540] [SCALING] Statefulset name to scale : flink-4000m-4096
[0m[2025-01-22T00:58:04.100881] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 1 replica.
[0m[2025-01-22T00:58:09.110985] [FLK_MGR] Running job.
[0m[2025-01-22T00:58:09.111017] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T00:58:09.552286] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-brcpg
[0m[2025-01-22T00:58:13.646653] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 31981d67096cd757181e662aaa050913

[0m[2025-01-22T00:58:13.646708] [FLK_MGR] Running job id: 31981d67096cd757181e662aaa050913
[0m[2025-01-22T00:58:13.646715] [FLK_MGR] Getting job info.
[0m[2025-01-22T00:58:13.664784] [FLK_MGR] Job plan response: {"plan":{"jid":"31981d67096cd757181e662aaa050913","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T00:58:13.664946] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T00:58:14.086507] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-brcpg
[0m[2025-01-22T00:58:15.512070] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 00:58:12 : 31981d67096cd757181e662aaa050913 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T00:58:15.512125] [FLK_MGR] Running jobs: ['31981d67096cd757181e662aaa050913']
[0m[2025-01-22T00:58:15.512132] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T00:58:15.512138] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T01:02:15.536522] [SCALING] Scaling started.
[0m[2025-01-22T01:02:15.536622] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T01:02:15.550072] [SCALING] Scaling finished.
[0m[2025-01-22T01:02:15.550088] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:02:15.568864] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:02:15.587001] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T01:02:15.608811] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 0 replica.
[0m[2025-01-22T01:02:20.629836] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T01:02:20.643836] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T01:02:20.658439] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T01:02:20.672837] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T01:02:20.686785] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T01:02:20.716000] [POD_MGR] Pod flink-jobmanager-7d7c784b74-brcpg deleted
[0m[2025-01-22T01:02:22.584642] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:02:24.435107] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:02:24.435172] Reloading playbook: application/kafka
[0m[2025-01-22T01:02:30.358753] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T01:03:16.336310] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T01:03:16.336447] [EXPERIMENT] Run 2 completed. Start: 1737507480, End: 1737507796
[0m[2025-01-22T01:03:16.336453] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T01:03:26.337493] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T01:03:28.226290] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:03:30.076054] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:03:30.076112] [SCALING] Setting up experiment.


[0m[2025-01-22T01:03:30.076120] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:03:30.082737] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:03:30.101326] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T01:03:30.134677] [SCALING] Statefulset name to scale : flink-4000m-4096
[0m[2025-01-22T01:03:30.146397] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 1 replica.
[0m[2025-01-22T01:03:35.157057] [FLK_MGR] Running job.
[0m[2025-01-22T01:03:35.157087] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T01:03:35.541852] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-8nlfx
[0m[2025-01-22T01:03:39.643106] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5777ca6eb28782ef6b63063ca225e92d

[0m[2025-01-22T01:03:39.643161] [FLK_MGR] Running job id: 5777ca6eb28782ef6b63063ca225e92d
[0m[2025-01-22T01:03:39.643170] [FLK_MGR] Getting job info.
[0m[2025-01-22T01:03:39.660239] [FLK_MGR] Job plan response: {"plan":{"jid":"5777ca6eb28782ef6b63063ca225e92d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T01:03:39.660404] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T01:03:40.080980] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-8nlfx
[0m[2025-01-22T01:03:41.543897] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 01:03:38 : 5777ca6eb28782ef6b63063ca225e92d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T01:03:41.543953] [FLK_MGR] Running jobs: ['5777ca6eb28782ef6b63063ca225e92d']
[0m[2025-01-22T01:03:41.543960] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T01:03:41.543966] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T01:07:41.567608] [SCALING] Scaling started.
[0m[2025-01-22T01:07:41.567660] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T01:07:41.580137] [SCALING] Scaling finished.
[0m[2025-01-22T01:07:41.580156] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:07:41.598501] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:07:41.617218] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T01:07:41.645198] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 0 replica.
[0m[2025-01-22T01:07:46.666717] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T01:07:46.682401] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T01:07:46.696495] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T01:07:46.710765] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T01:07:46.724367] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T01:07:46.763930] [POD_MGR] Pod flink-jobmanager-7d7c784b74-8nlfx deleted
[0m[2025-01-22T01:07:48.664417] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:07:50.524757] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:07:50.524819] Reloading playbook: application/kafka
[0m[2025-01-22T01:07:56.484704] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T01:08:42.432727] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T01:08:42.432855] [EXPERIMENT] Run 3 completed. Start: 1737507806, End: 1737508122
[0m[2025-01-22T01:08:42.432861] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T01:08:52.433895] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T01:08:54.308901] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:08:56.183145] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:08:56.183198] [SCALING] Setting up experiment.


[0m[2025-01-22T01:08:56.183206] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:08:56.188770] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:08:56.207890] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T01:08:56.224335] [SCALING] Statefulset name to scale : flink-4000m-4096
[0m[2025-01-22T01:08:56.256101] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 1 replica.
[0m[2025-01-22T01:09:01.267445] [FLK_MGR] Running job.
[0m[2025-01-22T01:09:01.267473] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T01:09:01.698189] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-qb749
[0m[2025-01-22T01:09:05.734531] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 792146cb70e5c26df282a86b6d493095

[0m[2025-01-22T01:09:05.734584] [FLK_MGR] Running job id: 792146cb70e5c26df282a86b6d493095
[0m[2025-01-22T01:09:05.734591] [FLK_MGR] Getting job info.
[0m[2025-01-22T01:09:05.751998] [FLK_MGR] Job plan response: {"plan":{"jid":"792146cb70e5c26df282a86b6d493095","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T01:09:05.752132] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T01:09:06.160871] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-qb749
[0m[2025-01-22T01:09:07.592073] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 01:09:04 : 792146cb70e5c26df282a86b6d493095 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T01:09:07.592126] [FLK_MGR] Running jobs: ['792146cb70e5c26df282a86b6d493095']
[0m[2025-01-22T01:09:07.592133] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T01:09:07.592139] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T01:13:07.615418] [SCALING] Scaling started.
[0m[2025-01-22T01:13:07.615513] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T01:13:07.627742] [SCALING] Scaling finished.
[0m[2025-01-22T01:13:07.627762] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:13:07.646981] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:13:07.664866] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T01:13:07.688028] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 0 replica.
[0m[2025-01-22T01:13:12.710502] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T01:13:12.724947] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T01:13:12.739861] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T01:13:12.754077] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T01:13:12.767870] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T01:13:12.797878] [POD_MGR] Pod flink-jobmanager-7d7c784b74-qb749 deleted
[0m[2025-01-22T01:13:14.668789] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:13:16.606487] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:13:16.606551] Reloading playbook: application/kafka
[0m[2025-01-22T01:13:22.610991] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T01:14:08.567543] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T01:14:08.567668] [EXPERIMENT] Run 4 completed. Start: 1737508132, End: 1737508448
[0m[2025-01-22T01:14:08.567674] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T01:14:18.568648] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T01:14:20.485386] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:14:22.354661] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:14:22.354719] [SCALING] Setting up experiment.


[0m[2025-01-22T01:14:22.354728] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:14:22.360196] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:14:22.377119] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T01:14:22.394650] [SCALING] Statefulset name to scale : flink-4000m-4096
[0m[2025-01-22T01:14:22.405799] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 1 replica.
[0m[2025-01-22T01:14:27.415533] [FLK_MGR] Running job.
[0m[2025-01-22T01:14:27.415562] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T01:14:27.852606] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-fzznp
[0m[2025-01-22T01:14:31.952616] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID af0c39e9ed10b85b507707a5a9cad57e

[0m[2025-01-22T01:14:31.952664] [FLK_MGR] Running job id: af0c39e9ed10b85b507707a5a9cad57e
[0m[2025-01-22T01:14:31.952671] [FLK_MGR] Getting job info.
[0m[2025-01-22T01:14:31.970391] [FLK_MGR] Job plan response: {"plan":{"jid":"af0c39e9ed10b85b507707a5a9cad57e","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T01:14:31.970557] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T01:14:32.392949] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-fzznp
[0m[2025-01-22T01:14:33.849806] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 01:14:30 : af0c39e9ed10b85b507707a5a9cad57e : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T01:14:33.849860] [FLK_MGR] Running jobs: ['af0c39e9ed10b85b507707a5a9cad57e']
[0m[2025-01-22T01:14:33.849867] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T01:14:33.849873] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T01:18:33.873988] [SCALING] Scaling started.
[0m[2025-01-22T01:18:33.874072] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T01:18:33.888188] [SCALING] Scaling finished.
[0m[2025-01-22T01:18:33.888217] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:18:33.909582] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:18:33.927142] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T01:18:33.948659] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 0 replica.
[0m[2025-01-22T01:18:38.970168] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T01:18:38.983249] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T01:18:38.996130] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T01:18:39.008697] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T01:18:39.021356] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T01:18:39.047639] [POD_MGR] Pod flink-jobmanager-7d7c784b74-fzznp deleted
[0m[2025-01-22T01:18:40.900172] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:18:42.803731] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:18:42.803796] Reloading playbook: application/kafka
[0m[2025-01-22T01:18:48.807916] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T01:19:34.789710] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T01:19:34.789891] [EXPERIMENT] Run 5 completed. Start: 1737508458, End: 1737508774
[0m[2025-01-22T01:19:34.789897] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T01:19:47.002191] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T01:19:47.002351] [RESOURCE_E] Running experiment with 4000m cores and 8192 memory.
[0m[2025-01-22T01:19:54.239056] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T01:19:54.239124] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T01:19:56.113810] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:19:57.992123] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:19:57.992180] [SCALING] Setting up experiment.


[0m[2025-01-22T01:19:57.992192] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:19:58.000424] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:19:58.017841] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T01:19:58.035991] [SCALING] Statefulset name to scale : flink-4000m-8192
[0m[2025-01-22T01:19:58.046716] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 1 replica.
[0m[2025-01-22T01:20:03.057263] [FLK_MGR] Running job.
[0m[2025-01-22T01:20:03.057293] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T01:20:03.525606] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-zc5jc
[0m[2025-01-22T01:20:07.664252] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c6424ec37b01683d54adb389716dc248

[0m[2025-01-22T01:20:07.664299] [FLK_MGR] Running job id: c6424ec37b01683d54adb389716dc248
[0m[2025-01-22T01:20:07.664306] [FLK_MGR] Getting job info.
[0m[2025-01-22T01:20:07.681374] [FLK_MGR] Job plan response: {"plan":{"jid":"c6424ec37b01683d54adb389716dc248","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T01:20:07.681514] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T01:20:08.051109] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-zc5jc
[0m[2025-01-22T01:20:09.481972] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 01:20:06 : c6424ec37b01683d54adb389716dc248 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T01:20:09.482035] [FLK_MGR] Running jobs: ['c6424ec37b01683d54adb389716dc248']
[0m[2025-01-22T01:20:09.482042] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T01:20:09.482047] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T01:24:09.507241] [SCALING] Scaling started.
[0m[2025-01-22T01:24:09.507341] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T01:24:09.519907] [SCALING] Scaling finished.
[0m[2025-01-22T01:24:09.519925] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:24:09.539652] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:24:09.557866] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T01:24:09.578272] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 0 replica.
[0m[2025-01-22T01:24:19.605565] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T01:24:19.621625] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T01:24:19.636815] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T01:24:19.656998] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T01:24:19.672300] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T01:24:19.697860] [POD_MGR] Pod flink-jobmanager-7d7c784b74-zc5jc deleted
[0m[2025-01-22T01:24:21.577861] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:24:23.530427] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:24:23.530491] Reloading playbook: application/kafka
[0m[2025-01-22T01:24:29.663116] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T01:25:15.673476] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T01:25:15.674062] [EXPERIMENT] Run 1 completed. Start: 1737508794, End: 1737509115
[0m[2025-01-22T01:25:15.674069] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T01:25:25.675040] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T01:25:27.546594] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:25:29.380061] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:25:29.380123] [SCALING] Setting up experiment.


[0m[2025-01-22T01:25:29.380134] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:25:29.386062] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:25:29.403847] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T01:25:29.422143] [SCALING] Statefulset name to scale : flink-4000m-8192
[0m[2025-01-22T01:25:29.432687] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 1 replica.
[0m[2025-01-22T01:25:34.443219] [FLK_MGR] Running job.
[0m[2025-01-22T01:25:34.443251] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T01:25:34.877024] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-ll4wm
[0m[2025-01-22T01:25:39.046764] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 51c799406cae1a10a86aa55c457d387a

[0m[2025-01-22T01:25:39.046814] [FLK_MGR] Running job id: 51c799406cae1a10a86aa55c457d387a
[0m[2025-01-22T01:25:39.046822] [FLK_MGR] Getting job info.
[0m[2025-01-22T01:25:39.064486] [FLK_MGR] Job plan response: {"plan":{"jid":"51c799406cae1a10a86aa55c457d387a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T01:25:39.064632] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T01:25:39.477026] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-ll4wm
[0m[2025-01-22T01:25:40.922207] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 01:25:38 : 51c799406cae1a10a86aa55c457d387a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T01:25:40.922262] [FLK_MGR] Running jobs: ['51c799406cae1a10a86aa55c457d387a']
[0m[2025-01-22T01:25:40.922270] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T01:25:40.922277] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T01:29:40.945191] [SCALING] Scaling started.
[0m[2025-01-22T01:29:40.945242] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T01:29:40.957540] [SCALING] Scaling finished.
[0m[2025-01-22T01:29:40.957558] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:29:40.975733] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:29:40.998410] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T01:29:41.020250] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 0 replica.
[0m[2025-01-22T01:29:46.043593] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T01:29:46.058662] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T01:29:46.072347] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T01:29:46.088353] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T01:29:46.102029] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T01:29:46.124009] [POD_MGR] Pod flink-jobmanager-7d7c784b74-ll4wm deleted
[0m[2025-01-22T01:29:48.025122] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:29:49.915708] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:29:49.915776] Reloading playbook: application/kafka
[0m[2025-01-22T01:29:55.938172] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T01:30:41.892302] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T01:30:41.892596] [EXPERIMENT] Run 2 completed. Start: 1737509125, End: 1737509441
[0m[2025-01-22T01:30:41.892604] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T01:30:51.893649] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T01:30:53.810470] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:30:55.669976] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:30:55.670191] [SCALING] Setting up experiment.


[0m[2025-01-22T01:30:55.670282] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:30:55.675929] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:30:55.699936] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T01:30:55.720080] [SCALING] Statefulset name to scale : flink-4000m-8192
[0m[2025-01-22T01:30:55.729964] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 1 replica.
[0m[2025-01-22T01:31:00.739142] [FLK_MGR] Running job.
[0m[2025-01-22T01:31:00.739170] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T01:31:01.202594] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-js2vc
[0m[2025-01-22T01:31:05.229379] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0f6aab877413bbce31f934b687275732

[0m[2025-01-22T01:31:05.229430] [FLK_MGR] Running job id: 0f6aab877413bbce31f934b687275732
[0m[2025-01-22T01:31:05.229437] [FLK_MGR] Getting job info.
[0m[2025-01-22T01:31:05.248795] [FLK_MGR] Job plan response: {"plan":{"jid":"0f6aab877413bbce31f934b687275732","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T01:31:05.248941] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T01:31:05.698136] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-js2vc
[0m[2025-01-22T01:31:07.131507] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 01:31:04 : 0f6aab877413bbce31f934b687275732 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T01:31:07.131569] [FLK_MGR] Running jobs: ['0f6aab877413bbce31f934b687275732']
[0m[2025-01-22T01:31:07.131576] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T01:31:07.131586] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T01:35:07.158771] [SCALING] Scaling started.
[0m[2025-01-22T01:35:07.158881] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T01:35:07.173579] [SCALING] Scaling finished.
[0m[2025-01-22T01:35:07.173602] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:35:07.193369] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:35:07.211223] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T01:35:07.234445] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 0 replica.
[0m[2025-01-22T01:35:17.262115] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T01:35:17.277447] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T01:35:17.292013] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T01:35:17.305113] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T01:35:17.319386] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T01:35:17.351081] [POD_MGR] Pod flink-jobmanager-7d7c784b74-js2vc deleted
[0m[2025-01-22T01:35:19.250334] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:35:21.186488] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:35:21.186676] Reloading playbook: application/kafka
[0m[2025-01-22T01:35:27.130770] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T01:36:13.073012] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T01:36:13.073167] [EXPERIMENT] Run 3 completed. Start: 1737509451, End: 1737509773
[0m[2025-01-22T01:36:13.073174] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T01:36:23.074180] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T01:36:24.968777] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:36:26.833489] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:36:26.833551] [SCALING] Setting up experiment.


[0m[2025-01-22T01:36:26.833559] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:36:26.838558] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:36:26.852944] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T01:36:26.867613] [SCALING] Statefulset name to scale : flink-4000m-8192
[0m[2025-01-22T01:36:26.878543] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 1 replica.
[0m[2025-01-22T01:36:31.888835] [FLK_MGR] Running job.
[0m[2025-01-22T01:36:31.888883] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T01:36:32.361456] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-b4wpw
[0m[2025-01-22T01:36:36.521889] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0dea68bfeee12ed5f9ecd98847879390

[0m[2025-01-22T01:36:36.521939] [FLK_MGR] Running job id: 0dea68bfeee12ed5f9ecd98847879390
[0m[2025-01-22T01:36:36.521946] [FLK_MGR] Getting job info.
[0m[2025-01-22T01:36:36.539971] [FLK_MGR] Job plan response: {"plan":{"jid":"0dea68bfeee12ed5f9ecd98847879390","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T01:36:36.540200] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T01:36:36.930851] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-b4wpw
[0m[2025-01-22T01:36:38.388771] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 01:36:35 : 0dea68bfeee12ed5f9ecd98847879390 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T01:36:38.388827] [FLK_MGR] Running jobs: ['0dea68bfeee12ed5f9ecd98847879390']
[0m[2025-01-22T01:36:38.388834] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T01:36:38.388845] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T01:40:38.411000] [SCALING] Scaling started.
[0m[2025-01-22T01:40:38.411100] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T01:40:38.426054] [SCALING] Scaling finished.
[0m[2025-01-22T01:40:38.426079] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:40:38.445280] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:40:38.464929] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T01:40:38.486819] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 0 replica.
[0m[2025-01-22T01:40:43.510530] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T01:40:43.525074] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T01:40:43.540839] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T01:40:43.554729] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T01:40:43.568242] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T01:40:43.602331] [POD_MGR] Pod flink-jobmanager-7d7c784b74-b4wpw deleted
[0m[2025-01-22T01:40:45.472431] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:40:47.383865] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:40:47.383930] Reloading playbook: application/kafka
[0m[2025-01-22T01:40:53.371143] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T01:41:39.330458] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T01:41:39.330537] [EXPERIMENT] Run 4 completed. Start: 1737509783, End: 1737510099
[0m[2025-01-22T01:41:39.330542] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T01:41:49.331537] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T01:41:51.230527] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:41:53.103061] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:41:53.103126] [SCALING] Setting up experiment.


[0m[2025-01-22T01:41:53.103135] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:41:53.109934] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:41:53.125197] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T01:41:53.141991] [SCALING] Statefulset name to scale : flink-4000m-8192
[0m[2025-01-22T01:41:53.152159] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 1 replica.
[0m[2025-01-22T01:41:58.161702] [FLK_MGR] Running job.
[0m[2025-01-22T01:41:58.161731] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T01:41:58.539781] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-m2m6s
[0m[2025-01-22T01:42:02.626707] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c4bee59f5f8743b3579032a5f74542b5

[0m[2025-01-22T01:42:02.626786] [FLK_MGR] Running job id: c4bee59f5f8743b3579032a5f74542b5
[0m[2025-01-22T01:42:02.626797] [FLK_MGR] Getting job info.
[0m[2025-01-22T01:42:02.644994] [FLK_MGR] Job plan response: {"plan":{"jid":"c4bee59f5f8743b3579032a5f74542b5","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T01:42:02.645151] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T01:42:03.098408] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-m2m6s
[0m[2025-01-22T01:42:04.552189] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 01:42:01 : c4bee59f5f8743b3579032a5f74542b5 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T01:42:04.552251] [FLK_MGR] Running jobs: ['c4bee59f5f8743b3579032a5f74542b5']
[0m[2025-01-22T01:42:04.552258] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T01:42:04.552289] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T01:46:04.575703] [SCALING] Scaling started.
[0m[2025-01-22T01:46:04.575834] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T01:46:04.589704] [SCALING] Scaling finished.
[0m[2025-01-22T01:46:04.589730] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:46:04.609697] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:46:04.627128] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T01:46:04.648546] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 0 replica.
[0m[2025-01-22T01:46:09.670131] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T01:46:09.684776] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T01:46:09.699272] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T01:46:09.714038] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T01:46:09.729225] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T01:46:09.752215] [POD_MGR] Pod flink-jobmanager-7d7c784b74-m2m6s deleted
[0m[2025-01-22T01:46:11.662848] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:46:13.547533] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:46:13.547596] Reloading playbook: application/kafka
[0m[2025-01-22T01:46:19.529657] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T01:47:05.531574] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T01:47:05.531706] [EXPERIMENT] Run 5 completed. Start: 1737510109, End: 1737510425
[0m[2025-01-22T01:47:05.531713] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T01:47:17.782944] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T01:47:17.782999] [RESOURCE_E] Running experiment with 4000m cores and 16384 memory.
[0m[2025-01-22T01:47:25.040389] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T01:47:25.040457] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T01:47:26.915668] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:47:28.805581] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:47:28.805640] [SCALING] Setting up experiment.


[0m[2025-01-22T01:47:28.805649] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:47:28.810898] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:47:28.826035] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T01:47:28.843778] [SCALING] Statefulset name to scale : flink-4000m-16384
[0m[2025-01-22T01:47:28.854550] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 1 replica.
[0m[2025-01-22T01:47:33.865018] [FLK_MGR] Running job.
[0m[2025-01-22T01:47:33.865048] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T01:47:34.290012] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-v9l6r
[0m[2025-01-22T01:47:38.506597] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 7b5fef6c963f3e4de6e8b373f4acdee8

[0m[2025-01-22T01:47:38.506646] [FLK_MGR] Running job id: 7b5fef6c963f3e4de6e8b373f4acdee8
[0m[2025-01-22T01:47:38.506653] [FLK_MGR] Getting job info.
[0m[2025-01-22T01:47:38.523897] [FLK_MGR] Job plan response: {"plan":{"jid":"7b5fef6c963f3e4de6e8b373f4acdee8","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T01:47:38.524033] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T01:47:38.993362] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-v9l6r
[0m[2025-01-22T01:47:40.429082] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 01:47:37 : 7b5fef6c963f3e4de6e8b373f4acdee8 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T01:47:40.429139] [FLK_MGR] Running jobs: ['7b5fef6c963f3e4de6e8b373f4acdee8']
[0m[2025-01-22T01:47:40.429146] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T01:47:40.429152] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T01:51:40.452658] [SCALING] Scaling started.
[0m[2025-01-22T01:51:40.452719] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T01:51:40.464918] [SCALING] Scaling finished.
[0m[2025-01-22T01:51:40.464936] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:51:40.483710] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:51:40.500653] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T01:51:40.520937] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 0 replica.
[0m[2025-01-22T01:51:45.544391] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T01:51:45.557247] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T01:51:45.570224] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T01:51:45.583441] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T01:51:45.597354] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T01:51:45.620589] [POD_MGR] Pod flink-jobmanager-7d7c784b74-v9l6r deleted
[0m[2025-01-22T01:51:47.519569] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:51:49.357603] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:51:49.357667] Reloading playbook: application/kafka
[0m[2025-01-22T01:51:55.379652] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T01:52:41.361339] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T01:52:41.361457] [EXPERIMENT] Run 1 completed. Start: 1737510445, End: 1737510761
[0m[2025-01-22T01:52:41.361465] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T01:52:51.362593] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T01:52:53.204725] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:52:55.077382] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:52:55.077435] [SCALING] Setting up experiment.


[0m[2025-01-22T01:52:55.077443] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:52:55.085072] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:52:55.101380] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T01:52:55.117317] [SCALING] Statefulset name to scale : flink-4000m-16384
[0m[2025-01-22T01:52:55.129159] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 1 replica.
[0m[2025-01-22T01:53:00.139357] [FLK_MGR] Running job.
[0m[2025-01-22T01:53:00.139384] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T01:53:00.609100] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-zvhmx
[0m[2025-01-22T01:53:04.799262] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 14e893af6c893513ac419dc0c1ba94ee

[0m[2025-01-22T01:53:04.799316] [FLK_MGR] Running job id: 14e893af6c893513ac419dc0c1ba94ee
[0m[2025-01-22T01:53:04.799326] [FLK_MGR] Getting job info.
[0m[2025-01-22T01:53:04.818812] [FLK_MGR] Job plan response: {"plan":{"jid":"14e893af6c893513ac419dc0c1ba94ee","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T01:53:04.818948] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T01:53:05.187671] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-zvhmx
[0m[2025-01-22T01:53:06.643887] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 01:53:03 : 14e893af6c893513ac419dc0c1ba94ee : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T01:53:06.643942] [FLK_MGR] Running jobs: ['14e893af6c893513ac419dc0c1ba94ee']
[0m[2025-01-22T01:53:06.643949] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T01:53:06.643970] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T01:57:06.667721] [SCALING] Scaling started.
[0m[2025-01-22T01:57:06.667841] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T01:57:06.680208] [SCALING] Scaling finished.
[0m[2025-01-22T01:57:06.680235] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:57:06.700582] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:57:06.787619] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T01:57:06.809790] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 0 replica.
[0m[2025-01-22T01:57:16.834594] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T01:57:16.847314] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T01:57:16.860080] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T01:57:16.872694] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T01:57:16.885416] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T01:57:16.913863] [POD_MGR] Pod flink-jobmanager-7d7c784b74-zvhmx deleted
[0m[2025-01-22T01:57:18.797762] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:57:20.715595] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T01:57:20.715658] Reloading playbook: application/kafka
[0m[2025-01-22T01:57:26.729515] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T01:58:12.725806] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T01:58:12.725946] [EXPERIMENT] Run 2 completed. Start: 1737510771, End: 1737511092
[0m[2025-01-22T01:58:12.725952] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T01:58:22.726975] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T01:58:24.609946] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:58:26.467726] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T01:58:26.467785] [SCALING] Setting up experiment.


[0m[2025-01-22T01:58:26.467794] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T01:58:26.473505] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T01:58:26.490424] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T01:58:26.508511] [SCALING] Statefulset name to scale : flink-4000m-16384
[0m[2025-01-22T01:58:26.518321] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 1 replica.
[0m[2025-01-22T01:58:31.529854] [FLK_MGR] Running job.
[0m[2025-01-22T01:58:31.529882] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T01:58:31.903684] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-nklwz
[0m[2025-01-22T01:58:36.055822] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 026c12416070b6ca4f3bed8eed832521

[0m[2025-01-22T01:58:36.055878] [FLK_MGR] Running job id: 026c12416070b6ca4f3bed8eed832521
[0m[2025-01-22T01:58:36.055889] [FLK_MGR] Getting job info.
[0m[2025-01-22T01:58:36.075724] [FLK_MGR] Job plan response: {"plan":{"jid":"026c12416070b6ca4f3bed8eed832521","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T01:58:36.075866] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T01:58:36.511610] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-nklwz
[0m[2025-01-22T01:58:37.950929] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 01:58:35 : 026c12416070b6ca4f3bed8eed832521 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T01:58:37.950982] [FLK_MGR] Running jobs: ['026c12416070b6ca4f3bed8eed832521']
[0m[2025-01-22T01:58:37.950991] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T01:58:37.950997] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T02:02:37.973515] [SCALING] Scaling started.
[0m[2025-01-22T02:02:37.973567] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T02:02:37.987590] [SCALING] Scaling finished.
[0m[2025-01-22T02:02:37.987611] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:02:38.006237] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:02:38.030602] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T02:02:38.052736] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 0 replica.
[0m[2025-01-22T02:02:43.073449] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T02:02:43.087375] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T02:02:43.101286] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T02:02:43.115931] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T02:02:43.129658] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T02:02:43.152179] [POD_MGR] Pod flink-jobmanager-7d7c784b74-nklwz deleted
[0m[2025-01-22T02:02:45.002562] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:02:46.883833] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:02:46.883900] Reloading playbook: application/kafka
[0m[2025-01-22T02:02:52.887892] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T02:03:38.821360] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T02:03:38.821722] [EXPERIMENT] Run 3 completed. Start: 1737511102, End: 1737511418
[0m[2025-01-22T02:03:38.821746] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T02:03:48.822828] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T02:03:50.682701] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:03:52.568541] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:03:52.568598] [SCALING] Setting up experiment.


[0m[2025-01-22T02:03:52.568607] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:03:52.573763] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:03:52.590123] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T02:03:52.607641] [SCALING] Statefulset name to scale : flink-4000m-16384
[0m[2025-01-22T02:03:52.617355] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 1 replica.
[0m[2025-01-22T02:03:57.627148] [FLK_MGR] Running job.
[0m[2025-01-22T02:03:57.627175] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T02:03:58.054283] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-g2v2b
[0m[2025-01-22T02:04:02.220970] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fd362f98cd3598d2a8a5d1c83d573dfb

[0m[2025-01-22T02:04:02.221024] [FLK_MGR] Running job id: fd362f98cd3598d2a8a5d1c83d573dfb
[0m[2025-01-22T02:04:02.221035] [FLK_MGR] Getting job info.
[0m[2025-01-22T02:04:02.239065] [FLK_MGR] Job plan response: {"plan":{"jid":"fd362f98cd3598d2a8a5d1c83d573dfb","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T02:04:02.239213] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T02:04:02.678093] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-g2v2b
[0m[2025-01-22T02:04:04.095814] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 02:04:01 : fd362f98cd3598d2a8a5d1c83d573dfb : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T02:04:04.095871] [FLK_MGR] Running jobs: ['fd362f98cd3598d2a8a5d1c83d573dfb']
[0m[2025-01-22T02:04:04.095878] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T02:04:04.095884] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T02:08:04.120785] [SCALING] Scaling started.
[0m[2025-01-22T02:08:04.120883] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T02:08:04.134895] [SCALING] Scaling finished.
[0m[2025-01-22T02:08:04.134913] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:08:04.151662] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:08:04.170035] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T02:08:04.191244] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 0 replica.
[0m[2025-01-22T02:08:14.218815] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T02:08:14.231830] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T02:08:14.246624] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T02:08:14.262974] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T02:08:14.277601] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T02:08:14.312078] [POD_MGR] Pod flink-jobmanager-7d7c784b74-g2v2b deleted
[0m[2025-01-22T02:08:16.203631] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:08:18.119190] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:08:18.119254] Reloading playbook: application/kafka
[0m[2025-01-22T02:08:24.116464] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T02:09:10.063013] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T02:09:10.063141] [EXPERIMENT] Run 4 completed. Start: 1737511428, End: 1737511750
[0m[2025-01-22T02:09:10.063147] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T02:09:20.064236] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T02:09:21.936207] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:09:23.816967] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:09:23.817024] [SCALING] Setting up experiment.


[0m[2025-01-22T02:09:23.817032] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:09:23.822625] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:09:23.838525] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T02:09:23.855530] [SCALING] Statefulset name to scale : flink-4000m-16384
[0m[2025-01-22T02:09:23.866867] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 1 replica.
[0m[2025-01-22T02:09:28.877129] [FLK_MGR] Running job.
[0m[2025-01-22T02:09:28.877157] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T02:09:29.312625] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-pq9nr
[0m[2025-01-22T02:09:33.428298] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 61f1860cb76f4ebf657a876cab2ee481

[0m[2025-01-22T02:09:33.428350] [FLK_MGR] Running job id: 61f1860cb76f4ebf657a876cab2ee481
[0m[2025-01-22T02:09:33.428357] [FLK_MGR] Getting job info.
[0m[2025-01-22T02:09:33.446262] [FLK_MGR] Job plan response: {"plan":{"jid":"61f1860cb76f4ebf657a876cab2ee481","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T02:09:33.446398] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T02:09:33.871639] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-pq9nr
[0m[2025-01-22T02:09:35.318288] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 02:09:32 : 61f1860cb76f4ebf657a876cab2ee481 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T02:09:35.318342] [FLK_MGR] Running jobs: ['61f1860cb76f4ebf657a876cab2ee481']
[0m[2025-01-22T02:09:35.318349] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T02:09:35.318356] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T02:13:35.341440] [SCALING] Scaling started.
[0m[2025-01-22T02:13:35.341491] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T02:13:35.354673] [SCALING] Scaling finished.
[0m[2025-01-22T02:13:35.354695] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:13:35.375605] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:13:35.393126] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T02:13:35.415278] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 0 replica.
[0m[2025-01-22T02:13:45.441863] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T02:13:45.455123] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T02:13:45.467913] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T02:13:45.481302] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T02:13:45.496371] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T02:13:45.543200] [POD_MGR] Pod flink-jobmanager-7d7c784b74-pq9nr deleted
[0m[2025-01-22T02:13:47.432000] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:13:49.339395] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:13:49.339455] Reloading playbook: application/kafka
[0m[2025-01-22T02:13:55.360579] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T02:14:41.341020] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T02:14:41.341144] [EXPERIMENT] Run 5 completed. Start: 1737511760, End: 1737512081
[0m[2025-01-22T02:14:41.341150] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T02:14:53.584961] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T02:14:53.585022] [RESOURCE_E] Running experiment with 4000m cores and 32768 memory.
[0m[2025-01-22T02:15:00.846276] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T02:15:00.846340] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T02:15:02.701740] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:15:04.574568] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:15:04.574627] [SCALING] Setting up experiment.


[0m[2025-01-22T02:15:04.574635] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:15:04.580100] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:15:04.598587] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T02:15:04.616143] [SCALING] Statefulset name to scale : flink-4000m-32768
[0m[2025-01-22T02:15:04.627966] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 1 replica.
[0m[2025-01-22T02:15:09.637712] [FLK_MGR] Running job.
[0m[2025-01-22T02:15:09.637740] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T02:15:10.076831] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-vjfct
[0m[2025-01-22T02:15:14.172736] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID da41cbb8d6f1deab6e5971f83367912b

[0m[2025-01-22T02:15:14.172786] [FLK_MGR] Running job id: da41cbb8d6f1deab6e5971f83367912b
[0m[2025-01-22T02:15:14.172794] [FLK_MGR] Getting job info.
[0m[2025-01-22T02:15:14.190133] [FLK_MGR] Job plan response: {"plan":{"jid":"da41cbb8d6f1deab6e5971f83367912b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T02:15:14.190283] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T02:15:14.566425] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-vjfct
[0m[2025-01-22T02:15:16.012504] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 02:15:13 : da41cbb8d6f1deab6e5971f83367912b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T02:15:16.012556] [FLK_MGR] Running jobs: ['da41cbb8d6f1deab6e5971f83367912b']
[0m[2025-01-22T02:15:16.012563] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T02:15:16.012569] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T02:19:16.035068] [SCALING] Scaling started.
[0m[2025-01-22T02:19:16.035162] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T02:19:16.048702] [SCALING] Scaling finished.
[0m[2025-01-22T02:19:16.048721] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:19:16.067913] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:19:16.085077] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T02:19:16.105056] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 0 replica.
[0m[2025-01-22T02:19:26.131227] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T02:19:26.144092] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T02:19:26.156653] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T02:19:26.169216] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T02:19:26.181878] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T02:19:26.220710] [POD_MGR] Pod flink-jobmanager-7d7c784b74-vjfct deleted
[0m[2025-01-22T02:19:28.136654] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:19:30.052193] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:19:30.052254] Reloading playbook: application/kafka
[0m[2025-01-22T02:19:36.033782] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T02:20:22.003338] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T02:20:22.003470] [EXPERIMENT] Run 1 completed. Start: 1737512100, End: 1737512422
[0m[2025-01-22T02:20:22.003476] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T02:20:32.004567] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T02:20:33.849781] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:20:35.731377] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:20:35.731435] [SCALING] Setting up experiment.


[0m[2025-01-22T02:20:35.731443] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:20:35.736695] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:20:35.752690] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T02:20:35.770040] [SCALING] Statefulset name to scale : flink-4000m-32768
[0m[2025-01-22T02:20:35.780575] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 1 replica.
[0m[2025-01-22T02:20:40.791081] [FLK_MGR] Running job.
[0m[2025-01-22T02:20:40.791110] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T02:20:41.207590] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-qt8rw
[0m[2025-01-22T02:20:45.345387] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9baf6cf0d9eabb95806d88b7da53c27a

[0m[2025-01-22T02:20:45.345439] [FLK_MGR] Running job id: 9baf6cf0d9eabb95806d88b7da53c27a
[0m[2025-01-22T02:20:45.345449] [FLK_MGR] Getting job info.
[0m[2025-01-22T02:20:45.365422] [FLK_MGR] Job plan response: {"plan":{"jid":"9baf6cf0d9eabb95806d88b7da53c27a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T02:20:45.365601] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T02:20:45.808311] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-qt8rw
[0m[2025-01-22T02:20:47.274105] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 02:20:44 : 9baf6cf0d9eabb95806d88b7da53c27a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T02:20:47.274160] [FLK_MGR] Running jobs: ['9baf6cf0d9eabb95806d88b7da53c27a']
[0m[2025-01-22T02:20:47.274165] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T02:20:47.274171] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T02:24:47.299634] [SCALING] Scaling started.
[0m[2025-01-22T02:24:47.299739] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T02:24:47.314077] [SCALING] Scaling finished.
[0m[2025-01-22T02:24:47.314095] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:24:47.332543] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:24:47.348907] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T02:24:47.370140] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 0 replica.
[0m[2025-01-22T02:24:52.390499] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T02:24:52.404031] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T02:24:52.417343] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T02:24:52.430160] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T02:24:52.442986] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T02:24:52.470197] [POD_MGR] Pod flink-jobmanager-7d7c784b74-qt8rw deleted
[0m[2025-01-22T02:24:54.380600] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:24:56.247600] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:24:56.247671] Reloading playbook: application/kafka
[0m[2025-01-22T02:25:02.168535] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T02:25:48.137678] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T02:25:48.137799] [EXPERIMENT] Run 2 completed. Start: 1737512432, End: 1737512748
[0m[2025-01-22T02:25:48.137805] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T02:25:58.138836] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T02:26:00.002933] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:26:01.896374] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:26:01.896427] [SCALING] Setting up experiment.


[0m[2025-01-22T02:26:01.896435] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:26:01.902106] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:26:01.919743] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T02:26:01.939106] [SCALING] Statefulset name to scale : flink-4000m-32768
[0m[2025-01-22T02:26:01.950265] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 1 replica.
[0m[2025-01-22T02:26:06.960012] [FLK_MGR] Running job.
[0m[2025-01-22T02:26:06.960040] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T02:26:07.395556] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-9mgg8
[0m[2025-01-22T02:26:11.440636] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 92182c12d386adb110a1acc05b0947f4

[0m[2025-01-22T02:26:11.440690] [FLK_MGR] Running job id: 92182c12d386adb110a1acc05b0947f4
[0m[2025-01-22T02:26:11.440696] [FLK_MGR] Getting job info.
[0m[2025-01-22T02:26:11.458644] [FLK_MGR] Job plan response: {"plan":{"jid":"92182c12d386adb110a1acc05b0947f4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T02:26:11.458784] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T02:26:11.878700] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-9mgg8
[0m[2025-01-22T02:26:13.346953] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 02:26:10 : 92182c12d386adb110a1acc05b0947f4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T02:26:13.347014] [FLK_MGR] Running jobs: ['92182c12d386adb110a1acc05b0947f4']
[0m[2025-01-22T02:26:13.347022] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T02:26:13.347029] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T02:30:13.370004] [SCALING] Scaling started.
[0m[2025-01-22T02:30:13.370053] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T02:30:13.383555] [SCALING] Scaling finished.
[0m[2025-01-22T02:30:13.383577] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:30:13.408875] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:30:13.427174] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T02:30:13.450042] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 0 replica.
[0m[2025-01-22T02:30:23.477334] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T02:30:23.491914] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T02:30:23.505849] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T02:30:23.519023] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T02:30:23.532352] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T02:30:23.562133] [POD_MGR] Pod flink-jobmanager-7d7c784b74-9mgg8 deleted
[0m[2025-01-22T02:30:25.476272] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:30:27.371324] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:30:27.371391] Reloading playbook: application/kafka
[0m[2025-01-22T02:30:33.300844] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T02:31:19.239287] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T02:31:19.239428] [EXPERIMENT] Run 3 completed. Start: 1737512758, End: 1737513079
[0m[2025-01-22T02:31:19.239435] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T02:31:29.240476] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T02:31:31.099040] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:31:32.962758] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:31:32.962819] [SCALING] Setting up experiment.


[0m[2025-01-22T02:31:32.962827] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:31:32.967928] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:31:32.984050] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T02:31:32.999786] [SCALING] Statefulset name to scale : flink-4000m-32768
[0m[2025-01-22T02:31:33.009446] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 1 replica.
[0m[2025-01-22T02:31:38.018047] [FLK_MGR] Running job.
[0m[2025-01-22T02:31:38.018076] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T02:31:38.461565] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-znpj8
[0m[2025-01-22T02:31:42.523911] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 95c15d771e5b040c25293e76c5cd94a4

[0m[2025-01-22T02:31:42.523959] [FLK_MGR] Running job id: 95c15d771e5b040c25293e76c5cd94a4
[0m[2025-01-22T02:31:42.523967] [FLK_MGR] Getting job info.
[0m[2025-01-22T02:31:42.542019] [FLK_MGR] Job plan response: {"plan":{"jid":"95c15d771e5b040c25293e76c5cd94a4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T02:31:42.542162] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T02:31:42.910057] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-znpj8
[0m[2025-01-22T02:31:44.364878] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 02:31:41 : 95c15d771e5b040c25293e76c5cd94a4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T02:31:44.364935] [FLK_MGR] Running jobs: ['95c15d771e5b040c25293e76c5cd94a4']
[0m[2025-01-22T02:31:44.364942] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T02:31:44.364949] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T02:35:44.387908] [SCALING] Scaling started.
[0m[2025-01-22T02:35:44.388003] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T02:35:44.400333] [SCALING] Scaling finished.
[0m[2025-01-22T02:35:44.400352] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:35:44.420338] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:35:44.437870] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T02:35:44.461037] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 0 replica.
[0m[2025-01-22T02:35:54.488922] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T02:35:54.503357] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T02:35:54.517156] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T02:35:54.529855] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T02:35:54.543909] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T02:35:54.567017] [POD_MGR] Pod flink-jobmanager-7d7c784b74-znpj8 deleted
[0m[2025-01-22T02:35:56.475132] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:35:58.374583] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:35:58.374648] Reloading playbook: application/kafka
[0m[2025-01-22T02:36:04.334638] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T02:36:50.294952] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T02:36:50.295077] [EXPERIMENT] Run 4 completed. Start: 1737513089, End: 1737513410
[0m[2025-01-22T02:36:50.295083] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T02:37:00.296176] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T02:37:02.162864] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:37:04.054554] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:37:04.054694] [SCALING] Setting up experiment.


[0m[2025-01-22T02:37:04.054714] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:37:04.060198] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:37:04.154052] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T02:37:04.171251] [SCALING] Statefulset name to scale : flink-4000m-32768
[0m[2025-01-22T02:37:04.183082] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 1 replica.
[0m[2025-01-22T02:37:09.194425] [FLK_MGR] Running job.
[0m[2025-01-22T02:37:09.194450] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T02:37:09.568024] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xn7fj
[0m[2025-01-22T02:37:13.625855] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 596c2b5972391cb242d20095954f093f

[0m[2025-01-22T02:37:13.625900] [FLK_MGR] Running job id: 596c2b5972391cb242d20095954f093f
[0m[2025-01-22T02:37:13.625908] [FLK_MGR] Getting job info.
[0m[2025-01-22T02:37:13.643664] [FLK_MGR] Job plan response: {"plan":{"jid":"596c2b5972391cb242d20095954f093f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T02:37:13.643809] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T02:37:14.074108] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xn7fj
[0m[2025-01-22T02:37:15.522969] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 02:37:12 : 596c2b5972391cb242d20095954f093f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T02:37:15.523024] [FLK_MGR] Running jobs: ['596c2b5972391cb242d20095954f093f']
[0m[2025-01-22T02:37:15.523030] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T02:37:15.523036] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T02:41:15.547755] [SCALING] Scaling started.
[0m[2025-01-22T02:41:15.547815] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T02:41:15.562119] [SCALING] Scaling finished.
[0m[2025-01-22T02:41:15.562142] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:41:15.580270] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:41:15.597768] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T02:41:15.617440] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 0 replica.
[0m[2025-01-22T02:41:20.640783] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T02:41:20.655692] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T02:41:20.670639] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T02:41:20.686340] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T02:41:20.701544] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T02:41:20.736416] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xn7fj deleted
[0m[2025-01-22T02:41:22.597550] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:41:24.521070] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:41:24.521136] Reloading playbook: application/kafka
[0m[2025-01-22T02:41:30.432063] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T02:42:16.383591] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T02:42:16.383716] [EXPERIMENT] Run 5 completed. Start: 1737513420, End: 1737513736
[0m[2025-01-22T02:42:16.383722] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T02:42:28.617427] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T02:42:28.617528] [RESOURCE_E] Running experiment with 8000m cores and 1024 memory.
[0m[2025-01-22T02:42:35.751353] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T02:42:35.751415] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T02:42:37.639829] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:42:39.506074] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:42:39.506134] [SCALING] Setting up experiment.


[0m[2025-01-22T02:42:39.506144] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:42:39.512037] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:42:39.526712] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T02:42:39.543971] [SCALING] Statefulset name to scale : flink-8000m-1024
[0m[2025-01-22T02:42:39.553306] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 1 replica.
[0m[2025-01-22T02:42:44.563044] [FLK_MGR] Running job.
[0m[2025-01-22T02:42:44.563071] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T02:42:44.992083] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-cfgdr
[0m[2025-01-22T02:42:49.048582] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 957ccbb769d11894cc8cb9061fabddde

[0m[2025-01-22T02:42:49.048627] [FLK_MGR] Running job id: 957ccbb769d11894cc8cb9061fabddde
[0m[2025-01-22T02:42:49.048634] [FLK_MGR] Getting job info.
[0m[2025-01-22T02:42:49.066137] [FLK_MGR] Job plan response: {"plan":{"jid":"957ccbb769d11894cc8cb9061fabddde","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T02:42:49.066288] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T02:42:49.476607] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-cfgdr
[0m[2025-01-22T02:42:50.922401] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 02:42:48 : 957ccbb769d11894cc8cb9061fabddde : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T02:42:50.922453] [FLK_MGR] Running jobs: ['957ccbb769d11894cc8cb9061fabddde']
[0m[2025-01-22T02:42:50.922459] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T02:42:50.922466] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T02:46:50.945437] [SCALING] Scaling started.
[0m[2025-01-22T02:46:50.945487] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T02:46:50.958210] [SCALING] Scaling finished.
[0m[2025-01-22T02:46:50.958232] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:46:50.976417] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:46:50.993961] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T02:46:51.014569] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 0 replica.
[0m[2025-01-22T02:46:51.033658] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T02:46:51.049084] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T02:46:51.062499] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T02:46:51.075714] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T02:46:51.090131] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T02:46:51.120470] [POD_MGR] Pod flink-jobmanager-7d7c784b74-cfgdr deleted
[0m[2025-01-22T02:46:53.075143] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:46:54.966056] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:46:54.966141] Reloading playbook: application/kafka
[0m[2025-01-22T02:47:00.928954] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T02:47:46.933792] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T02:47:46.933992] [EXPERIMENT] Run 1 completed. Start: 1737513755, End: 1737514066
[0m[2025-01-22T02:47:46.933999] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T02:47:56.935182] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T02:47:58.802794] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:48:00.677913] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:48:00.677967] [SCALING] Setting up experiment.


[0m[2025-01-22T02:48:00.677978] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:48:00.684010] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:48:00.699167] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T02:48:00.718811] [SCALING] Statefulset name to scale : flink-8000m-1024
[0m[2025-01-22T02:48:00.730934] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 1 replica.
[0m[2025-01-22T02:48:05.741270] [FLK_MGR] Running job.
[0m[2025-01-22T02:48:05.741300] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T02:48:06.207286] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-gv2st
[0m[2025-01-22T02:48:10.321829] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 686826e0088e5ff2ffb6e69fd3d95303

[0m[2025-01-22T02:48:10.321880] [FLK_MGR] Running job id: 686826e0088e5ff2ffb6e69fd3d95303
[0m[2025-01-22T02:48:10.321887] [FLK_MGR] Getting job info.
[0m[2025-01-22T02:48:10.340005] [FLK_MGR] Job plan response: {"plan":{"jid":"686826e0088e5ff2ffb6e69fd3d95303","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T02:48:10.340138] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T02:48:10.728333] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-gv2st
[0m[2025-01-22T02:48:12.152410] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 02:48:09 : 686826e0088e5ff2ffb6e69fd3d95303 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T02:48:12.152467] [FLK_MGR] Running jobs: ['686826e0088e5ff2ffb6e69fd3d95303']
[0m[2025-01-22T02:48:12.152476] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T02:48:12.152483] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T02:52:12.175956] [SCALING] Scaling started.
[0m[2025-01-22T02:52:12.176008] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T02:52:12.189473] [SCALING] Scaling finished.
[0m[2025-01-22T02:52:12.189497] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:52:12.207094] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:52:12.225502] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T02:52:12.296987] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 0 replica.
[0m[2025-01-22T02:52:12.319487] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T02:52:12.334756] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T02:52:12.349431] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T02:52:12.363737] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T02:52:12.378685] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T02:52:12.405355] [POD_MGR] Pod flink-jobmanager-7d7c784b74-gv2st deleted
[0m[2025-01-22T02:52:14.322821] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:52:16.248134] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:52:16.248201] Reloading playbook: application/kafka
[0m[2025-01-22T02:52:22.261355] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T02:53:08.245031] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T02:53:08.245155] [EXPERIMENT] Run 2 completed. Start: 1737514076, End: 1737514388
[0m[2025-01-22T02:53:08.245161] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T02:53:18.246263] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T02:53:20.146459] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:53:22.020073] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:53:22.020136] [SCALING] Setting up experiment.


[0m[2025-01-22T02:53:22.020145] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:53:22.025213] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:53:22.041430] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T02:53:22.058184] [SCALING] Statefulset name to scale : flink-8000m-1024
[0m[2025-01-22T02:53:22.069563] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 1 replica.
[0m[2025-01-22T02:53:27.079994] [FLK_MGR] Running job.
[0m[2025-01-22T02:53:27.080026] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T02:53:27.473641] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-92tnx
[0m[2025-01-22T02:53:31.612364] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 65053936524e1eb0d07addb9b39c2dff

[0m[2025-01-22T02:53:31.612414] [FLK_MGR] Running job id: 65053936524e1eb0d07addb9b39c2dff
[0m[2025-01-22T02:53:31.612422] [FLK_MGR] Getting job info.
[0m[2025-01-22T02:53:31.630209] [FLK_MGR] Job plan response: {"plan":{"jid":"65053936524e1eb0d07addb9b39c2dff","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T02:53:31.630358] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T02:53:32.042208] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-92tnx
[0m[2025-01-22T02:53:33.483618] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 02:53:30 : 65053936524e1eb0d07addb9b39c2dff : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T02:53:33.483672] [FLK_MGR] Running jobs: ['65053936524e1eb0d07addb9b39c2dff']
[0m[2025-01-22T02:53:33.483679] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T02:53:33.483684] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T02:57:33.509067] [SCALING] Scaling started.
[0m[2025-01-22T02:57:33.509129] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T02:57:33.523572] [SCALING] Scaling finished.
[0m[2025-01-22T02:57:33.523602] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:57:33.542199] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:57:33.558899] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T02:57:33.579056] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 0 replica.
[0m[2025-01-22T02:57:33.595346] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T02:57:33.609187] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T02:57:33.623242] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T02:57:33.636715] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T02:57:33.651600] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T02:57:33.692299] [POD_MGR] Pod flink-jobmanager-7d7c784b74-92tnx deleted
[0m[2025-01-22T02:57:35.587739] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:57:37.458267] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T02:57:37.458504] Reloading playbook: application/kafka
[0m[2025-01-22T02:57:43.469969] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T02:58:29.445931] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T02:58:29.446156] [EXPERIMENT] Run 3 completed. Start: 1737514398, End: 1737514709
[0m[2025-01-22T02:58:29.446185] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T02:58:39.447150] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T02:58:41.344165] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:58:43.244506] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T02:58:43.244567] [SCALING] Setting up experiment.


[0m[2025-01-22T02:58:43.244578] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T02:58:43.250747] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T02:58:43.266610] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T02:58:43.288464] [SCALING] Statefulset name to scale : flink-8000m-1024
[0m[2025-01-22T02:58:43.299224] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 1 replica.
[0m[2025-01-22T02:58:48.309758] [FLK_MGR] Running job.
[0m[2025-01-22T02:58:48.309834] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T02:58:48.751250] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jrdjn
[0m[2025-01-22T02:58:52.825265] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 39a8f262c060e76963eb911787f0c638

[0m[2025-01-22T02:58:52.825314] [FLK_MGR] Running job id: 39a8f262c060e76963eb911787f0c638
[0m[2025-01-22T02:58:52.825323] [FLK_MGR] Getting job info.
[0m[2025-01-22T02:58:52.843935] [FLK_MGR] Job plan response: {"plan":{"jid":"39a8f262c060e76963eb911787f0c638","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T02:58:52.844097] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T02:58:53.265377] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jrdjn
[0m[2025-01-22T02:58:54.705824] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 02:58:51 : 39a8f262c060e76963eb911787f0c638 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T02:58:54.705877] [FLK_MGR] Running jobs: ['39a8f262c060e76963eb911787f0c638']
[0m[2025-01-22T02:58:54.705884] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T02:58:54.705905] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T03:02:54.729204] [SCALING] Scaling started.
[0m[2025-01-22T03:02:54.729277] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T03:02:54.741775] [SCALING] Scaling finished.
[0m[2025-01-22T03:02:54.741813] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:02:54.762030] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:02:54.779479] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T03:02:54.801425] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 0 replica.
[0m[2025-01-22T03:02:54.822284] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T03:02:54.835286] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T03:02:54.849388] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T03:02:54.863010] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T03:02:54.876826] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T03:02:54.911152] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jrdjn deleted
[0m[2025-01-22T03:02:56.807112] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:02:58.719850] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:02:58.719916] Reloading playbook: application/kafka
[0m[2025-01-22T03:03:04.707899] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T03:03:50.715697] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T03:03:50.715874] [EXPERIMENT] Run 4 completed. Start: 1737514719, End: 1737515030
[0m[2025-01-22T03:03:50.715884] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T03:04:00.716954] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T03:04:02.586848] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:04:04.450725] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:04:04.450787] [SCALING] Setting up experiment.


[0m[2025-01-22T03:04:04.450796] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:04:04.457125] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:04:04.474116] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T03:04:04.492863] [SCALING] Statefulset name to scale : flink-8000m-1024
[0m[2025-01-22T03:04:04.504418] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 1 replica.
[0m[2025-01-22T03:04:09.515809] [FLK_MGR] Running job.
[0m[2025-01-22T03:04:09.515904] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T03:04:09.961584] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-52cmj
[0m[2025-01-22T03:04:14.144734] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c61f7c6b61f79293ddf83edfbf4cfd6a

[0m[2025-01-22T03:04:14.144780] [FLK_MGR] Running job id: c61f7c6b61f79293ddf83edfbf4cfd6a
[0m[2025-01-22T03:04:14.144787] [FLK_MGR] Getting job info.
[0m[2025-01-22T03:04:14.163573] [FLK_MGR] Job plan response: {"plan":{"jid":"c61f7c6b61f79293ddf83edfbf4cfd6a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T03:04:14.163724] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T03:04:14.604716] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-52cmj
[0m[2025-01-22T03:04:16.076881] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 03:04:13 : c61f7c6b61f79293ddf83edfbf4cfd6a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T03:04:16.076942] [FLK_MGR] Running jobs: ['c61f7c6b61f79293ddf83edfbf4cfd6a']
[0m[2025-01-22T03:04:16.076950] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T03:04:16.076957] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T03:08:16.101632] [SCALING] Scaling started.
[0m[2025-01-22T03:08:16.101692] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T03:08:16.115010] [SCALING] Scaling finished.
[0m[2025-01-22T03:08:16.115035] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:08:16.133355] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:08:16.150598] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T03:08:16.171073] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 0 replica.
[0m[2025-01-22T03:08:16.187686] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T03:08:16.203198] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T03:08:16.216788] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T03:08:16.229917] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T03:08:16.242552] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T03:08:16.275614] [POD_MGR] Pod flink-jobmanager-7d7c784b74-52cmj deleted
[0m[2025-01-22T03:08:18.191457] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:08:20.108141] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:08:20.108206] Reloading playbook: application/kafka
[0m[2025-01-22T03:08:26.104806] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T03:09:12.059754] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T03:09:12.059885] [EXPERIMENT] Run 5 completed. Start: 1737515040, End: 1737515352
[0m[2025-01-22T03:09:12.059891] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T03:09:24.308858] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T03:09:24.308916] [RESOURCE_E] Running experiment with 8000m cores and 2048 memory.
[0m[2025-01-22T03:09:31.591995] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T03:09:31.592057] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T03:09:33.446173] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:09:35.319816] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:09:35.319874] [SCALING] Setting up experiment.


[0m[2025-01-22T03:09:35.319883] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:09:35.325735] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:09:35.342583] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T03:09:35.360925] [SCALING] Statefulset name to scale : flink-8000m-2048
[0m[2025-01-22T03:09:35.371171] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 1 replica.
[0m[2025-01-22T03:09:40.386064] [FLK_MGR] Running job.
[0m[2025-01-22T03:09:40.386094] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T03:09:40.766960] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-zzc78
[0m[2025-01-22T03:09:44.840442] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 81b65811726d6da67828db71168879d6

[0m[2025-01-22T03:09:44.840505] [FLK_MGR] Running job id: 81b65811726d6da67828db71168879d6
[0m[2025-01-22T03:09:44.840513] [FLK_MGR] Getting job info.
[0m[2025-01-22T03:09:44.860339] [FLK_MGR] Job plan response: {"plan":{"jid":"81b65811726d6da67828db71168879d6","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T03:09:44.860507] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T03:09:45.301190] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-zzc78
[0m[2025-01-22T03:09:46.753074] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 03:09:43 : 81b65811726d6da67828db71168879d6 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T03:09:46.753139] [FLK_MGR] Running jobs: ['81b65811726d6da67828db71168879d6']
[0m[2025-01-22T03:09:46.753147] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T03:09:46.753157] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T03:13:46.778404] [SCALING] Scaling started.
[0m[2025-01-22T03:13:46.778463] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T03:13:46.791541] [SCALING] Scaling finished.
[0m[2025-01-22T03:13:46.791569] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:13:46.810670] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:13:46.826988] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T03:13:46.849305] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 0 replica.
[0m[2025-01-22T03:13:56.874551] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T03:13:56.887636] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T03:13:56.900588] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T03:13:56.914430] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T03:13:56.929141] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T03:13:56.951932] [POD_MGR] Pod flink-jobmanager-7d7c784b74-zzc78 deleted
[0m[2025-01-22T03:13:58.837054] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:14:00.749834] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:14:00.749909] Reloading playbook: application/kafka
[0m[2025-01-22T03:14:06.711335] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T03:14:52.668542] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T03:14:52.668735] [EXPERIMENT] Run 1 completed. Start: 1737515371, End: 1737515692
[0m[2025-01-22T03:14:52.668742] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T03:15:02.669867] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T03:15:04.543797] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:15:06.424982] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:15:06.425065] [SCALING] Setting up experiment.


[0m[2025-01-22T03:15:06.425078] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:15:06.430845] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:15:06.446283] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T03:15:06.465523] [SCALING] Statefulset name to scale : flink-8000m-2048
[0m[2025-01-22T03:15:06.475975] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 1 replica.
[0m[2025-01-22T03:15:11.486912] [FLK_MGR] Running job.
[0m[2025-01-22T03:15:11.486939] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T03:15:11.942579] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-z6q6m
[0m[2025-01-22T03:15:16.133766] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 44da887120fee5d125575781da4dddb1

[0m[2025-01-22T03:15:16.133823] [FLK_MGR] Running job id: 44da887120fee5d125575781da4dddb1
[0m[2025-01-22T03:15:16.133831] [FLK_MGR] Getting job info.
[0m[2025-01-22T03:15:16.150560] [FLK_MGR] Job plan response: {"plan":{"jid":"44da887120fee5d125575781da4dddb1","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T03:15:16.150719] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T03:15:16.593311] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-z6q6m
[0m[2025-01-22T03:15:18.018006] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 03:15:15 : 44da887120fee5d125575781da4dddb1 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T03:15:18.018065] [FLK_MGR] Running jobs: ['44da887120fee5d125575781da4dddb1']
[0m[2025-01-22T03:15:18.018072] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T03:15:18.018079] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T03:19:18.043187] [SCALING] Scaling started.
[0m[2025-01-22T03:19:18.043290] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T03:19:18.057810] [SCALING] Scaling finished.
[0m[2025-01-22T03:19:18.057833] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:19:18.077120] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:19:18.093938] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T03:19:18.113541] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 0 replica.
[0m[2025-01-22T03:19:23.133821] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T03:19:23.146795] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T03:19:23.159933] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T03:19:23.172630] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T03:19:23.186947] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T03:19:23.220823] [POD_MGR] Pod flink-jobmanager-7d7c784b74-z6q6m deleted
[0m[2025-01-22T03:19:25.108989] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:19:26.971781] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:19:26.971846] Reloading playbook: application/kafka
[0m[2025-01-22T03:19:32.914215] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T03:20:18.914338] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T03:20:18.914477] [EXPERIMENT] Run 2 completed. Start: 1737515702, End: 1737516018
[0m[2025-01-22T03:20:18.914484] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T03:20:28.915678] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T03:20:30.789001] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:20:32.679421] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:20:32.679482] [SCALING] Setting up experiment.


[0m[2025-01-22T03:20:32.679491] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:20:32.685088] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:20:32.701706] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T03:20:32.718870] [SCALING] Statefulset name to scale : flink-8000m-2048
[0m[2025-01-22T03:20:32.729233] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 1 replica.
[0m[2025-01-22T03:20:37.739197] [FLK_MGR] Running job.
[0m[2025-01-22T03:20:37.739224] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T03:20:38.176284] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-2fxff
[0m[2025-01-22T03:20:42.237430] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 84bb0c9896c4eff26e8cefeae73714bb

[0m[2025-01-22T03:20:42.237479] [FLK_MGR] Running job id: 84bb0c9896c4eff26e8cefeae73714bb
[0m[2025-01-22T03:20:42.237486] [FLK_MGR] Getting job info.
[0m[2025-01-22T03:20:42.256008] [FLK_MGR] Job plan response: {"plan":{"jid":"84bb0c9896c4eff26e8cefeae73714bb","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T03:20:42.256162] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T03:20:42.744999] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-2fxff
[0m[2025-01-22T03:20:44.154872] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 03:20:41 : 84bb0c9896c4eff26e8cefeae73714bb : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T03:20:44.154929] [FLK_MGR] Running jobs: ['84bb0c9896c4eff26e8cefeae73714bb']
[0m[2025-01-22T03:20:44.154936] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T03:20:44.154941] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T03:24:44.179431] [SCALING] Scaling started.
[0m[2025-01-22T03:24:44.179529] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T03:24:44.192204] [SCALING] Scaling finished.
[0m[2025-01-22T03:24:44.192221] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:24:44.211077] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:24:44.228983] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T03:24:44.252737] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 0 replica.
[0m[2025-01-22T03:24:54.278943] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T03:24:54.295048] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T03:24:54.308942] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T03:24:54.322648] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T03:24:54.336016] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T03:24:54.358390] [POD_MGR] Pod flink-jobmanager-7d7c784b74-2fxff deleted
[0m[2025-01-22T03:24:56.280982] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:24:58.158311] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:24:58.158378] Reloading playbook: application/kafka
[0m[2025-01-22T03:25:04.107008] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T03:25:50.080288] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T03:25:50.080483] [EXPERIMENT] Run 3 completed. Start: 1737516028, End: 1737516350
[0m[2025-01-22T03:25:50.080491] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T03:26:00.081543] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T03:26:01.991245] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:26:03.847211] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:26:03.847267] [SCALING] Setting up experiment.


[0m[2025-01-22T03:26:03.847275] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:26:03.852716] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:26:03.868037] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T03:26:03.884910] [SCALING] Statefulset name to scale : flink-8000m-2048
[0m[2025-01-22T03:26:03.894935] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 1 replica.
[0m[2025-01-22T03:26:08.903667] [FLK_MGR] Running job.
[0m[2025-01-22T03:26:08.903696] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T03:26:09.350094] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-5ntfn
[0m[2025-01-22T03:26:13.489176] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID ac208a4d4c4c2a7025a1f967b0ff77bc

[0m[2025-01-22T03:26:13.489228] [FLK_MGR] Running job id: ac208a4d4c4c2a7025a1f967b0ff77bc
[0m[2025-01-22T03:26:13.489240] [FLK_MGR] Getting job info.
[0m[2025-01-22T03:26:13.507820] [FLK_MGR] Job plan response: {"plan":{"jid":"ac208a4d4c4c2a7025a1f967b0ff77bc","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T03:26:13.507984] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T03:26:13.878178] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-5ntfn
[0m[2025-01-22T03:26:15.316994] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 03:26:12 : ac208a4d4c4c2a7025a1f967b0ff77bc : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T03:26:15.317052] [FLK_MGR] Running jobs: ['ac208a4d4c4c2a7025a1f967b0ff77bc']
[0m[2025-01-22T03:26:15.317058] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T03:26:15.317104] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T03:30:15.340384] [SCALING] Scaling started.
[0m[2025-01-22T03:30:15.340483] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T03:30:15.354434] [SCALING] Scaling finished.
[0m[2025-01-22T03:30:15.354459] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:30:15.373126] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:30:15.390999] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T03:30:15.412209] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 0 replica.
[0m[2025-01-22T03:30:20.433121] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T03:30:20.446350] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T03:30:20.459764] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T03:30:20.472631] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T03:30:20.487012] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T03:30:20.517175] [POD_MGR] Pod flink-jobmanager-7d7c784b74-5ntfn deleted
[0m[2025-01-22T03:30:22.425384] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:30:24.341729] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:30:24.341791] Reloading playbook: application/kafka
[0m[2025-01-22T03:30:30.269047] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T03:31:16.245439] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T03:31:16.245570] [EXPERIMENT] Run 4 completed. Start: 1737516360, End: 1737516676
[0m[2025-01-22T03:31:16.245575] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T03:31:26.246479] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T03:31:28.126722] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:31:29.980520] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:31:29.980579] [SCALING] Setting up experiment.


[0m[2025-01-22T03:31:29.980587] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:31:29.986371] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:31:30.003611] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T03:31:30.020110] [SCALING] Statefulset name to scale : flink-8000m-2048
[0m[2025-01-22T03:31:30.036163] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 1 replica.
[0m[2025-01-22T03:31:35.047456] [FLK_MGR] Running job.
[0m[2025-01-22T03:31:35.047485] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T03:31:35.487689] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-v8h48
[0m[2025-01-22T03:31:39.565050] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9c41ba478fc3fc5da6da36bdac28690f

[0m[2025-01-22T03:31:39.565100] [FLK_MGR] Running job id: 9c41ba478fc3fc5da6da36bdac28690f
[0m[2025-01-22T03:31:39.565110] [FLK_MGR] Getting job info.
[0m[2025-01-22T03:31:39.582652] [FLK_MGR] Job plan response: {"plan":{"jid":"9c41ba478fc3fc5da6da36bdac28690f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T03:31:39.582801] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T03:31:40.015517] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-v8h48
[0m[2025-01-22T03:31:41.462293] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 03:31:38 : 9c41ba478fc3fc5da6da36bdac28690f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T03:31:41.462348] [FLK_MGR] Running jobs: ['9c41ba478fc3fc5da6da36bdac28690f']
[0m[2025-01-22T03:31:41.462355] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T03:31:41.462362] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T03:35:41.485910] [SCALING] Scaling started.
[0m[2025-01-22T03:35:41.486008] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T03:35:41.499908] [SCALING] Scaling finished.
[0m[2025-01-22T03:35:41.499929] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:35:41.519186] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:35:41.538873] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T03:35:41.561323] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 0 replica.
[0m[2025-01-22T03:35:46.581702] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T03:35:46.595239] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T03:35:46.608602] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T03:35:46.621628] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T03:35:46.634928] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T03:35:46.670134] [POD_MGR] Pod flink-jobmanager-7d7c784b74-v8h48 deleted
[0m[2025-01-22T03:35:48.592814] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:35:50.424978] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:35:50.425046] Reloading playbook: application/kafka
[0m[2025-01-22T03:35:56.387060] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T03:36:42.320809] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T03:36:42.320954] [EXPERIMENT] Run 5 completed. Start: 1737516686, End: 1737517002
[0m[2025-01-22T03:36:42.320962] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T03:36:54.525130] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T03:36:54.525185] [RESOURCE_E] Running experiment with 8000m cores and 4096 memory.
[0m[2025-01-22T03:37:01.752790] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T03:37:01.752851] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T03:37:03.656918] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:37:05.556135] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:37:05.556193] [SCALING] Setting up experiment.


[0m[2025-01-22T03:37:05.556202] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:37:05.561520] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:37:05.577772] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T03:37:05.594848] [SCALING] Statefulset name to scale : flink-8000m-4096
[0m[2025-01-22T03:37:05.604987] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 1 replica.
[0m[2025-01-22T03:37:10.614613] [FLK_MGR] Running job.
[0m[2025-01-22T03:37:10.614642] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T03:37:11.034026] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-28r8r
[0m[2025-01-22T03:37:15.125105] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f45af1b1045e88b45a2da1dd049edd1c

[0m[2025-01-22T03:37:15.125156] [FLK_MGR] Running job id: f45af1b1045e88b45a2da1dd049edd1c
[0m[2025-01-22T03:37:15.125165] [FLK_MGR] Getting job info.
[0m[2025-01-22T03:37:15.143405] [FLK_MGR] Job plan response: {"plan":{"jid":"f45af1b1045e88b45a2da1dd049edd1c","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T03:37:15.143604] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T03:37:15.577323] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-28r8r
[0m[2025-01-22T03:37:16.995817] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 03:37:14 : f45af1b1045e88b45a2da1dd049edd1c : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T03:37:16.995876] [FLK_MGR] Running jobs: ['f45af1b1045e88b45a2da1dd049edd1c']
[0m[2025-01-22T03:37:16.995883] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T03:37:16.995889] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T03:41:17.019849] [SCALING] Scaling started.
[0m[2025-01-22T03:41:17.019953] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T03:41:17.033660] [SCALING] Scaling finished.
[0m[2025-01-22T03:41:17.033684] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:41:17.049915] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:41:17.068405] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T03:41:17.091319] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 0 replica.
[0m[2025-01-22T03:41:22.113035] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T03:41:22.129460] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T03:41:22.144237] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T03:41:22.157073] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T03:41:22.169490] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T03:41:22.204285] [POD_MGR] Pod flink-jobmanager-7d7c784b74-28r8r deleted
[0m[2025-01-22T03:41:24.110523] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:41:26.031216] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:41:26.031276] Reloading playbook: application/kafka
[0m[2025-01-22T03:41:31.979718] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T03:42:17.936582] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T03:42:17.936717] [EXPERIMENT] Run 1 completed. Start: 1737517021, End: 1737517337
[0m[2025-01-22T03:42:17.936723] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T03:42:27.937738] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T03:42:29.819018] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:42:31.710188] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:42:31.710244] [SCALING] Setting up experiment.


[0m[2025-01-22T03:42:31.710252] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:42:31.715789] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:42:31.731131] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T03:42:31.745999] [SCALING] Statefulset name to scale : flink-8000m-4096
[0m[2025-01-22T03:42:31.757296] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 1 replica.
[0m[2025-01-22T03:42:36.767230] [FLK_MGR] Running job.
[0m[2025-01-22T03:42:36.767256] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T03:42:37.225118] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-rbzsq
[0m[2025-01-22T03:42:41.381205] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8557f2ef15ec4b7e2751277704dd2368

[0m[2025-01-22T03:42:41.381261] [FLK_MGR] Running job id: 8557f2ef15ec4b7e2751277704dd2368
[0m[2025-01-22T03:42:41.381269] [FLK_MGR] Getting job info.
[0m[2025-01-22T03:42:41.398511] [FLK_MGR] Job plan response: {"plan":{"jid":"8557f2ef15ec4b7e2751277704dd2368","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T03:42:41.398650] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T03:42:41.770068] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-rbzsq
[0m[2025-01-22T03:42:43.181097] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 03:42:40 : 8557f2ef15ec4b7e2751277704dd2368 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T03:42:43.181158] [FLK_MGR] Running jobs: ['8557f2ef15ec4b7e2751277704dd2368']
[0m[2025-01-22T03:42:43.181165] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T03:42:43.181171] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T03:46:43.204414] [SCALING] Scaling started.
[0m[2025-01-22T03:46:43.204517] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T03:46:43.217488] [SCALING] Scaling finished.
[0m[2025-01-22T03:46:43.217510] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:46:43.235142] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:46:43.252095] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T03:46:43.271869] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 0 replica.
[0m[2025-01-22T03:46:53.298330] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T03:46:53.366261] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T03:46:53.380291] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T03:46:53.393032] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T03:46:53.406210] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T03:46:53.438685] [POD_MGR] Pod flink-jobmanager-7d7c784b74-rbzsq deleted
[0m[2025-01-22T03:46:55.343118] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:46:57.275496] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:46:57.275564] Reloading playbook: application/kafka
[0m[2025-01-22T03:47:03.281823] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T03:47:49.295726] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T03:47:49.295916] [EXPERIMENT] Run 2 completed. Start: 1737517347, End: 1737517669
[0m[2025-01-22T03:47:49.295923] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T03:47:59.296909] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T03:48:01.157266] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:48:03.024355] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:48:03.024416] [SCALING] Setting up experiment.


[0m[2025-01-22T03:48:03.024424] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:48:03.029907] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:48:03.046086] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T03:48:03.062997] [SCALING] Statefulset name to scale : flink-8000m-4096
[0m[2025-01-22T03:48:03.073201] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 1 replica.
[0m[2025-01-22T03:48:08.081971] [FLK_MGR] Running job.
[0m[2025-01-22T03:48:08.081999] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T03:48:08.460724] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-hjj48
[0m[2025-01-22T03:48:12.620038] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f3e3cebc8962718e1a3b018bf8a83c8b

[0m[2025-01-22T03:48:12.620097] [FLK_MGR] Running job id: f3e3cebc8962718e1a3b018bf8a83c8b
[0m[2025-01-22T03:48:12.620107] [FLK_MGR] Getting job info.
[0m[2025-01-22T03:48:12.637514] [FLK_MGR] Job plan response: {"plan":{"jid":"f3e3cebc8962718e1a3b018bf8a83c8b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T03:48:12.637662] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T03:48:13.064395] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-hjj48
[0m[2025-01-22T03:48:14.536888] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 03:48:11 : f3e3cebc8962718e1a3b018bf8a83c8b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T03:48:14.536941] [FLK_MGR] Running jobs: ['f3e3cebc8962718e1a3b018bf8a83c8b']
[0m[2025-01-22T03:48:14.536949] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T03:48:14.536956] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T03:52:14.560852] [SCALING] Scaling started.
[0m[2025-01-22T03:52:14.560949] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T03:52:14.574782] [SCALING] Scaling finished.
[0m[2025-01-22T03:52:14.574805] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:52:14.594215] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:52:14.610754] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T03:52:14.630479] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 0 replica.
[0m[2025-01-22T03:52:24.655997] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T03:52:24.670267] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T03:52:24.684283] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T03:52:24.699194] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T03:52:24.711918] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T03:52:24.733760] [POD_MGR] Pod flink-jobmanager-7d7c784b74-hjj48 deleted
[0m[2025-01-22T03:52:26.594336] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:52:28.522442] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:52:28.522503] Reloading playbook: application/kafka
[0m[2025-01-22T03:52:34.479707] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T03:53:20.412063] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T03:53:20.412197] [EXPERIMENT] Run 3 completed. Start: 1737517679, End: 1737518000
[0m[2025-01-22T03:53:20.412203] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T03:53:30.413232] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T03:53:32.309200] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:53:34.165724] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:53:34.165780] [SCALING] Setting up experiment.


[0m[2025-01-22T03:53:34.165788] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:53:34.171470] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:53:34.189796] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T03:53:34.207232] [SCALING] Statefulset name to scale : flink-8000m-4096
[0m[2025-01-22T03:53:34.218057] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 1 replica.
[0m[2025-01-22T03:53:39.228632] [FLK_MGR] Running job.
[0m[2025-01-22T03:53:39.228663] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T03:53:39.652247] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-nr9vl
[0m[2025-01-22T03:53:43.758790] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID bf3d9f84a6059ca1c144cfaafd11a529

[0m[2025-01-22T03:53:43.758843] [FLK_MGR] Running job id: bf3d9f84a6059ca1c144cfaafd11a529
[0m[2025-01-22T03:53:43.758854] [FLK_MGR] Getting job info.
[0m[2025-01-22T03:53:43.776426] [FLK_MGR] Job plan response: {"plan":{"jid":"bf3d9f84a6059ca1c144cfaafd11a529","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T03:53:43.776572] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T03:53:44.198140] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-nr9vl
[0m[2025-01-22T03:53:45.653325] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 03:53:42 : bf3d9f84a6059ca1c144cfaafd11a529 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T03:53:45.653377] [FLK_MGR] Running jobs: ['bf3d9f84a6059ca1c144cfaafd11a529']
[0m[2025-01-22T03:53:45.653384] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T03:53:45.653390] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T03:57:45.676803] [SCALING] Scaling started.
[0m[2025-01-22T03:57:45.676900] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T03:57:45.690653] [SCALING] Scaling finished.
[0m[2025-01-22T03:57:45.690673] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:57:45.708768] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:57:45.724951] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T03:57:45.747205] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 0 replica.
[0m[2025-01-22T03:57:50.767612] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T03:57:50.781298] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T03:57:50.795231] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T03:57:50.811533] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T03:57:50.825398] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T03:57:50.859148] [POD_MGR] Pod flink-jobmanager-7d7c784b74-nr9vl deleted
[0m[2025-01-22T03:57:52.737221] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:57:54.683389] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T03:57:54.683449] Reloading playbook: application/kafka
[0m[2025-01-22T03:58:00.689553] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T03:58:46.667503] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T03:58:46.667626] [EXPERIMENT] Run 4 completed. Start: 1737518010, End: 1737518326
[0m[2025-01-22T03:58:46.667632] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T03:58:56.668669] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T03:58:58.550752] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:59:00.425925] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T03:59:00.426012] [SCALING] Setting up experiment.


[0m[2025-01-22T03:59:00.426026] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T03:59:00.442676] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T03:59:00.458946] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T03:59:00.489014] [SCALING] Statefulset name to scale : flink-8000m-4096
[0m[2025-01-22T03:59:00.500236] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 1 replica.
[0m[2025-01-22T03:59:05.511020] [FLK_MGR] Running job.
[0m[2025-01-22T03:59:05.511049] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T03:59:05.942179] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-5dvg8
[0m[2025-01-22T03:59:10.095800] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 53382321731999daf2b00b5cd495017f

[0m[2025-01-22T03:59:10.095850] [FLK_MGR] Running job id: 53382321731999daf2b00b5cd495017f
[0m[2025-01-22T03:59:10.095858] [FLK_MGR] Getting job info.
[0m[2025-01-22T03:59:10.112698] [FLK_MGR] Job plan response: {"plan":{"jid":"53382321731999daf2b00b5cd495017f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T03:59:10.112836] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T03:59:10.539871] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-5dvg8
[0m[2025-01-22T03:59:11.998501] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 03:59:09 : 53382321731999daf2b00b5cd495017f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T03:59:11.998552] [FLK_MGR] Running jobs: ['53382321731999daf2b00b5cd495017f']
[0m[2025-01-22T03:59:11.998559] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T03:59:11.998565] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T04:03:12.020875] [SCALING] Scaling started.
[0m[2025-01-22T04:03:12.020971] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T04:03:12.034220] [SCALING] Scaling finished.
[0m[2025-01-22T04:03:12.034239] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:03:12.050611] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:03:12.068711] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T04:03:12.090749] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 0 replica.
[0m[2025-01-22T04:03:22.118202] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T04:03:22.133864] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T04:03:22.148953] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T04:03:22.162888] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T04:03:22.176564] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T04:03:22.210674] [POD_MGR] Pod flink-jobmanager-7d7c784b74-5dvg8 deleted
[0m[2025-01-22T04:03:24.071962] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:03:25.956233] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:03:25.956297] Reloading playbook: application/kafka
[0m[2025-01-22T04:03:31.925888] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T04:04:17.875966] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T04:04:17.876091] [EXPERIMENT] Run 5 completed. Start: 1737518336, End: 1737518657
[0m[2025-01-22T04:04:17.876097] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T04:04:30.130607] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T04:04:30.130663] [RESOURCE_E] Running experiment with 8000m cores and 8192 memory.
[0m[2025-01-22T04:04:37.400264] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T04:04:37.400329] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T04:04:39.249533] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:04:41.105946] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:04:41.106002] [SCALING] Setting up experiment.


[0m[2025-01-22T04:04:41.106011] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:04:41.111291] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:04:41.126467] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T04:04:41.142251] [SCALING] Statefulset name to scale : flink-8000m-8192
[0m[2025-01-22T04:04:41.152345] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 1 replica.
[0m[2025-01-22T04:04:46.161604] [FLK_MGR] Running job.
[0m[2025-01-22T04:04:46.161633] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T04:04:46.535805] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-88q5z
[0m[2025-01-22T04:04:50.632042] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 504b83e2cc0029c26076fd7a87e897da

[0m[2025-01-22T04:04:50.632094] [FLK_MGR] Running job id: 504b83e2cc0029c26076fd7a87e897da
[0m[2025-01-22T04:04:50.632104] [FLK_MGR] Getting job info.
[0m[2025-01-22T04:04:50.649523] [FLK_MGR] Job plan response: {"plan":{"jid":"504b83e2cc0029c26076fd7a87e897da","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T04:04:50.649670] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T04:04:51.085931] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-88q5z
[0m[2025-01-22T04:04:52.520035] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 04:04:49 : 504b83e2cc0029c26076fd7a87e897da : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T04:04:52.520092] [FLK_MGR] Running jobs: ['504b83e2cc0029c26076fd7a87e897da']
[0m[2025-01-22T04:04:52.520099] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T04:04:52.520105] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T04:08:52.543756] [SCALING] Scaling started.
[0m[2025-01-22T04:08:52.543855] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T04:08:52.558032] [SCALING] Scaling finished.
[0m[2025-01-22T04:08:52.558051] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:08:52.577230] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:08:52.596644] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T04:08:52.617325] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 0 replica.
[0m[2025-01-22T04:09:02.641979] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T04:09:02.655503] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T04:09:02.670557] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T04:09:02.686149] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T04:09:02.699653] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T04:09:02.731078] [POD_MGR] Pod flink-jobmanager-7d7c784b74-88q5z deleted
[0m[2025-01-22T04:09:04.591610] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:09:06.478474] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:09:06.478529] Reloading playbook: application/kafka
[0m[2025-01-22T04:09:12.474274] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T04:09:58.330578] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T04:09:58.330704] [EXPERIMENT] Run 1 completed. Start: 1737518677, End: 1737518998
[0m[2025-01-22T04:09:58.330711] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T04:10:08.331790] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T04:10:10.228910] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:10:12.085922] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:10:12.085975] [SCALING] Setting up experiment.


[0m[2025-01-22T04:10:12.085982] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:10:12.091587] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:10:12.107544] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T04:10:12.137772] [SCALING] Statefulset name to scale : flink-8000m-8192
[0m[2025-01-22T04:10:12.149346] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 1 replica.
[0m[2025-01-22T04:10:17.158705] [FLK_MGR] Running job.
[0m[2025-01-22T04:10:17.158735] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T04:10:17.590482] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-2whf7
[0m[2025-01-22T04:10:21.673029] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 2456b767a19b2d9b1e2e009f87edae3d

[0m[2025-01-22T04:10:21.673083] [FLK_MGR] Running job id: 2456b767a19b2d9b1e2e009f87edae3d
[0m[2025-01-22T04:10:21.673090] [FLK_MGR] Getting job info.
[0m[2025-01-22T04:10:21.690879] [FLK_MGR] Job plan response: {"plan":{"jid":"2456b767a19b2d9b1e2e009f87edae3d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T04:10:21.691038] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T04:10:22.131805] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-2whf7
[0m[2025-01-22T04:10:23.573407] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 04:10:20 : 2456b767a19b2d9b1e2e009f87edae3d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T04:10:23.573461] [FLK_MGR] Running jobs: ['2456b767a19b2d9b1e2e009f87edae3d']
[0m[2025-01-22T04:10:23.573467] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T04:10:23.573473] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T04:14:23.598686] [SCALING] Scaling started.
[0m[2025-01-22T04:14:23.598786] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T04:14:23.611264] [SCALING] Scaling finished.
[0m[2025-01-22T04:14:23.611286] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:14:23.630924] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:14:23.647777] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T04:14:23.669684] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 0 replica.
[0m[2025-01-22T04:14:33.694562] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T04:14:33.707611] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T04:14:33.720448] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T04:14:33.733210] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T04:14:33.745930] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T04:14:33.780936] [POD_MGR] Pod flink-jobmanager-7d7c784b74-2whf7 deleted
[0m[2025-01-22T04:14:35.702818] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:14:37.623258] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:14:37.623359] Reloading playbook: application/kafka
[0m[2025-01-22T04:14:43.621313] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T04:15:29.592103] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T04:15:29.592227] [EXPERIMENT] Run 2 completed. Start: 1737519008, End: 1737519329
[0m[2025-01-22T04:15:29.592234] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T04:15:39.593332] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T04:15:41.450572] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:15:43.328281] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:15:43.328334] [SCALING] Setting up experiment.


[0m[2025-01-22T04:15:43.328342] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:15:43.335410] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:15:43.352558] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T04:15:43.371918] [SCALING] Statefulset name to scale : flink-8000m-8192
[0m[2025-01-22T04:15:43.385120] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 1 replica.
[0m[2025-01-22T04:15:48.397324] [FLK_MGR] Running job.
[0m[2025-01-22T04:15:48.397353] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T04:15:48.835905] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xng7p
[0m[2025-01-22T04:15:52.967456] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID bf21815577be151809d90c9d5a182e14

[0m[2025-01-22T04:15:52.967518] [FLK_MGR] Running job id: bf21815577be151809d90c9d5a182e14
[0m[2025-01-22T04:15:52.967525] [FLK_MGR] Getting job info.
[0m[2025-01-22T04:15:52.986120] [FLK_MGR] Job plan response: {"plan":{"jid":"bf21815577be151809d90c9d5a182e14","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T04:15:52.986290] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T04:15:53.398296] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xng7p
[0m[2025-01-22T04:15:54.842557] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 04:15:52 : bf21815577be151809d90c9d5a182e14 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T04:15:54.842626] [FLK_MGR] Running jobs: ['bf21815577be151809d90c9d5a182e14']
[0m[2025-01-22T04:15:54.842634] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T04:15:54.842642] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T04:19:54.866023] [SCALING] Scaling started.
[0m[2025-01-22T04:19:54.866074] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T04:19:54.879668] [SCALING] Scaling finished.
[0m[2025-01-22T04:19:54.879692] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:19:54.896725] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:19:54.915670] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T04:19:54.937607] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 0 replica.
[0m[2025-01-22T04:19:59.960202] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T04:19:59.975077] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T04:19:59.990183] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T04:20:00.005089] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T04:20:00.020638] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T04:20:00.064339] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xng7p deleted
[0m[2025-01-22T04:20:01.981562] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:20:03.894406] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:20:03.894467] Reloading playbook: application/kafka
[0m[2025-01-22T04:20:09.857281] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T04:20:55.809289] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T04:20:55.809528] [EXPERIMENT] Run 3 completed. Start: 1737519339, End: 1737519655
[0m[2025-01-22T04:20:55.809535] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T04:21:05.810595] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T04:21:07.705909] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:21:09.560627] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:21:09.560681] [SCALING] Setting up experiment.


[0m[2025-01-22T04:21:09.560692] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:21:09.566651] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:21:09.583046] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T04:21:09.599400] [SCALING] Statefulset name to scale : flink-8000m-8192
[0m[2025-01-22T04:21:09.608800] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 1 replica.
[0m[2025-01-22T04:21:14.618238] [FLK_MGR] Running job.
[0m[2025-01-22T04:21:14.618267] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T04:21:15.061441] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-wbqjx
[0m[2025-01-22T04:21:19.214860] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID aae3dc941732110da7656a34c5bfb6b5

[0m[2025-01-22T04:21:19.214909] [FLK_MGR] Running job id: aae3dc941732110da7656a34c5bfb6b5
[0m[2025-01-22T04:21:19.214916] [FLK_MGR] Getting job info.
[0m[2025-01-22T04:21:19.231396] [FLK_MGR] Job plan response: {"plan":{"jid":"aae3dc941732110da7656a34c5bfb6b5","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T04:21:19.231537] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T04:21:19.602262] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-wbqjx
[0m[2025-01-22T04:21:21.047468] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 04:21:18 : aae3dc941732110da7656a34c5bfb6b5 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T04:21:21.047522] [FLK_MGR] Running jobs: ['aae3dc941732110da7656a34c5bfb6b5']
[0m[2025-01-22T04:21:21.047530] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T04:21:21.047536] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T04:25:21.070643] [SCALING] Scaling started.
[0m[2025-01-22T04:25:21.070738] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T04:25:21.085559] [SCALING] Scaling finished.
[0m[2025-01-22T04:25:21.085577] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:25:21.104816] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:25:21.122788] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T04:25:21.144031] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 0 replica.
[0m[2025-01-22T04:25:26.164840] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T04:25:26.178244] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T04:25:26.191426] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T04:25:26.204715] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T04:25:26.218962] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T04:25:26.252960] [POD_MGR] Pod flink-jobmanager-7d7c784b74-wbqjx deleted
[0m[2025-01-22T04:25:28.118632] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:25:30.017829] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:25:30.017902] Reloading playbook: application/kafka
[0m[2025-01-22T04:25:35.982104] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T04:26:21.971369] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T04:26:21.971585] [EXPERIMENT] Run 4 completed. Start: 1737519665, End: 1737519981
[0m[2025-01-22T04:26:21.971592] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T04:26:31.972720] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T04:26:33.835981] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:26:35.688250] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:26:35.688299] [SCALING] Setting up experiment.


[0m[2025-01-22T04:26:35.688309] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:26:35.695239] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:26:35.711006] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T04:26:35.728534] [SCALING] Statefulset name to scale : flink-8000m-8192
[0m[2025-01-22T04:26:35.738066] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 1 replica.
[0m[2025-01-22T04:26:40.747215] [FLK_MGR] Running job.
[0m[2025-01-22T04:26:40.747247] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T04:26:41.181309] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-69mc8
[0m[2025-01-22T04:26:45.312398] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9f037e68fb3478191cd79f36fd6a61f9

[0m[2025-01-22T04:26:45.312447] [FLK_MGR] Running job id: 9f037e68fb3478191cd79f36fd6a61f9
[0m[2025-01-22T04:26:45.312454] [FLK_MGR] Getting job info.
[0m[2025-01-22T04:26:45.330394] [FLK_MGR] Job plan response: {"plan":{"jid":"9f037e68fb3478191cd79f36fd6a61f9","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T04:26:45.330553] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T04:26:45.749337] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-69mc8
[0m[2025-01-22T04:26:47.184899] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 04:26:44 : 9f037e68fb3478191cd79f36fd6a61f9 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T04:26:47.184953] [FLK_MGR] Running jobs: ['9f037e68fb3478191cd79f36fd6a61f9']
[0m[2025-01-22T04:26:47.184961] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T04:26:47.184967] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T04:30:47.208535] [SCALING] Scaling started.
[0m[2025-01-22T04:30:47.208586] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T04:30:47.222627] [SCALING] Scaling finished.
[0m[2025-01-22T04:30:47.222644] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:30:47.241707] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:30:47.260960] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T04:30:47.282438] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 0 replica.
[0m[2025-01-22T04:30:57.310049] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T04:30:57.324527] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T04:30:57.338266] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T04:30:57.351037] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T04:30:57.364404] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T04:30:57.403684] [POD_MGR] Pod flink-jobmanager-7d7c784b74-69mc8 deleted
[0m[2025-01-22T04:30:59.259134] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:31:01.203417] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:31:01.203475] Reloading playbook: application/kafka
[0m[2025-01-22T04:31:07.156960] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T04:31:53.160447] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T04:31:53.160722] [EXPERIMENT] Run 5 completed. Start: 1737519991, End: 1737520313
[0m[2025-01-22T04:31:53.160730] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T04:32:05.382770] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T04:32:05.382824] [RESOURCE_E] Running experiment with 8000m cores and 16384 memory.
[0m[2025-01-22T04:32:12.638422] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T04:32:12.638499] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T04:32:14.506279] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:32:16.377057] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:32:16.377109] [SCALING] Setting up experiment.


[0m[2025-01-22T04:32:16.377120] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:32:16.383217] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:32:16.398659] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T04:32:16.414545] [SCALING] Statefulset name to scale : flink-8000m-16384
[0m[2025-01-22T04:32:16.425803] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 1 replica.
[0m[2025-01-22T04:32:21.436657] [FLK_MGR] Running job.
[0m[2025-01-22T04:32:21.436684] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T04:32:21.884876] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-dkn9f
[0m[2025-01-22T04:32:26.008826] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8a94959cd4938de191ad81b4272543c9

[0m[2025-01-22T04:32:26.008876] [FLK_MGR] Running job id: 8a94959cd4938de191ad81b4272543c9
[0m[2025-01-22T04:32:26.008883] [FLK_MGR] Getting job info.
[0m[2025-01-22T04:32:26.025644] [FLK_MGR] Job plan response: {"plan":{"jid":"8a94959cd4938de191ad81b4272543c9","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T04:32:26.025795] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T04:32:26.451098] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-dkn9f
[0m[2025-01-22T04:32:27.881498] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 04:32:25 : 8a94959cd4938de191ad81b4272543c9 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T04:32:27.881558] [FLK_MGR] Running jobs: ['8a94959cd4938de191ad81b4272543c9']
[0m[2025-01-22T04:32:27.881567] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T04:32:27.881578] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T04:36:27.904921] [SCALING] Scaling started.
[0m[2025-01-22T04:36:27.905023] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T04:36:27.918977] [SCALING] Scaling finished.
[0m[2025-01-22T04:36:27.918999] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:36:27.937585] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:36:27.956264] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T04:36:27.979411] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 0 replica.
[0m[2025-01-22T04:36:38.007459] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T04:36:38.021792] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T04:36:38.035419] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T04:36:38.049684] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T04:36:38.062770] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T04:36:38.087904] [POD_MGR] Pod flink-jobmanager-7d7c784b74-dkn9f deleted
[0m[2025-01-22T04:36:39.965740] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:36:41.858034] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:36:41.858249] Reloading playbook: application/kafka
[0m[2025-01-22T04:36:47.789208] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T04:37:33.710645] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T04:37:33.710764] [EXPERIMENT] Run 1 completed. Start: 1737520332, End: 1737520653
[0m[2025-01-22T04:37:33.710769] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T04:37:43.711776] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T04:37:45.603280] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:37:47.436685] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:37:47.436837] [SCALING] Setting up experiment.


[0m[2025-01-22T04:37:47.436869] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:37:47.442117] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:37:47.459702] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T04:37:47.476944] [SCALING] Statefulset name to scale : flink-8000m-16384
[0m[2025-01-22T04:37:47.487728] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 1 replica.
[0m[2025-01-22T04:37:52.498155] [FLK_MGR] Running job.
[0m[2025-01-22T04:37:52.498182] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T04:37:52.942543] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-g59tt
[0m[2025-01-22T04:37:57.155338] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 4a3b5b90a807354815cd0144ce4cb543

[0m[2025-01-22T04:37:57.155399] [FLK_MGR] Running job id: 4a3b5b90a807354815cd0144ce4cb543
[0m[2025-01-22T04:37:57.155408] [FLK_MGR] Getting job info.
[0m[2025-01-22T04:37:57.174072] [FLK_MGR] Job plan response: {"plan":{"jid":"4a3b5b90a807354815cd0144ce4cb543","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T04:37:57.174235] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T04:37:57.551999] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-g59tt
[0m[2025-01-22T04:37:59.014888] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 04:37:56 : 4a3b5b90a807354815cd0144ce4cb543 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T04:37:59.014948] [FLK_MGR] Running jobs: ['4a3b5b90a807354815cd0144ce4cb543']
[0m[2025-01-22T04:37:59.014957] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T04:37:59.014967] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T04:41:59.039204] [SCALING] Scaling started.
[0m[2025-01-22T04:41:59.039308] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T04:41:59.052185] [SCALING] Scaling finished.
[0m[2025-01-22T04:41:59.052209] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:41:59.071970] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:41:59.088024] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T04:41:59.110756] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 0 replica.
[0m[2025-01-22T04:42:04.130642] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T04:42:04.143352] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T04:42:04.155695] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T04:42:04.168749] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T04:42:04.226280] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T04:42:04.248318] [POD_MGR] Pod flink-jobmanager-7d7c784b74-g59tt deleted
[0m[2025-01-22T04:42:06.124812] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:42:08.050315] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:42:08.050373] Reloading playbook: application/kafka
[0m[2025-01-22T04:42:14.017023] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T04:43:19.960440] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T04:43:19.960563] [EXPERIMENT] Run 2 completed. Start: 1737520663, End: 1737520999
[0m[2025-01-22T04:43:19.960572] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T04:43:29.961648] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T04:43:31.825207] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:43:33.697989] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:43:33.698044] [SCALING] Setting up experiment.


[0m[2025-01-22T04:43:33.698053] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:43:33.704674] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:43:33.721640] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T04:43:33.739611] [SCALING] Statefulset name to scale : flink-8000m-16384
[0m[2025-01-22T04:43:33.749921] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 1 replica.
[0m[2025-01-22T04:43:38.759582] [FLK_MGR] Running job.
[0m[2025-01-22T04:43:38.759611] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T04:43:39.126909] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-ftcck
[0m[2025-01-22T04:43:43.246923] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID eb755c733bb3d67c5d222d53913da3ce

[0m[2025-01-22T04:43:43.246973] [FLK_MGR] Running job id: eb755c733bb3d67c5d222d53913da3ce
[0m[2025-01-22T04:43:43.246981] [FLK_MGR] Getting job info.
[0m[2025-01-22T04:43:43.264198] [FLK_MGR] Job plan response: {"plan":{"jid":"eb755c733bb3d67c5d222d53913da3ce","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T04:43:43.264344] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T04:43:43.710117] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-ftcck
[0m[2025-01-22T04:43:45.135969] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 04:43:42 : eb755c733bb3d67c5d222d53913da3ce : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T04:43:45.136028] [FLK_MGR] Running jobs: ['eb755c733bb3d67c5d222d53913da3ce']
[0m[2025-01-22T04:43:45.136035] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T04:43:45.136045] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T04:47:45.159727] [SCALING] Scaling started.
[0m[2025-01-22T04:47:45.159840] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T04:47:45.174661] [SCALING] Scaling finished.
[0m[2025-01-22T04:47:45.174705] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:47:45.195679] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:47:45.211781] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T04:47:45.233487] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 0 replica.
[0m[2025-01-22T04:47:50.253932] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T04:47:50.267897] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T04:47:50.282330] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T04:47:50.295042] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T04:47:50.307566] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T04:47:50.342972] [POD_MGR] Pod flink-jobmanager-7d7c784b74-ftcck deleted
[0m[2025-01-22T04:47:52.197383] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:47:54.076601] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:47:54.076669] Reloading playbook: application/kafka
[0m[2025-01-22T04:48:00.052836] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T04:48:45.996726] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T04:48:45.997066] [EXPERIMENT] Run 3 completed. Start: 1737521009, End: 1737521325
[0m[2025-01-22T04:48:45.997091] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T04:48:55.998185] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T04:48:57.896024] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:48:59.761573] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:48:59.761631] [SCALING] Setting up experiment.


[0m[2025-01-22T04:48:59.761640] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:48:59.766691] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:48:59.781450] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T04:48:59.796873] [SCALING] Statefulset name to scale : flink-8000m-16384
[0m[2025-01-22T04:48:59.809901] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 1 replica.
[0m[2025-01-22T04:49:04.821040] [FLK_MGR] Running job.
[0m[2025-01-22T04:49:04.821091] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T04:49:05.256432] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-q9kpf
[0m[2025-01-22T04:49:09.351223] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f0ac37742124b0d006aef31b4ada6d8f

[0m[2025-01-22T04:49:09.351276] [FLK_MGR] Running job id: f0ac37742124b0d006aef31b4ada6d8f
[0m[2025-01-22T04:49:09.351283] [FLK_MGR] Getting job info.
[0m[2025-01-22T04:49:09.368663] [FLK_MGR] Job plan response: {"plan":{"jid":"f0ac37742124b0d006aef31b4ada6d8f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T04:49:09.368802] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T04:49:09.831310] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-q9kpf
[0m[2025-01-22T04:49:11.272414] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 04:49:08 : f0ac37742124b0d006aef31b4ada6d8f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T04:49:11.272469] [FLK_MGR] Running jobs: ['f0ac37742124b0d006aef31b4ada6d8f']
[0m[2025-01-22T04:49:11.272476] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T04:49:11.272482] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T04:53:11.297744] [SCALING] Scaling started.
[0m[2025-01-22T04:53:11.297843] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T04:53:11.310430] [SCALING] Scaling finished.
[0m[2025-01-22T04:53:11.310448] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:53:11.329440] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:53:11.346239] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T04:53:11.368929] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 0 replica.
[0m[2025-01-22T04:53:16.389423] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T04:53:16.405936] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T04:53:16.421772] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T04:53:16.434468] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T04:53:16.448143] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T04:53:16.475137] [POD_MGR] Pod flink-jobmanager-7d7c784b74-q9kpf deleted
[0m[2025-01-22T04:53:18.373523] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:53:20.293490] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:53:20.293559] Reloading playbook: application/kafka
[0m[2025-01-22T04:53:26.307934] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T04:54:12.237775] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T04:54:12.237906] [EXPERIMENT] Run 4 completed. Start: 1737521335, End: 1737521652
[0m[2025-01-22T04:54:12.237912] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T04:54:22.239013] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T04:54:24.108270] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:54:25.960221] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T04:54:25.960279] [SCALING] Setting up experiment.


[0m[2025-01-22T04:54:25.960287] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:54:25.965335] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:54:25.981341] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T04:54:25.997835] [SCALING] Statefulset name to scale : flink-8000m-16384
[0m[2025-01-22T04:54:26.007517] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 1 replica.
[0m[2025-01-22T04:54:31.016983] [FLK_MGR] Running job.
[0m[2025-01-22T04:54:31.017011] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T04:54:31.444787] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xqmtz
[0m[2025-01-22T04:54:35.536665] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 53935d7097b002ca6e571a5e6a2088a5

[0m[2025-01-22T04:54:35.536715] [FLK_MGR] Running job id: 53935d7097b002ca6e571a5e6a2088a5
[0m[2025-01-22T04:54:35.536722] [FLK_MGR] Getting job info.
[0m[2025-01-22T04:54:35.555080] [FLK_MGR] Job plan response: {"plan":{"jid":"53935d7097b002ca6e571a5e6a2088a5","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T04:54:35.555229] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T04:54:35.939148] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xqmtz
[0m[2025-01-22T04:54:37.392807] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 04:54:34 : 53935d7097b002ca6e571a5e6a2088a5 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T04:54:37.392874] [FLK_MGR] Running jobs: ['53935d7097b002ca6e571a5e6a2088a5']
[0m[2025-01-22T04:54:37.392887] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T04:54:37.392923] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T04:58:37.414795] [SCALING] Scaling started.
[0m[2025-01-22T04:58:37.414929] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T04:58:37.428809] [SCALING] Scaling finished.
[0m[2025-01-22T04:58:37.428840] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T04:58:37.520385] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T04:58:37.540037] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T04:58:37.564683] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 0 replica.
[0m[2025-01-22T04:58:47.591901] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T04:58:47.605426] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T04:58:47.618264] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T04:58:47.631803] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T04:58:47.645269] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T04:58:47.677384] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xqmtz deleted
[0m[2025-01-22T04:58:49.569294] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:58:51.473533] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T04:58:51.473594] Reloading playbook: application/kafka
[0m[2025-01-22T04:58:57.450426] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T04:59:43.419552] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T04:59:43.419684] [EXPERIMENT] Run 5 completed. Start: 1737521662, End: 1737521983
[0m[2025-01-22T04:59:43.419690] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T04:59:55.673977] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T04:59:55.674034] [RESOURCE_E] Running experiment with 8000m cores and 32768 memory.
[0m[2025-01-22T05:00:02.939152] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T05:00:02.939217] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T05:00:04.795012] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:00:06.678711] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:00:06.678769] [SCALING] Setting up experiment.


[0m[2025-01-22T05:00:06.678777] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:00:06.684776] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:00:06.701191] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T05:00:06.716955] [SCALING] Statefulset name to scale : flink-8000m-32768
[0m[2025-01-22T05:00:06.726639] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 1 replica.
[0m[2025-01-22T05:00:11.738818] [FLK_MGR] Running job.
[0m[2025-01-22T05:00:11.738848] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T05:00:12.107845] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-njf68
[0m[2025-01-22T05:00:16.216033] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f155987121af9252bb17397a9f7527ae

[0m[2025-01-22T05:00:16.216084] [FLK_MGR] Running job id: f155987121af9252bb17397a9f7527ae
[0m[2025-01-22T05:00:16.216090] [FLK_MGR] Getting job info.
[0m[2025-01-22T05:00:16.236181] [FLK_MGR] Job plan response: {"plan":{"jid":"f155987121af9252bb17397a9f7527ae","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T05:00:16.236315] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T05:00:16.667921] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-njf68
[0m[2025-01-22T05:00:18.110956] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 05:00:15 : f155987121af9252bb17397a9f7527ae : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T05:00:18.111016] [FLK_MGR] Running jobs: ['f155987121af9252bb17397a9f7527ae']
[0m[2025-01-22T05:00:18.111024] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T05:00:18.111034] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T05:04:18.136412] [SCALING] Scaling started.
[0m[2025-01-22T05:04:18.136534] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T05:04:18.150100] [SCALING] Scaling finished.
[0m[2025-01-22T05:04:18.150135] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:04:18.167377] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:04:18.184425] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T05:04:18.206105] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 0 replica.
[0m[2025-01-22T05:04:23.228968] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T05:04:23.243282] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T05:04:23.258210] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T05:04:23.272197] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T05:04:23.286671] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T05:04:23.309741] [POD_MGR] Pod flink-jobmanager-7d7c784b74-njf68 deleted
[0m[2025-01-22T05:04:25.183250] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:04:27.067954] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:04:27.068015] Reloading playbook: application/kafka
[0m[2025-01-22T05:04:32.973933] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T05:05:18.907887] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T05:05:18.908022] [EXPERIMENT] Run 1 completed. Start: 1737522002, End: 1737522318
[0m[2025-01-22T05:05:18.908029] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T05:05:28.909100] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T05:05:30.777157] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:05:32.641508] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:05:32.641660] [SCALING] Setting up experiment.


[0m[2025-01-22T05:05:32.641689] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:05:32.647117] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:05:32.663413] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T05:05:32.681193] [SCALING] Statefulset name to scale : flink-8000m-32768
[0m[2025-01-22T05:05:32.690808] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 1 replica.
[0m[2025-01-22T05:05:37.701395] [FLK_MGR] Running job.
[0m[2025-01-22T05:05:37.701424] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T05:05:38.140678] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-n2mt7
[0m[2025-01-22T05:05:42.245894] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID bab4fee5e15da53ba92c7ed7e636861e

[0m[2025-01-22T05:05:42.245941] [FLK_MGR] Running job id: bab4fee5e15da53ba92c7ed7e636861e
[0m[2025-01-22T05:05:42.245949] [FLK_MGR] Getting job info.
[0m[2025-01-22T05:05:42.265718] [FLK_MGR] Job plan response: {"plan":{"jid":"bab4fee5e15da53ba92c7ed7e636861e","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T05:05:42.265875] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T05:05:42.726420] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-n2mt7
[0m[2025-01-22T05:05:44.154798] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 05:05:41 : bab4fee5e15da53ba92c7ed7e636861e : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T05:05:44.154858] [FLK_MGR] Running jobs: ['bab4fee5e15da53ba92c7ed7e636861e']
[0m[2025-01-22T05:05:44.154864] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T05:05:44.154870] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T05:09:44.179335] [SCALING] Scaling started.
[0m[2025-01-22T05:09:44.179390] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T05:09:44.192254] [SCALING] Scaling finished.
[0m[2025-01-22T05:09:44.192271] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:09:44.210324] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:09:44.226748] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T05:09:44.248999] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 0 replica.
[0m[2025-01-22T05:09:54.276382] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T05:09:54.289710] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T05:09:54.302743] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T05:09:54.315499] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T05:09:54.328155] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T05:09:54.350300] [POD_MGR] Pod flink-jobmanager-7d7c784b74-n2mt7 deleted
[0m[2025-01-22T05:09:56.288133] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:09:58.210701] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:09:58.210766] Reloading playbook: application/kafka
[0m[2025-01-22T05:10:04.200740] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T05:10:50.214737] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T05:10:50.214893] [EXPERIMENT] Run 2 completed. Start: 1737522328, End: 1737522650
[0m[2025-01-22T05:10:50.214901] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T05:11:00.215924] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T05:11:02.119866] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:11:04.007058] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:11:04.007117] [SCALING] Setting up experiment.


[0m[2025-01-22T05:11:04.007126] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:11:04.013329] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:11:04.029514] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T05:11:04.044655] [SCALING] Statefulset name to scale : flink-8000m-32768
[0m[2025-01-22T05:11:04.063718] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 1 replica.
[0m[2025-01-22T05:11:09.073214] [FLK_MGR] Running job.
[0m[2025-01-22T05:11:09.073242] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T05:11:09.496114] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-vb4mx
[0m[2025-01-22T05:11:13.558254] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 95290d0a8d3fc6e3781248bceb9d445e

[0m[2025-01-22T05:11:13.558304] [FLK_MGR] Running job id: 95290d0a8d3fc6e3781248bceb9d445e
[0m[2025-01-22T05:11:13.558312] [FLK_MGR] Getting job info.
[0m[2025-01-22T05:11:13.577272] [FLK_MGR] Job plan response: {"plan":{"jid":"95290d0a8d3fc6e3781248bceb9d445e","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T05:11:13.577429] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T05:11:14.023141] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-vb4mx
[0m[2025-01-22T05:11:15.466888] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 05:11:12 : 95290d0a8d3fc6e3781248bceb9d445e : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T05:11:15.466945] [FLK_MGR] Running jobs: ['95290d0a8d3fc6e3781248bceb9d445e']
[0m[2025-01-22T05:11:15.466951] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T05:11:15.466957] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T05:15:15.491443] [SCALING] Scaling started.
[0m[2025-01-22T05:15:15.491502] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T05:15:15.505427] [SCALING] Scaling finished.
[0m[2025-01-22T05:15:15.505452] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:15:15.524428] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:15:15.541848] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T05:15:15.563322] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 0 replica.
[0m[2025-01-22T05:15:20.583415] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T05:15:20.596483] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T05:15:20.609367] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T05:15:20.622226] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T05:15:20.635255] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T05:15:20.663929] [POD_MGR] Pod flink-jobmanager-7d7c784b74-vb4mx deleted
[0m[2025-01-22T05:15:22.583469] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:15:24.501700] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:15:24.501758] Reloading playbook: application/kafka
[0m[2025-01-22T05:15:30.453315] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T05:16:16.404896] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T05:16:16.405019] [EXPERIMENT] Run 3 completed. Start: 1737522660, End: 1737522976
[0m[2025-01-22T05:16:16.405025] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T05:16:26.406136] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T05:16:28.266021] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:16:30.124907] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:16:30.124961] [SCALING] Setting up experiment.


[0m[2025-01-22T05:16:30.124970] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:16:30.130374] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:16:30.147107] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T05:16:30.162589] [SCALING] Statefulset name to scale : flink-8000m-32768
[0m[2025-01-22T05:16:30.174202] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 1 replica.
[0m[2025-01-22T05:16:35.183504] [FLK_MGR] Running job.
[0m[2025-01-22T05:16:35.183531] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T05:16:35.632341] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jvzkg
[0m[2025-01-22T05:16:39.739144] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 3135c9d63e68ab63b22588225451349f

[0m[2025-01-22T05:16:39.739192] [FLK_MGR] Running job id: 3135c9d63e68ab63b22588225451349f
[0m[2025-01-22T05:16:39.739200] [FLK_MGR] Getting job info.
[0m[2025-01-22T05:16:39.755122] [FLK_MGR] Job plan response: {"plan":{"jid":"3135c9d63e68ab63b22588225451349f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T05:16:39.755257] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T05:16:40.155290] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jvzkg
[0m[2025-01-22T05:16:41.622119] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 05:16:38 : 3135c9d63e68ab63b22588225451349f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T05:16:41.622172] [FLK_MGR] Running jobs: ['3135c9d63e68ab63b22588225451349f']
[0m[2025-01-22T05:16:41.622179] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T05:16:41.622185] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T05:20:41.645740] [SCALING] Scaling started.
[0m[2025-01-22T05:20:41.645824] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T05:20:41.658740] [SCALING] Scaling finished.
[0m[2025-01-22T05:20:41.658763] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:20:41.676797] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:20:41.694921] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T05:20:41.715443] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 0 replica.
[0m[2025-01-22T05:20:46.736855] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T05:20:46.750298] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T05:20:46.763625] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T05:20:46.777011] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T05:20:46.790476] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T05:20:46.814622] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jvzkg deleted
[0m[2025-01-22T05:20:48.718251] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:20:50.628829] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:20:50.628893] Reloading playbook: application/kafka
[0m[2025-01-22T05:20:56.637056] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T05:21:42.624367] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T05:21:42.624497] [EXPERIMENT] Run 4 completed. Start: 1737522986, End: 1737523302
[0m[2025-01-22T05:21:42.624503] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T05:21:52.625479] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T05:21:54.463486] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:21:56.338487] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:21:56.338542] [SCALING] Setting up experiment.


[0m[2025-01-22T05:21:56.338550] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:21:56.343823] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:21:56.359337] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T05:21:56.378893] [SCALING] Statefulset name to scale : flink-8000m-32768
[0m[2025-01-22T05:21:56.389376] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 1 replica.
[0m[2025-01-22T05:22:01.399875] [FLK_MGR] Running job.
[0m[2025-01-22T05:22:01.399903] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T05:22:01.840473] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-474dn
[0m[2025-01-22T05:22:05.930022] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 687e2c522f3f9d235613a1281c48d498

[0m[2025-01-22T05:22:05.930071] [FLK_MGR] Running job id: 687e2c522f3f9d235613a1281c48d498
[0m[2025-01-22T05:22:05.930081] [FLK_MGR] Getting job info.
[0m[2025-01-22T05:22:05.947599] [FLK_MGR] Job plan response: {"plan":{"jid":"687e2c522f3f9d235613a1281c48d498","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T05:22:05.947727] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T05:22:06.370980] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-474dn
[0m[2025-01-22T05:22:07.838318] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 05:22:04 : 687e2c522f3f9d235613a1281c48d498 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T05:22:07.838375] [FLK_MGR] Running jobs: ['687e2c522f3f9d235613a1281c48d498']
[0m[2025-01-22T05:22:07.838383] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T05:22:07.838389] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T05:26:07.861711] [SCALING] Scaling started.
[0m[2025-01-22T05:26:07.861809] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T05:26:07.876905] [SCALING] Scaling finished.
[0m[2025-01-22T05:26:07.876925] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:26:07.894159] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:26:07.913372] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T05:26:07.935111] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 0 replica.
[0m[2025-01-22T05:26:12.956768] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T05:26:12.971379] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T05:26:12.984805] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T05:26:12.999356] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T05:26:13.013549] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T05:26:13.033133] [POD_MGR] Pod flink-jobmanager-7d7c784b74-474dn deleted
[0m[2025-01-22T05:26:14.938584] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:26:16.836538] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:26:16.836608] Reloading playbook: application/kafka
[0m[2025-01-22T05:26:22.802444] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T05:27:08.697569] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T05:27:08.697693] [EXPERIMENT] Run 5 completed. Start: 1737523312, End: 1737523628
[0m[2025-01-22T05:27:08.697699] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T05:27:20.932944] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T05:27:20.933002] [RESOURCE_E] Running experiment with 16000m cores and 1024 memory.
[0m[2025-01-22T05:27:28.190559] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T05:27:28.190636] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T05:27:30.053058] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:27:31.932392] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:27:31.932447] [SCALING] Setting up experiment.


[0m[2025-01-22T05:27:31.932455] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:27:31.938628] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:27:31.955130] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T05:27:31.972432] [SCALING] Statefulset name to scale : flink-16000m-1024
[0m[2025-01-22T05:27:31.983702] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 1 replica.
[0m[2025-01-22T05:27:36.993973] [FLK_MGR] Running job.
[0m[2025-01-22T05:27:36.994002] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T05:27:37.424532] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-pvrgk
[0m[2025-01-22T05:27:41.593077] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 7becf6571501e641f57d6a3181867729

[0m[2025-01-22T05:27:41.593128] [FLK_MGR] Running job id: 7becf6571501e641f57d6a3181867729
[0m[2025-01-22T05:27:41.593135] [FLK_MGR] Getting job info.
[0m[2025-01-22T05:27:41.609863] [FLK_MGR] Job plan response: {"plan":{"jid":"7becf6571501e641f57d6a3181867729","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T05:27:41.610003] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T05:27:42.031079] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-pvrgk
[0m[2025-01-22T05:27:43.479918] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 05:27:40 : 7becf6571501e641f57d6a3181867729 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T05:27:43.479972] [FLK_MGR] Running jobs: ['7becf6571501e641f57d6a3181867729']
[0m[2025-01-22T05:27:43.479981] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T05:27:43.479987] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T05:31:43.503015] [SCALING] Scaling started.
[0m[2025-01-22T05:31:43.503067] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T05:31:43.516574] [SCALING] Scaling finished.
[0m[2025-01-22T05:31:43.516596] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:31:43.533924] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:31:43.551223] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T05:31:43.571633] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 0 replica.
[0m[2025-01-22T05:31:43.590822] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T05:31:43.603701] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T05:31:43.616177] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T05:31:43.628862] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T05:31:43.641451] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T05:31:43.673335] [POD_MGR] Pod flink-jobmanager-7d7c784b74-pvrgk deleted
[0m[2025-01-22T05:31:45.599804] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:31:47.505756] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:31:47.505823] Reloading playbook: application/kafka
[0m[2025-01-22T05:31:53.493020] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T05:32:39.435880] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T05:32:39.436025] [EXPERIMENT] Run 1 completed. Start: 1737523648, End: 1737523959
[0m[2025-01-22T05:32:39.436031] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T05:32:49.436975] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T05:32:51.305276] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:32:53.179548] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:32:53.179611] [SCALING] Setting up experiment.


[0m[2025-01-22T05:32:53.179620] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:32:53.185181] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:32:53.203497] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T05:32:53.220219] [SCALING] Statefulset name to scale : flink-16000m-1024
[0m[2025-01-22T05:32:53.231466] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 1 replica.
[0m[2025-01-22T05:32:58.241496] [FLK_MGR] Running job.
[0m[2025-01-22T05:32:58.241522] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T05:32:58.676115] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mc6mg
[0m[2025-01-22T05:33:02.755930] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 97f468940138f15ce89dadcb530b8d16

[0m[2025-01-22T05:33:02.755978] [FLK_MGR] Running job id: 97f468940138f15ce89dadcb530b8d16
[0m[2025-01-22T05:33:02.755985] [FLK_MGR] Getting job info.
[0m[2025-01-22T05:33:02.771260] [FLK_MGR] Job plan response: {"plan":{"jid":"97f468940138f15ce89dadcb530b8d16","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T05:33:02.771408] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T05:33:03.147027] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mc6mg
[0m[2025-01-22T05:33:04.594438] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 05:33:01 : 97f468940138f15ce89dadcb530b8d16 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T05:33:04.594491] [FLK_MGR] Running jobs: ['97f468940138f15ce89dadcb530b8d16']
[0m[2025-01-22T05:33:04.594498] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T05:33:04.594504] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T05:37:04.617149] [SCALING] Scaling started.
[0m[2025-01-22T05:37:04.617245] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T05:37:04.631193] [SCALING] Scaling finished.
[0m[2025-01-22T05:37:04.631212] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:37:04.649757] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:37:04.666149] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T05:37:04.685949] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 0 replica.
[0m[2025-01-22T05:37:09.706619] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T05:37:09.721564] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T05:37:09.736175] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T05:37:09.750032] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T05:37:09.763597] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T05:37:09.799077] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mc6mg deleted
[0m[2025-01-22T05:37:11.671005] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:37:13.603423] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:37:13.603464] Reloading playbook: application/kafka
[0m[2025-01-22T05:37:19.602700] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T05:38:05.549586] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T05:38:05.549707] [EXPERIMENT] Run 2 completed. Start: 1737523969, End: 1737524285
[0m[2025-01-22T05:38:05.549714] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T05:38:15.550948] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T05:38:17.421378] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:38:19.288061] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:38:19.288119] [SCALING] Setting up experiment.


[0m[2025-01-22T05:38:19.288128] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:38:19.293418] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:38:19.313094] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T05:38:19.330418] [SCALING] Statefulset name to scale : flink-16000m-1024
[0m[2025-01-22T05:38:19.340559] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 1 replica.
[0m[2025-01-22T05:38:24.350347] [FLK_MGR] Running job.
[0m[2025-01-22T05:38:24.350375] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T05:38:24.719667] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-nrs6x
[0m[2025-01-22T05:38:28.803898] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b2e073385d26a9be30238bc1e2863138

[0m[2025-01-22T05:38:28.803963] [FLK_MGR] Running job id: b2e073385d26a9be30238bc1e2863138
[0m[2025-01-22T05:38:28.803974] [FLK_MGR] Getting job info.
[0m[2025-01-22T05:38:28.822207] [FLK_MGR] Job plan response: {"plan":{"jid":"b2e073385d26a9be30238bc1e2863138","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T05:38:28.822632] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T05:38:29.244280] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-nrs6x
[0m[2025-01-22T05:38:30.700020] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 05:38:27 : b2e073385d26a9be30238bc1e2863138 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T05:38:30.700073] [FLK_MGR] Running jobs: ['b2e073385d26a9be30238bc1e2863138']
[0m[2025-01-22T05:38:30.700080] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T05:38:30.700087] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T05:42:30.724114] [SCALING] Scaling started.
[0m[2025-01-22T05:42:30.724214] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T05:42:30.737286] [SCALING] Scaling finished.
[0m[2025-01-22T05:42:30.737304] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:42:30.768103] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:42:30.787291] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T05:42:30.807973] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 0 replica.
[0m[2025-01-22T05:42:30.825295] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T05:42:30.839600] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T05:42:30.853845] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T05:42:30.868811] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T05:42:30.884583] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T05:42:30.906307] [POD_MGR] Pod flink-jobmanager-7d7c784b74-nrs6x deleted
[0m[2025-01-22T05:42:32.780683] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:42:34.672989] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:42:34.673051] Reloading playbook: application/kafka
[0m[2025-01-22T05:42:40.645885] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T05:43:26.557166] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T05:43:26.557324] [EXPERIMENT] Run 3 completed. Start: 1737524295, End: 1737524606
[0m[2025-01-22T05:43:26.557331] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T05:43:36.558290] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T05:43:38.436703] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:43:40.313261] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:43:40.313319] [SCALING] Setting up experiment.


[0m[2025-01-22T05:43:40.313329] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:43:40.319119] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:43:40.334176] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T05:43:40.354749] [SCALING] Statefulset name to scale : flink-16000m-1024
[0m[2025-01-22T05:43:40.365206] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 1 replica.
[0m[2025-01-22T05:43:45.376854] [FLK_MGR] Running job.
[0m[2025-01-22T05:43:45.376882] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T05:43:45.823799] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jwj4g
[0m[2025-01-22T05:43:49.953313] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f4b3558139733ee3766d3df4681078f5

[0m[2025-01-22T05:43:49.953363] [FLK_MGR] Running job id: f4b3558139733ee3766d3df4681078f5
[0m[2025-01-22T05:43:49.953371] [FLK_MGR] Getting job info.
[0m[2025-01-22T05:43:49.971902] [FLK_MGR] Job plan response: {"plan":{"jid":"f4b3558139733ee3766d3df4681078f5","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T05:43:49.972048] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T05:43:50.417408] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jwj4g
[0m[2025-01-22T05:43:51.852613] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 05:43:48 : f4b3558139733ee3766d3df4681078f5 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T05:43:51.852667] [FLK_MGR] Running jobs: ['f4b3558139733ee3766d3df4681078f5']
[0m[2025-01-22T05:43:51.852675] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T05:43:51.852681] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T05:47:51.876077] [SCALING] Scaling started.
[0m[2025-01-22T05:47:51.876174] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T05:47:51.888403] [SCALING] Scaling finished.
[0m[2025-01-22T05:47:51.888422] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:47:51.906716] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:47:51.923776] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T05:47:51.944519] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 0 replica.
[0m[2025-01-22T05:47:56.963550] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T05:47:56.977441] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T05:47:56.991930] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T05:47:57.006385] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T05:47:57.020636] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T05:47:57.049939] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jwj4g deleted
[0m[2025-01-22T05:47:58.931719] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:48:00.854050] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:48:00.854130] Reloading playbook: application/kafka
[0m[2025-01-22T05:48:06.828477] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T05:48:52.807364] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T05:48:52.807481] [EXPERIMENT] Run 4 completed. Start: 1737524616, End: 1737524932
[0m[2025-01-22T05:48:52.807488] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T05:49:02.808585] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T05:49:04.684413] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:49:06.550184] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:49:06.550233] [SCALING] Setting up experiment.


[0m[2025-01-22T05:49:06.550241] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:49:06.555673] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:49:06.571925] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T05:49:06.592490] [SCALING] Statefulset name to scale : flink-16000m-1024
[0m[2025-01-22T05:49:06.603015] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 1 replica.
[0m[2025-01-22T05:49:11.613315] [FLK_MGR] Running job.
[0m[2025-01-22T05:49:11.613344] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T05:49:12.060180] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-gn95k
[0m[2025-01-22T05:49:16.160542] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 3eb52a3de759dd1594161c3952257206

[0m[2025-01-22T05:49:16.160601] [FLK_MGR] Running job id: 3eb52a3de759dd1594161c3952257206
[0m[2025-01-22T05:49:16.160609] [FLK_MGR] Getting job info.
[0m[2025-01-22T05:49:16.177867] [FLK_MGR] Job plan response: {"plan":{"jid":"3eb52a3de759dd1594161c3952257206","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T05:49:16.178004] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T05:49:16.558422] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-gn95k
[0m[2025-01-22T05:49:18.007423] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 05:49:15 : 3eb52a3de759dd1594161c3952257206 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T05:49:18.007480] [FLK_MGR] Running jobs: ['3eb52a3de759dd1594161c3952257206']
[0m[2025-01-22T05:49:18.007487] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T05:49:18.007494] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T05:53:18.030112] [SCALING] Scaling started.
[0m[2025-01-22T05:53:18.030166] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T05:53:18.043212] [SCALING] Scaling finished.
[0m[2025-01-22T05:53:18.043233] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:53:18.062636] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:53:18.080178] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T05:53:18.135641] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 0 replica.
[0m[2025-01-22T05:53:18.158380] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T05:53:18.171813] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T05:53:18.184830] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T05:53:18.197580] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T05:53:18.210751] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T05:53:18.241216] [POD_MGR] Pod flink-jobmanager-7d7c784b74-gn95k deleted
[0m[2025-01-22T05:53:20.162290] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:53:22.071811] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:53:22.071875] Reloading playbook: application/kafka
[0m[2025-01-22T05:53:27.969541] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T05:54:13.951645] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T05:54:13.951788] [EXPERIMENT] Run 5 completed. Start: 1737524942, End: 1737525253
[0m[2025-01-22T05:54:13.951794] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T05:54:26.079796] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T05:54:26.079851] [RESOURCE_E] Running experiment with 16000m cores and 2048 memory.
[0m[2025-01-22T05:54:33.260317] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T05:54:33.260417] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T05:54:35.130128] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:54:36.999970] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T05:54:37.000027] [SCALING] Setting up experiment.


[0m[2025-01-22T05:54:37.000038] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:54:37.005731] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:54:37.022065] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T05:54:37.037952] [SCALING] Statefulset name to scale : flink-16000m-2048
[0m[2025-01-22T05:54:37.048513] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 1 replica.
[0m[2025-01-22T05:54:42.059509] [FLK_MGR] Running job.
[0m[2025-01-22T05:54:42.059536] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T05:54:42.435060] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-62fxs
[0m[2025-01-22T05:54:46.607053] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 029073e78e5aa5c5118276c653aa62d0

[0m[2025-01-22T05:54:46.607106] [FLK_MGR] Running job id: 029073e78e5aa5c5118276c653aa62d0
[0m[2025-01-22T05:54:46.607113] [FLK_MGR] Getting job info.
[0m[2025-01-22T05:54:46.624399] [FLK_MGR] Job plan response: {"plan":{"jid":"029073e78e5aa5c5118276c653aa62d0","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T05:54:46.624530] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T05:54:47.044304] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-62fxs
[0m[2025-01-22T05:54:48.490743] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 05:54:45 : 029073e78e5aa5c5118276c653aa62d0 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T05:54:48.490800] [FLK_MGR] Running jobs: ['029073e78e5aa5c5118276c653aa62d0']
[0m[2025-01-22T05:54:48.490806] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T05:54:48.490811] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T05:58:48.516150] [SCALING] Scaling started.
[0m[2025-01-22T05:58:48.516204] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T05:58:48.530132] [SCALING] Scaling finished.
[0m[2025-01-22T05:58:48.530156] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T05:58:48.549943] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T05:58:48.566300] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T05:58:48.588609] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 0 replica.
[0m[2025-01-22T05:58:53.609793] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T05:58:53.622705] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T05:58:53.635529] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T05:58:53.648704] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T05:58:53.661704] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T05:58:53.689817] [POD_MGR] Pod flink-jobmanager-7d7c784b74-62fxs deleted
[0m[2025-01-22T05:58:55.556317] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:58:57.412374] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T05:58:57.412433] Reloading playbook: application/kafka
[0m[2025-01-22T05:59:03.304937] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T05:59:49.273944] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T05:59:49.274146] [EXPERIMENT] Run 1 completed. Start: 1737525273, End: 1737525589
[0m[2025-01-22T05:59:49.274153] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T05:59:59.275200] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T06:00:01.157661] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:00:03.026332] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:00:03.026402] [SCALING] Setting up experiment.


[0m[2025-01-22T06:00:03.026413] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:00:03.034820] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:00:03.052027] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T06:00:03.070798] [SCALING] Statefulset name to scale : flink-16000m-2048
[0m[2025-01-22T06:00:03.081473] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 1 replica.
[0m[2025-01-22T06:00:08.092501] [FLK_MGR] Running job.
[0m[2025-01-22T06:00:08.092564] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T06:00:08.528244] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-bgnt9
[0m[2025-01-22T06:00:12.639173] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 64717b25ac859398abb846312f7fd580

[0m[2025-01-22T06:00:12.639226] [FLK_MGR] Running job id: 64717b25ac859398abb846312f7fd580
[0m[2025-01-22T06:00:12.639233] [FLK_MGR] Getting job info.
[0m[2025-01-22T06:00:12.656027] [FLK_MGR] Job plan response: {"plan":{"jid":"64717b25ac859398abb846312f7fd580","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T06:00:12.656169] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T06:00:13.078080] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-bgnt9
[0m[2025-01-22T06:00:14.517828] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 06:00:11 : 64717b25ac859398abb846312f7fd580 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T06:00:14.517882] [FLK_MGR] Running jobs: ['64717b25ac859398abb846312f7fd580']
[0m[2025-01-22T06:00:14.517889] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T06:00:14.517894] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T06:04:14.541896] [SCALING] Scaling started.
[0m[2025-01-22T06:04:14.541995] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T06:04:14.553955] [SCALING] Scaling finished.
[0m[2025-01-22T06:04:14.553974] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:04:14.571659] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:04:14.590562] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T06:04:14.612488] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 0 replica.
[0m[2025-01-22T06:04:19.633346] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T06:04:19.646181] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T06:04:19.660604] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T06:04:19.675671] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T06:04:19.690048] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T06:04:19.725637] [POD_MGR] Pod flink-jobmanager-7d7c784b74-bgnt9 deleted
[0m[2025-01-22T06:04:21.617038] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:04:23.535349] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:04:23.535414] Reloading playbook: application/kafka
[0m[2025-01-22T06:04:29.523434] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T06:05:15.508121] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T06:05:15.508394] [EXPERIMENT] Run 2 completed. Start: 1737525599, End: 1737525915
[0m[2025-01-22T06:05:15.508402] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T06:05:25.509376] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T06:05:27.392704] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:05:29.245424] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:05:29.245479] [SCALING] Setting up experiment.


[0m[2025-01-22T06:05:29.245490] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:05:29.272674] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:05:29.289669] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T06:05:29.310986] [SCALING] Statefulset name to scale : flink-16000m-2048
[0m[2025-01-22T06:05:29.325440] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 1 replica.
[0m[2025-01-22T06:05:34.336032] [FLK_MGR] Running job.
[0m[2025-01-22T06:05:34.336063] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T06:05:34.781893] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xk8qq
[0m[2025-01-22T06:05:38.918871] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID be4540ea2cd6e0a064ada529fe1b5a8d

[0m[2025-01-22T06:05:38.918919] [FLK_MGR] Running job id: be4540ea2cd6e0a064ada529fe1b5a8d
[0m[2025-01-22T06:05:38.918925] [FLK_MGR] Getting job info.
[0m[2025-01-22T06:05:38.935721] [FLK_MGR] Job plan response: {"plan":{"jid":"be4540ea2cd6e0a064ada529fe1b5a8d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T06:05:38.935858] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T06:05:39.364653] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xk8qq
[0m[2025-01-22T06:05:40.831252] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 06:05:37 : be4540ea2cd6e0a064ada529fe1b5a8d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T06:05:40.831310] [FLK_MGR] Running jobs: ['be4540ea2cd6e0a064ada529fe1b5a8d']
[0m[2025-01-22T06:05:40.831316] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T06:05:40.831322] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T06:09:40.855470] [SCALING] Scaling started.
[0m[2025-01-22T06:09:40.855527] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T06:09:40.868478] [SCALING] Scaling finished.
[0m[2025-01-22T06:09:40.868502] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:09:40.887697] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:09:40.905686] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T06:09:40.933334] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 0 replica.
[0m[2025-01-22T06:09:45.954425] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T06:09:45.968713] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T06:09:45.983391] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T06:09:45.998073] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T06:09:46.013966] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T06:09:46.041957] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xk8qq deleted
[0m[2025-01-22T06:09:47.944005] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:09:49.845352] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:09:49.845416] Reloading playbook: application/kafka
[0m[2025-01-22T06:09:55.832439] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T06:10:41.839963] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T06:10:41.840174] [EXPERIMENT] Run 3 completed. Start: 1737525925, End: 1737526241
[0m[2025-01-22T06:10:41.840183] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T06:10:51.841173] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T06:10:53.717606] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:10:55.561826] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:10:55.561884] [SCALING] Setting up experiment.


[0m[2025-01-22T06:10:55.561893] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:10:55.567700] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:10:55.587616] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T06:10:55.602411] [SCALING] Statefulset name to scale : flink-16000m-2048
[0m[2025-01-22T06:10:55.613219] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 1 replica.
[0m[2025-01-22T06:11:00.623138] [FLK_MGR] Running job.
[0m[2025-01-22T06:11:00.623165] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T06:11:01.063952] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-4nkm5
[0m[2025-01-22T06:11:05.106022] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 1838e2d42c955fe3c9b074ec85b86975

[0m[2025-01-22T06:11:05.106071] [FLK_MGR] Running job id: 1838e2d42c955fe3c9b074ec85b86975
[0m[2025-01-22T06:11:05.106077] [FLK_MGR] Getting job info.
[0m[2025-01-22T06:11:05.122604] [FLK_MGR] Job plan response: {"plan":{"jid":"1838e2d42c955fe3c9b074ec85b86975","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T06:11:05.122752] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T06:11:05.497294] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-4nkm5
[0m[2025-01-22T06:11:07.013025] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 06:11:04 : 1838e2d42c955fe3c9b074ec85b86975 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T06:11:07.013079] [FLK_MGR] Running jobs: ['1838e2d42c955fe3c9b074ec85b86975']
[0m[2025-01-22T06:11:07.013086] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T06:11:07.013092] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T06:15:07.035584] [SCALING] Scaling started.
[0m[2025-01-22T06:15:07.035637] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T06:15:07.048760] [SCALING] Scaling finished.
[0m[2025-01-22T06:15:07.048784] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:15:07.070804] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:15:07.088645] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T06:15:07.111968] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 0 replica.
[0m[2025-01-22T06:15:07.134233] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T06:15:07.148692] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T06:15:07.162713] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T06:15:07.177793] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T06:15:07.191653] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T06:15:07.232050] [POD_MGR] Pod flink-jobmanager-7d7c784b74-4nkm5 deleted
[0m[2025-01-22T06:15:09.150967] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:15:11.082375] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:15:11.082436] Reloading playbook: application/kafka
[0m[2025-01-22T06:15:17.074752] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T06:16:03.019022] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T06:16:03.019191] [EXPERIMENT] Run 4 completed. Start: 1737526251, End: 1737526563
[0m[2025-01-22T06:16:03.019198] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T06:16:13.020284] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T06:16:14.850332] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:16:16.698954] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:16:16.699009] [SCALING] Setting up experiment.


[0m[2025-01-22T06:16:16.699019] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:16:16.704236] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:16:16.720599] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T06:16:16.736883] [SCALING] Statefulset name to scale : flink-16000m-2048
[0m[2025-01-22T06:16:16.748328] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 1 replica.
[0m[2025-01-22T06:16:21.757904] [FLK_MGR] Running job.
[0m[2025-01-22T06:16:21.757933] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T06:16:22.187108] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-prm8h
[0m[2025-01-22T06:16:26.331142] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9790917d002912d3afc1be458f9253a8

[0m[2025-01-22T06:16:26.331192] [FLK_MGR] Running job id: 9790917d002912d3afc1be458f9253a8
[0m[2025-01-22T06:16:26.331199] [FLK_MGR] Getting job info.
[0m[2025-01-22T06:16:26.346905] [FLK_MGR] Job plan response: {"plan":{"jid":"9790917d002912d3afc1be458f9253a8","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T06:16:26.347037] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T06:16:26.752979] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-prm8h
[0m[2025-01-22T06:16:28.185991] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 06:16:25 : 9790917d002912d3afc1be458f9253a8 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T06:16:28.186095] [FLK_MGR] Running jobs: ['9790917d002912d3afc1be458f9253a8']
[0m[2025-01-22T06:16:28.186104] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T06:16:28.186115] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T06:20:28.211168] [SCALING] Scaling started.
[0m[2025-01-22T06:20:28.211280] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T06:20:28.226012] [SCALING] Scaling finished.
[0m[2025-01-22T06:20:28.226039] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:20:28.246022] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:20:28.263450] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T06:20:28.284924] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 0 replica.
[0m[2025-01-22T06:20:38.313529] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T06:20:38.326757] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T06:20:38.340104] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T06:20:38.353650] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T06:20:38.366953] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T06:20:38.401556] [POD_MGR] Pod flink-jobmanager-7d7c784b74-prm8h deleted
[0m[2025-01-22T06:20:40.303750] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:20:42.227292] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:20:42.227355] Reloading playbook: application/kafka
[0m[2025-01-22T06:20:48.187512] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T06:21:34.142533] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T06:21:34.142673] [EXPERIMENT] Run 5 completed. Start: 1737526573, End: 1737526894
[0m[2025-01-22T06:21:34.142679] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T06:21:46.367906] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T06:21:46.367960] [RESOURCE_E] Running experiment with 16000m cores and 4096 memory.
[0m[2025-01-22T06:21:53.623076] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T06:21:53.623140] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T06:21:55.509235] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:21:57.389695] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:21:57.389755] [SCALING] Setting up experiment.


[0m[2025-01-22T06:21:57.389763] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:21:57.395379] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:21:57.411977] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T06:21:57.427926] [SCALING] Statefulset name to scale : flink-16000m-4096
[0m[2025-01-22T06:21:57.439034] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 1 replica.
[0m[2025-01-22T06:22:02.451368] [FLK_MGR] Running job.
[0m[2025-01-22T06:22:02.451396] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T06:22:02.885373] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-2q2ft
[0m[2025-01-22T06:22:06.957078] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fca8233b2cb48469b43adc6e4485d070

[0m[2025-01-22T06:22:06.957125] [FLK_MGR] Running job id: fca8233b2cb48469b43adc6e4485d070
[0m[2025-01-22T06:22:06.957131] [FLK_MGR] Getting job info.
[0m[2025-01-22T06:22:06.975306] [FLK_MGR] Job plan response: {"plan":{"jid":"fca8233b2cb48469b43adc6e4485d070","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T06:22:06.975434] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T06:22:07.386045] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-2q2ft
[0m[2025-01-22T06:22:08.827664] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 06:22:05 : fca8233b2cb48469b43adc6e4485d070 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T06:22:08.827726] [FLK_MGR] Running jobs: ['fca8233b2cb48469b43adc6e4485d070']
[0m[2025-01-22T06:22:08.827737] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T06:22:08.827765] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T06:26:08.851695] [SCALING] Scaling started.
[0m[2025-01-22T06:26:08.851768] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T06:26:08.864452] [SCALING] Scaling finished.
[0m[2025-01-22T06:26:08.864480] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:26:08.882719] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:26:08.901298] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T06:26:08.925173] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 0 replica.
[0m[2025-01-22T06:26:13.945636] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T06:26:13.959711] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T06:26:13.973849] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T06:26:13.987393] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T06:26:14.000443] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T06:26:14.023890] [POD_MGR] Pod flink-jobmanager-7d7c784b74-2q2ft deleted
[0m[2025-01-22T06:26:15.897590] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:26:17.806242] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:26:17.806315] Reloading playbook: application/kafka
[0m[2025-01-22T06:26:23.743158] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T06:27:09.662574] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T06:27:09.662896] [EXPERIMENT] Run 1 completed. Start: 1737526913, End: 1737527229
[0m[2025-01-22T06:27:09.662926] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T06:27:19.663961] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T06:27:21.505894] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:27:23.412046] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:27:23.412113] [SCALING] Setting up experiment.


[0m[2025-01-22T06:27:23.412121] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:27:23.417207] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:27:23.432854] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T06:27:23.451621] [SCALING] Statefulset name to scale : flink-16000m-4096
[0m[2025-01-22T06:27:23.462771] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 1 replica.
[0m[2025-01-22T06:27:28.472138] [FLK_MGR] Running job.
[0m[2025-01-22T06:27:28.472168] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T06:27:28.922789] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-bpmzs
[0m[2025-01-22T06:27:33.022984] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f018f9e70f19a0392a5ed8e38fa78a15

[0m[2025-01-22T06:27:33.023033] [FLK_MGR] Running job id: f018f9e70f19a0392a5ed8e38fa78a15
[0m[2025-01-22T06:27:33.023041] [FLK_MGR] Getting job info.
[0m[2025-01-22T06:27:33.040946] [FLK_MGR] Job plan response: {"plan":{"jid":"f018f9e70f19a0392a5ed8e38fa78a15","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T06:27:33.041092] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T06:27:33.434571] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-bpmzs
[0m[2025-01-22T06:27:34.872717] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 06:27:32 : f018f9e70f19a0392a5ed8e38fa78a15 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T06:27:34.872771] [FLK_MGR] Running jobs: ['f018f9e70f19a0392a5ed8e38fa78a15']
[0m[2025-01-22T06:27:34.872779] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T06:27:34.872797] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T06:31:34.895275] [SCALING] Scaling started.
[0m[2025-01-22T06:31:34.895331] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T06:31:34.907616] [SCALING] Scaling finished.
[0m[2025-01-22T06:31:34.907644] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:31:34.926669] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:31:34.944219] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T06:31:34.979332] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 0 replica.
[0m[2025-01-22T06:31:45.005933] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T06:31:45.020619] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T06:31:45.036127] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T06:31:45.050895] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T06:31:45.064872] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T06:31:45.100461] [POD_MGR] Pod flink-jobmanager-7d7c784b74-bpmzs deleted
[0m[2025-01-22T06:31:46.957312] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:31:48.883671] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:31:48.883748] Reloading playbook: application/kafka
[0m[2025-01-22T06:31:54.859062] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T06:32:40.849671] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T06:32:40.849743] [EXPERIMENT] Run 2 completed. Start: 1737527239, End: 1737527560
[0m[2025-01-22T06:32:40.849748] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T06:32:50.850747] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T06:32:52.689177] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:32:54.560495] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:32:54.560555] [SCALING] Setting up experiment.


[0m[2025-01-22T06:32:54.560564] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:32:54.566122] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:32:54.583889] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T06:32:54.603167] [SCALING] Statefulset name to scale : flink-16000m-4096
[0m[2025-01-22T06:32:54.614049] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 1 replica.
[0m[2025-01-22T06:32:59.624728] [FLK_MGR] Running job.
[0m[2025-01-22T06:32:59.624754] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T06:32:59.999265] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mjjzt
[0m[2025-01-22T06:33:04.135077] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a67fdc7fde3727ff998fbb4b400c599e

[0m[2025-01-22T06:33:04.135136] [FLK_MGR] Running job id: a67fdc7fde3727ff998fbb4b400c599e
[0m[2025-01-22T06:33:04.135143] [FLK_MGR] Getting job info.
[0m[2025-01-22T06:33:04.152212] [FLK_MGR] Job plan response: {"plan":{"jid":"a67fdc7fde3727ff998fbb4b400c599e","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T06:33:04.152364] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T06:33:04.571267] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mjjzt
[0m[2025-01-22T06:33:05.989851] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 06:33:03 : a67fdc7fde3727ff998fbb4b400c599e : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T06:33:05.989913] [FLK_MGR] Running jobs: ['a67fdc7fde3727ff998fbb4b400c599e']
[0m[2025-01-22T06:33:05.989921] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T06:33:05.989953] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T06:37:06.014319] [SCALING] Scaling started.
[0m[2025-01-22T06:37:06.014396] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T06:37:06.028660] [SCALING] Scaling finished.
[0m[2025-01-22T06:37:06.028682] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:37:06.046665] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:37:06.063849] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T06:37:06.086203] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 0 replica.
[0m[2025-01-22T06:37:11.107161] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T06:37:11.123031] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T06:37:11.136401] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T06:37:11.150558] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T06:37:11.164589] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T06:37:11.188291] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mjjzt deleted
[0m[2025-01-22T06:37:13.053053] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:37:14.973434] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:37:14.973500] Reloading playbook: application/kafka
[0m[2025-01-22T06:37:20.965094] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T06:38:06.915087] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T06:38:06.915240] [EXPERIMENT] Run 3 completed. Start: 1737527570, End: 1737527886
[0m[2025-01-22T06:38:06.915247] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T06:38:16.916128] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T06:38:18.819577] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:38:20.716504] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:38:20.716561] [SCALING] Setting up experiment.


[0m[2025-01-22T06:38:20.716570] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:38:20.722238] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:38:20.737853] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T06:38:20.757847] [SCALING] Statefulset name to scale : flink-16000m-4096
[0m[2025-01-22T06:38:20.768108] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 1 replica.
[0m[2025-01-22T06:38:25.778613] [FLK_MGR] Running job.
[0m[2025-01-22T06:38:25.778691] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T06:38:26.237025] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-t75vp
[0m[2025-01-22T06:38:30.344963] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 04e535a1e315c00e0238b9b793a927c8

[0m[2025-01-22T06:38:30.345021] [FLK_MGR] Running job id: 04e535a1e315c00e0238b9b793a927c8
[0m[2025-01-22T06:38:30.345028] [FLK_MGR] Getting job info.
[0m[2025-01-22T06:38:30.365003] [FLK_MGR] Job plan response: {"plan":{"jid":"04e535a1e315c00e0238b9b793a927c8","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T06:38:30.365321] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T06:38:30.845203] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-t75vp
[0m[2025-01-22T06:38:32.277551] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 06:38:29 : 04e535a1e315c00e0238b9b793a927c8 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T06:38:32.277608] [FLK_MGR] Running jobs: ['04e535a1e315c00e0238b9b793a927c8']
[0m[2025-01-22T06:38:32.277615] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T06:38:32.277620] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T06:42:32.302389] [SCALING] Scaling started.
[0m[2025-01-22T06:42:32.302497] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T06:42:32.316533] [SCALING] Scaling finished.
[0m[2025-01-22T06:42:32.316551] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:42:32.334255] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:42:32.351932] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T06:42:32.374282] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 0 replica.
[0m[2025-01-22T06:42:37.395176] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T06:42:37.412687] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T06:42:37.427507] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T06:42:37.441716] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T06:42:37.454500] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T06:42:37.486774] [POD_MGR] Pod flink-jobmanager-7d7c784b74-t75vp deleted
[0m[2025-01-22T06:42:39.399545] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:42:41.287511] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:42:41.287573] Reloading playbook: application/kafka
[0m[2025-01-22T06:42:47.247442] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T06:43:33.235247] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T06:43:33.235383] [EXPERIMENT] Run 4 completed. Start: 1737527896, End: 1737528213
[0m[2025-01-22T06:43:33.235390] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T06:43:43.236440] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T06:43:45.126862] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:43:46.989621] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:43:46.989678] [SCALING] Setting up experiment.


[0m[2025-01-22T06:43:46.989686] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:43:46.995352] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:43:47.011481] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T06:43:47.039273] [SCALING] Statefulset name to scale : flink-16000m-4096
[0m[2025-01-22T06:43:47.049292] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 1 replica.
[0m[2025-01-22T06:43:52.059718] [FLK_MGR] Running job.
[0m[2025-01-22T06:43:52.059745] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T06:43:52.485951] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-s5grg
[0m[2025-01-22T06:43:56.550720] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID e54d1d074426f9458257b650e35e5fe6

[0m[2025-01-22T06:43:56.550769] [FLK_MGR] Running job id: e54d1d074426f9458257b650e35e5fe6
[0m[2025-01-22T06:43:56.550776] [FLK_MGR] Getting job info.
[0m[2025-01-22T06:43:56.570192] [FLK_MGR] Job plan response: {"plan":{"jid":"e54d1d074426f9458257b650e35e5fe6","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T06:43:56.570346] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T06:43:56.953551] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-s5grg
[0m[2025-01-22T06:43:58.394103] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 06:43:55 : e54d1d074426f9458257b650e35e5fe6 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T06:43:58.394167] [FLK_MGR] Running jobs: ['e54d1d074426f9458257b650e35e5fe6']
[0m[2025-01-22T06:43:58.394174] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T06:43:58.394196] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T06:47:58.416015] [SCALING] Scaling started.
[0m[2025-01-22T06:47:58.416083] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T06:47:58.429673] [SCALING] Scaling finished.
[0m[2025-01-22T06:47:58.429700] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:47:58.447476] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:47:58.463249] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T06:47:58.553714] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 0 replica.
[0m[2025-01-22T06:48:03.573405] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T06:48:03.585933] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T06:48:03.598527] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T06:48:03.611580] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T06:48:03.624143] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T06:48:03.658682] [POD_MGR] Pod flink-jobmanager-7d7c784b74-s5grg deleted
[0m[2025-01-22T06:48:05.510148] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:48:07.390781] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:48:07.390839] Reloading playbook: application/kafka
[0m[2025-01-22T06:48:13.346227] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T06:48:59.295243] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T06:48:59.295376] [EXPERIMENT] Run 5 completed. Start: 1737528223, End: 1737528539
[0m[2025-01-22T06:48:59.295382] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T06:49:11.530697] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T06:49:11.530752] [RESOURCE_E] Running experiment with 16000m cores and 8192 memory.
[0m[2025-01-22T06:49:18.800095] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T06:49:18.800165] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T06:49:20.687876] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:49:22.559807] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:49:22.559866] [SCALING] Setting up experiment.


[0m[2025-01-22T06:49:22.559874] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:49:22.565113] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:49:22.580138] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T06:49:22.621556] [SCALING] Statefulset name to scale : flink-16000m-8192
[0m[2025-01-22T06:49:22.634487] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 1 replica.
[0m[2025-01-22T06:49:27.647523] [FLK_MGR] Running job.
[0m[2025-01-22T06:49:27.647552] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T06:49:28.028735] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-tgxfl
[0m[2025-01-22T06:49:32.127271] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID df3c797fb9dc0825bdd0e791b9167695

[0m[2025-01-22T06:49:32.127330] [FLK_MGR] Running job id: df3c797fb9dc0825bdd0e791b9167695
[0m[2025-01-22T06:49:32.127344] [FLK_MGR] Getting job info.
[0m[2025-01-22T06:49:32.144488] [FLK_MGR] Job plan response: {"plan":{"jid":"df3c797fb9dc0825bdd0e791b9167695","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T06:49:32.144647] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T06:49:32.582657] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-tgxfl
[0m[2025-01-22T06:49:34.020418] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 06:49:31 : df3c797fb9dc0825bdd0e791b9167695 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T06:49:34.020474] [FLK_MGR] Running jobs: ['df3c797fb9dc0825bdd0e791b9167695']
[0m[2025-01-22T06:49:34.020481] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T06:49:34.020488] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T06:53:34.044663] [SCALING] Scaling started.
[0m[2025-01-22T06:53:34.044762] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T06:53:34.058995] [SCALING] Scaling finished.
[0m[2025-01-22T06:53:34.059014] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:53:34.076906] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:53:34.095349] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T06:53:34.116510] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 0 replica.
[0m[2025-01-22T06:53:44.143800] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T06:53:44.158974] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T06:53:44.173251] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T06:53:44.188889] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T06:53:44.202882] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T06:53:44.226388] [POD_MGR] Pod flink-jobmanager-7d7c784b74-tgxfl deleted
[0m[2025-01-22T06:53:46.099543] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:53:48.033919] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:53:48.033983] Reloading playbook: application/kafka
[0m[2025-01-22T06:53:54.018224] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T06:54:39.982481] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T06:54:39.982614] [EXPERIMENT] Run 1 completed. Start: 1737528558, End: 1737528879
[0m[2025-01-22T06:54:39.982621] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T06:54:49.983595] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T06:54:51.884081] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:54:53.770139] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T06:54:53.770198] [SCALING] Setting up experiment.


[0m[2025-01-22T06:54:53.770206] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:54:53.775619] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:54:53.792780] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T06:54:53.813089] [SCALING] Statefulset name to scale : flink-16000m-8192
[0m[2025-01-22T06:54:53.823790] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 1 replica.
[0m[2025-01-22T06:54:58.834119] [FLK_MGR] Running job.
[0m[2025-01-22T06:54:58.834149] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T06:54:59.270840] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-bxg6q
[0m[2025-01-22T06:55:03.345323] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 51e2f891a6c18bd10b6b38e581fcebfb

[0m[2025-01-22T06:55:03.345386] [FLK_MGR] Running job id: 51e2f891a6c18bd10b6b38e581fcebfb
[0m[2025-01-22T06:55:03.345401] [FLK_MGR] Getting job info.
[0m[2025-01-22T06:55:03.364365] [FLK_MGR] Job plan response: {"plan":{"jid":"51e2f891a6c18bd10b6b38e581fcebfb","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T06:55:03.364515] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T06:55:03.807087] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-bxg6q
[0m[2025-01-22T06:55:05.235022] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 06:55:02 : 51e2f891a6c18bd10b6b38e581fcebfb : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T06:55:05.235075] [FLK_MGR] Running jobs: ['51e2f891a6c18bd10b6b38e581fcebfb']
[0m[2025-01-22T06:55:05.235082] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T06:55:05.235089] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T06:59:05.258990] [SCALING] Scaling started.
[0m[2025-01-22T06:59:05.259087] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T06:59:05.270954] [SCALING] Scaling finished.
[0m[2025-01-22T06:59:05.270972] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T06:59:05.288459] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T06:59:05.304174] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T06:59:05.325374] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 0 replica.
[0m[2025-01-22T06:59:15.351754] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T06:59:15.366505] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T06:59:15.381621] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T06:59:15.395600] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T06:59:15.409809] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T06:59:15.431891] [POD_MGR] Pod flink-jobmanager-7d7c784b74-bxg6q deleted
[0m[2025-01-22T06:59:17.372847] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:59:19.301669] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T06:59:19.301734] Reloading playbook: application/kafka
[0m[2025-01-22T06:59:25.284257] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T07:00:11.252164] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T07:00:11.252294] [EXPERIMENT] Run 2 completed. Start: 1737528889, End: 1737529211
[0m[2025-01-22T07:00:11.252299] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T07:00:21.253219] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T07:00:23.140530] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:00:25.002276] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:00:25.002333] [SCALING] Setting up experiment.


[0m[2025-01-22T07:00:25.002341] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:00:25.008927] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:00:25.027092] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T07:00:25.043604] [SCALING] Statefulset name to scale : flink-16000m-8192
[0m[2025-01-22T07:00:25.054994] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 1 replica.
[0m[2025-01-22T07:00:30.065212] [FLK_MGR] Running job.
[0m[2025-01-22T07:00:30.065241] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T07:00:30.506034] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-nqrdr
[0m[2025-01-22T07:00:34.602688] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 23402d1cf549c809e41698aa89779f86

[0m[2025-01-22T07:00:34.602741] [FLK_MGR] Running job id: 23402d1cf549c809e41698aa89779f86
[0m[2025-01-22T07:00:34.602750] [FLK_MGR] Getting job info.
[0m[2025-01-22T07:00:34.620719] [FLK_MGR] Job plan response: {"plan":{"jid":"23402d1cf549c809e41698aa89779f86","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T07:00:34.620870] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T07:00:35.048331] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-nqrdr
[0m[2025-01-22T07:00:36.493585] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 07:00:33 : 23402d1cf549c809e41698aa89779f86 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T07:00:36.493637] [FLK_MGR] Running jobs: ['23402d1cf549c809e41698aa89779f86']
[0m[2025-01-22T07:00:36.493644] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T07:00:36.493651] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T07:04:36.517174] [SCALING] Scaling started.
[0m[2025-01-22T07:04:36.517300] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T07:04:36.531678] [SCALING] Scaling finished.
[0m[2025-01-22T07:04:36.531697] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:04:36.551670] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:04:36.578666] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T07:04:36.610512] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 0 replica.
[0m[2025-01-22T07:04:41.632170] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T07:04:41.645349] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T07:04:41.658475] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T07:04:41.671636] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T07:04:41.686021] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T07:04:41.720359] [POD_MGR] Pod flink-jobmanager-7d7c784b74-nqrdr deleted
[0m[2025-01-22T07:04:43.632558] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:04:45.502816] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:04:45.502877] Reloading playbook: application/kafka
[0m[2025-01-22T07:04:51.510794] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T07:05:37.509599] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T07:05:37.509725] [EXPERIMENT] Run 3 completed. Start: 1737529221, End: 1737529537
[0m[2025-01-22T07:05:37.509731] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T07:05:47.510721] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T07:05:49.392556] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:05:51.264612] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:05:51.264689] [SCALING] Setting up experiment.


[0m[2025-01-22T07:05:51.264697] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:05:51.269858] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:05:51.284812] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T07:05:51.300532] [SCALING] Statefulset name to scale : flink-16000m-8192
[0m[2025-01-22T07:05:51.310367] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 1 replica.
[0m[2025-01-22T07:05:56.319351] [FLK_MGR] Running job.
[0m[2025-01-22T07:05:56.319380] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T07:05:56.689638] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-gml9k
[0m[2025-01-22T07:06:00.795483] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6e2e8d9060d5833838a68979e2f7e3b7

[0m[2025-01-22T07:06:00.795537] [FLK_MGR] Running job id: 6e2e8d9060d5833838a68979e2f7e3b7
[0m[2025-01-22T07:06:00.795548] [FLK_MGR] Getting job info.
[0m[2025-01-22T07:06:00.813906] [FLK_MGR] Job plan response: {"plan":{"jid":"6e2e8d9060d5833838a68979e2f7e3b7","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T07:06:00.814065] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T07:06:01.233081] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-gml9k
[0m[2025-01-22T07:06:02.666523] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 07:05:59 : 6e2e8d9060d5833838a68979e2f7e3b7 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T07:06:02.666578] [FLK_MGR] Running jobs: ['6e2e8d9060d5833838a68979e2f7e3b7']
[0m[2025-01-22T07:06:02.666585] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T07:06:02.666592] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T07:10:02.690411] [SCALING] Scaling started.
[0m[2025-01-22T07:10:02.690506] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T07:10:02.703843] [SCALING] Scaling finished.
[0m[2025-01-22T07:10:02.703862] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:10:02.724013] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:10:02.741824] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T07:10:02.763302] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 0 replica.
[0m[2025-01-22T07:10:07.785970] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T07:10:07.799208] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T07:10:07.813102] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T07:10:07.826585] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T07:10:07.839542] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T07:10:07.866116] [POD_MGR] Pod flink-jobmanager-7d7c784b74-gml9k deleted
[0m[2025-01-22T07:10:09.763015] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:10:11.655961] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:10:11.656027] Reloading playbook: application/kafka
[0m[2025-01-22T07:10:17.598070] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T07:11:03.572533] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T07:11:03.572659] [EXPERIMENT] Run 4 completed. Start: 1737529547, End: 1737529863
[0m[2025-01-22T07:11:03.572666] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T07:11:13.573767] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T07:11:15.444057] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:11:17.336361] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:11:17.336413] [SCALING] Setting up experiment.


[0m[2025-01-22T07:11:17.336421] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:11:17.342932] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:11:17.359552] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T07:11:17.375555] [SCALING] Statefulset name to scale : flink-16000m-8192
[0m[2025-01-22T07:11:17.385507] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 1 replica.
[0m[2025-01-22T07:11:22.395984] [FLK_MGR] Running job.
[0m[2025-01-22T07:11:22.396013] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T07:11:22.816120] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-rqmbf
[0m[2025-01-22T07:11:26.959037] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 294ea1ef017b47c1969441152268ce18

[0m[2025-01-22T07:11:26.959088] [FLK_MGR] Running job id: 294ea1ef017b47c1969441152268ce18
[0m[2025-01-22T07:11:26.959099] [FLK_MGR] Getting job info.
[0m[2025-01-22T07:11:26.978411] [FLK_MGR] Job plan response: {"plan":{"jid":"294ea1ef017b47c1969441152268ce18","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T07:11:26.978579] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T07:11:27.425631] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-rqmbf
[0m[2025-01-22T07:11:28.857263] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 07:11:25 : 294ea1ef017b47c1969441152268ce18 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T07:11:28.857323] [FLK_MGR] Running jobs: ['294ea1ef017b47c1969441152268ce18']
[0m[2025-01-22T07:11:28.857330] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T07:11:28.857336] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T07:15:28.881948] [SCALING] Scaling started.
[0m[2025-01-22T07:15:28.882045] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T07:15:28.896092] [SCALING] Scaling finished.
[0m[2025-01-22T07:15:28.896114] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:15:28.914745] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:15:28.933154] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T07:15:28.955258] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 0 replica.
[0m[2025-01-22T07:15:33.977588] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T07:15:33.992396] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T07:15:34.005655] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T07:15:34.019742] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T07:15:34.033552] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T07:15:34.057276] [POD_MGR] Pod flink-jobmanager-7d7c784b74-rqmbf deleted
[0m[2025-01-22T07:15:35.939860] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:15:37.964388] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:15:37.964455] Reloading playbook: application/kafka
[0m[2025-01-22T07:15:43.898350] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T07:16:29.872391] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T07:16:29.872528] [EXPERIMENT] Run 5 completed. Start: 1737529873, End: 1737530189
[0m[2025-01-22T07:16:29.872536] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T07:16:42.086116] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T07:16:42.086171] [RESOURCE_E] Running experiment with 16000m cores and 16384 memory.
[0m[2025-01-22T07:16:49.364499] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T07:16:49.364558] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T07:16:51.261887] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:16:53.160504] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:16:53.160557] [SCALING] Setting up experiment.


[0m[2025-01-22T07:16:53.160565] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:16:53.167907] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:16:53.184720] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T07:16:53.203201] [SCALING] Statefulset name to scale : flink-16000m-16384
[0m[2025-01-22T07:16:53.213870] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 1 replica.
[0m[2025-01-22T07:16:58.223437] [FLK_MGR] Running job.
[0m[2025-01-22T07:16:58.223466] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T07:16:58.671572] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-6nzcv
[0m[2025-01-22T07:17:02.737464] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 812b705a378e51d68c5f87faf441c903

[0m[2025-01-22T07:17:02.737514] [FLK_MGR] Running job id: 812b705a378e51d68c5f87faf441c903
[0m[2025-01-22T07:17:02.737521] [FLK_MGR] Getting job info.
[0m[2025-01-22T07:17:02.755148] [FLK_MGR] Job plan response: {"plan":{"jid":"812b705a378e51d68c5f87faf441c903","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T07:17:02.755295] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T07:17:03.177904] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-6nzcv
[0m[2025-01-22T07:17:04.619964] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 07:17:01 : 812b705a378e51d68c5f87faf441c903 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T07:17:04.620017] [FLK_MGR] Running jobs: ['812b705a378e51d68c5f87faf441c903']
[0m[2025-01-22T07:17:04.620024] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T07:17:04.620031] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T07:21:04.643117] [SCALING] Scaling started.
[0m[2025-01-22T07:21:04.643167] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T07:21:04.657103] [SCALING] Scaling finished.
[0m[2025-01-22T07:21:04.657125] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:21:04.675360] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:21:04.692406] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T07:21:04.723767] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 0 replica.
[0m[2025-01-22T07:21:09.747531] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T07:21:09.760202] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T07:21:09.772838] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T07:21:09.785352] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T07:21:09.797759] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T07:21:09.828135] [POD_MGR] Pod flink-jobmanager-7d7c784b74-6nzcv deleted
[0m[2025-01-22T07:21:11.697823] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:21:13.633709] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:21:13.633774] Reloading playbook: application/kafka
[0m[2025-01-22T07:21:19.592134] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T07:22:05.568585] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T07:22:05.568718] [EXPERIMENT] Run 1 completed. Start: 1737530209, End: 1737530525
[0m[2025-01-22T07:22:05.568724] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T07:22:15.569725] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T07:22:17.410879] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:22:19.281435] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:22:19.281492] [SCALING] Setting up experiment.


[0m[2025-01-22T07:22:19.281501] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:22:19.286866] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:22:19.306018] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T07:22:19.320584] [SCALING] Statefulset name to scale : flink-16000m-16384
[0m[2025-01-22T07:22:19.332495] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 1 replica.
[0m[2025-01-22T07:22:24.343238] [FLK_MGR] Running job.
[0m[2025-01-22T07:22:24.343267] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T07:22:24.800147] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-h6cjt
[0m[2025-01-22T07:22:28.866092] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 7bacc0ebfff952801e9bbee275a112bc

[0m[2025-01-22T07:22:28.866142] [FLK_MGR] Running job id: 7bacc0ebfff952801e9bbee275a112bc
[0m[2025-01-22T07:22:28.866150] [FLK_MGR] Getting job info.
[0m[2025-01-22T07:22:28.885678] [FLK_MGR] Job plan response: {"plan":{"jid":"7bacc0ebfff952801e9bbee275a112bc","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T07:22:28.885837] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T07:22:29.284261] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-h6cjt
[0m[2025-01-22T07:22:30.726169] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 07:22:27 : 7bacc0ebfff952801e9bbee275a112bc : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T07:22:30.726221] [FLK_MGR] Running jobs: ['7bacc0ebfff952801e9bbee275a112bc']
[0m[2025-01-22T07:22:30.726228] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T07:22:30.726234] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T07:26:30.749355] [SCALING] Scaling started.
[0m[2025-01-22T07:26:30.749446] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T07:26:30.764102] [SCALING] Scaling finished.
[0m[2025-01-22T07:26:30.764121] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:26:30.781229] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:26:30.797444] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T07:26:30.818945] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 0 replica.
[0m[2025-01-22T07:26:35.839319] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T07:26:35.852448] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T07:26:35.865309] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T07:26:35.877944] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T07:26:35.890591] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T07:26:35.923701] [POD_MGR] Pod flink-jobmanager-7d7c784b74-h6cjt deleted
[0m[2025-01-22T07:26:37.841369] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:26:39.779540] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:26:39.779606] Reloading playbook: application/kafka
[0m[2025-01-22T07:26:45.705308] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T07:27:31.710365] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T07:27:31.710498] [EXPERIMENT] Run 2 completed. Start: 1737530535, End: 1737530851
[0m[2025-01-22T07:27:31.710504] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T07:27:41.711484] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T07:27:43.568488] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:27:45.433713] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:27:45.433755] [SCALING] Setting up experiment.


[0m[2025-01-22T07:27:45.433764] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:27:45.439491] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:27:45.455389] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T07:27:45.471636] [SCALING] Statefulset name to scale : flink-16000m-16384
[0m[2025-01-22T07:27:45.483209] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 1 replica.
[0m[2025-01-22T07:27:50.498652] [FLK_MGR] Running job.
[0m[2025-01-22T07:27:50.498684] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T07:27:50.875092] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mcfc4
[0m[2025-01-22T07:27:55.024563] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f0ae27bee4fc6e06925fe5f49c0b5091

[0m[2025-01-22T07:27:55.024618] [FLK_MGR] Running job id: f0ae27bee4fc6e06925fe5f49c0b5091
[0m[2025-01-22T07:27:55.024625] [FLK_MGR] Getting job info.
[0m[2025-01-22T07:27:55.041812] [FLK_MGR] Job plan response: {"plan":{"jid":"f0ae27bee4fc6e06925fe5f49c0b5091","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T07:27:55.041953] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T07:27:55.470899] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mcfc4
[0m[2025-01-22T07:27:56.885600] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 07:27:54 : f0ae27bee4fc6e06925fe5f49c0b5091 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T07:27:56.885652] [FLK_MGR] Running jobs: ['f0ae27bee4fc6e06925fe5f49c0b5091']
[0m[2025-01-22T07:27:56.885659] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T07:27:56.885665] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T07:31:56.908643] [SCALING] Scaling started.
[0m[2025-01-22T07:31:56.908693] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T07:31:56.922936] [SCALING] Scaling finished.
[0m[2025-01-22T07:31:56.922958] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:31:56.942392] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:31:56.960659] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T07:31:56.982460] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 0 replica.
[0m[2025-01-22T07:32:07.010486] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T07:32:07.024466] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T07:32:07.038551] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T07:32:07.052656] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T07:32:07.066992] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T07:32:07.094839] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mcfc4 deleted
[0m[2025-01-22T07:32:08.943214] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:32:10.858281] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:32:10.858341] Reloading playbook: application/kafka
[0m[2025-01-22T07:32:16.879018] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T07:33:02.847640] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T07:33:02.847766] [EXPERIMENT] Run 3 completed. Start: 1737530861, End: 1737531182
[0m[2025-01-22T07:33:02.847772] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T07:33:12.848904] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T07:33:14.715310] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:33:16.616022] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:33:16.616079] [SCALING] Setting up experiment.


[0m[2025-01-22T07:33:16.616088] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:33:16.621443] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:33:16.637508] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T07:33:16.658782] [SCALING] Statefulset name to scale : flink-16000m-16384
[0m[2025-01-22T07:33:16.668975] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 1 replica.
[0m[2025-01-22T07:33:21.679166] [FLK_MGR] Running job.
[0m[2025-01-22T07:33:21.679196] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T07:33:22.123421] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-m2ptt
[0m[2025-01-22T07:33:26.250868] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 794632177c6151969e16aea064d1a153

[0m[2025-01-22T07:33:26.250920] [FLK_MGR] Running job id: 794632177c6151969e16aea064d1a153
[0m[2025-01-22T07:33:26.250928] [FLK_MGR] Getting job info.
[0m[2025-01-22T07:33:26.267242] [FLK_MGR] Job plan response: {"plan":{"jid":"794632177c6151969e16aea064d1a153","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T07:33:26.267380] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T07:33:26.686742] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-m2ptt
[0m[2025-01-22T07:33:28.132313] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 07:33:25 : 794632177c6151969e16aea064d1a153 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T07:33:28.132369] [FLK_MGR] Running jobs: ['794632177c6151969e16aea064d1a153']
[0m[2025-01-22T07:33:28.132376] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T07:33:28.132382] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T07:37:28.155040] [SCALING] Scaling started.
[0m[2025-01-22T07:37:28.155092] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T07:37:28.168372] [SCALING] Scaling finished.
[0m[2025-01-22T07:37:28.168392] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:37:28.186293] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:37:28.202571] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T07:37:28.225990] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 0 replica.
[0m[2025-01-22T07:37:33.246677] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T07:37:33.259522] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T07:37:33.272050] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T07:37:33.285041] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T07:37:33.297219] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T07:37:33.332265] [POD_MGR] Pod flink-jobmanager-7d7c784b74-m2ptt deleted
[0m[2025-01-22T07:37:35.191089] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:37:37.118143] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:37:37.118209] Reloading playbook: application/kafka
[0m[2025-01-22T07:37:43.073757] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T07:38:29.055478] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T07:38:29.055637] [EXPERIMENT] Run 4 completed. Start: 1737531192, End: 1737531509
[0m[2025-01-22T07:38:29.055645] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T07:38:39.056696] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T07:38:40.910725] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:38:42.797327] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:38:42.797389] [SCALING] Setting up experiment.


[0m[2025-01-22T07:38:42.797397] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:38:42.803361] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:38:42.819435] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T07:38:42.836264] [SCALING] Statefulset name to scale : flink-16000m-16384
[0m[2025-01-22T07:38:42.846367] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 1 replica.
[0m[2025-01-22T07:38:47.857739] [FLK_MGR] Running job.
[0m[2025-01-22T07:38:47.857768] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T07:38:48.287515] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-kckfl
[0m[2025-01-22T07:38:52.387543] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 508692a0d68d8e6f1b9761f8a6c2b6d2

[0m[2025-01-22T07:38:52.387601] [FLK_MGR] Running job id: 508692a0d68d8e6f1b9761f8a6c2b6d2
[0m[2025-01-22T07:38:52.387609] [FLK_MGR] Getting job info.
[0m[2025-01-22T07:38:52.404610] [FLK_MGR] Job plan response: {"plan":{"jid":"508692a0d68d8e6f1b9761f8a6c2b6d2","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T07:38:52.404773] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T07:38:52.772304] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-kckfl
[0m[2025-01-22T07:38:54.196398] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 07:38:51 : 508692a0d68d8e6f1b9761f8a6c2b6d2 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T07:38:54.196450] [FLK_MGR] Running jobs: ['508692a0d68d8e6f1b9761f8a6c2b6d2']
[0m[2025-01-22T07:38:54.196456] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T07:38:54.196463] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T07:42:54.220106] [SCALING] Scaling started.
[0m[2025-01-22T07:42:54.220200] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T07:42:54.232343] [SCALING] Scaling finished.
[0m[2025-01-22T07:42:54.232362] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:42:54.251643] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:42:54.269136] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T07:42:54.296416] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 0 replica.
[0m[2025-01-22T07:43:04.359205] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T07:43:04.375438] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T07:43:04.389024] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T07:43:04.402351] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T07:43:04.416172] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T07:43:04.439958] [POD_MGR] Pod flink-jobmanager-7d7c784b74-kckfl deleted
[0m[2025-01-22T07:43:06.337619] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:43:08.303923] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:43:08.303987] Reloading playbook: application/kafka
[0m[2025-01-22T07:43:14.249524] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T07:44:00.228586] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T07:44:00.228712] [EXPERIMENT] Run 5 completed. Start: 1737531519, End: 1737531840
[0m[2025-01-22T07:44:00.228719] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T07:44:12.449417] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T07:44:12.449477] [RESOURCE_E] Running experiment with 16000m cores and 32768 memory.
[0m[2025-01-22T07:44:19.691777] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T07:44:19.691839] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T07:44:21.563714] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:44:23.413946] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:44:23.414001] [SCALING] Setting up experiment.


[0m[2025-01-22T07:44:23.414009] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:44:23.419181] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:44:23.435817] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T07:44:23.452770] [SCALING] Statefulset name to scale : flink-16000m-32768
[0m[2025-01-22T07:44:23.463992] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 1 replica.
[0m[2025-01-22T07:44:28.473498] [FLK_MGR] Running job.
[0m[2025-01-22T07:44:28.473527] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T07:44:28.848527] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-tdvd9
[0m[2025-01-22T07:44:32.908108] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 56337615352fec7731aa8c8bb5e50cc7

[0m[2025-01-22T07:44:32.908159] [FLK_MGR] Running job id: 56337615352fec7731aa8c8bb5e50cc7
[0m[2025-01-22T07:44:32.908166] [FLK_MGR] Getting job info.
[0m[2025-01-22T07:44:32.926251] [FLK_MGR] Job plan response: {"plan":{"jid":"56337615352fec7731aa8c8bb5e50cc7","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T07:44:32.926396] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T07:44:33.341447] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-tdvd9
[0m[2025-01-22T07:44:34.778069] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 07:44:31 : 56337615352fec7731aa8c8bb5e50cc7 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T07:44:34.778123] [FLK_MGR] Running jobs: ['56337615352fec7731aa8c8bb5e50cc7']
[0m[2025-01-22T07:44:34.778130] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T07:44:34.778137] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T07:48:34.801533] [SCALING] Scaling started.
[0m[2025-01-22T07:48:34.801580] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T07:48:34.814194] [SCALING] Scaling finished.
[0m[2025-01-22T07:48:34.814212] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:48:34.833213] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:48:34.855298] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T07:48:34.878142] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 0 replica.
[0m[2025-01-22T07:48:39.898253] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T07:48:39.911945] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T07:48:39.926187] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T07:48:39.939635] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T07:48:39.957456] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T07:48:39.995164] [POD_MGR] Pod flink-jobmanager-7d7c784b74-tdvd9 deleted
[0m[2025-01-22T07:48:41.895681] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:48:43.831978] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:48:43.832054] Reloading playbook: application/kafka
[0m[2025-01-22T07:48:49.816379] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T07:49:35.814014] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T07:49:35.814399] [EXPERIMENT] Run 1 completed. Start: 1737531859, End: 1737532175
[0m[2025-01-22T07:49:35.814432] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T07:49:45.815539] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T07:49:47.717089] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:49:49.607496] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:49:49.607569] [SCALING] Setting up experiment.


[0m[2025-01-22T07:49:49.607580] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:49:49.614403] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:49:49.630833] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T07:49:49.652846] [SCALING] Statefulset name to scale : flink-16000m-32768
[0m[2025-01-22T07:49:49.666713] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 1 replica.
[0m[2025-01-22T07:49:54.678068] [FLK_MGR] Running job.
[0m[2025-01-22T07:49:54.678100] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T07:49:55.119198] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jndgs
[0m[2025-01-22T07:49:59.274259] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 98254915036ac34c0664cd8b904c019f

[0m[2025-01-22T07:49:59.274314] [FLK_MGR] Running job id: 98254915036ac34c0664cd8b904c019f
[0m[2025-01-22T07:49:59.274322] [FLK_MGR] Getting job info.
[0m[2025-01-22T07:49:59.291409] [FLK_MGR] Job plan response: {"plan":{"jid":"98254915036ac34c0664cd8b904c019f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T07:49:59.291558] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T07:49:59.708756] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jndgs
[0m[2025-01-22T07:50:01.180511] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 07:49:58 : 98254915036ac34c0664cd8b904c019f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T07:50:01.180569] [FLK_MGR] Running jobs: ['98254915036ac34c0664cd8b904c019f']
[0m[2025-01-22T07:50:01.180576] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T07:50:01.180582] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T07:54:01.205201] [SCALING] Scaling started.
[0m[2025-01-22T07:54:01.205323] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T07:54:01.218390] [SCALING] Scaling finished.
[0m[2025-01-22T07:54:01.218409] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:54:01.242815] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:54:01.260258] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T07:54:01.282131] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 0 replica.
[0m[2025-01-22T07:54:06.302205] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T07:54:06.316192] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T07:54:06.329831] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T07:54:06.342387] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T07:54:06.354968] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T07:54:06.384180] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jndgs deleted
[0m[2025-01-22T07:54:08.228055] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:54:10.136124] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:54:10.136203] Reloading playbook: application/kafka
[0m[2025-01-22T07:54:16.091049] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T07:55:02.083222] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T07:55:02.083444] [EXPERIMENT] Run 2 completed. Start: 1737532185, End: 1737532502
[0m[2025-01-22T07:55:02.083452] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T07:55:12.084684] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T07:55:13.968503] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:55:15.849723] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T07:55:15.849779] [SCALING] Setting up experiment.


[0m[2025-01-22T07:55:15.849787] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:55:15.854936] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:55:15.871681] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T07:55:15.892828] [SCALING] Statefulset name to scale : flink-16000m-32768
[0m[2025-01-22T07:55:15.902946] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 1 replica.
[0m[2025-01-22T07:55:20.913173] [FLK_MGR] Running job.
[0m[2025-01-22T07:55:20.913201] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T07:55:21.348512] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-vckwr
[0m[2025-01-22T07:55:25.465405] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 7ab49f01c656514f964c014d3160c52a

[0m[2025-01-22T07:55:25.465452] [FLK_MGR] Running job id: 7ab49f01c656514f964c014d3160c52a
[0m[2025-01-22T07:55:25.465459] [FLK_MGR] Getting job info.
[0m[2025-01-22T07:55:25.483526] [FLK_MGR] Job plan response: {"plan":{"jid":"7ab49f01c656514f964c014d3160c52a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T07:55:25.483676] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T07:55:25.923193] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-vckwr
[0m[2025-01-22T07:55:27.354867] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 07:55:24 : 7ab49f01c656514f964c014d3160c52a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T07:55:27.354924] [FLK_MGR] Running jobs: ['7ab49f01c656514f964c014d3160c52a']
[0m[2025-01-22T07:55:27.354931] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T07:55:27.354940] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T07:59:27.379111] [SCALING] Scaling started.
[0m[2025-01-22T07:59:27.379214] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T07:59:27.392554] [SCALING] Scaling finished.
[0m[2025-01-22T07:59:27.392576] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T07:59:27.412146] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T07:59:27.430569] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T07:59:27.451503] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 0 replica.
[0m[2025-01-22T07:59:32.472719] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T07:59:32.486938] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T07:59:32.500000] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T07:59:32.512850] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T07:59:32.525606] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T07:59:32.552289] [POD_MGR] Pod flink-jobmanager-7d7c784b74-vckwr deleted
[0m[2025-01-22T07:59:34.479816] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:59:36.361544] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T07:59:36.361705] Reloading playbook: application/kafka
[0m[2025-01-22T07:59:42.345374] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T08:00:28.299418] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T08:00:28.299862] [EXPERIMENT] Run 3 completed. Start: 1737532512, End: 1737532828
[0m[2025-01-22T08:00:28.299916] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T08:00:38.300956] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T08:00:40.167767] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:00:42.040023] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:00:42.040084] [SCALING] Setting up experiment.


[0m[2025-01-22T08:00:42.040093] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:00:42.045920] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:00:42.062557] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T08:00:42.079924] [SCALING] Statefulset name to scale : flink-16000m-32768
[0m[2025-01-22T08:00:42.092727] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 1 replica.
[0m[2025-01-22T08:00:47.103422] [FLK_MGR] Running job.
[0m[2025-01-22T08:00:47.103452] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T08:00:47.475112] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-whcz7
[0m[2025-01-22T08:00:51.628266] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 55f62607fbfa9cd667f824df45c821fb

[0m[2025-01-22T08:00:51.628319] [FLK_MGR] Running job id: 55f62607fbfa9cd667f824df45c821fb
[0m[2025-01-22T08:00:51.628325] [FLK_MGR] Getting job info.
[0m[2025-01-22T08:00:51.644852] [FLK_MGR] Job plan response: {"plan":{"jid":"55f62607fbfa9cd667f824df45c821fb","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T08:00:51.644996] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T08:00:52.074952] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-whcz7
[0m[2025-01-22T08:00:53.527817] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 08:00:50 : 55f62607fbfa9cd667f824df45c821fb : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T08:00:53.527880] [FLK_MGR] Running jobs: ['55f62607fbfa9cd667f824df45c821fb']
[0m[2025-01-22T08:00:53.527888] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T08:00:53.527900] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T08:04:53.551501] [SCALING] Scaling started.
[0m[2025-01-22T08:04:53.551608] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T08:04:53.565652] [SCALING] Scaling finished.
[0m[2025-01-22T08:04:53.565677] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:04:53.584518] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:04:53.603794] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T08:04:53.626953] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 0 replica.
[0m[2025-01-22T08:04:58.648704] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T08:04:58.662942] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T08:04:58.677689] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T08:04:58.692660] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T08:04:58.708844] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T08:04:58.747606] [POD_MGR] Pod flink-jobmanager-7d7c784b74-whcz7 deleted
[0m[2025-01-22T08:05:00.647392] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:05:02.563612] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:05:02.563674] Reloading playbook: application/kafka
[0m[2025-01-22T08:05:08.559161] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T08:05:54.538951] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T08:05:54.539090] [EXPERIMENT] Run 4 completed. Start: 1737532838, End: 1737533154
[0m[2025-01-22T08:05:54.539097] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T08:06:04.540108] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T08:06:06.420455] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:06:08.286533] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:06:08.286592] [SCALING] Setting up experiment.


[0m[2025-01-22T08:06:08.286600] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:06:08.292333] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:06:08.309663] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T08:06:08.326924] [SCALING] Statefulset name to scale : flink-16000m-32768
[0m[2025-01-22T08:06:08.338077] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 1 replica.
[0m[2025-01-22T08:06:13.350934] [FLK_MGR] Running job.
[0m[2025-01-22T08:06:13.350962] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T08:06:13.772879] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-fnrln
[0m[2025-01-22T08:06:17.885283] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 2530ea301dda17f57056228e4fd90117

[0m[2025-01-22T08:06:17.885332] [FLK_MGR] Running job id: 2530ea301dda17f57056228e4fd90117
[0m[2025-01-22T08:06:17.885340] [FLK_MGR] Getting job info.
[0m[2025-01-22T08:06:17.903317] [FLK_MGR] Job plan response: {"plan":{"jid":"2530ea301dda17f57056228e4fd90117","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T08:06:17.903468] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T08:06:18.339634] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-fnrln
[0m[2025-01-22T08:06:19.787987] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 08:06:16 : 2530ea301dda17f57056228e4fd90117 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T08:06:19.788044] [FLK_MGR] Running jobs: ['2530ea301dda17f57056228e4fd90117']
[0m[2025-01-22T08:06:19.788051] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T08:06:19.788061] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T08:10:19.810853] [SCALING] Scaling started.
[0m[2025-01-22T08:10:19.810955] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T08:10:19.825207] [SCALING] Scaling finished.
[0m[2025-01-22T08:10:19.825246] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:10:19.846309] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:10:19.884819] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T08:10:19.907764] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 0 replica.
[0m[2025-01-22T08:10:24.931651] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T08:10:24.948010] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T08:10:24.963133] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T08:10:24.978952] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T08:10:24.995734] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T08:10:25.036969] [POD_MGR] Pod flink-jobmanager-7d7c784b74-fnrln deleted
[0m[2025-01-22T08:10:26.930714] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:10:28.832825] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:10:28.832888] Reloading playbook: application/kafka
[0m[2025-01-22T08:10:34.881148] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T08:11:20.804753] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T08:11:20.804907] [EXPERIMENT] Run 5 completed. Start: 1737533164, End: 1737533480
[0m[2025-01-22T08:11:20.804915] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T08:11:33.035036] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T08:11:33.035105] [RESOURCE_E] Running experiment with 32000m cores and 1024 memory.
[0m[2025-01-22T08:11:40.286693] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T08:11:40.286759] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T08:11:42.179893] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:11:44.044199] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:11:44.044343] [SCALING] Setting up experiment.


[0m[2025-01-22T08:11:44.044372] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:11:44.049373] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:11:44.064189] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T08:11:44.079159] [SCALING] Statefulset name to scale : flink-32000m-1024
[0m[2025-01-22T08:11:44.088974] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 1 replica.
[0m[2025-01-22T08:11:49.100194] [FLK_MGR] Running job.
[0m[2025-01-22T08:11:49.100243] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T08:11:49.536035] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-6kszj
[0m[2025-01-22T08:11:53.694686] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID e1849be50a6376f092d07c262d10f3cb

[0m[2025-01-22T08:11:53.694741] [FLK_MGR] Running job id: e1849be50a6376f092d07c262d10f3cb
[0m[2025-01-22T08:11:53.694748] [FLK_MGR] Getting job info.
[0m[2025-01-22T08:11:53.711213] [FLK_MGR] Job plan response: {"plan":{"jid":"e1849be50a6376f092d07c262d10f3cb","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T08:11:53.711349] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T08:11:54.153127] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-6kszj
[0m[2025-01-22T08:11:55.601432] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 08:11:52 : e1849be50a6376f092d07c262d10f3cb : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T08:11:55.601487] [FLK_MGR] Running jobs: ['e1849be50a6376f092d07c262d10f3cb']
[0m[2025-01-22T08:11:55.601494] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T08:11:55.601499] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T08:15:55.625046] [SCALING] Scaling started.
[0m[2025-01-22T08:15:55.625147] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T08:15:55.639081] [SCALING] Scaling finished.
[0m[2025-01-22T08:15:55.639100] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:15:55.659697] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:15:55.676198] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T08:15:55.697007] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 0 replica.
[0m[2025-01-22T08:15:55.717496] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T08:15:55.730771] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T08:15:55.745035] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T08:15:55.757219] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T08:15:55.769701] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T08:15:55.796594] [POD_MGR] Pod flink-jobmanager-7d7c784b74-6kszj deleted
[0m[2025-01-22T08:15:57.681560] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:15:59.613988] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:15:59.614051] Reloading playbook: application/kafka
[0m[2025-01-22T08:16:05.609826] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T08:16:51.575064] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T08:16:51.575191] [EXPERIMENT] Run 1 completed. Start: 1737533500, End: 1737533811
[0m[2025-01-22T08:16:51.575197] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T08:17:01.576271] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T08:17:03.465647] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:17:05.335356] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:17:05.335414] [SCALING] Setting up experiment.


[0m[2025-01-22T08:17:05.335422] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:17:05.343111] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:17:05.359816] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T08:17:05.378497] [SCALING] Statefulset name to scale : flink-32000m-1024
[0m[2025-01-22T08:17:05.389409] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 1 replica.
[0m[2025-01-22T08:17:10.403524] [FLK_MGR] Running job.
[0m[2025-01-22T08:17:10.403550] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T08:17:10.838467] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-6x4f8
[0m[2025-01-22T08:17:14.920679] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 05355efc4745e29d4b12294f8562f5a0

[0m[2025-01-22T08:17:14.920731] [FLK_MGR] Running job id: 05355efc4745e29d4b12294f8562f5a0
[0m[2025-01-22T08:17:14.920739] [FLK_MGR] Getting job info.
[0m[2025-01-22T08:17:14.939192] [FLK_MGR] Job plan response: {"plan":{"jid":"05355efc4745e29d4b12294f8562f5a0","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T08:17:14.939356] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T08:17:15.323174] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-6x4f8
[0m[2025-01-22T08:17:16.743026] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 08:17:13 : 05355efc4745e29d4b12294f8562f5a0 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T08:17:16.743086] [FLK_MGR] Running jobs: ['05355efc4745e29d4b12294f8562f5a0']
[0m[2025-01-22T08:17:16.743094] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T08:17:16.743109] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T08:21:16.767119] [SCALING] Scaling started.
[0m[2025-01-22T08:21:16.767221] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T08:21:16.781513] [SCALING] Scaling finished.
[0m[2025-01-22T08:21:16.781550] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:21:16.799204] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:21:16.816064] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T08:21:16.836796] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 0 replica.
[0m[2025-01-22T08:21:21.858716] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T08:21:21.873757] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T08:21:21.886895] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T08:21:21.900586] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T08:21:21.913001] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T08:21:21.950587] [POD_MGR] Pod flink-jobmanager-7d7c784b74-6x4f8 deleted
[0m[2025-01-22T08:21:23.836582] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:21:25.750235] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:21:25.750417] Reloading playbook: application/kafka
[0m[2025-01-22T08:21:31.713129] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T08:22:17.701610] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T08:22:17.701930] [EXPERIMENT] Run 2 completed. Start: 1737533821, End: 1737534137
[0m[2025-01-22T08:22:17.701959] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T08:22:27.703089] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T08:22:29.560770] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:22:31.442161] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:22:31.442384] [SCALING] Setting up experiment.


[0m[2025-01-22T08:22:31.442433] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:22:31.448298] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:22:31.463525] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T08:22:31.481384] [SCALING] Statefulset name to scale : flink-32000m-1024
[0m[2025-01-22T08:22:31.546715] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 1 replica.
[0m[2025-01-22T08:22:36.557758] [FLK_MGR] Running job.
[0m[2025-01-22T08:22:36.557782] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T08:22:36.929710] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-nh2pv
[0m[2025-01-22T08:22:41.049900] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5a20b7eacbf9c69cb5de9305ef495d65

[0m[2025-01-22T08:22:41.049949] [FLK_MGR] Running job id: 5a20b7eacbf9c69cb5de9305ef495d65
[0m[2025-01-22T08:22:41.049956] [FLK_MGR] Getting job info.
[0m[2025-01-22T08:22:41.068064] [FLK_MGR] Job plan response: {"plan":{"jid":"5a20b7eacbf9c69cb5de9305ef495d65","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T08:22:41.068219] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T08:22:41.519830] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-nh2pv
[0m[2025-01-22T08:22:42.975059] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 08:22:40 : 5a20b7eacbf9c69cb5de9305ef495d65 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T08:22:42.975122] [FLK_MGR] Running jobs: ['5a20b7eacbf9c69cb5de9305ef495d65']
[0m[2025-01-22T08:22:42.975129] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T08:22:42.975135] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T08:26:42.998211] [SCALING] Scaling started.
[0m[2025-01-22T08:26:42.998310] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T08:26:43.012466] [SCALING] Scaling finished.
[0m[2025-01-22T08:26:43.012488] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:26:43.029939] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:26:43.045895] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T08:26:43.066325] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 0 replica.
[0m[2025-01-22T08:26:48.086758] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T08:26:48.102219] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T08:26:48.115834] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T08:26:48.130103] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T08:26:48.143268] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T08:26:48.178024] [POD_MGR] Pod flink-jobmanager-7d7c784b74-nh2pv deleted
[0m[2025-01-22T08:26:50.031176] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:26:51.952511] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:26:51.952566] Reloading playbook: application/kafka
[0m[2025-01-22T08:26:57.919693] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T08:27:43.873917] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T08:27:43.874254] [EXPERIMENT] Run 3 completed. Start: 1737534147, End: 1737534463
[0m[2025-01-22T08:27:43.874284] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T08:27:53.875235] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T08:27:55.788603] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:27:57.651743] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:27:57.651823] [SCALING] Setting up experiment.


[0m[2025-01-22T08:27:57.651836] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:27:57.661891] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:27:57.680424] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T08:27:57.698622] [SCALING] Statefulset name to scale : flink-32000m-1024
[0m[2025-01-22T08:27:57.707991] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 1 replica.
[0m[2025-01-22T08:28:02.717817] [FLK_MGR] Running job.
[0m[2025-01-22T08:28:02.717844] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T08:28:03.171280] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-j5l4l
[0m[2025-01-22T08:28:07.251844] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID aa55fcfed665e1adbf84b4ca9c249720

[0m[2025-01-22T08:28:07.251895] [FLK_MGR] Running job id: aa55fcfed665e1adbf84b4ca9c249720
[0m[2025-01-22T08:28:07.251902] [FLK_MGR] Getting job info.
[0m[2025-01-22T08:28:07.270178] [FLK_MGR] Job plan response: {"plan":{"jid":"aa55fcfed665e1adbf84b4ca9c249720","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T08:28:07.270315] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T08:28:07.709416] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-j5l4l
[0m[2025-01-22T08:28:09.153044] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 08:28:06 : aa55fcfed665e1adbf84b4ca9c249720 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T08:28:09.153104] [FLK_MGR] Running jobs: ['aa55fcfed665e1adbf84b4ca9c249720']
[0m[2025-01-22T08:28:09.153111] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T08:28:09.153118] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T08:32:09.176312] [SCALING] Scaling started.
[0m[2025-01-22T08:32:09.176371] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T08:32:09.188040] [SCALING] Scaling finished.
[0m[2025-01-22T08:32:09.188057] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:32:09.206223] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:32:09.222738] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T08:32:09.243507] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 0 replica.
[0m[2025-01-22T08:32:14.265532] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T08:32:14.279056] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T08:32:14.291681] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T08:32:14.304323] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T08:32:14.317032] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T08:32:14.350388] [POD_MGR] Pod flink-jobmanager-7d7c784b74-j5l4l deleted
[0m[2025-01-22T08:32:16.240532] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:32:18.162325] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:32:18.162386] Reloading playbook: application/kafka
[0m[2025-01-22T08:32:24.109814] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T08:33:10.077423] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T08:33:10.077563] [EXPERIMENT] Run 4 completed. Start: 1737534473, End: 1737534790
[0m[2025-01-22T08:33:10.077570] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T08:33:20.078574] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T08:33:21.963222] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:33:23.854317] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:33:23.854387] [SCALING] Setting up experiment.


[0m[2025-01-22T08:33:23.854397] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:33:23.860773] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:33:23.877681] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T08:33:23.900571] [SCALING] Statefulset name to scale : flink-32000m-1024
[0m[2025-01-22T08:33:23.910626] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 1 replica.
[0m[2025-01-22T08:33:28.920059] [FLK_MGR] Running job.
[0m[2025-01-22T08:33:28.920090] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T08:33:29.338978] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-kg88q
[0m[2025-01-22T08:33:33.513241] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8debf5949b9be106832d2768e28478a1

[0m[2025-01-22T08:33:33.513301] [FLK_MGR] Running job id: 8debf5949b9be106832d2768e28478a1
[0m[2025-01-22T08:33:33.513309] [FLK_MGR] Getting job info.
[0m[2025-01-22T08:33:33.530624] [FLK_MGR] Job plan response: {"plan":{"jid":"8debf5949b9be106832d2768e28478a1","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T08:33:33.530762] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T08:33:33.901606] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-kg88q
[0m[2025-01-22T08:33:35.340109] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 08:33:32 : 8debf5949b9be106832d2768e28478a1 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T08:33:35.340167] [FLK_MGR] Running jobs: ['8debf5949b9be106832d2768e28478a1']
[0m[2025-01-22T08:33:35.340175] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T08:33:35.340186] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T08:37:35.365960] [SCALING] Scaling started.
[0m[2025-01-22T08:37:35.366022] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T08:37:35.380494] [SCALING] Scaling finished.
[0m[2025-01-22T08:37:35.380519] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:37:35.397780] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:37:35.414714] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T08:37:35.436886] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 0 replica.
[0m[2025-01-22T08:37:40.456827] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T08:37:40.470787] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T08:37:40.486468] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T08:37:40.544283] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T08:37:40.560332] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T08:37:40.585675] [POD_MGR] Pod flink-jobmanager-7d7c784b74-kg88q deleted
[0m[2025-01-22T08:37:42.442337] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:37:44.344237] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:37:44.344300] Reloading playbook: application/kafka
[0m[2025-01-22T08:37:50.329778] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T08:38:36.284244] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T08:38:36.284360] [EXPERIMENT] Run 5 completed. Start: 1737534800, End: 1737535116
[0m[2025-01-22T08:38:36.284366] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T08:38:48.522548] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T08:38:48.522614] [RESOURCE_E] Running experiment with 32000m cores and 2048 memory.
[0m[2025-01-22T08:38:55.788764] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T08:38:55.788835] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T08:38:57.654677] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:38:59.514568] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:38:59.514627] [SCALING] Setting up experiment.


[0m[2025-01-22T08:38:59.514636] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:38:59.520265] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:38:59.535514] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T08:38:59.551134] [SCALING] Statefulset name to scale : flink-32000m-2048
[0m[2025-01-22T08:38:59.562699] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 1 replica.
[0m[2025-01-22T08:39:04.573836] [FLK_MGR] Running job.
[0m[2025-01-22T08:39:04.573865] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T08:39:04.939743] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-qlcth
[0m[2025-01-22T08:39:09.139144] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8bf59ca8381d5150b0a26a59b949eaa1

[0m[2025-01-22T08:39:09.139195] [FLK_MGR] Running job id: 8bf59ca8381d5150b0a26a59b949eaa1
[0m[2025-01-22T08:39:09.139202] [FLK_MGR] Getting job info.
[0m[2025-01-22T08:39:09.157242] [FLK_MGR] Job plan response: {"plan":{"jid":"8bf59ca8381d5150b0a26a59b949eaa1","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T08:39:09.157417] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T08:39:09.603682] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-qlcth
[0m[2025-01-22T08:39:11.036396] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 08:39:08 : 8bf59ca8381d5150b0a26a59b949eaa1 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T08:39:11.036454] [FLK_MGR] Running jobs: ['8bf59ca8381d5150b0a26a59b949eaa1']
[0m[2025-01-22T08:39:11.036462] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T08:39:11.036468] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T08:43:11.060422] [SCALING] Scaling started.
[0m[2025-01-22T08:43:11.060474] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T08:43:11.073281] [SCALING] Scaling finished.
[0m[2025-01-22T08:43:11.073303] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:43:11.092233] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:43:11.109046] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T08:43:11.130861] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 0 replica.
[0m[2025-01-22T08:43:11.148265] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T08:43:11.164984] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T08:43:11.178720] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T08:43:11.191385] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T08:43:11.203904] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T08:43:11.230514] [POD_MGR] Pod flink-jobmanager-7d7c784b74-qlcth deleted
[0m[2025-01-22T08:43:13.117471] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:43:14.987356] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:43:14.987419] Reloading playbook: application/kafka
[0m[2025-01-22T08:43:21.021955] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T08:44:06.986365] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T08:44:06.986498] [EXPERIMENT] Run 1 completed. Start: 1737535135, End: 1737535446
[0m[2025-01-22T08:44:06.986505] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T08:44:16.987541] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T08:44:18.875988] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:44:20.765208] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:44:20.765275] [SCALING] Setting up experiment.


[0m[2025-01-22T08:44:20.765283] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:44:20.771031] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:44:20.787260] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T08:44:20.803488] [SCALING] Statefulset name to scale : flink-32000m-2048
[0m[2025-01-22T08:44:20.812969] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 1 replica.
[0m[2025-01-22T08:44:25.823579] [FLK_MGR] Running job.
[0m[2025-01-22T08:44:25.823612] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T08:44:26.283111] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-7plt2
[0m[2025-01-22T08:44:30.443600] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5a87da4960126d7fbcdf38d59a6c7298

[0m[2025-01-22T08:44:30.443652] [FLK_MGR] Running job id: 5a87da4960126d7fbcdf38d59a6c7298
[0m[2025-01-22T08:44:30.443661] [FLK_MGR] Getting job info.
[0m[2025-01-22T08:44:30.461849] [FLK_MGR] Job plan response: {"plan":{"jid":"5a87da4960126d7fbcdf38d59a6c7298","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T08:44:30.461993] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T08:44:30.909461] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-7plt2
[0m[2025-01-22T08:44:32.334035] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 08:44:29 : 5a87da4960126d7fbcdf38d59a6c7298 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T08:44:32.334095] [FLK_MGR] Running jobs: ['5a87da4960126d7fbcdf38d59a6c7298']
[0m[2025-01-22T08:44:32.334102] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T08:44:32.334108] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T08:48:32.357249] [SCALING] Scaling started.
[0m[2025-01-22T08:48:32.357364] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T08:48:32.371329] [SCALING] Scaling finished.
[0m[2025-01-22T08:48:32.371353] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:48:32.390932] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:48:32.408718] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T08:48:32.429592] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 0 replica.
[0m[2025-01-22T08:48:37.450470] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T08:48:37.465114] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T08:48:37.480004] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T08:48:37.494585] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T08:48:37.508401] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T08:48:37.539506] [POD_MGR] Pod flink-jobmanager-7d7c784b74-7plt2 deleted
[0m[2025-01-22T08:48:39.419207] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:48:41.388722] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:48:41.388784] Reloading playbook: application/kafka
[0m[2025-01-22T08:48:47.329347] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T08:49:33.310495] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T08:49:33.310633] [EXPERIMENT] Run 2 completed. Start: 1737535456, End: 1737535773
[0m[2025-01-22T08:49:33.310640] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T08:49:43.311609] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T08:49:45.207673] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:49:47.069338] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:49:47.069395] [SCALING] Setting up experiment.


[0m[2025-01-22T08:49:47.069405] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:49:47.074817] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:49:47.090210] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T08:49:47.106425] [SCALING] Statefulset name to scale : flink-32000m-2048
[0m[2025-01-22T08:49:47.117279] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 1 replica.
[0m[2025-01-22T08:49:52.130137] [FLK_MGR] Running job.
[0m[2025-01-22T08:49:52.130163] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T08:49:52.572264] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-db6wb
[0m[2025-01-22T08:49:56.648893] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID ba0b981fcb17c9157a60007357d8cbda

[0m[2025-01-22T08:49:56.648942] [FLK_MGR] Running job id: ba0b981fcb17c9157a60007357d8cbda
[0m[2025-01-22T08:49:56.648950] [FLK_MGR] Getting job info.
[0m[2025-01-22T08:49:56.667911] [FLK_MGR] Job plan response: {"plan":{"jid":"ba0b981fcb17c9157a60007357d8cbda","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T08:49:56.668064] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T08:49:57.226366] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-db6wb
[0m[2025-01-22T08:49:58.662136] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 08:49:55 : ba0b981fcb17c9157a60007357d8cbda : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T08:49:58.662195] [FLK_MGR] Running jobs: ['ba0b981fcb17c9157a60007357d8cbda']
[0m[2025-01-22T08:49:58.662202] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T08:49:58.662208] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T08:53:58.685657] [SCALING] Scaling started.
[0m[2025-01-22T08:53:58.685752] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T08:53:58.699573] [SCALING] Scaling finished.
[0m[2025-01-22T08:53:58.699595] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:53:58.718927] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:53:58.737168] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T08:53:58.757585] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 0 replica.
[0m[2025-01-22T08:54:03.777503] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T08:54:03.790644] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T08:54:03.803765] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T08:54:03.816735] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T08:54:03.829501] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T08:54:03.859037] [POD_MGR] Pod flink-jobmanager-7d7c784b74-db6wb deleted
[0m[2025-01-22T08:54:05.737733] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:54:07.607819] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:54:07.607881] Reloading playbook: application/kafka
[0m[2025-01-22T08:54:13.507821] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T08:55:19.451808] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T08:55:19.451937] [EXPERIMENT] Run 3 completed. Start: 1737535783, End: 1737536119
[0m[2025-01-22T08:55:19.451944] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T08:55:29.453119] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T08:55:31.372160] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:55:33.246655] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T08:55:33.246738] [SCALING] Setting up experiment.


[0m[2025-01-22T08:55:33.246751] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:55:33.253339] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:55:33.269044] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T08:55:33.284567] [SCALING] Statefulset name to scale : flink-32000m-2048
[0m[2025-01-22T08:55:33.295141] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 1 replica.
[0m[2025-01-22T08:55:38.305637] [FLK_MGR] Running job.
[0m[2025-01-22T08:55:38.305664] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T08:55:38.687977] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-sfpfm
[0m[2025-01-22T08:55:42.853282] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 26cbc996a34dfbe0c1edb6eae0a6df2f

[0m[2025-01-22T08:55:42.853339] [FLK_MGR] Running job id: 26cbc996a34dfbe0c1edb6eae0a6df2f
[0m[2025-01-22T08:55:42.853349] [FLK_MGR] Getting job info.
[0m[2025-01-22T08:55:42.870893] [FLK_MGR] Job plan response: {"plan":{"jid":"26cbc996a34dfbe0c1edb6eae0a6df2f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T08:55:42.871054] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T08:55:43.295666] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sfpfm
[0m[2025-01-22T08:55:44.734016] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 08:55:41 : 26cbc996a34dfbe0c1edb6eae0a6df2f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T08:55:44.734068] [FLK_MGR] Running jobs: ['26cbc996a34dfbe0c1edb6eae0a6df2f']
[0m[2025-01-22T08:55:44.734075] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T08:55:44.734081] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T08:59:44.757590] [SCALING] Scaling started.
[0m[2025-01-22T08:59:44.757641] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T08:59:44.770181] [SCALING] Scaling finished.
[0m[2025-01-22T08:59:44.770201] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T08:59:44.788784] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T08:59:44.805524] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T08:59:44.826121] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 0 replica.
[0m[2025-01-22T08:59:49.847152] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T08:59:49.862871] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T08:59:49.877566] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T08:59:49.892054] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T08:59:49.906472] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T08:59:49.939690] [POD_MGR] Pod flink-jobmanager-7d7c784b74-sfpfm deleted
[0m[2025-01-22T08:59:51.794563] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:59:53.708588] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T08:59:53.708649] Reloading playbook: application/kafka
[0m[2025-01-22T08:59:59.734836] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T09:00:45.704179] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T09:00:45.704424] [EXPERIMENT] Run 4 completed. Start: 1737536129, End: 1737536445
[0m[2025-01-22T09:00:45.704430] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T09:00:55.705559] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T09:00:57.581638] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:00:59.450132] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:00:59.450186] [SCALING] Setting up experiment.


[0m[2025-01-22T09:00:59.450195] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:00:59.455631] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:00:59.471450] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T09:00:59.487638] [SCALING] Statefulset name to scale : flink-32000m-2048
[0m[2025-01-22T09:00:59.498729] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 1 replica.
[0m[2025-01-22T09:01:04.508915] [FLK_MGR] Running job.
[0m[2025-01-22T09:01:04.508944] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T09:01:04.938039] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-65jrc
[0m[2025-01-22T09:01:09.077304] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 51b110e4ce890ad8552b553504533a0b

[0m[2025-01-22T09:01:09.077352] [FLK_MGR] Running job id: 51b110e4ce890ad8552b553504533a0b
[0m[2025-01-22T09:01:09.077360] [FLK_MGR] Getting job info.
[0m[2025-01-22T09:01:09.092829] [FLK_MGR] Job plan response: {"plan":{"jid":"51b110e4ce890ad8552b553504533a0b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T09:01:09.092957] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T09:01:09.512515] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-65jrc
[0m[2025-01-22T09:01:10.968327] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 09:01:08 : 51b110e4ce890ad8552b553504533a0b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T09:01:10.968383] [FLK_MGR] Running jobs: ['51b110e4ce890ad8552b553504533a0b']
[0m[2025-01-22T09:01:10.968391] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T09:01:10.968397] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T09:05:10.991261] [SCALING] Scaling started.
[0m[2025-01-22T09:05:10.991313] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T09:05:11.015377] [SCALING] Scaling finished.
[0m[2025-01-22T09:05:11.015396] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:05:11.033299] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:05:11.053617] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T09:05:11.077461] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 0 replica.
[0m[2025-01-22T09:05:16.098499] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T09:05:16.112488] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T09:05:16.126278] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T09:05:16.141695] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T09:05:16.156071] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T09:05:16.177962] [POD_MGR] Pod flink-jobmanager-7d7c784b74-65jrc deleted
[0m[2025-01-22T09:05:18.065900] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:05:19.938269] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:05:19.938329] Reloading playbook: application/kafka
[0m[2025-01-22T09:05:25.853805] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T09:06:11.923377] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T09:06:11.923497] [EXPERIMENT] Run 5 completed. Start: 1737536455, End: 1737536771
[0m[2025-01-22T09:06:11.923504] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T09:06:24.186449] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T09:06:24.186502] [RESOURCE_E] Running experiment with 32000m cores and 4096 memory.
[0m[2025-01-22T09:06:31.332892] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T09:06:31.333024] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T09:06:33.218247] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:06:35.085001] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:06:35.085135] [SCALING] Setting up experiment.


[0m[2025-01-22T09:06:35.085168] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:06:35.091036] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:06:35.107984] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T09:06:35.130159] [SCALING] Statefulset name to scale : flink-32000m-4096
[0m[2025-01-22T09:06:35.140165] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 1 replica.
[0m[2025-01-22T09:06:40.150429] [FLK_MGR] Running job.
[0m[2025-01-22T09:06:40.150458] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T09:06:40.595149] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-4hg6r
[0m[2025-01-22T09:06:44.718645] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f838d9c019d627903c6cbcbfe5a17577

[0m[2025-01-22T09:06:44.718699] [FLK_MGR] Running job id: f838d9c019d627903c6cbcbfe5a17577
[0m[2025-01-22T09:06:44.718706] [FLK_MGR] Getting job info.
[0m[2025-01-22T09:06:44.736052] [FLK_MGR] Job plan response: {"plan":{"jid":"f838d9c019d627903c6cbcbfe5a17577","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T09:06:44.736208] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T09:06:45.156078] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-4hg6r
[0m[2025-01-22T09:06:46.609366] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 09:06:43 : f838d9c019d627903c6cbcbfe5a17577 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T09:06:46.609422] [FLK_MGR] Running jobs: ['f838d9c019d627903c6cbcbfe5a17577']
[0m[2025-01-22T09:06:46.609429] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T09:06:46.609434] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T09:10:46.633428] [SCALING] Scaling started.
[0m[2025-01-22T09:10:46.633533] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T09:10:46.647183] [SCALING] Scaling finished.
[0m[2025-01-22T09:10:46.647201] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:10:46.666103] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:10:46.682958] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T09:10:46.705189] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 0 replica.
[0m[2025-01-22T09:10:56.731602] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T09:10:56.746444] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T09:10:56.762379] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T09:10:56.776535] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T09:10:56.790661] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T09:10:56.819715] [POD_MGR] Pod flink-jobmanager-7d7c784b74-4hg6r deleted
[0m[2025-01-22T09:10:58.681217] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:11:00.646695] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:11:00.646764] Reloading playbook: application/kafka
[0m[2025-01-22T09:11:06.587483] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T09:11:52.495698] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T09:11:52.495826] [EXPERIMENT] Run 1 completed. Start: 1737536791, End: 1737537112
[0m[2025-01-22T09:11:52.495832] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T09:12:02.496927] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T09:12:04.373682] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:12:06.249889] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:12:06.249953] [SCALING] Setting up experiment.


[0m[2025-01-22T09:12:06.249965] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:12:06.255676] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:12:06.271021] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T09:12:06.286290] [SCALING] Statefulset name to scale : flink-32000m-4096
[0m[2025-01-22T09:12:06.298490] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 1 replica.
[0m[2025-01-22T09:12:11.308073] [FLK_MGR] Running job.
[0m[2025-01-22T09:12:11.308110] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T09:12:11.750566] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-nnxhf
[0m[2025-01-22T09:12:15.905364] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b0ca9fd2aaf45d7e46e7439f49982076

[0m[2025-01-22T09:12:15.905417] [FLK_MGR] Running job id: b0ca9fd2aaf45d7e46e7439f49982076
[0m[2025-01-22T09:12:15.905424] [FLK_MGR] Getting job info.
[0m[2025-01-22T09:12:15.922995] [FLK_MGR] Job plan response: {"plan":{"jid":"b0ca9fd2aaf45d7e46e7439f49982076","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T09:12:15.923140] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T09:12:16.297601] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-nnxhf
[0m[2025-01-22T09:12:17.746776] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 09:12:14 : b0ca9fd2aaf45d7e46e7439f49982076 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T09:12:17.746832] [FLK_MGR] Running jobs: ['b0ca9fd2aaf45d7e46e7439f49982076']
[0m[2025-01-22T09:12:17.746839] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T09:12:17.746845] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T09:16:17.770889] [SCALING] Scaling started.
[0m[2025-01-22T09:16:17.770940] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T09:16:17.784045] [SCALING] Scaling finished.
[0m[2025-01-22T09:16:17.784070] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:16:17.803280] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:16:17.822325] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T09:16:17.843237] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 0 replica.
[0m[2025-01-22T09:16:22.864654] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T09:16:22.877963] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T09:16:22.892326] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T09:16:22.905267] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T09:16:22.918829] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T09:16:22.940121] [POD_MGR] Pod flink-jobmanager-7d7c784b74-nnxhf deleted
[0m[2025-01-22T09:16:24.829143] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:16:26.737699] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:16:26.737761] Reloading playbook: application/kafka
[0m[2025-01-22T09:16:32.738054] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T09:17:18.722060] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T09:17:18.722276] [EXPERIMENT] Run 2 completed. Start: 1737537122, End: 1737537438
[0m[2025-01-22T09:17:18.722284] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T09:17:28.723453] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T09:17:30.592346] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:17:32.451376] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:17:32.451436] [SCALING] Setting up experiment.


[0m[2025-01-22T09:17:32.451447] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:17:32.457674] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:17:32.474288] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T09:17:32.493949] [SCALING] Statefulset name to scale : flink-32000m-4096
[0m[2025-01-22T09:17:32.504151] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 1 replica.
[0m[2025-01-22T09:17:37.517930] [FLK_MGR] Running job.
[0m[2025-01-22T09:17:37.517968] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T09:17:37.946559] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-hkrhh
[0m[2025-01-22T09:17:42.056611] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 672dc400ec9267d213c214ac76745945

[0m[2025-01-22T09:17:42.056666] [FLK_MGR] Running job id: 672dc400ec9267d213c214ac76745945
[0m[2025-01-22T09:17:42.056675] [FLK_MGR] Getting job info.
[0m[2025-01-22T09:17:42.075533] [FLK_MGR] Job plan response: {"plan":{"jid":"672dc400ec9267d213c214ac76745945","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T09:17:42.075687] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T09:17:42.512500] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-hkrhh
[0m[2025-01-22T09:17:43.952080] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 09:17:41 : 672dc400ec9267d213c214ac76745945 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T09:17:43.952132] [FLK_MGR] Running jobs: ['672dc400ec9267d213c214ac76745945']
[0m[2025-01-22T09:17:43.952139] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T09:17:43.952145] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T09:21:43.974198] [SCALING] Scaling started.
[0m[2025-01-22T09:21:43.974248] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T09:21:43.986687] [SCALING] Scaling finished.
[0m[2025-01-22T09:21:43.986710] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:21:44.004275] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:21:44.022163] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T09:21:44.043333] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 0 replica.
[0m[2025-01-22T09:21:54.071917] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T09:21:54.087703] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T09:21:54.102169] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T09:21:54.117900] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T09:21:54.131401] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T09:21:54.155988] [POD_MGR] Pod flink-jobmanager-7d7c784b74-hkrhh deleted
[0m[2025-01-22T09:21:56.023833] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:21:57.922283] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:21:57.922344] Reloading playbook: application/kafka
[0m[2025-01-22T09:22:03.881002] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T09:22:49.855535] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T09:22:49.855754] [EXPERIMENT] Run 3 completed. Start: 1737537448, End: 1737537769
[0m[2025-01-22T09:22:49.855761] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T09:22:59.856710] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T09:23:01.756086] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:23:03.623664] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:23:03.623722] [SCALING] Setting up experiment.


[0m[2025-01-22T09:23:03.623733] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:23:03.630493] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:23:03.647847] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T09:23:03.667564] [SCALING] Statefulset name to scale : flink-32000m-4096
[0m[2025-01-22T09:23:03.678442] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 1 replica.
[0m[2025-01-22T09:23:08.688477] [FLK_MGR] Running job.
[0m[2025-01-22T09:23:08.688505] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T09:23:09.124126] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-cdlfd
[0m[2025-01-22T09:23:13.239663] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c2c106bec394334f5ee40e5e68c4b806

[0m[2025-01-22T09:23:13.239716] [FLK_MGR] Running job id: c2c106bec394334f5ee40e5e68c4b806
[0m[2025-01-22T09:23:13.239723] [FLK_MGR] Getting job info.
[0m[2025-01-22T09:23:13.257250] [FLK_MGR] Job plan response: {"plan":{"jid":"c2c106bec394334f5ee40e5e68c4b806","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T09:23:13.257409] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T09:23:13.676541] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-cdlfd
[0m[2025-01-22T09:23:15.113583] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 09:23:12 : c2c106bec394334f5ee40e5e68c4b806 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T09:23:15.113636] [FLK_MGR] Running jobs: ['c2c106bec394334f5ee40e5e68c4b806']
[0m[2025-01-22T09:23:15.113642] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T09:23:15.113649] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T09:27:15.136699] [SCALING] Scaling started.
[0m[2025-01-22T09:27:15.136749] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T09:27:15.148904] [SCALING] Scaling finished.
[0m[2025-01-22T09:27:15.148925] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:27:15.168025] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:27:15.185626] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T09:27:15.208985] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 0 replica.
[0m[2025-01-22T09:27:20.229784] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T09:27:20.248287] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T09:27:20.265661] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T09:27:20.281173] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T09:27:20.294400] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T09:27:20.320916] [POD_MGR] Pod flink-jobmanager-7d7c784b74-cdlfd deleted
[0m[2025-01-22T09:27:22.181587] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:27:24.085621] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:27:24.085751] Reloading playbook: application/kafka
[0m[2025-01-22T09:27:30.073044] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T09:28:16.030426] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T09:28:16.030587] [EXPERIMENT] Run 4 completed. Start: 1737537779, End: 1737538096
[0m[2025-01-22T09:28:16.030595] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T09:28:26.031580] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T09:28:27.919902] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:28:29.818917] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:28:29.818973] [SCALING] Setting up experiment.


[0m[2025-01-22T09:28:29.818984] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:28:29.823992] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:28:29.840424] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T09:28:29.860921] [SCALING] Statefulset name to scale : flink-32000m-4096
[0m[2025-01-22T09:28:29.876628] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 1 replica.
[0m[2025-01-22T09:28:34.893270] [FLK_MGR] Running job.
[0m[2025-01-22T09:28:34.893306] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T09:28:35.347854] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-lvjzj
[0m[2025-01-22T09:28:39.442869] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID bd8be5a048104000234f5b45a91c2cc3

[0m[2025-01-22T09:28:39.442922] [FLK_MGR] Running job id: bd8be5a048104000234f5b45a91c2cc3
[0m[2025-01-22T09:28:39.442929] [FLK_MGR] Getting job info.
[0m[2025-01-22T09:28:39.459565] [FLK_MGR] Job plan response: {"plan":{"jid":"bd8be5a048104000234f5b45a91c2cc3","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T09:28:39.459719] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T09:28:39.831716] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-lvjzj
[0m[2025-01-22T09:28:41.291427] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 09:28:38 : bd8be5a048104000234f5b45a91c2cc3 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T09:28:41.291481] [FLK_MGR] Running jobs: ['bd8be5a048104000234f5b45a91c2cc3']
[0m[2025-01-22T09:28:41.291488] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T09:28:41.291494] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T09:32:41.314845] [SCALING] Scaling started.
[0m[2025-01-22T09:32:41.314898] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T09:32:41.327042] [SCALING] Scaling finished.
[0m[2025-01-22T09:32:41.327060] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:32:41.346462] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:32:41.363009] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T09:32:41.387250] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 0 replica.
[0m[2025-01-22T09:32:51.420786] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T09:32:51.435745] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T09:32:51.450449] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T09:32:51.466690] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T09:32:51.483049] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T09:32:51.593430] [POD_MGR] Pod flink-jobmanager-7d7c784b74-lvjzj deleted
[0m[2025-01-22T09:32:53.495857] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:32:55.381103] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:32:55.381168] Reloading playbook: application/kafka
[0m[2025-01-22T09:33:01.467739] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T09:33:47.419628] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T09:33:47.419771] [EXPERIMENT] Run 5 completed. Start: 1737538106, End: 1737538427
[0m[2025-01-22T09:33:47.419778] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T09:33:59.637503] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T09:33:59.637558] [RESOURCE_E] Running experiment with 32000m cores and 8192 memory.
[0m[2025-01-22T09:34:06.872235] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T09:34:06.872447] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T09:34:08.738593] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:34:10.597940] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:34:10.597999] [SCALING] Setting up experiment.


[0m[2025-01-22T09:34:10.598008] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:34:10.603805] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:34:10.622041] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T09:34:10.638606] [SCALING] Statefulset name to scale : flink-32000m-8192
[0m[2025-01-22T09:34:10.648754] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 1 replica.
[0m[2025-01-22T09:34:15.658187] [FLK_MGR] Running job.
[0m[2025-01-22T09:34:15.658216] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T09:34:16.031664] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mfchm
[0m[2025-01-22T09:34:20.161731] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0e3de16dac618b06504b3556b069aee9

[0m[2025-01-22T09:34:20.161785] [FLK_MGR] Running job id: 0e3de16dac618b06504b3556b069aee9
[0m[2025-01-22T09:34:20.161792] [FLK_MGR] Getting job info.
[0m[2025-01-22T09:34:20.179594] [FLK_MGR] Job plan response: {"plan":{"jid":"0e3de16dac618b06504b3556b069aee9","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T09:34:20.179753] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T09:34:20.625753] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mfchm
[0m[2025-01-22T09:34:22.056345] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 09:34:19 : 0e3de16dac618b06504b3556b069aee9 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T09:34:22.056408] [FLK_MGR] Running jobs: ['0e3de16dac618b06504b3556b069aee9']
[0m[2025-01-22T09:34:22.056416] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T09:34:22.056426] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T09:38:22.080922] [SCALING] Scaling started.
[0m[2025-01-22T09:38:22.081032] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T09:38:22.094758] [SCALING] Scaling finished.
[0m[2025-01-22T09:38:22.094799] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:38:22.112797] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:38:22.131624] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T09:38:22.153516] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 0 replica.
[0m[2025-01-22T09:38:27.173477] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T09:38:27.186430] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T09:38:27.198937] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T09:38:27.211744] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T09:38:27.224604] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T09:38:27.254498] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mfchm deleted
[0m[2025-01-22T09:38:29.119446] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:38:31.036346] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:38:31.036410] Reloading playbook: application/kafka
[0m[2025-01-22T09:38:37.003797] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T09:39:22.960006] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T09:39:22.960136] [EXPERIMENT] Run 1 completed. Start: 1737538446, End: 1737538762
[0m[2025-01-22T09:39:22.960142] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T09:39:32.961180] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T09:39:34.839953] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:39:36.725838] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:39:36.725975] [SCALING] Setting up experiment.


[0m[2025-01-22T09:39:36.725984] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:39:36.731336] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:39:36.747111] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T09:39:36.766551] [SCALING] Statefulset name to scale : flink-32000m-8192
[0m[2025-01-22T09:39:36.777755] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 1 replica.
[0m[2025-01-22T09:39:41.791394] [FLK_MGR] Running job.
[0m[2025-01-22T09:39:41.791424] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T09:39:42.224542] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-vlkt7
[0m[2025-01-22T09:39:46.307899] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 3bd2781a11bd68ca7e3ed0e3830b8a0a

[0m[2025-01-22T09:39:46.307952] [FLK_MGR] Running job id: 3bd2781a11bd68ca7e3ed0e3830b8a0a
[0m[2025-01-22T09:39:46.307960] [FLK_MGR] Getting job info.
[0m[2025-01-22T09:39:46.325495] [FLK_MGR] Job plan response: {"plan":{"jid":"3bd2781a11bd68ca7e3ed0e3830b8a0a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T09:39:46.325646] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T09:39:46.756381] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-vlkt7
[0m[2025-01-22T09:39:48.198122] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 09:39:45 : 3bd2781a11bd68ca7e3ed0e3830b8a0a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T09:39:48.198184] [FLK_MGR] Running jobs: ['3bd2781a11bd68ca7e3ed0e3830b8a0a']
[0m[2025-01-22T09:39:48.198195] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T09:39:48.198206] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T09:43:48.222383] [SCALING] Scaling started.
[0m[2025-01-22T09:43:48.222485] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T09:43:48.236935] [SCALING] Scaling finished.
[0m[2025-01-22T09:43:48.236968] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:43:48.256472] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:43:48.273573] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T09:43:48.295171] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 0 replica.
[0m[2025-01-22T09:43:53.315830] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T09:43:53.331574] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T09:43:53.346394] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T09:43:53.361710] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T09:43:53.377560] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T09:43:53.399582] [POD_MGR] Pod flink-jobmanager-7d7c784b74-vlkt7 deleted
[0m[2025-01-22T09:43:55.302578] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:43:57.178848] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:43:57.178913] Reloading playbook: application/kafka
[0m[2025-01-22T09:44:03.149649] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T09:45:09.119721] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T09:45:09.119896] [EXPERIMENT] Run 2 completed. Start: 1737538772, End: 1737539109
[0m[2025-01-22T09:45:09.119902] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T09:45:19.120934] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T09:45:20.982240] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:45:22.862181] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:45:22.862284] [SCALING] Setting up experiment.


[0m[2025-01-22T09:45:22.862324] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:45:22.868994] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:45:22.885064] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T09:45:22.902761] [SCALING] Statefulset name to scale : flink-32000m-8192
[0m[2025-01-22T09:45:22.915080] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 1 replica.
[0m[2025-01-22T09:45:27.925361] [FLK_MGR] Running job.
[0m[2025-01-22T09:45:27.925390] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T09:45:28.376806] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-m6xd7
[0m[2025-01-22T09:45:32.481175] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9a8067623cefbd589c6f4528f6173c7e

[0m[2025-01-22T09:45:32.481220] [FLK_MGR] Running job id: 9a8067623cefbd589c6f4528f6173c7e
[0m[2025-01-22T09:45:32.481227] [FLK_MGR] Getting job info.
[0m[2025-01-22T09:45:32.498848] [FLK_MGR] Job plan response: {"plan":{"jid":"9a8067623cefbd589c6f4528f6173c7e","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T09:45:32.499011] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T09:45:32.933964] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-m6xd7
[0m[2025-01-22T09:45:34.378989] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 09:45:31 : 9a8067623cefbd589c6f4528f6173c7e : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T09:45:34.379048] [FLK_MGR] Running jobs: ['9a8067623cefbd589c6f4528f6173c7e']
[0m[2025-01-22T09:45:34.379055] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T09:45:34.379061] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T09:49:34.401706] [SCALING] Scaling started.
[0m[2025-01-22T09:49:34.401756] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T09:49:34.413252] [SCALING] Scaling finished.
[0m[2025-01-22T09:49:34.413277] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:49:34.431582] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:49:34.470124] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T09:49:34.491948] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 0 replica.
[0m[2025-01-22T09:49:39.512949] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T09:49:39.526370] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T09:49:39.539961] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T09:49:39.553409] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T09:49:39.567386] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T09:49:39.601508] [POD_MGR] Pod flink-jobmanager-7d7c784b74-m6xd7 deleted
[0m[2025-01-22T09:49:41.454078] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:49:43.310013] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:49:43.310078] Reloading playbook: application/kafka
[0m[2025-01-22T09:49:49.262493] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T09:50:35.231204] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T09:50:35.231331] [EXPERIMENT] Run 3 completed. Start: 1737539119, End: 1737539435
[0m[2025-01-22T09:50:35.231336] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T09:50:45.232329] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T09:50:47.111821] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:50:48.985129] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:50:48.985186] [SCALING] Setting up experiment.


[0m[2025-01-22T09:50:48.985194] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:50:48.990648] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:50:49.007241] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T09:50:49.025418] [SCALING] Statefulset name to scale : flink-32000m-8192
[0m[2025-01-22T09:50:49.035641] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 1 replica.
[0m[2025-01-22T09:50:54.046414] [FLK_MGR] Running job.
[0m[2025-01-22T09:50:54.046445] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T09:50:54.417412] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-wn52k
[0m[2025-01-22T09:50:58.516441] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 798f034ee71331be6194b85f2105f387

[0m[2025-01-22T09:50:58.516494] [FLK_MGR] Running job id: 798f034ee71331be6194b85f2105f387
[0m[2025-01-22T09:50:58.516501] [FLK_MGR] Getting job info.
[0m[2025-01-22T09:50:58.533649] [FLK_MGR] Job plan response: {"plan":{"jid":"798f034ee71331be6194b85f2105f387","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T09:50:58.533791] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T09:50:58.984159] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-wn52k
[0m[2025-01-22T09:51:00.425188] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 09:50:57 : 798f034ee71331be6194b85f2105f387 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T09:51:00.425248] [FLK_MGR] Running jobs: ['798f034ee71331be6194b85f2105f387']
[0m[2025-01-22T09:51:00.425265] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T09:51:00.425278] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T09:55:00.450380] [SCALING] Scaling started.
[0m[2025-01-22T09:55:00.450441] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T09:55:00.464543] [SCALING] Scaling finished.
[0m[2025-01-22T09:55:00.464583] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:55:00.482292] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:55:00.500159] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T09:55:00.522104] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 0 replica.
[0m[2025-01-22T09:55:10.548637] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T09:55:10.563354] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T09:55:10.577656] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T09:55:10.591326] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T09:55:10.604886] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T09:55:10.628104] [POD_MGR] Pod flink-jobmanager-7d7c784b74-wn52k deleted
[0m[2025-01-22T09:55:12.524482] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:55:14.428114] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T09:55:14.428178] Reloading playbook: application/kafka
[0m[2025-01-22T09:55:20.404286] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T09:56:06.355137] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T09:56:06.355276] [EXPERIMENT] Run 4 completed. Start: 1737539445, End: 1737539766
[0m[2025-01-22T09:56:06.355283] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T09:56:16.356396] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T09:56:18.219013] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:56:20.109898] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T09:56:20.110059] [SCALING] Setting up experiment.


[0m[2025-01-22T09:56:20.110101] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T09:56:20.116476] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T09:56:20.132192] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T09:56:20.149472] [SCALING] Statefulset name to scale : flink-32000m-8192
[0m[2025-01-22T09:56:20.159152] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 1 replica.
[0m[2025-01-22T09:56:25.168039] [FLK_MGR] Running job.
[0m[2025-01-22T09:56:25.168131] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T09:56:25.604970] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mst2r
[0m[2025-01-22T09:56:29.774909] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8ef8c12e1451baa94cea929f51033507

[0m[2025-01-22T09:56:29.774956] [FLK_MGR] Running job id: 8ef8c12e1451baa94cea929f51033507
[0m[2025-01-22T09:56:29.774964] [FLK_MGR] Getting job info.
[0m[2025-01-22T09:56:29.793680] [FLK_MGR] Job plan response: {"plan":{"jid":"8ef8c12e1451baa94cea929f51033507","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T09:56:29.793829] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T09:56:30.230365] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mst2r
[0m[2025-01-22T09:56:31.667508] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 09:56:28 : 8ef8c12e1451baa94cea929f51033507 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T09:56:31.667564] [FLK_MGR] Running jobs: ['8ef8c12e1451baa94cea929f51033507']
[0m[2025-01-22T09:56:31.667570] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T09:56:31.667576] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T10:00:31.691840] [SCALING] Scaling started.
[0m[2025-01-22T10:00:31.691939] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T10:00:31.706418] [SCALING] Scaling finished.
[0m[2025-01-22T10:00:31.706440] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:00:31.724518] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:00:31.742485] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T10:00:31.763837] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 0 replica.
[0m[2025-01-22T10:00:36.786133] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T10:00:36.799857] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T10:00:36.813077] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T10:00:36.826639] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T10:00:36.841433] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T10:00:36.876532] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mst2r deleted
[0m[2025-01-22T10:00:38.789534] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:00:40.680610] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:00:40.680672] Reloading playbook: application/kafka
[0m[2025-01-22T10:00:46.639345] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T10:01:32.638652] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T10:01:32.638782] [EXPERIMENT] Run 5 completed. Start: 1737539776, End: 1737540092
[0m[2025-01-22T10:01:32.638787] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T10:01:44.764105] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T10:01:44.764157] [RESOURCE_E] Running experiment with 32000m cores and 16384 memory.
[0m[2025-01-22T10:01:51.981810] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T10:01:51.981968] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T10:01:53.824357] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:01:55.679620] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:01:55.679676] [SCALING] Setting up experiment.


[0m[2025-01-22T10:01:55.679684] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:01:55.685424] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:01:55.701495] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T10:01:55.718944] [SCALING] Statefulset name to scale : flink-32000m-16384
[0m[2025-01-22T10:01:55.731726] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 1 replica.
[0m[2025-01-22T10:02:00.741517] [FLK_MGR] Running job.
[0m[2025-01-22T10:02:00.741545] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T10:02:01.204981] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-hzvwd
[0m[2025-01-22T10:02:05.333616] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID bf0212170e8fb3603ed823b7ae4128a8

[0m[2025-01-22T10:02:05.333684] [FLK_MGR] Running job id: bf0212170e8fb3603ed823b7ae4128a8
[0m[2025-01-22T10:02:05.333696] [FLK_MGR] Getting job info.
[0m[2025-01-22T10:02:05.355385] [FLK_MGR] Job plan response: {"plan":{"jid":"bf0212170e8fb3603ed823b7ae4128a8","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T10:02:05.355539] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T10:02:05.790304] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-hzvwd
[0m[2025-01-22T10:02:07.238039] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 10:02:04 : bf0212170e8fb3603ed823b7ae4128a8 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T10:02:07.238094] [FLK_MGR] Running jobs: ['bf0212170e8fb3603ed823b7ae4128a8']
[0m[2025-01-22T10:02:07.238102] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T10:02:07.238109] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T10:06:07.261725] [SCALING] Scaling started.
[0m[2025-01-22T10:06:07.261823] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T10:06:07.275034] [SCALING] Scaling finished.
[0m[2025-01-22T10:06:07.275051] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:06:07.294101] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:06:07.312584] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T10:06:07.333879] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 0 replica.
[0m[2025-01-22T10:06:17.362481] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T10:06:17.376498] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T10:06:17.390809] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T10:06:17.405593] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T10:06:17.419399] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T10:06:17.453423] [POD_MGR] Pod flink-jobmanager-7d7c784b74-hzvwd deleted
[0m[2025-01-22T10:06:19.332904] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:06:21.297724] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:06:21.297786] Reloading playbook: application/kafka
[0m[2025-01-22T10:06:27.234994] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T10:07:13.161353] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T10:07:13.161487] [EXPERIMENT] Run 1 completed. Start: 1737540111, End: 1737540433
[0m[2025-01-22T10:07:13.161493] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T10:07:23.162567] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T10:07:25.040613] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:07:26.910924] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:07:26.910981] [SCALING] Setting up experiment.


[0m[2025-01-22T10:07:26.910989] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:07:26.916437] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:07:26.934015] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T10:07:26.953326] [SCALING] Statefulset name to scale : flink-32000m-16384
[0m[2025-01-22T10:07:26.963273] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 1 replica.
[0m[2025-01-22T10:07:31.972570] [FLK_MGR] Running job.
[0m[2025-01-22T10:07:31.972600] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T10:07:32.413533] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-dk84r
[0m[2025-01-22T10:07:36.545633] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fc908bc828eb0293376341b77526edc2

[0m[2025-01-22T10:07:36.545685] [FLK_MGR] Running job id: fc908bc828eb0293376341b77526edc2
[0m[2025-01-22T10:07:36.545692] [FLK_MGR] Getting job info.
[0m[2025-01-22T10:07:36.564181] [FLK_MGR] Job plan response: {"plan":{"jid":"fc908bc828eb0293376341b77526edc2","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T10:07:36.564328] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T10:07:36.945163] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-dk84r
[0m[2025-01-22T10:07:38.408711] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 10:07:35 : fc908bc828eb0293376341b77526edc2 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T10:07:38.408766] [FLK_MGR] Running jobs: ['fc908bc828eb0293376341b77526edc2']
[0m[2025-01-22T10:07:38.408773] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T10:07:38.408779] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T10:11:38.430588] [SCALING] Scaling started.
[0m[2025-01-22T10:11:38.430639] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T10:11:38.443779] [SCALING] Scaling finished.
[0m[2025-01-22T10:11:38.443798] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:11:38.461008] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:11:38.478489] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T10:11:38.498947] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 0 replica.
[0m[2025-01-22T10:11:48.525732] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T10:11:48.539490] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T10:11:48.552368] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T10:11:48.565032] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T10:11:48.577463] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T10:11:48.599194] [POD_MGR] Pod flink-jobmanager-7d7c784b74-dk84r deleted
[0m[2025-01-22T10:11:50.493486] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:11:52.450155] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:11:52.450219] Reloading playbook: application/kafka
[0m[2025-01-22T10:11:58.381384] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T10:12:44.302055] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T10:12:44.302172] [EXPERIMENT] Run 2 completed. Start: 1737540443, End: 1737540764
[0m[2025-01-22T10:12:44.302178] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T10:12:54.303271] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T10:12:56.195928] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:12:58.076974] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:12:58.077031] [SCALING] Setting up experiment.


[0m[2025-01-22T10:12:58.077039] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:12:58.083240] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:12:58.098613] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T10:12:58.116355] [SCALING] Statefulset name to scale : flink-32000m-16384
[0m[2025-01-22T10:12:58.127486] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 1 replica.
[0m[2025-01-22T10:13:03.137169] [FLK_MGR] Running job.
[0m[2025-01-22T10:13:03.137200] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T10:13:03.603778] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-5q6bq
[0m[2025-01-22T10:13:07.739298] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 77444a542aa2bbfd87e8130152a02bd4

[0m[2025-01-22T10:13:07.739352] [FLK_MGR] Running job id: 77444a542aa2bbfd87e8130152a02bd4
[0m[2025-01-22T10:13:07.739363] [FLK_MGR] Getting job info.
[0m[2025-01-22T10:13:07.755694] [FLK_MGR] Job plan response: {"plan":{"jid":"77444a542aa2bbfd87e8130152a02bd4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T10:13:07.755836] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T10:13:08.178049] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-5q6bq
[0m[2025-01-22T10:13:09.615539] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 10:13:06 : 77444a542aa2bbfd87e8130152a02bd4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T10:13:09.615593] [FLK_MGR] Running jobs: ['77444a542aa2bbfd87e8130152a02bd4']
[0m[2025-01-22T10:13:09.615600] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T10:13:09.615606] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T10:17:09.639113] [SCALING] Scaling started.
[0m[2025-01-22T10:17:09.639162] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T10:17:09.652490] [SCALING] Scaling finished.
[0m[2025-01-22T10:17:09.652509] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:17:09.670130] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:17:09.685966] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T10:17:09.707026] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 0 replica.
[0m[2025-01-22T10:17:14.727393] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T10:17:14.743883] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T10:17:14.757119] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T10:17:14.770723] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T10:17:14.783772] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T10:17:14.814193] [POD_MGR] Pod flink-jobmanager-7d7c784b74-5q6bq deleted
[0m[2025-01-22T10:17:16.679968] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:17:18.525397] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:17:18.525458] Reloading playbook: application/kafka
[0m[2025-01-22T10:17:24.426138] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T10:18:10.388441] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T10:18:10.388568] [EXPERIMENT] Run 3 completed. Start: 1737540774, End: 1737541090
[0m[2025-01-22T10:18:10.388574] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T10:18:20.389517] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T10:18:22.286482] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:18:24.185105] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:18:24.185160] [SCALING] Setting up experiment.


[0m[2025-01-22T10:18:24.185168] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:18:24.190750] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:18:24.206545] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T10:18:24.224950] [SCALING] Statefulset name to scale : flink-32000m-16384
[0m[2025-01-22T10:18:24.238985] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 1 replica.
[0m[2025-01-22T10:18:29.248750] [FLK_MGR] Running job.
[0m[2025-01-22T10:18:29.248779] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T10:18:29.675406] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-9cbbr
[0m[2025-01-22T10:18:33.814698] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6a64ac597f1943928d8b630ad25dbf69

[0m[2025-01-22T10:18:33.814746] [FLK_MGR] Running job id: 6a64ac597f1943928d8b630ad25dbf69
[0m[2025-01-22T10:18:33.814757] [FLK_MGR] Getting job info.
[0m[2025-01-22T10:18:33.830859] [FLK_MGR] Job plan response: {"plan":{"jid":"6a64ac597f1943928d8b630ad25dbf69","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T10:18:33.831001] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T10:18:34.291138] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-9cbbr
[0m[2025-01-22T10:18:35.721882] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 10:18:32 : 6a64ac597f1943928d8b630ad25dbf69 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T10:18:35.721934] [FLK_MGR] Running jobs: ['6a64ac597f1943928d8b630ad25dbf69']
[0m[2025-01-22T10:18:35.721941] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T10:18:35.721948] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T10:22:35.745905] [SCALING] Scaling started.
[0m[2025-01-22T10:22:35.745959] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T10:22:35.759186] [SCALING] Scaling finished.
[0m[2025-01-22T10:22:35.759208] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:22:35.779475] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:22:35.796503] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T10:22:35.818287] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 0 replica.
[0m[2025-01-22T10:22:40.839021] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T10:22:40.851965] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T10:22:40.864913] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T10:22:40.878083] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T10:22:40.892111] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T10:22:40.922447] [POD_MGR] Pod flink-jobmanager-7d7c784b74-9cbbr deleted
[0m[2025-01-22T10:22:42.822293] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:22:44.729042] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:22:44.729108] Reloading playbook: application/kafka
[0m[2025-01-22T10:22:50.725300] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T10:23:36.701911] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T10:23:36.702027] [EXPERIMENT] Run 4 completed. Start: 1737541100, End: 1737541416
[0m[2025-01-22T10:23:36.702033] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T10:23:46.703001] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T10:23:48.546965] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:23:50.406999] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:23:50.407060] [SCALING] Setting up experiment.


[0m[2025-01-22T10:23:50.407068] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:23:50.412594] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:23:50.428928] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T10:23:50.447079] [SCALING] Statefulset name to scale : flink-32000m-16384
[0m[2025-01-22T10:23:50.458343] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 1 replica.
[0m[2025-01-22T10:23:55.468798] [FLK_MGR] Running job.
[0m[2025-01-22T10:23:55.468826] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T10:23:55.926874] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-vbb7c
[0m[2025-01-22T10:24:00.070235] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 12c81ddad13a526501d44bfedbd92d5d

[0m[2025-01-22T10:24:00.070284] [FLK_MGR] Running job id: 12c81ddad13a526501d44bfedbd92d5d
[0m[2025-01-22T10:24:00.070291] [FLK_MGR] Getting job info.
[0m[2025-01-22T10:24:00.087158] [FLK_MGR] Job plan response: {"plan":{"jid":"12c81ddad13a526501d44bfedbd92d5d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T10:24:00.087299] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T10:24:00.468261] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-vbb7c
[0m[2025-01-22T10:24:01.905638] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 10:23:59 : 12c81ddad13a526501d44bfedbd92d5d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T10:24:01.905694] [FLK_MGR] Running jobs: ['12c81ddad13a526501d44bfedbd92d5d']
[0m[2025-01-22T10:24:01.905702] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T10:24:01.905708] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T10:28:01.928840] [SCALING] Scaling started.
[0m[2025-01-22T10:28:01.928893] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T10:28:01.941384] [SCALING] Scaling finished.
[0m[2025-01-22T10:28:01.941407] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:28:01.959574] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:28:01.976973] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T10:28:01.997708] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 0 replica.
[0m[2025-01-22T10:28:12.025849] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T10:28:12.041161] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T10:28:12.057164] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T10:28:12.070370] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T10:28:12.085233] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T10:28:12.109560] [POD_MGR] Pod flink-jobmanager-7d7c784b74-vbb7c deleted
[0m[2025-01-22T10:28:13.994655] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:28:15.898182] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:28:15.898245] Reloading playbook: application/kafka
[0m[2025-01-22T10:28:21.884853] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T10:29:07.889562] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T10:29:07.889686] [EXPERIMENT] Run 5 completed. Start: 1737541426, End: 1737541747
[0m[2025-01-22T10:29:07.889692] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T10:29:20.120454] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T10:29:20.120515] [RESOURCE_E] Running experiment with 32000m cores and 32768 memory.
[0m[2025-01-22T10:29:27.399679] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-22T10:29:27.399748] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-22T10:29:29.261485] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:29:31.128521] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:29:31.128581] [SCALING] Setting up experiment.


[0m[2025-01-22T10:29:31.128590] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:29:31.137375] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:29:31.155011] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T10:29:31.170536] [SCALING] Statefulset name to scale : flink-32000m-32768
[0m[2025-01-22T10:29:31.181119] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 1 replica.
[0m[2025-01-22T10:29:36.194754] [FLK_MGR] Running job.
[0m[2025-01-22T10:29:36.194781] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T10:29:36.565626] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mgjkd
[0m[2025-01-22T10:29:40.687581] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a9e0db6ab27f4dc7dd7c7e61cd572bad

[0m[2025-01-22T10:29:40.687635] [FLK_MGR] Running job id: a9e0db6ab27f4dc7dd7c7e61cd572bad
[0m[2025-01-22T10:29:40.687646] [FLK_MGR] Getting job info.
[0m[2025-01-22T10:29:40.704930] [FLK_MGR] Job plan response: {"plan":{"jid":"a9e0db6ab27f4dc7dd7c7e61cd572bad","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T10:29:40.705074] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T10:29:41.144177] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mgjkd
[0m[2025-01-22T10:29:42.571212] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 10:29:39 : a9e0db6ab27f4dc7dd7c7e61cd572bad : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T10:29:42.571268] [FLK_MGR] Running jobs: ['a9e0db6ab27f4dc7dd7c7e61cd572bad']
[0m[2025-01-22T10:29:42.571274] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T10:29:42.571280] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T10:33:42.594892] [SCALING] Scaling started.
[0m[2025-01-22T10:33:42.594942] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T10:33:42.608937] [SCALING] Scaling finished.
[0m[2025-01-22T10:33:42.608960] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:33:42.626620] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:33:42.644187] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T10:33:42.667080] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 0 replica.
[0m[2025-01-22T10:33:47.689242] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T10:33:47.704294] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T10:33:47.720033] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T10:33:47.734176] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T10:33:47.750213] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T10:33:47.784497] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mgjkd deleted
[0m[2025-01-22T10:33:49.689066] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:33:51.603710] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:33:51.603771] Reloading playbook: application/kafka
[0m[2025-01-22T10:33:57.596925] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T10:34:43.515498] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T10:34:43.515613] [EXPERIMENT] Run 1 completed. Start: 1737541767, End: 1737542083
[0m[2025-01-22T10:34:43.515619] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T10:34:53.516664] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-22T10:34:55.394900] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:34:57.253439] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:34:57.253494] [SCALING] Setting up experiment.


[0m[2025-01-22T10:34:57.253503] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:34:57.261305] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:34:57.277115] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T10:34:57.293849] [SCALING] Statefulset name to scale : flink-32000m-32768
[0m[2025-01-22T10:34:57.303642] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 1 replica.
[0m[2025-01-22T10:35:02.314461] [FLK_MGR] Running job.
[0m[2025-01-22T10:35:02.314491] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T10:35:02.747764] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-q77hg
[0m[2025-01-22T10:35:06.878370] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 1acf48823bcf438ebb8eaf1c058de72c

[0m[2025-01-22T10:35:06.878422] [FLK_MGR] Running job id: 1acf48823bcf438ebb8eaf1c058de72c
[0m[2025-01-22T10:35:06.878429] [FLK_MGR] Getting job info.
[0m[2025-01-22T10:35:06.895706] [FLK_MGR] Job plan response: {"plan":{"jid":"1acf48823bcf438ebb8eaf1c058de72c","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T10:35:06.895845] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T10:35:07.329199] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-q77hg
[0m[2025-01-22T10:35:08.783651] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 10:35:05 : 1acf48823bcf438ebb8eaf1c058de72c : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T10:35:08.783706] [FLK_MGR] Running jobs: ['1acf48823bcf438ebb8eaf1c058de72c']
[0m[2025-01-22T10:35:08.783713] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T10:35:08.783719] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T10:39:08.806464] [SCALING] Scaling started.
[0m[2025-01-22T10:39:08.806552] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T10:39:08.824536] [SCALING] Scaling finished.
[0m[2025-01-22T10:39:08.824572] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:39:08.842491] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:39:08.859245] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T10:39:08.881777] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 0 replica.
[0m[2025-01-22T10:39:18.908659] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T10:39:18.925366] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T10:39:18.940078] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T10:39:18.953609] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T10:39:18.968175] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T10:39:19.001341] [POD_MGR] Pod flink-jobmanager-7d7c784b74-q77hg deleted
[0m[2025-01-22T10:39:20.869332] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:39:22.778306] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:39:22.778374] Reloading playbook: application/kafka
[0m[2025-01-22T10:39:28.669162] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T10:40:14.637677] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T10:40:14.637816] [EXPERIMENT] Run 2 completed. Start: 1737542093, End: 1737542414
[0m[2025-01-22T10:40:14.637823] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T10:40:24.639171] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-22T10:40:26.506164] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:40:28.351580] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:40:28.351671] [SCALING] Setting up experiment.


[0m[2025-01-22T10:40:28.351683] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:40:28.357988] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:40:28.373369] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T10:40:28.390219] [SCALING] Statefulset name to scale : flink-32000m-32768
[0m[2025-01-22T10:40:28.400847] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 1 replica.
[0m[2025-01-22T10:40:33.411065] [FLK_MGR] Running job.
[0m[2025-01-22T10:40:33.411093] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T10:40:33.842366] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-zpdrk
[0m[2025-01-22T10:40:37.956363] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 025c25be7fee869aa0830ea4296f8a3a

[0m[2025-01-22T10:40:37.956411] [FLK_MGR] Running job id: 025c25be7fee869aa0830ea4296f8a3a
[0m[2025-01-22T10:40:37.956418] [FLK_MGR] Getting job info.
[0m[2025-01-22T10:40:37.974831] [FLK_MGR] Job plan response: {"plan":{"jid":"025c25be7fee869aa0830ea4296f8a3a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T10:40:37.974982] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T10:40:38.423998] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-zpdrk
[0m[2025-01-22T10:40:39.866920] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 10:40:36 : 025c25be7fee869aa0830ea4296f8a3a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T10:40:39.866973] [FLK_MGR] Running jobs: ['025c25be7fee869aa0830ea4296f8a3a']
[0m[2025-01-22T10:40:39.866980] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T10:40:39.866986] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T10:44:39.889588] [SCALING] Scaling started.
[0m[2025-01-22T10:44:39.889638] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T10:44:39.903111] [SCALING] Scaling finished.
[0m[2025-01-22T10:44:39.903130] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:44:39.920935] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:44:39.937339] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T10:44:39.957587] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 0 replica.
[0m[2025-01-22T10:44:50.000070] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T10:44:50.019845] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T10:44:50.032933] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T10:44:50.047307] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T10:44:50.060730] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T10:44:50.096924] [POD_MGR] Pod flink-jobmanager-7d7c784b74-zpdrk deleted
[0m[2025-01-22T10:44:51.967968] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:44:53.905811] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:44:53.905873] Reloading playbook: application/kafka
[0m[2025-01-22T10:44:59.872437] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T10:45:45.845245] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T10:45:45.845541] [EXPERIMENT] Run 3 completed. Start: 1737542424, End: 1737542745
[0m[2025-01-22T10:45:45.845548] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T10:45:55.846592] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-22T10:45:57.725971] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:45:59.588029] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:45:59.588085] [SCALING] Setting up experiment.


[0m[2025-01-22T10:45:59.588096] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:45:59.593843] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:45:59.608394] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T10:45:59.624366] [SCALING] Statefulset name to scale : flink-32000m-32768
[0m[2025-01-22T10:45:59.634897] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 1 replica.
[0m[2025-01-22T10:46:04.648872] [FLK_MGR] Running job.
[0m[2025-01-22T10:46:04.648902] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T10:46:05.032533] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-kbm96
[0m[2025-01-22T10:46:09.178620] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0b56359713f2083366dd2c2618d5c79c

[0m[2025-01-22T10:46:09.178676] [FLK_MGR] Running job id: 0b56359713f2083366dd2c2618d5c79c
[0m[2025-01-22T10:46:09.178683] [FLK_MGR] Getting job info.
[0m[2025-01-22T10:46:09.197648] [FLK_MGR] Job plan response: {"plan":{"jid":"0b56359713f2083366dd2c2618d5c79c","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T10:46:09.197793] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T10:46:09.620150] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-kbm96
[0m[2025-01-22T10:46:11.079173] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 10:46:08 : 0b56359713f2083366dd2c2618d5c79c : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T10:46:11.079231] [FLK_MGR] Running jobs: ['0b56359713f2083366dd2c2618d5c79c']
[0m[2025-01-22T10:46:11.079239] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T10:46:11.079245] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T10:50:11.104362] [SCALING] Scaling started.
[0m[2025-01-22T10:50:11.104415] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T10:50:11.118069] [SCALING] Scaling finished.
[0m[2025-01-22T10:50:11.118086] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:50:11.136137] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:50:11.156230] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T10:50:11.177041] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 0 replica.
[0m[2025-01-22T10:50:16.199036] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T10:50:16.214682] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T10:50:16.228002] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T10:50:16.240657] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T10:50:16.253223] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T10:50:16.274931] [POD_MGR] Pod flink-jobmanager-7d7c784b74-kbm96 deleted
[0m[2025-01-22T10:50:18.166146] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:50:20.022704] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:50:20.022778] Reloading playbook: application/kafka
[0m[2025-01-22T10:50:25.933652] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T10:51:11.917365] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T10:51:11.917489] [EXPERIMENT] Run 4 completed. Start: 1737542755, End: 1737543071
[0m[2025-01-22T10:51:11.917495] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T10:51:21.918503] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-22T10:51:23.840992] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:51:25.692725] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-22T10:51:25.692780] [SCALING] Setting up experiment.


[0m[2025-01-22T10:51:25.692788] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:51:25.697859] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:51:25.712206] [SCALING] First node: paradoxe-18.rennes.grid5000.fr

[0m[2025-01-22T10:51:25.730276] [SCALING] Statefulset name to scale : flink-32000m-32768
[0m[2025-01-22T10:51:25.740541] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 1 replica.
[0m[2025-01-22T10:51:30.750201] [FLK_MGR] Running job.
[0m[2025-01-22T10:51:30.750229] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-22T10:51:31.163896] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-fk2xm
[0m[2025-01-22T10:51:35.290385] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c7fef8521bfacc93932903913db37ba3

[0m[2025-01-22T10:51:35.290437] [FLK_MGR] Running job id: c7fef8521bfacc93932903913db37ba3
[0m[2025-01-22T10:51:35.290445] [FLK_MGR] Getting job info.
[0m[2025-01-22T10:51:35.310404] [FLK_MGR] Job plan response: {"plan":{"jid":"c7fef8521bfacc93932903913db37ba3","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-22T10:51:35.310559] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-22T10:51:35.726911] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-fk2xm
[0m[2025-01-22T10:51:37.156228] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
22.01.2025 10:51:34 : c7fef8521bfacc93932903913db37ba3 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-22T10:51:37.156290] [FLK_MGR] Running jobs: ['c7fef8521bfacc93932903913db37ba3']
[0m[2025-01-22T10:51:37.156297] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-22T10:51:37.156303] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-22T10:55:37.179582] [SCALING] Scaling started.
[0m[2025-01-22T10:55:37.179678] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-22T10:55:37.194378] [SCALING] Scaling finished.
[0m[2025-01-22T10:55:37.194401] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-22T10:55:37.212673] [NODE_MGR] Resetting state labels.
[0m[2025-01-22T10:55:37.230114] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-22T10:55:37.254694] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 0 replica.
[0m[2025-01-22T10:55:47.282421] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-22T10:55:47.299015] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-22T10:55:47.313595] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-22T10:55:47.326988] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-22T10:55:47.340976] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-22T10:55:47.393060] [POD_MGR] Pod flink-jobmanager-7d7c784b74-fk2xm deleted
[0m[2025-01-22T10:55:49.304755] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:55:51.265866] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-22T10:55:51.265934] Reloading playbook: application/kafka
[0m[2025-01-22T10:55:57.258467] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-22T10:56:43.247769] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-22T10:56:43.247893] [EXPERIMENT] Run 5 completed. Start: 1737543081, End: 1737543403
[0m[2025-01-22T10:56:43.247899] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-22T10:56:55.472871] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-22T10:56:55.473236] [FSM] Run phase complete, transitioning to finishing.
[0m[2025-01-22T10:56:55.473578] [FSM] Finish phase started.
[0m[2025-01-22T10:56:55.473602] [FSM] State is States.FINISHING
[0m[2025-01-22T10:56:55.474072] FolderManager initialized with base path: /experiment-volume. Date: None
