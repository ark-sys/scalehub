[0m[2025-01-18T10:34:52.394159] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T10:34:54.323256] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T10:34:54.323430] [SCALING] Setting up experiment.


[0m[2025-01-18T10:34:54.323479] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T10:34:54.336075] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T10:34:54.367659] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T10:34:54.389541] [SCALING] Statefulset name to scale : flink-1000m-1024
[0m[2025-01-18T10:34:54.400281] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 1 replica.
[0m[2025-01-18T10:34:59.411354] [FLK_MGR] Running job.
[0m[2025-01-18T10:34:59.411383] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T10:34:59.793738] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-4gfh5
[0m[2025-01-18T10:35:03.912805] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8f82100626a612a989a89818b2be6a94

[0m[2025-01-18T10:35:03.912856] [FLK_MGR] Running job id: 8f82100626a612a989a89818b2be6a94
[0m[2025-01-18T10:35:03.912865] [FLK_MGR] Getting job info.
[0m[2025-01-18T10:35:03.930215] [FLK_MGR] Job plan response: {"plan":{"jid":"8f82100626a612a989a89818b2be6a94","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T10:35:03.930353] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T10:35:04.344839] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-4gfh5
[0m[2025-01-18T10:35:05.797851] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 10:35:02 : 8f82100626a612a989a89818b2be6a94 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T10:35:05.797932] [FLK_MGR] Running jobs: ['8f82100626a612a989a89818b2be6a94']
[0m[2025-01-18T10:35:05.797943] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T10:35:05.797956] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T10:39:05.822265] [SCALING] Scaling started.
[0m[2025-01-18T10:39:05.822315] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T10:39:05.834821] [SCALING] Scaling finished.
[0m[2025-01-18T10:39:05.834845] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T10:39:05.852653] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T10:39:05.871007] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T10:39:05.890673] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 0 replica.
[0m[2025-01-18T10:39:10.912539] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T10:39:10.928891] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T10:39:10.943290] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T10:39:10.958260] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T10:39:10.972389] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T10:39:11.002371] [POD_MGR] Pod flink-jobmanager-7d7c784b74-4gfh5 deleted
[0m[2025-01-18T10:39:12.972132] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T10:39:14.850070] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T10:39:14.850133] Reloading playbook: application/kafka
[0m[2025-01-18T10:39:20.882878] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T10:40:01.819007] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T10:40:01.819223] [EXPERIMENT] Run 1 completed. Start: 1737196490, End: 1737196801
[0m[2025-01-18T10:40:01.819230] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T10:40:11.820183] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T10:40:13.727094] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T10:40:15.642120] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T10:40:15.642199] [SCALING] Setting up experiment.


[0m[2025-01-18T10:40:15.642213] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T10:40:15.647862] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T10:40:15.663866] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T10:40:15.680649] [SCALING] Statefulset name to scale : flink-1000m-1024
[0m[2025-01-18T10:40:15.692136] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 1 replica.
[0m[2025-01-18T10:40:20.702865] [FLK_MGR] Running job.
[0m[2025-01-18T10:40:20.702893] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T10:40:21.090634] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-4l965
[0m[2025-01-18T10:40:25.188882] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b0a2cbefab25f420c1ff014d819f1384

[0m[2025-01-18T10:40:25.188929] [FLK_MGR] Running job id: b0a2cbefab25f420c1ff014d819f1384
[0m[2025-01-18T10:40:25.188937] [FLK_MGR] Getting job info.
[0m[2025-01-18T10:40:25.206878] [FLK_MGR] Job plan response: {"plan":{"jid":"b0a2cbefab25f420c1ff014d819f1384","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T10:40:25.207014] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T10:40:27.057657] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-4l965
[0m[2025-01-18T10:40:28.490513] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 10:40:24 : b0a2cbefab25f420c1ff014d819f1384 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T10:40:28.490569] [FLK_MGR] Running jobs: ['b0a2cbefab25f420c1ff014d819f1384']
[0m[2025-01-18T10:40:28.490576] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T10:40:28.490581] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T10:44:28.513132] [SCALING] Scaling started.
[0m[2025-01-18T10:44:28.513179] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T10:44:28.528831] [SCALING] Scaling finished.
[0m[2025-01-18T10:44:28.528864] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T10:44:28.546544] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T10:44:28.564210] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T10:44:28.587769] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 0 replica.
[0m[2025-01-18T10:44:33.610091] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T10:44:33.624857] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T10:44:33.638467] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T10:44:33.652875] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T10:44:33.667908] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T10:44:33.692045] [POD_MGR] Pod flink-jobmanager-7d7c784b74-4l965 deleted
[0m[2025-01-18T10:44:35.590299] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T10:44:37.510214] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T10:44:37.510287] Reloading playbook: application/kafka
[0m[2025-01-18T10:44:43.483948] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T10:45:24.434921] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T10:45:24.435118] [EXPERIMENT] Run 2 completed. Start: 1737196811, End: 1737197124
[0m[2025-01-18T10:45:24.435125] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T10:45:34.436088] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T10:45:36.336737] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T10:45:38.229131] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T10:45:38.229202] [SCALING] Setting up experiment.


[0m[2025-01-18T10:45:38.229212] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T10:45:38.235427] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T10:45:38.251864] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T10:45:38.269622] [SCALING] Statefulset name to scale : flink-1000m-1024
[0m[2025-01-18T10:45:38.296909] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 1 replica.
[0m[2025-01-18T10:45:43.308641] [FLK_MGR] Running job.
[0m[2025-01-18T10:45:43.308675] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T10:45:43.689700] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-f2m5c
[0m[2025-01-18T10:45:47.785353] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b0a88f8077b9b0405f7b239114b4950f

[0m[2025-01-18T10:45:47.785413] [FLK_MGR] Running job id: b0a88f8077b9b0405f7b239114b4950f
[0m[2025-01-18T10:45:47.785426] [FLK_MGR] Getting job info.
[0m[2025-01-18T10:45:47.802540] [FLK_MGR] Job plan response: {"plan":{"jid":"b0a88f8077b9b0405f7b239114b4950f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T10:45:47.802703] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T10:45:48.188679] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-f2m5c
[0m[2025-01-18T10:45:49.624847] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 10:45:46 : b0a88f8077b9b0405f7b239114b4950f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T10:45:49.624910] [FLK_MGR] Running jobs: ['b0a88f8077b9b0405f7b239114b4950f']
[0m[2025-01-18T10:45:49.624919] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T10:45:49.624931] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T10:49:49.647892] [SCALING] Scaling started.
[0m[2025-01-18T10:49:49.647996] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T10:49:49.661555] [SCALING] Scaling finished.
[0m[2025-01-18T10:49:49.661586] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T10:49:49.678579] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T10:49:49.699020] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T10:49:49.722602] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 0 replica.
[0m[2025-01-18T10:49:54.742086] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T10:49:54.755763] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T10:49:54.769765] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T10:49:54.785509] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T10:49:54.801008] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T10:49:54.841886] [POD_MGR] Pod flink-jobmanager-7d7c784b74-f2m5c deleted
[0m[2025-01-18T10:49:56.797119] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T10:49:58.754292] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T10:49:58.754367] Reloading playbook: application/kafka
[0m[2025-01-18T10:50:04.729031] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T10:50:45.676573] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T10:50:45.676788] [EXPERIMENT] Run 3 completed. Start: 1737197134, End: 1737197445
[0m[2025-01-18T10:50:45.676794] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T10:50:55.677853] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T10:50:57.596260] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T10:50:59.502682] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T10:50:59.502765] [SCALING] Setting up experiment.


[0m[2025-01-18T10:50:59.502775] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T10:50:59.507772] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T10:50:59.524013] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T10:50:59.540353] [SCALING] Statefulset name to scale : flink-1000m-1024
[0m[2025-01-18T10:50:59.551092] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 1 replica.
[0m[2025-01-18T10:51:04.562183] [FLK_MGR] Running job.
[0m[2025-01-18T10:51:04.562215] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T10:51:04.954684] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-sv6l8
[0m[2025-01-18T10:51:09.053936] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 07c77d83fc87308a92078de9ea8f0e9b

[0m[2025-01-18T10:51:09.053985] [FLK_MGR] Running job id: 07c77d83fc87308a92078de9ea8f0e9b
[0m[2025-01-18T10:51:09.053995] [FLK_MGR] Getting job info.
[0m[2025-01-18T10:51:09.073095] [FLK_MGR] Job plan response: {"plan":{"jid":"07c77d83fc87308a92078de9ea8f0e9b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T10:51:09.073222] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T10:51:09.459951] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sv6l8
[0m[2025-01-18T10:51:10.896493] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 10:51:08 : 07c77d83fc87308a92078de9ea8f0e9b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T10:51:10.896554] [FLK_MGR] Running jobs: ['07c77d83fc87308a92078de9ea8f0e9b']
[0m[2025-01-18T10:51:10.896566] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T10:51:10.896577] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T10:55:10.918568] [SCALING] Scaling started.
[0m[2025-01-18T10:55:10.918626] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T10:55:10.933191] [SCALING] Scaling finished.
[0m[2025-01-18T10:55:10.933219] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T10:55:10.954509] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T10:55:10.973884] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T10:55:10.994693] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 0 replica.
[0m[2025-01-18T10:55:21.023968] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T10:55:21.039205] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T10:55:21.053488] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T10:55:21.068985] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T10:55:21.083367] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T10:55:21.115098] [POD_MGR] Pod flink-jobmanager-7d7c784b74-sv6l8 deleted
[0m[2025-01-18T10:55:23.013470] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T10:55:24.952367] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T10:55:24.952452] Reloading playbook: application/kafka
[0m[2025-01-18T10:55:30.968367] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T10:56:12.010198] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T10:56:12.011033] [EXPERIMENT] Run 4 completed. Start: 1737197455, End: 1737197772
[0m[2025-01-18T10:56:12.011061] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T10:56:22.012293] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T10:56:23.933258] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T10:56:25.870519] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T10:56:25.870634] [SCALING] Setting up experiment.


[0m[2025-01-18T10:56:25.870647] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T10:56:25.877029] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T10:56:25.893718] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T10:56:25.912473] [SCALING] Statefulset name to scale : flink-1000m-1024
[0m[2025-01-18T10:56:25.923714] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 1 replica.
[0m[2025-01-18T10:56:30.935528] [FLK_MGR] Running job.
[0m[2025-01-18T10:56:30.935561] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T10:56:31.330827] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-75ljd
[0m[2025-01-18T10:56:35.398395] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID defe38e135fa1e19b0605a43128366ad

[0m[2025-01-18T10:56:35.398448] [FLK_MGR] Running job id: defe38e135fa1e19b0605a43128366ad
[0m[2025-01-18T10:56:35.398457] [FLK_MGR] Getting job info.
[0m[2025-01-18T10:56:35.416903] [FLK_MGR] Job plan response: {"plan":{"jid":"defe38e135fa1e19b0605a43128366ad","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T10:56:35.417058] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T10:56:35.802515] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-75ljd
[0m[2025-01-18T10:56:37.243391] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 10:56:34 : defe38e135fa1e19b0605a43128366ad : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T10:56:37.243453] [FLK_MGR] Running jobs: ['defe38e135fa1e19b0605a43128366ad']
[0m[2025-01-18T10:56:37.243462] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T10:56:37.243474] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T11:00:37.265858] [SCALING] Scaling started.
[0m[2025-01-18T11:00:37.265927] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T11:00:37.279986] [SCALING] Scaling finished.
[0m[2025-01-18T11:00:37.280018] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:00:37.300454] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:00:37.320889] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T11:00:37.342982] [STS_MGR] StatefulSet flink-1000m-1024 scaled to 0 replica.
[0m[2025-01-18T11:00:42.365140] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T11:00:42.379039] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T11:00:42.392610] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T11:00:42.406968] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T11:00:42.420222] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T11:00:42.456193] [POD_MGR] Pod flink-jobmanager-7d7c784b74-75ljd deleted
[0m[2025-01-18T11:00:44.403520] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:00:46.342972] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:00:46.343053] Reloading playbook: application/kafka
[0m[2025-01-18T11:00:52.327288] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T11:01:33.301779] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T11:01:33.302154] [EXPERIMENT] Run 5 completed. Start: 1737197782, End: 1737198093
[0m[2025-01-18T11:01:33.302161] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T11:01:45.471640] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T11:01:45.471722] [RESOURCE_E] Running experiment with 1000m cores and 2048 memory.
[0m[2025-01-18T11:01:52.743988] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T11:01:52.744081] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T11:01:54.653075] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:01:56.582200] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:01:56.582288] [SCALING] Setting up experiment.


[0m[2025-01-18T11:01:56.582301] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:01:56.587741] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:01:56.604885] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T11:01:56.622318] [SCALING] Statefulset name to scale : flink-1000m-2048
[0m[2025-01-18T11:01:56.633397] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 1 replica.
[0m[2025-01-18T11:02:01.644819] [FLK_MGR] Running job.
[0m[2025-01-18T11:02:01.644861] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T11:02:02.022778] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-n94qs
[0m[2025-01-18T11:02:06.111080] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b43e6116400b8573c8f2fad055a6fe7b

[0m[2025-01-18T11:02:06.111131] [FLK_MGR] Running job id: b43e6116400b8573c8f2fad055a6fe7b
[0m[2025-01-18T11:02:06.111139] [FLK_MGR] Getting job info.
[0m[2025-01-18T11:02:06.128421] [FLK_MGR] Job plan response: {"plan":{"jid":"b43e6116400b8573c8f2fad055a6fe7b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T11:02:06.128556] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T11:02:06.517398] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-n94qs
[0m[2025-01-18T11:02:07.940173] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 11:02:05 : b43e6116400b8573c8f2fad055a6fe7b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T11:02:07.940229] [FLK_MGR] Running jobs: ['b43e6116400b8573c8f2fad055a6fe7b']
[0m[2025-01-18T11:02:07.940237] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T11:02:07.940248] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T11:06:07.964083] [SCALING] Scaling started.
[0m[2025-01-18T11:06:07.964203] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T11:06:07.978799] [SCALING] Scaling finished.
[0m[2025-01-18T11:06:07.978828] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:06:07.997758] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:06:08.016054] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T11:06:08.036745] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 0 replica.
[0m[2025-01-18T11:06:13.059225] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T11:06:13.072480] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T11:06:13.085551] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T11:06:13.099719] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T11:06:13.116257] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T11:06:13.143214] [POD_MGR] Pod flink-jobmanager-7d7c784b74-n94qs deleted
[0m[2025-01-18T11:06:15.035037] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:06:16.980199] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:06:16.980282] Reloading playbook: application/kafka
[0m[2025-01-18T11:06:22.940425] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T11:07:03.920489] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T11:07:03.920794] [EXPERIMENT] Run 1 completed. Start: 1737198112, End: 1737198423
[0m[2025-01-18T11:07:03.920801] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T11:07:13.921731] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T11:07:15.828953] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:07:17.785690] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:07:17.785784] [SCALING] Setting up experiment.


[0m[2025-01-18T11:07:17.785795] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:07:17.791404] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:07:17.808950] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T11:07:17.826694] [SCALING] Statefulset name to scale : flink-1000m-2048
[0m[2025-01-18T11:07:17.837134] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 1 replica.
[0m[2025-01-18T11:07:22.847690] [FLK_MGR] Running job.
[0m[2025-01-18T11:07:22.847719] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T11:07:23.234151] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-fzb5k
[0m[2025-01-18T11:07:27.287398] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b8a3f625c81771247bd8edc85d8f7524

[0m[2025-01-18T11:07:27.287453] [FLK_MGR] Running job id: b8a3f625c81771247bd8edc85d8f7524
[0m[2025-01-18T11:07:27.287461] [FLK_MGR] Getting job info.
[0m[2025-01-18T11:07:27.306490] [FLK_MGR] Job plan response: {"plan":{"jid":"b8a3f625c81771247bd8edc85d8f7524","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T11:07:27.306693] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T11:07:27.685426] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-fzb5k
[0m[2025-01-18T11:07:29.096671] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 11:07:26 : b8a3f625c81771247bd8edc85d8f7524 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T11:07:29.096733] [FLK_MGR] Running jobs: ['b8a3f625c81771247bd8edc85d8f7524']
[0m[2025-01-18T11:07:29.096741] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T11:07:29.096752] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T11:11:29.119819] [SCALING] Scaling started.
[0m[2025-01-18T11:11:29.119929] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T11:11:29.132281] [SCALING] Scaling finished.
[0m[2025-01-18T11:11:29.132308] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:11:29.152107] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:11:29.171550] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T11:11:29.193411] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 0 replica.
[0m[2025-01-18T11:11:34.213581] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T11:11:34.227853] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T11:11:34.242215] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T11:11:34.255990] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T11:11:34.269108] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T11:11:34.317185] [POD_MGR] Pod flink-jobmanager-7d7c784b74-fzb5k deleted
[0m[2025-01-18T11:11:36.248193] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:11:38.232607] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:11:38.232685] Reloading playbook: application/kafka
[0m[2025-01-18T11:11:44.184235] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T11:12:25.207846] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T11:12:25.208120] [EXPERIMENT] Run 2 completed. Start: 1737198433, End: 1737198745
[0m[2025-01-18T11:12:25.208126] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T11:12:35.209101] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T11:12:37.122695] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:12:39.035312] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:12:39.035402] [SCALING] Setting up experiment.


[0m[2025-01-18T11:12:39.035417] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:12:39.041485] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:12:39.058118] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T11:12:39.073879] [SCALING] Statefulset name to scale : flink-1000m-2048
[0m[2025-01-18T11:12:39.083938] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 1 replica.
[0m[2025-01-18T11:12:44.094559] [FLK_MGR] Running job.
[0m[2025-01-18T11:12:44.094590] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T11:12:44.481205] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-9fcwk
[0m[2025-01-18T11:12:48.655305] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 551a54a2fdf8f575ffe9b6a30a1e9467

[0m[2025-01-18T11:12:48.655354] [FLK_MGR] Running job id: 551a54a2fdf8f575ffe9b6a30a1e9467
[0m[2025-01-18T11:12:48.655364] [FLK_MGR] Getting job info.
[0m[2025-01-18T11:12:48.672629] [FLK_MGR] Job plan response: {"plan":{"jid":"551a54a2fdf8f575ffe9b6a30a1e9467","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T11:12:48.672772] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T11:12:50.583261] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-9fcwk
[0m[2025-01-18T11:12:52.018196] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 11:12:47 : 551a54a2fdf8f575ffe9b6a30a1e9467 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T11:12:52.018247] [FLK_MGR] Running jobs: ['551a54a2fdf8f575ffe9b6a30a1e9467']
[0m[2025-01-18T11:12:52.018254] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T11:12:52.018262] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T11:16:52.041394] [SCALING] Scaling started.
[0m[2025-01-18T11:16:52.041439] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T11:16:52.055097] [SCALING] Scaling finished.
[0m[2025-01-18T11:16:52.055121] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:16:52.075038] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:16:52.092804] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T11:16:52.116436] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 0 replica.
[0m[2025-01-18T11:16:57.137508] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T11:16:57.153184] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T11:16:57.170878] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T11:16:57.186982] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T11:16:57.201886] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T11:16:57.241762] [POD_MGR] Pod flink-jobmanager-7d7c784b74-9fcwk deleted
[0m[2025-01-18T11:16:59.181227] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:17:01.130904] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:17:01.130997] Reloading playbook: application/kafka
[0m[2025-01-18T11:17:07.130346] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T11:17:48.115881] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T11:17:48.116133] [EXPERIMENT] Run 3 completed. Start: 1737198755, End: 1737199068
[0m[2025-01-18T11:17:48.116140] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T11:17:58.117094] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T11:18:00.029395] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:18:01.976187] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:18:01.976281] [SCALING] Setting up experiment.


[0m[2025-01-18T11:18:01.976292] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:18:01.982815] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:18:02.000665] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T11:18:02.020770] [SCALING] Statefulset name to scale : flink-1000m-2048
[0m[2025-01-18T11:18:02.033188] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 1 replica.
[0m[2025-01-18T11:18:07.046099] [FLK_MGR] Running job.
[0m[2025-01-18T11:18:07.046130] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T11:18:07.448843] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-tdbl9
[0m[2025-01-18T11:18:11.531941] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 68b0d6903c5b18fc09cb1b9a469bb0c2

[0m[2025-01-18T11:18:11.532000] [FLK_MGR] Running job id: 68b0d6903c5b18fc09cb1b9a469bb0c2
[0m[2025-01-18T11:18:11.532009] [FLK_MGR] Getting job info.
[0m[2025-01-18T11:18:11.551565] [FLK_MGR] Job plan response: {"plan":{"jid":"68b0d6903c5b18fc09cb1b9a469bb0c2","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T11:18:11.551717] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T11:18:11.971188] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-tdbl9
[0m[2025-01-18T11:18:13.381652] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 11:18:10 : 68b0d6903c5b18fc09cb1b9a469bb0c2 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T11:18:13.381710] [FLK_MGR] Running jobs: ['68b0d6903c5b18fc09cb1b9a469bb0c2']
[0m[2025-01-18T11:18:13.381718] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T11:18:13.381731] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T11:22:13.404267] [SCALING] Scaling started.
[0m[2025-01-18T11:22:13.404403] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T11:22:13.417739] [SCALING] Scaling finished.
[0m[2025-01-18T11:22:13.417764] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:22:13.435583] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:22:13.454975] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T11:22:13.478495] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 0 replica.
[0m[2025-01-18T11:22:18.500427] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T11:22:18.515463] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T11:22:18.529155] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T11:22:18.542986] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T11:22:18.555918] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T11:22:18.592416] [POD_MGR] Pod flink-jobmanager-7d7c784b74-tdbl9 deleted
[0m[2025-01-18T11:22:20.550933] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:22:22.534335] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:22:22.534429] Reloading playbook: application/kafka
[0m[2025-01-18T11:22:28.527587] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T11:23:09.534172] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T11:23:09.534495] [EXPERIMENT] Run 4 completed. Start: 1737199078, End: 1737199389
[0m[2025-01-18T11:23:09.534502] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T11:23:19.535544] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T11:23:21.442201] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:23:23.385343] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:23:23.385438] [SCALING] Setting up experiment.


[0m[2025-01-18T11:23:23.385449] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:23:23.390776] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:23:23.408264] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T11:23:23.426440] [SCALING] Statefulset name to scale : flink-1000m-2048
[0m[2025-01-18T11:23:23.437822] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 1 replica.
[0m[2025-01-18T11:23:28.448581] [FLK_MGR] Running job.
[0m[2025-01-18T11:23:28.448609] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T11:23:28.837023] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-7wh45
[0m[2025-01-18T11:23:32.985650] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8d571bbdad55bdc0503d61c3e4c580ab

[0m[2025-01-18T11:23:32.985703] [FLK_MGR] Running job id: 8d571bbdad55bdc0503d61c3e4c580ab
[0m[2025-01-18T11:23:32.985713] [FLK_MGR] Getting job info.
[0m[2025-01-18T11:23:33.002207] [FLK_MGR] Job plan response: {"plan":{"jid":"8d571bbdad55bdc0503d61c3e4c580ab","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T11:23:33.002351] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T11:23:33.393786] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-7wh45
[0m[2025-01-18T11:23:34.819022] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 11:23:32 : 8d571bbdad55bdc0503d61c3e4c580ab : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T11:23:34.819083] [FLK_MGR] Running jobs: ['8d571bbdad55bdc0503d61c3e4c580ab']
[0m[2025-01-18T11:23:34.819090] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T11:23:34.819102] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T11:27:34.841769] [SCALING] Scaling started.
[0m[2025-01-18T11:27:34.841881] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T11:27:34.856291] [SCALING] Scaling finished.
[0m[2025-01-18T11:27:34.856341] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:27:34.875529] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:27:34.893472] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T11:27:34.915497] [STS_MGR] StatefulSet flink-1000m-2048 scaled to 0 replica.
[0m[2025-01-18T11:27:44.945007] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T11:27:44.962347] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T11:27:44.977413] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T11:27:44.991915] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T11:27:45.007439] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T11:27:45.045963] [POD_MGR] Pod flink-jobmanager-7d7c784b74-7wh45 deleted
[0m[2025-01-18T11:27:46.964734] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:27:48.939388] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:27:48.939495] Reloading playbook: application/kafka
[0m[2025-01-18T11:27:54.960264] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T11:28:35.966862] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T11:28:35.967137] [EXPERIMENT] Run 5 completed. Start: 1737199399, End: 1737199715
[0m[2025-01-18T11:28:35.967144] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T11:28:48.233939] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T11:28:48.234030] [RESOURCE_E] Running experiment with 1000m cores and 4096 memory.
[0m[2025-01-18T11:28:55.546199] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T11:28:55.546289] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T11:28:57.484897] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:28:59.390650] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:28:59.390742] [SCALING] Setting up experiment.


[0m[2025-01-18T11:28:59.390755] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:28:59.396168] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:28:59.412976] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T11:28:59.430462] [SCALING] Statefulset name to scale : flink-1000m-4096
[0m[2025-01-18T11:28:59.440391] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 1 replica.
[0m[2025-01-18T11:29:04.449865] [FLK_MGR] Running job.
[0m[2025-01-18T11:29:04.449893] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T11:29:04.830965] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-8d8hj
[0m[2025-01-18T11:29:08.862999] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f380c94aea4876ebb883c9ff9f1eb82d

[0m[2025-01-18T11:29:08.863050] [FLK_MGR] Running job id: f380c94aea4876ebb883c9ff9f1eb82d
[0m[2025-01-18T11:29:08.863058] [FLK_MGR] Getting job info.
[0m[2025-01-18T11:29:08.880245] [FLK_MGR] Job plan response: {"plan":{"jid":"f380c94aea4876ebb883c9ff9f1eb82d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T11:29:08.880383] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T11:29:09.283643] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-8d8hj
[0m[2025-01-18T11:29:10.721434] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 11:29:07 : f380c94aea4876ebb883c9ff9f1eb82d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T11:29:10.721498] [FLK_MGR] Running jobs: ['f380c94aea4876ebb883c9ff9f1eb82d']
[0m[2025-01-18T11:29:10.721507] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T11:29:10.721519] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T11:33:10.744848] [SCALING] Scaling started.
[0m[2025-01-18T11:33:10.744904] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T11:33:10.759538] [SCALING] Scaling finished.
[0m[2025-01-18T11:33:10.759573] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:33:10.778459] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:33:10.797498] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T11:33:10.820092] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 0 replica.
[0m[2025-01-18T11:33:15.842878] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T11:33:15.856955] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T11:33:15.872458] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T11:33:15.887768] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T11:33:15.903204] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T11:33:15.924414] [POD_MGR] Pod flink-jobmanager-7d7c784b74-8d8hj deleted
[0m[2025-01-18T11:33:17.832063] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:33:19.780822] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:33:19.780922] Reloading playbook: application/kafka
[0m[2025-01-18T11:33:25.781017] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T11:34:06.791991] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T11:34:06.792247] [EXPERIMENT] Run 1 completed. Start: 1737199735, End: 1737200046
[0m[2025-01-18T11:34:06.792254] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T11:34:16.793244] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T11:34:18.771495] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:34:20.701465] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:34:20.701553] [SCALING] Setting up experiment.


[0m[2025-01-18T11:34:20.701567] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:34:20.707490] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:34:20.724119] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T11:34:20.740983] [SCALING] Statefulset name to scale : flink-1000m-4096
[0m[2025-01-18T11:34:20.751159] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 1 replica.
[0m[2025-01-18T11:34:25.760741] [FLK_MGR] Running job.
[0m[2025-01-18T11:34:25.760776] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T11:34:26.154423] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-bd4qj
[0m[2025-01-18T11:34:30.224194] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 3673300abb315984d58261256dbd1b24

[0m[2025-01-18T11:34:30.224241] [FLK_MGR] Running job id: 3673300abb315984d58261256dbd1b24
[0m[2025-01-18T11:34:30.224250] [FLK_MGR] Getting job info.
[0m[2025-01-18T11:34:30.242074] [FLK_MGR] Job plan response: {"plan":{"jid":"3673300abb315984d58261256dbd1b24","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T11:34:30.242210] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T11:34:30.619219] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-bd4qj
[0m[2025-01-18T11:34:32.066034] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 11:34:29 : 3673300abb315984d58261256dbd1b24 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T11:34:32.066095] [FLK_MGR] Running jobs: ['3673300abb315984d58261256dbd1b24']
[0m[2025-01-18T11:34:32.066104] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T11:34:32.066115] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T11:38:32.088906] [SCALING] Scaling started.
[0m[2025-01-18T11:38:32.089022] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T11:38:32.104086] [SCALING] Scaling finished.
[0m[2025-01-18T11:38:32.104113] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:38:32.124768] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:38:32.144470] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T11:38:32.168101] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 0 replica.
[0m[2025-01-18T11:38:37.192377] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T11:38:37.206692] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T11:38:37.220867] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T11:38:37.235935] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T11:38:37.249759] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T11:38:37.283087] [POD_MGR] Pod flink-jobmanager-7d7c784b74-bd4qj deleted
[0m[2025-01-18T11:38:39.203238] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:38:41.135229] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:38:41.135319] Reloading playbook: application/kafka
[0m[2025-01-18T11:38:47.112124] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T11:39:28.160914] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T11:39:28.161146] [EXPERIMENT] Run 2 completed. Start: 1737200056, End: 1737200368
[0m[2025-01-18T11:39:28.161154] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T11:39:38.162180] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T11:39:40.093033] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:39:42.009052] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:39:42.009161] [SCALING] Setting up experiment.


[0m[2025-01-18T11:39:42.009175] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:39:42.015277] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:39:42.032042] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T11:39:42.048702] [SCALING] Statefulset name to scale : flink-1000m-4096
[0m[2025-01-18T11:39:42.059182] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 1 replica.
[0m[2025-01-18T11:39:47.068616] [FLK_MGR] Running job.
[0m[2025-01-18T11:39:47.068644] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T11:39:47.466721] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-hvf2w
[0m[2025-01-18T11:39:51.524730] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c9d137803195299b440a59a15d42f0c1

[0m[2025-01-18T11:39:51.524775] [FLK_MGR] Running job id: c9d137803195299b440a59a15d42f0c1
[0m[2025-01-18T11:39:51.524786] [FLK_MGR] Getting job info.
[0m[2025-01-18T11:39:51.540839] [FLK_MGR] Job plan response: {"plan":{"jid":"c9d137803195299b440a59a15d42f0c1","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T11:39:51.540991] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T11:39:51.960160] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-hvf2w
[0m[2025-01-18T11:39:53.419291] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 11:39:50 : c9d137803195299b440a59a15d42f0c1 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T11:39:53.419352] [FLK_MGR] Running jobs: ['c9d137803195299b440a59a15d42f0c1']
[0m[2025-01-18T11:39:53.419360] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T11:39:53.419383] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T11:43:53.441565] [SCALING] Scaling started.
[0m[2025-01-18T11:43:53.441674] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T11:43:53.454212] [SCALING] Scaling finished.
[0m[2025-01-18T11:43:53.454237] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:43:53.472289] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:43:53.488432] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T11:43:53.508290] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 0 replica.
[0m[2025-01-18T11:44:03.536281] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T11:44:03.550339] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T11:44:03.567131] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T11:44:03.580373] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T11:44:03.593040] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T11:44:03.614382] [POD_MGR] Pod flink-jobmanager-7d7c784b74-hvf2w deleted
[0m[2025-01-18T11:44:05.527451] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:44:07.612846] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:44:07.612922] Reloading playbook: application/kafka
[0m[2025-01-18T11:44:13.589578] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T11:44:54.634748] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T11:44:54.635530] [EXPERIMENT] Run 3 completed. Start: 1737200378, End: 1737200694
[0m[2025-01-18T11:44:54.635556] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T11:45:04.636479] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T11:45:06.543776] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:45:08.478028] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:45:08.478118] [SCALING] Setting up experiment.


[0m[2025-01-18T11:45:08.478129] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:45:08.483910] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:45:08.501950] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T11:45:08.517835] [SCALING] Statefulset name to scale : flink-1000m-4096
[0m[2025-01-18T11:45:08.528204] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 1 replica.
[0m[2025-01-18T11:45:13.538847] [FLK_MGR] Running job.
[0m[2025-01-18T11:45:13.538877] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T11:45:13.926000] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-5f6vn
[0m[2025-01-18T11:45:18.109621] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 060024df58a6d71e7163f9feb3fb79bf

[0m[2025-01-18T11:45:18.109669] [FLK_MGR] Running job id: 060024df58a6d71e7163f9feb3fb79bf
[0m[2025-01-18T11:45:18.109680] [FLK_MGR] Getting job info.
[0m[2025-01-18T11:45:18.127179] [FLK_MGR] Job plan response: {"plan":{"jid":"060024df58a6d71e7163f9feb3fb79bf","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T11:45:18.127322] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T11:45:20.015792] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-5f6vn
[0m[2025-01-18T11:45:21.441464] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 11:45:17 : 060024df58a6d71e7163f9feb3fb79bf : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T11:45:21.441520] [FLK_MGR] Running jobs: ['060024df58a6d71e7163f9feb3fb79bf']
[0m[2025-01-18T11:45:21.441528] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T11:45:21.441535] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T11:49:21.464846] [SCALING] Scaling started.
[0m[2025-01-18T11:49:21.464938] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T11:49:21.477219] [SCALING] Scaling finished.
[0m[2025-01-18T11:49:21.477242] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:49:21.494937] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:49:21.511763] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T11:49:21.534092] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 0 replica.
[0m[2025-01-18T11:49:26.555128] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T11:49:26.569118] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T11:49:26.582189] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T11:49:26.595433] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T11:49:26.608349] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T11:49:26.639063] [POD_MGR] Pod flink-jobmanager-7d7c784b74-5f6vn deleted
[0m[2025-01-18T11:49:28.594893] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:49:30.493665] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:49:30.493752] Reloading playbook: application/kafka
[0m[2025-01-18T11:49:36.500834] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T11:50:17.530658] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T11:50:17.530881] [EXPERIMENT] Run 4 completed. Start: 1737200704, End: 1737201017
[0m[2025-01-18T11:50:17.530887] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T11:50:27.531966] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T11:50:29.435544] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:50:31.361211] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:50:31.361315] [SCALING] Setting up experiment.


[0m[2025-01-18T11:50:31.361327] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:50:31.366641] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:50:31.384078] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T11:50:31.400423] [SCALING] Statefulset name to scale : flink-1000m-4096
[0m[2025-01-18T11:50:31.411312] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 1 replica.
[0m[2025-01-18T11:50:36.422261] [FLK_MGR] Running job.
[0m[2025-01-18T11:50:36.422295] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T11:50:36.802570] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-28zw8
[0m[2025-01-18T11:50:40.869963] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 34382ba15a3e7618e3709d2003f61b34

[0m[2025-01-18T11:50:40.870012] [FLK_MGR] Running job id: 34382ba15a3e7618e3709d2003f61b34
[0m[2025-01-18T11:50:40.870020] [FLK_MGR] Getting job info.
[0m[2025-01-18T11:50:40.889911] [FLK_MGR] Job plan response: {"plan":{"jid":"34382ba15a3e7618e3709d2003f61b34","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T11:50:40.890717] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T11:50:41.361654] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-28zw8
[0m[2025-01-18T11:50:42.831940] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 11:50:39 : 34382ba15a3e7618e3709d2003f61b34 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T11:50:42.832006] [FLK_MGR] Running jobs: ['34382ba15a3e7618e3709d2003f61b34']
[0m[2025-01-18T11:50:42.832014] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T11:50:42.832027] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T11:54:42.854854] [SCALING] Scaling started.
[0m[2025-01-18T11:54:42.854956] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T11:54:42.870535] [SCALING] Scaling finished.
[0m[2025-01-18T11:54:42.870567] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:54:42.890483] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:54:42.909187] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T11:54:42.931770] [STS_MGR] StatefulSet flink-1000m-4096 scaled to 0 replica.
[0m[2025-01-18T11:54:47.951590] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T11:54:47.964730] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T11:54:47.977461] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T11:54:47.990447] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T11:54:48.003212] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T11:54:48.036117] [POD_MGR] Pod flink-jobmanager-7d7c784b74-28zw8 deleted
[0m[2025-01-18T11:54:49.952912] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:54:51.913578] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T11:54:51.913676] Reloading playbook: application/kafka
[0m[2025-01-18T11:54:57.911332] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T11:55:38.865572] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T11:55:38.865841] [EXPERIMENT] Run 5 completed. Start: 1737201027, End: 1737201338
[0m[2025-01-18T11:55:38.865848] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T11:55:51.162825] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T11:55:51.163055] [RESOURCE_E] Running experiment with 1000m cores and 8192 memory.
[0m[2025-01-18T11:55:58.441921] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T11:55:58.442005] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T11:56:00.336204] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:56:02.255735] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T11:56:02.255879] [SCALING] Setting up experiment.


[0m[2025-01-18T11:56:02.255927] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T11:56:02.261427] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T11:56:02.278320] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T11:56:02.295239] [SCALING] Statefulset name to scale : flink-1000m-8192
[0m[2025-01-18T11:56:02.307212] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 1 replica.
[0m[2025-01-18T11:56:07.318098] [FLK_MGR] Running job.
[0m[2025-01-18T11:56:07.318133] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T11:56:07.696743] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-njmwz
[0m[2025-01-18T11:56:11.719940] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 78017c8c28e2b162ffcaa4707d0dbc21

[0m[2025-01-18T11:56:11.719988] [FLK_MGR] Running job id: 78017c8c28e2b162ffcaa4707d0dbc21
[0m[2025-01-18T11:56:11.719995] [FLK_MGR] Getting job info.
[0m[2025-01-18T11:56:11.738152] [FLK_MGR] Job plan response: {"plan":{"jid":"78017c8c28e2b162ffcaa4707d0dbc21","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T11:56:11.738375] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T11:56:12.114032] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-njmwz
[0m[2025-01-18T11:56:13.575696] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 11:56:10 : 78017c8c28e2b162ffcaa4707d0dbc21 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T11:56:13.575762] [FLK_MGR] Running jobs: ['78017c8c28e2b162ffcaa4707d0dbc21']
[0m[2025-01-18T11:56:13.575769] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T11:56:13.575782] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T12:00:13.598836] [SCALING] Scaling started.
[0m[2025-01-18T12:00:13.598949] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T12:00:13.616800] [SCALING] Scaling finished.
[0m[2025-01-18T12:00:13.616828] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:00:13.633928] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:00:13.653069] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T12:00:13.677215] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 0 replica.
[0m[2025-01-18T12:00:18.698503] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T12:00:18.713917] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T12:00:18.728739] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T12:00:18.742763] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T12:00:18.757223] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T12:00:18.784716] [POD_MGR] Pod flink-jobmanager-7d7c784b74-njmwz deleted
[0m[2025-01-18T12:00:20.696463] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:00:22.671291] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:00:22.671374] Reloading playbook: application/kafka
[0m[2025-01-18T12:00:28.619750] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T12:01:09.575068] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T12:01:09.575298] [EXPERIMENT] Run 1 completed. Start: 1737201358, End: 1737201669
[0m[2025-01-18T12:01:09.575304] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T12:01:19.576238] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T12:01:21.516736] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:01:23.463962] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:01:23.464051] [SCALING] Setting up experiment.


[0m[2025-01-18T12:01:23.464062] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:01:23.469191] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:01:23.485471] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T12:01:23.503001] [SCALING] Statefulset name to scale : flink-1000m-8192
[0m[2025-01-18T12:01:23.512863] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 1 replica.
[0m[2025-01-18T12:01:28.523810] [FLK_MGR] Running job.
[0m[2025-01-18T12:01:28.523845] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T12:01:28.909950] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jhqxl
[0m[2025-01-18T12:01:33.006144] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID e9291729cbf236b3ea84870b420c5fd6

[0m[2025-01-18T12:01:33.006192] [FLK_MGR] Running job id: e9291729cbf236b3ea84870b420c5fd6
[0m[2025-01-18T12:01:33.006200] [FLK_MGR] Getting job info.
[0m[2025-01-18T12:01:33.023934] [FLK_MGR] Job plan response: {"plan":{"jid":"e9291729cbf236b3ea84870b420c5fd6","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T12:01:33.024078] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T12:01:33.400423] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jhqxl
[0m[2025-01-18T12:01:34.824583] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 12:01:32 : e9291729cbf236b3ea84870b420c5fd6 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T12:01:34.824641] [FLK_MGR] Running jobs: ['e9291729cbf236b3ea84870b420c5fd6']
[0m[2025-01-18T12:01:34.824649] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T12:01:34.824660] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T12:05:34.846986] [SCALING] Scaling started.
[0m[2025-01-18T12:05:34.847037] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T12:05:34.862385] [SCALING] Scaling finished.
[0m[2025-01-18T12:05:34.862413] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:05:34.883016] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:05:34.900005] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T12:05:34.921810] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 0 replica.
[0m[2025-01-18T12:05:39.943830] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T12:05:39.958315] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T12:05:39.974702] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T12:05:39.988786] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T12:05:40.003295] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T12:05:40.035251] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jhqxl deleted
[0m[2025-01-18T12:05:41.933625] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:05:43.917514] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:05:43.917601] Reloading playbook: application/kafka
[0m[2025-01-18T12:05:49.817550] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T12:06:30.840575] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T12:06:30.840835] [EXPERIMENT] Run 2 completed. Start: 1737201679, End: 1737201990
[0m[2025-01-18T12:06:30.840842] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T12:06:40.841837] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T12:06:42.741100] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:06:44.671162] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:06:44.671245] [SCALING] Setting up experiment.


[0m[2025-01-18T12:06:44.671259] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:06:44.677312] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:06:44.695286] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T12:06:44.713862] [SCALING] Statefulset name to scale : flink-1000m-8192
[0m[2025-01-18T12:06:44.725502] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 1 replica.
[0m[2025-01-18T12:06:49.736638] [FLK_MGR] Running job.
[0m[2025-01-18T12:06:49.736673] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T12:06:50.125046] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-lvx8l
[0m[2025-01-18T12:06:54.222764] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 25e749988e0f6b3fa9ffd0c46622fe8c

[0m[2025-01-18T12:06:54.222811] [FLK_MGR] Running job id: 25e749988e0f6b3fa9ffd0c46622fe8c
[0m[2025-01-18T12:06:54.222821] [FLK_MGR] Getting job info.
[0m[2025-01-18T12:06:54.240567] [FLK_MGR] Job plan response: {"plan":{"jid":"25e749988e0f6b3fa9ffd0c46622fe8c","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T12:06:54.240703] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T12:06:54.682008] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-lvx8l
[0m[2025-01-18T12:06:56.105869] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 12:06:53 : 25e749988e0f6b3fa9ffd0c46622fe8c : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T12:06:56.105929] [FLK_MGR] Running jobs: ['25e749988e0f6b3fa9ffd0c46622fe8c']
[0m[2025-01-18T12:06:56.105938] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T12:06:56.105950] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T12:10:56.129937] [SCALING] Scaling started.
[0m[2025-01-18T12:10:56.130050] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T12:10:56.143009] [SCALING] Scaling finished.
[0m[2025-01-18T12:10:56.143041] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:10:56.160290] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:10:56.178249] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T12:10:56.198409] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 0 replica.
[0m[2025-01-18T12:11:01.218519] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T12:11:01.233144] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T12:11:01.247327] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T12:11:01.263080] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T12:11:01.277009] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T12:11:01.312426] [POD_MGR] Pod flink-jobmanager-7d7c784b74-lvx8l deleted
[0m[2025-01-18T12:11:03.247827] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:11:05.152737] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:11:05.152810] Reloading playbook: application/kafka
[0m[2025-01-18T12:11:11.155637] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T12:11:52.153037] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T12:11:52.153280] [EXPERIMENT] Run 3 completed. Start: 1737202000, End: 1737202312
[0m[2025-01-18T12:11:52.153288] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T12:12:02.154299] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T12:12:04.054317] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:12:05.983177] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:12:05.983262] [SCALING] Setting up experiment.


[0m[2025-01-18T12:12:05.983272] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:12:05.988826] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:12:06.005380] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T12:12:06.023301] [SCALING] Statefulset name to scale : flink-1000m-8192
[0m[2025-01-18T12:12:06.034381] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 1 replica.
[0m[2025-01-18T12:12:11.045905] [FLK_MGR] Running job.
[0m[2025-01-18T12:12:11.045931] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T12:12:11.428335] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-f6bxj
[0m[2025-01-18T12:12:15.534903] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fa393a90341c1dcc1a774a438811fcd0

[0m[2025-01-18T12:12:15.534952] [FLK_MGR] Running job id: fa393a90341c1dcc1a774a438811fcd0
[0m[2025-01-18T12:12:15.534962] [FLK_MGR] Getting job info.
[0m[2025-01-18T12:12:15.552067] [FLK_MGR] Job plan response: {"plan":{"jid":"fa393a90341c1dcc1a774a438811fcd0","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T12:12:15.552208] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T12:12:15.941803] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-f6bxj
[0m[2025-01-18T12:12:17.379563] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 12:12:14 : fa393a90341c1dcc1a774a438811fcd0 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T12:12:17.379628] [FLK_MGR] Running jobs: ['fa393a90341c1dcc1a774a438811fcd0']
[0m[2025-01-18T12:12:17.379636] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T12:12:17.379648] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T12:16:17.402208] [SCALING] Scaling started.
[0m[2025-01-18T12:16:17.402265] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T12:16:17.416009] [SCALING] Scaling finished.
[0m[2025-01-18T12:16:17.416037] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:16:17.437052] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:16:17.454782] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T12:16:17.477655] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 0 replica.
[0m[2025-01-18T12:16:22.496729] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T12:16:22.511161] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T12:16:22.526513] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T12:16:22.543486] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T12:16:22.559289] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T12:16:22.595645] [POD_MGR] Pod flink-jobmanager-7d7c784b74-f6bxj deleted
[0m[2025-01-18T12:16:24.565927] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:16:26.471063] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:16:26.471150] Reloading playbook: application/kafka
[0m[2025-01-18T12:16:32.415040] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T12:17:13.442789] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T12:17:13.443696] [EXPERIMENT] Run 4 completed. Start: 1737202322, End: 1737202633
[0m[2025-01-18T12:17:13.443739] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T12:17:23.444789] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T12:17:25.332645] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:17:27.296843] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:17:27.296930] [SCALING] Setting up experiment.


[0m[2025-01-18T12:17:27.296941] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:17:27.303242] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:17:27.320963] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T12:17:27.339624] [SCALING] Statefulset name to scale : flink-1000m-8192
[0m[2025-01-18T12:17:27.349751] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 1 replica.
[0m[2025-01-18T12:17:32.360553] [FLK_MGR] Running job.
[0m[2025-01-18T12:17:32.360580] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T12:17:32.746191] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xwf62
[0m[2025-01-18T12:17:36.866997] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID e513823b4d9bcf2777ce14a94e249b05

[0m[2025-01-18T12:17:36.867049] [FLK_MGR] Running job id: e513823b4d9bcf2777ce14a94e249b05
[0m[2025-01-18T12:17:36.867058] [FLK_MGR] Getting job info.
[0m[2025-01-18T12:17:36.887492] [FLK_MGR] Job plan response: {"plan":{"jid":"e513823b4d9bcf2777ce14a94e249b05","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T12:17:36.887638] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T12:17:38.771595] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xwf62
[0m[2025-01-18T12:17:40.214531] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 12:17:35 : e513823b4d9bcf2777ce14a94e249b05 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T12:17:40.214583] [FLK_MGR] Running jobs: ['e513823b4d9bcf2777ce14a94e249b05']
[0m[2025-01-18T12:17:40.214590] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T12:17:40.214596] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T12:21:40.237359] [SCALING] Scaling started.
[0m[2025-01-18T12:21:40.237457] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T12:21:40.249952] [SCALING] Scaling finished.
[0m[2025-01-18T12:21:40.249971] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:21:40.268405] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:21:40.284305] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T12:21:40.310261] [STS_MGR] StatefulSet flink-1000m-8192 scaled to 0 replica.
[0m[2025-01-18T12:21:45.332681] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T12:21:45.347634] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T12:21:45.360813] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T12:21:45.375401] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T12:21:45.389105] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T12:21:45.422668] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xwf62 deleted
[0m[2025-01-18T12:21:47.363381] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:21:49.309614] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:21:49.309690] Reloading playbook: application/kafka
[0m[2025-01-18T12:21:55.264215] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T12:22:36.260633] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T12:22:36.260864] [EXPERIMENT] Run 5 completed. Start: 1737202643, End: 1737202956
[0m[2025-01-18T12:22:36.260871] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T12:22:48.519489] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T12:22:48.519575] [RESOURCE_E] Running experiment with 1000m cores and 16384 memory.
[0m[2025-01-18T12:22:55.814220] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T12:22:55.814323] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T12:22:57.731821] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:22:59.654968] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:22:59.655057] [SCALING] Setting up experiment.


[0m[2025-01-18T12:22:59.655068] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:22:59.660221] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:22:59.675869] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T12:22:59.694430] [SCALING] Statefulset name to scale : flink-1000m-16384
[0m[2025-01-18T12:22:59.705784] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 1 replica.
[0m[2025-01-18T12:23:04.717324] [FLK_MGR] Running job.
[0m[2025-01-18T12:23:04.717350] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T12:23:05.116193] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-4xbhf
[0m[2025-01-18T12:23:09.184137] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6e5a857f0aa6ab40414dc0d270c278b3

[0m[2025-01-18T12:23:09.184197] [FLK_MGR] Running job id: 6e5a857f0aa6ab40414dc0d270c278b3
[0m[2025-01-18T12:23:09.184209] [FLK_MGR] Getting job info.
[0m[2025-01-18T12:23:09.201965] [FLK_MGR] Job plan response: {"plan":{"jid":"6e5a857f0aa6ab40414dc0d270c278b3","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T12:23:09.202135] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T12:23:09.589331] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-4xbhf
[0m[2025-01-18T12:23:11.026252] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 12:23:08 : 6e5a857f0aa6ab40414dc0d270c278b3 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T12:23:11.026316] [FLK_MGR] Running jobs: ['6e5a857f0aa6ab40414dc0d270c278b3']
[0m[2025-01-18T12:23:11.026325] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T12:23:11.026337] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T12:27:11.049438] [SCALING] Scaling started.
[0m[2025-01-18T12:27:11.049551] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T12:27:11.064594] [SCALING] Scaling finished.
[0m[2025-01-18T12:27:11.064622] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:27:11.084442] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:27:11.102603] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T12:27:11.126062] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 0 replica.
[0m[2025-01-18T12:27:21.154650] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T12:27:21.169384] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T12:27:21.182838] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T12:27:21.195873] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T12:27:21.208790] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T12:27:21.241761] [POD_MGR] Pod flink-jobmanager-7d7c784b74-4xbhf deleted
[0m[2025-01-18T12:27:23.219964] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:27:25.118824] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:27:25.118908] Reloading playbook: application/kafka
[0m[2025-01-18T12:27:31.127637] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T12:28:12.146894] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T12:28:12.147196] [EXPERIMENT] Run 1 completed. Start: 1737202975, End: 1737203292
[0m[2025-01-18T12:28:12.147203] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T12:28:22.148153] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T12:28:24.050281] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:28:26.004907] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:28:26.004993] [SCALING] Setting up experiment.


[0m[2025-01-18T12:28:26.005004] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:28:26.010770] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:28:26.028663] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T12:28:26.046732] [SCALING] Statefulset name to scale : flink-1000m-16384
[0m[2025-01-18T12:28:26.059345] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 1 replica.
[0m[2025-01-18T12:28:31.071236] [FLK_MGR] Running job.
[0m[2025-01-18T12:28:31.071266] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T12:28:31.480506] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-h46jq
[0m[2025-01-18T12:28:35.590034] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID e48e00fbe6801c7c05370cbbbab1c9d5

[0m[2025-01-18T12:28:35.590089] [FLK_MGR] Running job id: e48e00fbe6801c7c05370cbbbab1c9d5
[0m[2025-01-18T12:28:35.590098] [FLK_MGR] Getting job info.
[0m[2025-01-18T12:28:35.607425] [FLK_MGR] Job plan response: {"plan":{"jid":"e48e00fbe6801c7c05370cbbbab1c9d5","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T12:28:35.607560] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T12:28:35.995121] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-h46jq
[0m[2025-01-18T12:28:37.444002] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 12:28:34 : e48e00fbe6801c7c05370cbbbab1c9d5 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T12:28:37.444065] [FLK_MGR] Running jobs: ['e48e00fbe6801c7c05370cbbbab1c9d5']
[0m[2025-01-18T12:28:37.444073] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T12:28:37.444087] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T12:32:37.466886] [SCALING] Scaling started.
[0m[2025-01-18T12:32:37.467021] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T12:32:37.480783] [SCALING] Scaling finished.
[0m[2025-01-18T12:32:37.480821] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:32:37.498493] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:32:37.515915] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T12:32:37.538470] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 0 replica.
[0m[2025-01-18T12:32:42.561026] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T12:32:42.578233] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T12:32:42.592704] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T12:32:42.607407] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T12:32:42.623850] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T12:32:42.649546] [POD_MGR] Pod flink-jobmanager-7d7c784b74-h46jq deleted
[0m[2025-01-18T12:32:44.573693] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:32:46.469120] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:32:46.469215] Reloading playbook: application/kafka
[0m[2025-01-18T12:32:52.493086] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T12:33:33.522145] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T12:33:33.522419] [EXPERIMENT] Run 2 completed. Start: 1737203302, End: 1737203613
[0m[2025-01-18T12:33:33.522426] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T12:33:43.523474] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T12:33:45.427118] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:33:47.351138] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:33:47.351223] [SCALING] Setting up experiment.


[0m[2025-01-18T12:33:47.351235] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:33:47.356855] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:33:47.374745] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T12:33:47.394142] [SCALING] Statefulset name to scale : flink-1000m-16384
[0m[2025-01-18T12:33:47.404524] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 1 replica.
[0m[2025-01-18T12:33:52.415156] [FLK_MGR] Running job.
[0m[2025-01-18T12:33:52.415188] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T12:33:52.797947] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-j8tz5
[0m[2025-01-18T12:33:56.883154] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 17d776e2c1b939205912d83f1f9f77f2

[0m[2025-01-18T12:33:56.883201] [FLK_MGR] Running job id: 17d776e2c1b939205912d83f1f9f77f2
[0m[2025-01-18T12:33:56.883209] [FLK_MGR] Getting job info.
[0m[2025-01-18T12:33:56.900689] [FLK_MGR] Job plan response: {"plan":{"jid":"17d776e2c1b939205912d83f1f9f77f2","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T12:33:56.900821] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T12:33:57.274572] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-j8tz5
[0m[2025-01-18T12:33:58.710676] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 12:33:55 : 17d776e2c1b939205912d83f1f9f77f2 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T12:33:58.710736] [FLK_MGR] Running jobs: ['17d776e2c1b939205912d83f1f9f77f2']
[0m[2025-01-18T12:33:58.710744] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T12:33:58.710757] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T12:37:58.734747] [SCALING] Scaling started.
[0m[2025-01-18T12:37:58.734859] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T12:37:58.747384] [SCALING] Scaling finished.
[0m[2025-01-18T12:37:58.747410] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:37:58.768085] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:37:58.789170] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T12:37:58.812474] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 0 replica.
[0m[2025-01-18T12:38:03.834915] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T12:38:03.851436] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T12:38:03.867244] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T12:38:03.882452] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T12:38:03.896312] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T12:38:03.924595] [POD_MGR] Pod flink-jobmanager-7d7c784b74-j8tz5 deleted
[0m[2025-01-18T12:38:05.875724] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:38:07.824208] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:38:07.824285] Reloading playbook: application/kafka
[0m[2025-01-18T12:38:13.813297] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T12:38:54.818711] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T12:38:54.818948] [EXPERIMENT] Run 3 completed. Start: 1737203623, End: 1737203934
[0m[2025-01-18T12:38:54.818955] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T12:39:04.819971] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T12:39:06.747247] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:39:08.683533] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:39:08.683723] [SCALING] Setting up experiment.


[0m[2025-01-18T12:39:08.683773] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:39:08.689010] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:39:08.706659] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T12:39:08.723858] [SCALING] Statefulset name to scale : flink-1000m-16384
[0m[2025-01-18T12:39:08.735015] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 1 replica.
[0m[2025-01-18T12:39:13.746192] [FLK_MGR] Running job.
[0m[2025-01-18T12:39:13.746222] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T12:39:14.131608] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-4svwz
[0m[2025-01-18T12:39:18.233770] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID cb9767b89be9fcfea03c6a1b190126bb

[0m[2025-01-18T12:39:18.233818] [FLK_MGR] Running job id: cb9767b89be9fcfea03c6a1b190126bb
[0m[2025-01-18T12:39:18.233826] [FLK_MGR] Getting job info.
[0m[2025-01-18T12:39:18.249730] [FLK_MGR] Job plan response: {"plan":{"jid":"cb9767b89be9fcfea03c6a1b190126bb","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T12:39:18.249865] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T12:39:18.622375] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-4svwz
[0m[2025-01-18T12:39:20.050783] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 12:39:17 : cb9767b89be9fcfea03c6a1b190126bb : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T12:39:20.050855] [FLK_MGR] Running jobs: ['cb9767b89be9fcfea03c6a1b190126bb']
[0m[2025-01-18T12:39:20.050864] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T12:39:20.050876] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T12:43:20.076368] [SCALING] Scaling started.
[0m[2025-01-18T12:43:20.076486] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T12:43:20.090254] [SCALING] Scaling finished.
[0m[2025-01-18T12:43:20.090283] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:43:20.109335] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:43:20.130351] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T12:43:20.154660] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 0 replica.
[0m[2025-01-18T12:43:25.174148] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T12:43:25.187516] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T12:43:25.200989] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T12:43:25.215206] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T12:43:25.228784] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T12:43:25.264237] [POD_MGR] Pod flink-jobmanager-7d7c784b74-4svwz deleted
[0m[2025-01-18T12:43:27.211696] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:43:29.163524] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:43:29.163605] Reloading playbook: application/kafka
[0m[2025-01-18T12:43:35.093625] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T12:44:16.117151] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T12:44:16.117370] [EXPERIMENT] Run 4 completed. Start: 1737203944, End: 1737204256
[0m[2025-01-18T12:44:16.117377] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T12:44:26.118417] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T12:44:28.055686] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:44:29.979070] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:44:29.979158] [SCALING] Setting up experiment.


[0m[2025-01-18T12:44:29.979173] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:44:29.985343] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:44:30.001528] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T12:44:30.017678] [SCALING] Statefulset name to scale : flink-1000m-16384
[0m[2025-01-18T12:44:30.027319] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 1 replica.
[0m[2025-01-18T12:44:35.037023] [FLK_MGR] Running job.
[0m[2025-01-18T12:44:35.037051] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T12:44:35.418118] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-g7r2r
[0m[2025-01-18T12:44:39.501902] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 3d06ff721e43944113464eb80aed26ae

[0m[2025-01-18T12:44:39.501954] [FLK_MGR] Running job id: 3d06ff721e43944113464eb80aed26ae
[0m[2025-01-18T12:44:39.501962] [FLK_MGR] Getting job info.
[0m[2025-01-18T12:44:39.520787] [FLK_MGR] Job plan response: {"plan":{"jid":"3d06ff721e43944113464eb80aed26ae","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T12:44:39.520925] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T12:44:39.890531] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-g7r2r
[0m[2025-01-18T12:44:41.311984] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 12:44:38 : 3d06ff721e43944113464eb80aed26ae : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T12:44:41.312043] [FLK_MGR] Running jobs: ['3d06ff721e43944113464eb80aed26ae']
[0m[2025-01-18T12:44:41.312051] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T12:44:41.312063] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T12:48:41.336541] [SCALING] Scaling started.
[0m[2025-01-18T12:48:41.336603] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T12:48:41.349515] [SCALING] Scaling finished.
[0m[2025-01-18T12:48:41.349542] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:48:41.370870] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:48:41.389896] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T12:48:41.414439] [STS_MGR] StatefulSet flink-1000m-16384 scaled to 0 replica.
[0m[2025-01-18T12:48:51.438945] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T12:48:51.451623] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T12:48:51.464553] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T12:48:51.477109] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T12:48:51.489872] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T12:48:51.511236] [POD_MGR] Pod flink-jobmanager-7d7c784b74-g7r2r deleted
[0m[2025-01-18T12:48:53.463270] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:48:55.424183] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:48:55.424277] Reloading playbook: application/kafka
[0m[2025-01-18T12:49:01.488099] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T12:49:42.513498] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T12:49:42.513762] [EXPERIMENT] Run 5 completed. Start: 1737204266, End: 1737204582
[0m[2025-01-18T12:49:42.513769] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T12:49:54.782116] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T12:49:54.782198] [RESOURCE_E] Running experiment with 1000m cores and 32768 memory.
[0m[2025-01-18T12:50:01.955152] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T12:50:01.955242] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T12:50:03.874654] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:50:05.766106] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:50:05.766189] [SCALING] Setting up experiment.


[0m[2025-01-18T12:50:05.766198] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:50:05.771493] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:50:05.788869] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T12:50:05.804988] [SCALING] Statefulset name to scale : flink-1000m-32768
[0m[2025-01-18T12:50:05.816694] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 1 replica.
[0m[2025-01-18T12:51:20.910491] [FLK_MGR] Running job.
[0m[2025-01-18T12:51:20.910565] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T12:51:21.313322] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-r4j6m
[0m[2025-01-18T12:51:25.407339] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8189fdd59457acfd8610a7f94d69813f

[0m[2025-01-18T12:51:25.407391] [FLK_MGR] Running job id: 8189fdd59457acfd8610a7f94d69813f
[0m[2025-01-18T12:51:25.407401] [FLK_MGR] Getting job info.
[0m[2025-01-18T12:51:25.423674] [FLK_MGR] Job plan response: {"plan":{"jid":"8189fdd59457acfd8610a7f94d69813f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T12:51:25.423833] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T12:51:27.351279] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-r4j6m
[0m[2025-01-18T12:51:28.802372] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 12:51:24 : 8189fdd59457acfd8610a7f94d69813f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T12:51:28.802427] [FLK_MGR] Running jobs: ['8189fdd59457acfd8610a7f94d69813f']
[0m[2025-01-18T12:51:28.802436] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T12:51:28.802442] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T12:55:28.825897] [SCALING] Scaling started.
[0m[2025-01-18T12:55:28.825998] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T12:55:28.839566] [SCALING] Scaling finished.
[0m[2025-01-18T12:55:28.839585] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:55:28.859689] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:55:28.877427] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T12:55:28.900483] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 0 replica.
[0m[2025-01-18T12:55:28.915788] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T12:55:28.931379] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T12:55:28.945926] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T12:55:28.960015] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T12:55:28.972499] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T12:55:29.007798] [POD_MGR] Pod flink-jobmanager-7d7c784b74-r4j6m deleted
[0m[2025-01-18T12:55:30.911687] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:55:32.838935] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T12:55:32.839016] Reloading playbook: application/kafka
[0m[2025-01-18T12:55:38.751947] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T12:56:19.703085] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T12:56:19.703346] [EXPERIMENT] Run 1 completed. Start: 1737204601, End: 1737204979
[0m[2025-01-18T12:56:19.703354] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T12:56:29.704375] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T12:56:31.604442] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:56:33.530958] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T12:56:33.531091] [SCALING] Setting up experiment.


[0m[2025-01-18T12:56:33.531134] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T12:56:33.536570] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T12:56:33.552384] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T12:56:33.567629] [SCALING] Statefulset name to scale : flink-1000m-32768
[0m[2025-01-18T12:56:33.577419] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 1 replica.
[0m[2025-01-18T12:57:48.664878] [FLK_MGR] Running job.
[0m[2025-01-18T12:57:48.664929] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T12:57:49.043411] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-qn4ll
[0m[2025-01-18T12:57:53.150126] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f461a0b03a75eb6f31d5257cffba9c68

[0m[2025-01-18T12:57:53.150181] [FLK_MGR] Running job id: f461a0b03a75eb6f31d5257cffba9c68
[0m[2025-01-18T12:57:53.150188] [FLK_MGR] Getting job info.
[0m[2025-01-18T12:57:53.167503] [FLK_MGR] Job plan response: {"plan":{"jid":"f461a0b03a75eb6f31d5257cffba9c68","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T12:57:53.167643] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T12:57:53.547784] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-qn4ll
[0m[2025-01-18T12:57:54.992518] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 12:57:52 : f461a0b03a75eb6f31d5257cffba9c68 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T12:57:54.992577] [FLK_MGR] Running jobs: ['f461a0b03a75eb6f31d5257cffba9c68']
[0m[2025-01-18T12:57:54.992586] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T12:57:54.992604] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T13:01:55.015079] [SCALING] Scaling started.
[0m[2025-01-18T13:01:55.015129] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T13:01:55.028848] [SCALING] Scaling finished.
[0m[2025-01-18T13:01:55.028883] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:01:55.047565] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:01:55.065569] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T13:01:55.087981] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 0 replica.
[0m[2025-01-18T13:01:55.104019] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T13:01:55.118039] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T13:01:55.132179] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T13:01:55.145747] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T13:01:55.162163] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T13:01:55.185513] [POD_MGR] Pod flink-jobmanager-7d7c784b74-qn4ll deleted
[0m[2025-01-18T13:01:57.130997] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:01:59.093748] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:01:59.093888] Reloading playbook: application/kafka
[0m[2025-01-18T13:02:05.109425] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T13:02:46.120703] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T13:02:46.120939] [EXPERIMENT] Run 2 completed. Start: 1737204989, End: 1737205366
[0m[2025-01-18T13:02:46.120947] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T13:02:56.121912] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T13:02:58.035149] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:02:59.946214] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:02:59.946355] [SCALING] Setting up experiment.


[0m[2025-01-18T13:02:59.946402] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:02:59.952256] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:02:59.970797] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T13:02:59.987994] [SCALING] Statefulset name to scale : flink-1000m-32768
[0m[2025-01-18T13:02:59.999483] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 1 replica.
[0m[2025-01-18T13:04:15.091532] [FLK_MGR] Running job.
[0m[2025-01-18T13:04:15.091637] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T13:04:15.480418] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-rdr95
[0m[2025-01-18T13:04:19.538251] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 4e4ed68a96377272d7d75571a0208a67

[0m[2025-01-18T13:04:19.538312] [FLK_MGR] Running job id: 4e4ed68a96377272d7d75571a0208a67
[0m[2025-01-18T13:04:19.538322] [FLK_MGR] Getting job info.
[0m[2025-01-18T13:04:19.554107] [FLK_MGR] Job plan response: {"plan":{"jid":"4e4ed68a96377272d7d75571a0208a67","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T13:04:19.554265] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T13:04:19.936902] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-rdr95
[0m[2025-01-18T13:04:21.387250] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 13:04:18 : 4e4ed68a96377272d7d75571a0208a67 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T13:04:21.387354] [FLK_MGR] Running jobs: ['4e4ed68a96377272d7d75571a0208a67']
[0m[2025-01-18T13:04:21.387363] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T13:04:21.387393] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T13:08:21.411973] [SCALING] Scaling started.
[0m[2025-01-18T13:08:21.412063] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T13:08:21.426830] [SCALING] Scaling finished.
[0m[2025-01-18T13:08:21.426877] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:08:21.447964] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:08:21.466191] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T13:08:21.489271] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 0 replica.
[0m[2025-01-18T13:08:21.505856] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T13:08:21.520859] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T13:08:21.535560] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T13:08:21.549624] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T13:08:21.563745] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T13:08:21.585770] [POD_MGR] Pod flink-jobmanager-7d7c784b74-rdr95 deleted
[0m[2025-01-18T13:08:23.515807] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:08:25.514726] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:08:25.514806] Reloading playbook: application/kafka
[0m[2025-01-18T13:08:31.578689] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T13:09:12.575350] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T13:09:12.575602] [EXPERIMENT] Run 3 completed. Start: 1737205376, End: 1737205752
[0m[2025-01-18T13:09:12.575609] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T13:09:22.576663] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T13:09:24.512890] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:09:26.456057] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:09:26.456146] [SCALING] Setting up experiment.


[0m[2025-01-18T13:09:26.456156] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:09:26.461620] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:09:26.494040] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T13:09:26.511587] [SCALING] Statefulset name to scale : flink-1000m-32768
[0m[2025-01-18T13:09:26.522947] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 1 replica.
[0m[2025-01-18T13:10:41.611771] [FLK_MGR] Running job.
[0m[2025-01-18T13:10:41.611821] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T13:10:42.001214] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-wbv4m
[0m[2025-01-18T13:10:46.025224] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5229f4697c337d2a5f9074437c79f4b4

[0m[2025-01-18T13:10:46.025270] [FLK_MGR] Running job id: 5229f4697c337d2a5f9074437c79f4b4
[0m[2025-01-18T13:10:46.025279] [FLK_MGR] Getting job info.
[0m[2025-01-18T13:10:46.041718] [FLK_MGR] Job plan response: {"plan":{"jid":"5229f4697c337d2a5f9074437c79f4b4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T13:10:46.041850] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T13:10:46.415114] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-wbv4m
[0m[2025-01-18T13:10:47.873357] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 13:10:45 : 5229f4697c337d2a5f9074437c79f4b4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T13:10:47.873447] [FLK_MGR] Running jobs: ['5229f4697c337d2a5f9074437c79f4b4']
[0m[2025-01-18T13:10:47.873455] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T13:10:47.873474] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T13:14:47.897260] [SCALING] Scaling started.
[0m[2025-01-18T13:14:47.897352] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T13:14:47.913418] [SCALING] Scaling finished.
[0m[2025-01-18T13:14:47.913454] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:14:47.931364] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:14:47.948539] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T13:14:47.970205] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 0 replica.
[0m[2025-01-18T13:14:47.985643] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T13:14:47.999710] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T13:14:48.012983] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T13:14:48.026328] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T13:14:48.039652] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T13:14:48.062220] [POD_MGR] Pod flink-jobmanager-7d7c784b74-wbv4m deleted
[0m[2025-01-18T13:14:50.004874] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:14:51.975377] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:14:51.975462] Reloading playbook: application/kafka
[0m[2025-01-18T13:14:57.962838] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T13:15:38.975303] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T13:15:38.975617] [EXPERIMENT] Run 4 completed. Start: 1737205762, End: 1737206138
[0m[2025-01-18T13:15:38.975626] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T13:15:48.976589] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T13:15:50.899200] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:15:52.830714] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:15:52.830804] [SCALING] Setting up experiment.


[0m[2025-01-18T13:15:52.830826] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:15:52.837723] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:15:52.854838] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T13:15:52.870614] [SCALING] Statefulset name to scale : flink-1000m-32768
[0m[2025-01-18T13:15:52.881477] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 1 replica.
[0m[2025-01-18T13:17:07.971102] [FLK_MGR] Running job.
[0m[2025-01-18T13:17:07.971219] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T13:17:08.373920] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-n5nmz
[0m[2025-01-18T13:17:12.401214] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5d7817639f4c54e9b6a9e30392b0188c

[0m[2025-01-18T13:17:12.401278] [FLK_MGR] Running job id: 5d7817639f4c54e9b6a9e30392b0188c
[0m[2025-01-18T13:17:12.401288] [FLK_MGR] Getting job info.
[0m[2025-01-18T13:17:12.419291] [FLK_MGR] Job plan response: {"plan":{"jid":"5d7817639f4c54e9b6a9e30392b0188c","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T13:17:12.419443] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T13:17:12.804070] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-n5nmz
[0m[2025-01-18T13:17:14.226899] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 13:17:11 : 5d7817639f4c54e9b6a9e30392b0188c : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T13:17:14.226971] [FLK_MGR] Running jobs: ['5d7817639f4c54e9b6a9e30392b0188c']
[0m[2025-01-18T13:17:14.226979] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T13:17:14.226993] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T13:21:14.251466] [SCALING] Scaling started.
[0m[2025-01-18T13:21:14.251815] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T13:21:14.267606] [SCALING] Scaling finished.
[0m[2025-01-18T13:21:14.267634] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:21:14.288495] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:21:14.305339] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T13:21:14.329126] [STS_MGR] StatefulSet flink-1000m-32768 scaled to 0 replica.
[0m[2025-01-18T13:21:14.345541] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T13:21:14.359675] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T13:21:14.373714] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T13:21:14.387682] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T13:21:14.401468] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T13:21:14.433724] [POD_MGR] Pod flink-jobmanager-7d7c784b74-n5nmz deleted
[0m[2025-01-18T13:21:16.367868] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:21:18.293047] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:21:18.293139] Reloading playbook: application/kafka
[0m[2025-01-18T13:21:24.237854] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T13:22:05.209053] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T13:22:05.209349] [EXPERIMENT] Run 5 completed. Start: 1737206148, End: 1737206525
[0m[2025-01-18T13:22:05.209356] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T13:22:17.464038] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T13:22:17.464136] [RESOURCE_E] Running experiment with 2000m cores and 1024 memory.
[0m[2025-01-18T13:22:24.769926] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T13:22:24.770011] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T13:22:26.700861] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:22:28.599066] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:22:28.599150] [SCALING] Setting up experiment.


[0m[2025-01-18T13:22:28.599161] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:22:28.604593] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:22:28.621463] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T13:22:28.637133] [SCALING] Statefulset name to scale : flink-2000m-1024
[0m[2025-01-18T13:22:28.646897] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 1 replica.
[0m[2025-01-18T13:22:33.657729] [FLK_MGR] Running job.
[0m[2025-01-18T13:22:33.657761] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T13:22:34.049967] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-rh7xs
[0m[2025-01-18T13:22:38.183081] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 7c4c66c6004c63cb6ce7606fa13eb34d

[0m[2025-01-18T13:22:38.183138] [FLK_MGR] Running job id: 7c4c66c6004c63cb6ce7606fa13eb34d
[0m[2025-01-18T13:22:38.183149] [FLK_MGR] Getting job info.
[0m[2025-01-18T13:22:38.200934] [FLK_MGR] Job plan response: {"plan":{"jid":"7c4c66c6004c63cb6ce7606fa13eb34d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T13:22:38.201084] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T13:22:38.581934] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-rh7xs
[0m[2025-01-18T13:22:40.019548] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 13:22:37 : 7c4c66c6004c63cb6ce7606fa13eb34d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T13:22:40.019611] [FLK_MGR] Running jobs: ['7c4c66c6004c63cb6ce7606fa13eb34d']
[0m[2025-01-18T13:22:40.019619] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T13:22:40.019636] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T13:26:40.042535] [SCALING] Scaling started.
[0m[2025-01-18T13:26:40.042643] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T13:26:40.057682] [SCALING] Scaling finished.
[0m[2025-01-18T13:26:40.057710] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:26:40.076589] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:26:40.093441] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T13:26:40.114946] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 0 replica.
[0m[2025-01-18T13:26:45.134997] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T13:26:45.150978] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T13:26:45.164646] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T13:26:45.178212] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T13:26:45.191635] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T13:26:45.227371] [POD_MGR] Pod flink-jobmanager-7d7c784b74-rh7xs deleted
[0m[2025-01-18T13:26:47.199627] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:26:49.143132] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:26:49.143222] Reloading playbook: application/kafka
[0m[2025-01-18T13:26:55.173981] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T13:27:36.206906] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T13:27:36.207139] [EXPERIMENT] Run 1 completed. Start: 1737206544, End: 1737206856
[0m[2025-01-18T13:27:36.207146] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T13:27:46.208222] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T13:27:48.158340] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:27:50.056272] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:27:50.056355] [SCALING] Setting up experiment.


[0m[2025-01-18T13:27:50.056366] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:27:50.062885] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:27:50.083580] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T13:27:50.104861] [SCALING] Statefulset name to scale : flink-2000m-1024
[0m[2025-01-18T13:27:50.121599] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 1 replica.
[0m[2025-01-18T13:27:55.136911] [FLK_MGR] Running job.
[0m[2025-01-18T13:27:55.136940] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T13:27:55.534029] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-n4fcs
[0m[2025-01-18T13:27:59.582374] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9e7842a2d47afd0279591da3ba806f8e

[0m[2025-01-18T13:27:59.582428] [FLK_MGR] Running job id: 9e7842a2d47afd0279591da3ba806f8e
[0m[2025-01-18T13:27:59.582437] [FLK_MGR] Getting job info.
[0m[2025-01-18T13:27:59.599241] [FLK_MGR] Job plan response: {"plan":{"jid":"9e7842a2d47afd0279591da3ba806f8e","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T13:27:59.599378] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T13:28:01.489986] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-n4fcs
[0m[2025-01-18T13:28:02.931386] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 13:27:58 : 9e7842a2d47afd0279591da3ba806f8e : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T13:28:02.931440] [FLK_MGR] Running jobs: ['9e7842a2d47afd0279591da3ba806f8e']
[0m[2025-01-18T13:28:02.931447] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T13:28:02.931457] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T13:32:02.954955] [SCALING] Scaling started.
[0m[2025-01-18T13:32:02.955006] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T13:32:02.970441] [SCALING] Scaling finished.
[0m[2025-01-18T13:32:02.970465] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:32:02.989458] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:32:03.008137] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T13:32:03.030691] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 0 replica.
[0m[2025-01-18T13:32:08.051816] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T13:32:08.065403] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T13:32:08.079469] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T13:32:08.094313] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T13:32:08.112368] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T13:32:08.149307] [POD_MGR] Pod flink-jobmanager-7d7c784b74-n4fcs deleted
[0m[2025-01-18T13:32:10.083251] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:32:12.053585] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:32:12.053715] Reloading playbook: application/kafka
[0m[2025-01-18T13:32:18.092980] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T13:32:59.092172] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T13:32:59.092437] [EXPERIMENT] Run 2 completed. Start: 1737206866, End: 1737207179
[0m[2025-01-18T13:32:59.092444] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T13:33:09.093451] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T13:33:11.009016] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:33:12.919036] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:33:12.919140] [SCALING] Setting up experiment.


[0m[2025-01-18T13:33:12.919154] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:33:12.925219] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:33:12.943604] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T13:33:12.960177] [SCALING] Statefulset name to scale : flink-2000m-1024
[0m[2025-01-18T13:33:12.970117] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 1 replica.
[0m[2025-01-18T13:33:17.979743] [FLK_MGR] Running job.
[0m[2025-01-18T13:33:17.979775] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T13:33:18.362150] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-5n8ww
[0m[2025-01-18T13:33:22.486188] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b27444ffabd855621e29733dba612700

[0m[2025-01-18T13:33:22.486244] [FLK_MGR] Running job id: b27444ffabd855621e29733dba612700
[0m[2025-01-18T13:33:22.486251] [FLK_MGR] Getting job info.
[0m[2025-01-18T13:33:22.503225] [FLK_MGR] Job plan response: {"plan":{"jid":"b27444ffabd855621e29733dba612700","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T13:33:22.503365] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T13:33:22.882735] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-5n8ww
[0m[2025-01-18T13:33:24.296101] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 13:33:21 : b27444ffabd855621e29733dba612700 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T13:33:24.296160] [FLK_MGR] Running jobs: ['b27444ffabd855621e29733dba612700']
[0m[2025-01-18T13:33:24.296168] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T13:33:24.296181] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T13:37:24.319598] [SCALING] Scaling started.
[0m[2025-01-18T13:37:24.319722] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T13:37:24.335246] [SCALING] Scaling finished.
[0m[2025-01-18T13:37:24.335271] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:37:24.355864] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:37:24.373988] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T13:37:24.396482] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 0 replica.
[0m[2025-01-18T13:37:34.422669] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T13:37:34.438558] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T13:37:34.454244] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T13:37:34.470964] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T13:37:34.485158] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T13:37:34.518691] [POD_MGR] Pod flink-jobmanager-7d7c784b74-5n8ww deleted
[0m[2025-01-18T13:37:36.403884] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:37:38.348097] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:37:38.348208] Reloading playbook: application/kafka
[0m[2025-01-18T13:37:44.387702] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T13:38:25.426870] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T13:38:25.427105] [EXPERIMENT] Run 3 completed. Start: 1737207189, End: 1737207505
[0m[2025-01-18T13:38:25.427111] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T13:38:35.428124] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T13:38:37.376138] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:38:39.303767] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:38:39.303846] [SCALING] Setting up experiment.


[0m[2025-01-18T13:38:39.303857] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:38:39.309163] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:38:39.325741] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T13:38:39.342777] [SCALING] Statefulset name to scale : flink-2000m-1024
[0m[2025-01-18T13:38:39.352825] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 1 replica.
[0m[2025-01-18T13:38:44.363443] [FLK_MGR] Running job.
[0m[2025-01-18T13:38:44.363481] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T13:38:44.748225] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jcqx4
[0m[2025-01-18T13:38:48.825609] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b06419e95fdfe14f6b89a5be262f98c0

[0m[2025-01-18T13:38:48.825655] [FLK_MGR] Running job id: b06419e95fdfe14f6b89a5be262f98c0
[0m[2025-01-18T13:38:48.825664] [FLK_MGR] Getting job info.
[0m[2025-01-18T13:38:48.842252] [FLK_MGR] Job plan response: {"plan":{"jid":"b06419e95fdfe14f6b89a5be262f98c0","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T13:38:48.842385] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T13:38:49.272902] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jcqx4
[0m[2025-01-18T13:38:50.719694] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 13:38:47 : b06419e95fdfe14f6b89a5be262f98c0 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T13:38:50.719759] [FLK_MGR] Running jobs: ['b06419e95fdfe14f6b89a5be262f98c0']
[0m[2025-01-18T13:38:50.719768] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T13:38:50.719782] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T13:42:50.743032] [SCALING] Scaling started.
[0m[2025-01-18T13:42:50.743089] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T13:42:50.758108] [SCALING] Scaling finished.
[0m[2025-01-18T13:42:50.758202] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:42:50.776993] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:42:50.795402] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T13:42:50.818985] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 0 replica.
[0m[2025-01-18T13:43:00.846492] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T13:43:00.861241] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T13:43:00.874972] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T13:43:00.889267] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T13:43:00.903557] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T13:43:00.929275] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jcqx4 deleted
[0m[2025-01-18T13:43:02.847260] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:43:04.754261] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:43:04.754337] Reloading playbook: application/kafka
[0m[2025-01-18T13:43:10.695250] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T13:43:51.693900] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T13:43:51.694175] [EXPERIMENT] Run 4 completed. Start: 1737207515, End: 1737207831
[0m[2025-01-18T13:43:51.694184] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T13:44:01.695188] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T13:44:03.641518] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:44:05.569956] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:44:05.570046] [SCALING] Setting up experiment.


[0m[2025-01-18T13:44:05.570060] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:44:05.575374] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:44:05.591671] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T13:44:05.607643] [SCALING] Statefulset name to scale : flink-2000m-1024
[0m[2025-01-18T13:44:05.619260] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 1 replica.
[0m[2025-01-18T13:44:10.629616] [FLK_MGR] Running job.
[0m[2025-01-18T13:44:10.629650] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T13:44:11.019029] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-9xrls
[0m[2025-01-18T13:44:15.128493] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 7aba2c6aff3da36d16ce3cc605e87bf7

[0m[2025-01-18T13:44:15.128539] [FLK_MGR] Running job id: 7aba2c6aff3da36d16ce3cc605e87bf7
[0m[2025-01-18T13:44:15.128549] [FLK_MGR] Getting job info.
[0m[2025-01-18T13:44:15.146000] [FLK_MGR] Job plan response: {"plan":{"jid":"7aba2c6aff3da36d16ce3cc605e87bf7","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T13:44:15.146136] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T13:44:15.532863] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-9xrls
[0m[2025-01-18T13:44:16.968973] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 13:44:14 : 7aba2c6aff3da36d16ce3cc605e87bf7 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T13:44:16.969050] [FLK_MGR] Running jobs: ['7aba2c6aff3da36d16ce3cc605e87bf7']
[0m[2025-01-18T13:44:16.969060] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T13:44:16.969088] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T13:48:16.991819] [SCALING] Scaling started.
[0m[2025-01-18T13:48:16.991925] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T13:48:17.006721] [SCALING] Scaling finished.
[0m[2025-01-18T13:48:17.006748] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:48:17.027500] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:48:17.046036] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T13:48:17.069677] [STS_MGR] StatefulSet flink-2000m-1024 scaled to 0 replica.
[0m[2025-01-18T13:48:22.092250] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T13:48:22.107196] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T13:48:22.121475] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T13:48:22.137941] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T13:48:22.155240] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T13:48:22.188107] [POD_MGR] Pod flink-jobmanager-7d7c784b74-9xrls deleted
[0m[2025-01-18T13:48:24.201394] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:48:26.153907] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:48:26.153990] Reloading playbook: application/kafka
[0m[2025-01-18T13:48:32.112556] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T13:49:13.120921] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T13:49:13.121282] [EXPERIMENT] Run 5 completed. Start: 1737207841, End: 1737208153
[0m[2025-01-18T13:49:13.121288] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T13:49:25.401587] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T13:49:25.401679] [RESOURCE_E] Running experiment with 2000m cores and 2048 memory.
[0m[2025-01-18T13:49:32.693776] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T13:49:32.693870] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T13:49:34.591678] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:49:36.501196] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:49:36.501279] [SCALING] Setting up experiment.


[0m[2025-01-18T13:49:36.501294] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:49:36.507419] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:49:36.523963] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T13:49:36.539381] [SCALING] Statefulset name to scale : flink-2000m-2048
[0m[2025-01-18T13:49:36.550792] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 1 replica.
[0m[2025-01-18T13:49:41.561213] [FLK_MGR] Running job.
[0m[2025-01-18T13:49:41.561299] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T13:49:41.942502] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-9xl67
[0m[2025-01-18T13:49:46.020887] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b5f156949ae91dbab308b2e1f9c269fa

[0m[2025-01-18T13:49:46.020948] [FLK_MGR] Running job id: b5f156949ae91dbab308b2e1f9c269fa
[0m[2025-01-18T13:49:46.020958] [FLK_MGR] Getting job info.
[0m[2025-01-18T13:49:46.041807] [FLK_MGR] Job plan response: {"plan":{"jid":"b5f156949ae91dbab308b2e1f9c269fa","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T13:49:46.042089] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T13:49:46.472153] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-9xl67
[0m[2025-01-18T13:49:47.911694] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 13:49:45 : b5f156949ae91dbab308b2e1f9c269fa : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T13:49:47.911755] [FLK_MGR] Running jobs: ['b5f156949ae91dbab308b2e1f9c269fa']
[0m[2025-01-18T13:49:47.911764] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T13:49:47.911775] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T13:53:47.934368] [SCALING] Scaling started.
[0m[2025-01-18T13:53:47.934432] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T13:53:47.946564] [SCALING] Scaling finished.
[0m[2025-01-18T13:53:47.946589] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:53:47.963898] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:53:47.982574] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T13:53:48.004799] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 0 replica.
[0m[2025-01-18T13:53:53.025621] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T13:53:53.040088] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T13:53:53.054168] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T13:53:53.067861] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T13:53:53.081424] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T13:53:53.113769] [POD_MGR] Pod flink-jobmanager-7d7c784b74-9xl67 deleted
[0m[2025-01-18T13:53:55.026556] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:53:56.994887] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:53:56.994970] Reloading playbook: application/kafka
[0m[2025-01-18T13:54:02.990584] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T13:54:43.926268] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T13:54:43.926558] [EXPERIMENT] Run 1 completed. Start: 1737208172, End: 1737208483
[0m[2025-01-18T13:54:43.926564] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T13:54:53.927592] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T13:54:55.851144] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:54:57.770655] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T13:54:57.770739] [SCALING] Setting up experiment.


[0m[2025-01-18T13:54:57.770749] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:54:57.776071] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:54:57.791846] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T13:54:57.810413] [SCALING] Statefulset name to scale : flink-2000m-2048
[0m[2025-01-18T13:54:57.821438] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 1 replica.
[0m[2025-01-18T13:55:02.833147] [FLK_MGR] Running job.
[0m[2025-01-18T13:55:02.833177] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T13:55:03.220680] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-5624j
[0m[2025-01-18T13:55:07.290345] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 243ba4820b2a3cefff9c4219cce54c83

[0m[2025-01-18T13:55:07.290423] [FLK_MGR] Running job id: 243ba4820b2a3cefff9c4219cce54c83
[0m[2025-01-18T13:55:07.290435] [FLK_MGR] Getting job info.
[0m[2025-01-18T13:55:07.312219] [FLK_MGR] Job plan response: {"plan":{"jid":"243ba4820b2a3cefff9c4219cce54c83","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T13:55:07.312417] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T13:55:07.683419] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-5624j
[0m[2025-01-18T13:55:09.084636] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 13:55:06 : 243ba4820b2a3cefff9c4219cce54c83 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T13:55:09.084700] [FLK_MGR] Running jobs: ['243ba4820b2a3cefff9c4219cce54c83']
[0m[2025-01-18T13:55:09.084709] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T13:55:09.084721] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T13:59:09.108388] [SCALING] Scaling started.
[0m[2025-01-18T13:59:09.108449] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T13:59:09.123114] [SCALING] Scaling finished.
[0m[2025-01-18T13:59:09.123139] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T13:59:09.141424] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T13:59:09.158194] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T13:59:09.181793] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 0 replica.
[0m[2025-01-18T13:59:14.203948] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T13:59:14.220223] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T13:59:14.235143] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T13:59:14.250335] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T13:59:14.264770] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T13:59:14.290134] [POD_MGR] Pod flink-jobmanager-7d7c784b74-5624j deleted
[0m[2025-01-18T13:59:16.208612] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:59:18.175056] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T13:59:18.175125] Reloading playbook: application/kafka
[0m[2025-01-18T13:59:24.203117] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T14:00:05.219457] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T14:00:05.219686] [EXPERIMENT] Run 2 completed. Start: 1737208493, End: 1737208805
[0m[2025-01-18T14:00:05.219692] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T14:00:15.220653] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T14:00:17.155146] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:00:19.063182] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:00:19.063261] [SCALING] Setting up experiment.


[0m[2025-01-18T14:00:19.063273] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:00:19.069284] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:00:19.089534] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T14:00:19.112962] [SCALING] Statefulset name to scale : flink-2000m-2048
[0m[2025-01-18T14:00:19.124140] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 1 replica.
[0m[2025-01-18T14:00:24.133912] [FLK_MGR] Running job.
[0m[2025-01-18T14:00:24.133937] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T14:00:24.538546] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-97x8p
[0m[2025-01-18T14:00:28.576755] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f26ea92e22688056936b304a5946ae69

[0m[2025-01-18T14:00:28.576815] [FLK_MGR] Running job id: f26ea92e22688056936b304a5946ae69
[0m[2025-01-18T14:00:28.576827] [FLK_MGR] Getting job info.
[0m[2025-01-18T14:00:28.595143] [FLK_MGR] Job plan response: {"plan":{"jid":"f26ea92e22688056936b304a5946ae69","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T14:00:28.595284] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T14:00:30.481521] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-97x8p
[0m[2025-01-18T14:00:31.921547] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 14:00:27 : f26ea92e22688056936b304a5946ae69 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T14:00:31.921599] [FLK_MGR] Running jobs: ['f26ea92e22688056936b304a5946ae69']
[0m[2025-01-18T14:00:31.921606] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T14:00:31.921613] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T14:04:31.945201] [SCALING] Scaling started.
[0m[2025-01-18T14:04:31.945295] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T14:04:31.957234] [SCALING] Scaling finished.
[0m[2025-01-18T14:04:31.957255] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:04:31.976148] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:04:31.993240] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T14:04:32.017748] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 0 replica.
[0m[2025-01-18T14:04:37.041278] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T14:04:37.056052] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T14:04:37.069727] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T14:04:37.082599] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T14:04:37.095455] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T14:04:37.129988] [POD_MGR] Pod flink-jobmanager-7d7c784b74-97x8p deleted
[0m[2025-01-18T14:04:39.071755] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:04:41.047215] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:04:41.047300] Reloading playbook: application/kafka
[0m[2025-01-18T14:04:47.034805] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T14:05:28.033637] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T14:05:28.033869] [EXPERIMENT] Run 3 completed. Start: 1737208815, End: 1737209128
[0m[2025-01-18T14:05:28.033875] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T14:05:38.034945] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T14:05:39.948871] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:05:41.869440] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:05:41.869532] [SCALING] Setting up experiment.


[0m[2025-01-18T14:05:41.869542] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:05:41.874646] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:05:41.890487] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T14:05:41.907569] [SCALING] Statefulset name to scale : flink-2000m-2048
[0m[2025-01-18T14:05:41.918097] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 1 replica.
[0m[2025-01-18T14:05:46.928196] [FLK_MGR] Running job.
[0m[2025-01-18T14:05:46.928224] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T14:05:47.315797] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-v2j2f
[0m[2025-01-18T14:05:51.395390] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f99eb4c54110d27a7e7d9504bfd62604

[0m[2025-01-18T14:05:51.395438] [FLK_MGR] Running job id: f99eb4c54110d27a7e7d9504bfd62604
[0m[2025-01-18T14:05:51.395445] [FLK_MGR] Getting job info.
[0m[2025-01-18T14:05:51.414548] [FLK_MGR] Job plan response: {"plan":{"jid":"f99eb4c54110d27a7e7d9504bfd62604","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T14:05:51.414726] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T14:05:51.828363] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-v2j2f
[0m[2025-01-18T14:05:53.293141] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 14:05:50 : f99eb4c54110d27a7e7d9504bfd62604 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T14:05:53.293207] [FLK_MGR] Running jobs: ['f99eb4c54110d27a7e7d9504bfd62604']
[0m[2025-01-18T14:05:53.293216] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T14:05:53.293229] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T14:09:53.315855] [SCALING] Scaling started.
[0m[2025-01-18T14:09:53.315959] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T14:09:53.330078] [SCALING] Scaling finished.
[0m[2025-01-18T14:09:53.330190] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:09:53.346820] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:09:53.365263] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T14:09:53.385832] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 0 replica.
[0m[2025-01-18T14:09:58.407003] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T14:09:58.420705] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T14:09:58.433759] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T14:09:58.450540] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T14:09:58.467729] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T14:09:58.496989] [POD_MGR] Pod flink-jobmanager-7d7c784b74-v2j2f deleted
[0m[2025-01-18T14:10:00.411241] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:10:02.339901] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:10:02.339999] Reloading playbook: application/kafka
[0m[2025-01-18T14:10:08.298453] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T14:10:49.278591] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T14:10:49.278891] [EXPERIMENT] Run 4 completed. Start: 1737209138, End: 1737209449
[0m[2025-01-18T14:10:49.278900] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T14:10:59.279903] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T14:11:01.214033] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:11:03.141454] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:11:03.141537] [SCALING] Setting up experiment.


[0m[2025-01-18T14:11:03.141547] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:11:03.147048] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:11:03.164789] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T14:11:03.184441] [SCALING] Statefulset name to scale : flink-2000m-2048
[0m[2025-01-18T14:11:03.196161] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 1 replica.
[0m[2025-01-18T14:11:08.206590] [FLK_MGR] Running job.
[0m[2025-01-18T14:11:08.206625] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T14:11:08.591753] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-dcgkt
[0m[2025-01-18T14:11:12.722632] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID be923c6c9e0f83e36b23d64202dcb707

[0m[2025-01-18T14:11:12.722678] [FLK_MGR] Running job id: be923c6c9e0f83e36b23d64202dcb707
[0m[2025-01-18T14:11:12.722685] [FLK_MGR] Getting job info.
[0m[2025-01-18T14:11:12.741047] [FLK_MGR] Job plan response: {"plan":{"jid":"be923c6c9e0f83e36b23d64202dcb707","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T14:11:12.741192] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T14:11:13.177521] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-dcgkt
[0m[2025-01-18T14:11:14.613664] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 14:11:11 : be923c6c9e0f83e36b23d64202dcb707 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T14:11:14.613722] [FLK_MGR] Running jobs: ['be923c6c9e0f83e36b23d64202dcb707']
[0m[2025-01-18T14:11:14.613730] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T14:11:14.613742] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T14:15:14.636344] [SCALING] Scaling started.
[0m[2025-01-18T14:15:14.636399] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T14:15:14.650786] [SCALING] Scaling finished.
[0m[2025-01-18T14:15:14.650823] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:15:14.669513] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:15:14.688718] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T14:15:14.710149] [STS_MGR] StatefulSet flink-2000m-2048 scaled to 0 replica.
[0m[2025-01-18T14:15:24.739459] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T14:15:24.756390] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T14:15:24.773930] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T14:15:24.789596] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T14:15:24.804798] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T14:15:24.846605] [POD_MGR] Pod flink-jobmanager-7d7c784b74-dcgkt deleted
[0m[2025-01-18T14:15:26.779196] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:15:28.742537] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:15:28.742628] Reloading playbook: application/kafka
[0m[2025-01-18T14:15:34.748796] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T14:16:15.781530] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T14:16:15.781853] [EXPERIMENT] Run 5 completed. Start: 1737209459, End: 1737209775
[0m[2025-01-18T14:16:15.781876] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T14:16:28.096405] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T14:16:28.096496] [RESOURCE_E] Running experiment with 2000m cores and 4096 memory.
[0m[2025-01-18T14:16:35.397977] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T14:16:35.398192] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T14:16:37.348769] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:16:39.254392] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:16:39.254482] [SCALING] Setting up experiment.


[0m[2025-01-18T14:16:39.254496] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:16:39.260348] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:16:39.278076] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T14:16:39.296307] [SCALING] Statefulset name to scale : flink-2000m-4096
[0m[2025-01-18T14:16:39.306661] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 1 replica.
[0m[2025-01-18T14:16:44.318241] [FLK_MGR] Running job.
[0m[2025-01-18T14:16:44.318279] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T14:16:44.717393] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xk5bm
[0m[2025-01-18T14:16:48.835836] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c7a4b96d7c6d66782cc08558d57f89e4

[0m[2025-01-18T14:16:48.835882] [FLK_MGR] Running job id: c7a4b96d7c6d66782cc08558d57f89e4
[0m[2025-01-18T14:16:48.835891] [FLK_MGR] Getting job info.
[0m[2025-01-18T14:16:48.852543] [FLK_MGR] Job plan response: {"plan":{"jid":"c7a4b96d7c6d66782cc08558d57f89e4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T14:16:48.852675] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T14:16:49.237708] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xk5bm
[0m[2025-01-18T14:16:50.670817] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 14:16:47 : c7a4b96d7c6d66782cc08558d57f89e4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T14:16:50.670880] [FLK_MGR] Running jobs: ['c7a4b96d7c6d66782cc08558d57f89e4']
[0m[2025-01-18T14:16:50.670891] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T14:16:50.670904] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T14:20:50.693841] [SCALING] Scaling started.
[0m[2025-01-18T14:20:50.693905] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T14:20:50.708009] [SCALING] Scaling finished.
[0m[2025-01-18T14:20:50.708038] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:20:50.727869] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:20:50.746442] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T14:20:50.767325] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 0 replica.
[0m[2025-01-18T14:20:55.789514] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T14:20:55.804251] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T14:20:55.819495] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T14:20:55.833072] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T14:20:55.848314] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T14:20:55.872133] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xk5bm deleted
[0m[2025-01-18T14:20:57.787172] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:20:59.705588] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:20:59.705661] Reloading playbook: application/kafka
[0m[2025-01-18T14:21:05.641724] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T14:21:46.666491] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T14:21:46.666706] [EXPERIMENT] Run 1 completed. Start: 1737209795, End: 1737210106
[0m[2025-01-18T14:21:46.666714] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T14:21:56.667736] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T14:21:58.592712] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:22:00.485161] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:22:00.485278] [SCALING] Setting up experiment.


[0m[2025-01-18T14:22:00.485289] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:22:00.492180] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:22:00.509626] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T14:22:00.526290] [SCALING] Statefulset name to scale : flink-2000m-4096
[0m[2025-01-18T14:22:00.537624] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 1 replica.
[0m[2025-01-18T14:22:05.548778] [FLK_MGR] Running job.
[0m[2025-01-18T14:22:05.548820] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T14:22:05.950477] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-j2vpt
[0m[2025-01-18T14:22:10.081187] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID df2b1699ad3ea5fefe2a6e746b527070

[0m[2025-01-18T14:22:10.081233] [FLK_MGR] Running job id: df2b1699ad3ea5fefe2a6e746b527070
[0m[2025-01-18T14:22:10.081240] [FLK_MGR] Getting job info.
[0m[2025-01-18T14:22:10.101390] [FLK_MGR] Job plan response: {"plan":{"jid":"df2b1699ad3ea5fefe2a6e746b527070","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T14:22:10.101536] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T14:22:10.484825] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-j2vpt
[0m[2025-01-18T14:22:11.926388] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 14:22:09 : df2b1699ad3ea5fefe2a6e746b527070 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T14:22:11.926455] [FLK_MGR] Running jobs: ['df2b1699ad3ea5fefe2a6e746b527070']
[0m[2025-01-18T14:22:11.926463] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T14:22:11.926476] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T14:26:11.948641] [SCALING] Scaling started.
[0m[2025-01-18T14:26:11.948786] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T14:26:11.969029] [SCALING] Scaling finished.
[0m[2025-01-18T14:26:11.969055] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:26:11.987834] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:26:12.004806] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T14:26:12.026859] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 0 replica.
[0m[2025-01-18T14:26:17.045658] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T14:26:17.058628] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T14:26:17.071795] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T14:26:17.084570] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T14:26:17.097248] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T14:26:17.125506] [POD_MGR] Pod flink-jobmanager-7d7c784b74-j2vpt deleted
[0m[2025-01-18T14:26:19.057263] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:26:21.036439] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:26:21.036525] Reloading playbook: application/kafka
[0m[2025-01-18T14:26:27.007772] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T14:27:08.080209] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T14:27:08.080449] [EXPERIMENT] Run 2 completed. Start: 1737210116, End: 1737210428
[0m[2025-01-18T14:27:08.080456] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T14:27:18.081361] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T14:27:20.016296] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:27:21.941972] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:27:21.942094] [SCALING] Setting up experiment.


[0m[2025-01-18T14:27:21.942107] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:27:21.948556] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:27:21.967618] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T14:27:21.985973] [SCALING] Statefulset name to scale : flink-2000m-4096
[0m[2025-01-18T14:27:21.996102] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 1 replica.
[0m[2025-01-18T14:27:27.007015] [FLK_MGR] Running job.
[0m[2025-01-18T14:27:27.007061] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T14:27:27.399801] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-cwppm
[0m[2025-01-18T14:27:31.486921] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 42a658766359e84999f9a767ba6eaa61

[0m[2025-01-18T14:27:31.486965] [FLK_MGR] Running job id: 42a658766359e84999f9a767ba6eaa61
[0m[2025-01-18T14:27:31.486975] [FLK_MGR] Getting job info.
[0m[2025-01-18T14:27:31.506327] [FLK_MGR] Job plan response: {"plan":{"jid":"42a658766359e84999f9a767ba6eaa61","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T14:27:31.506487] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T14:27:31.919460] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-cwppm
[0m[2025-01-18T14:27:33.351301] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 14:27:30 : 42a658766359e84999f9a767ba6eaa61 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T14:27:33.351361] [FLK_MGR] Running jobs: ['42a658766359e84999f9a767ba6eaa61']
[0m[2025-01-18T14:27:33.351369] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T14:27:33.351380] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T14:31:33.373522] [SCALING] Scaling started.
[0m[2025-01-18T14:31:33.373632] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T14:31:33.386381] [SCALING] Scaling finished.
[0m[2025-01-18T14:31:33.386409] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:31:33.405538] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:31:33.422728] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T14:31:33.444967] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 0 replica.
[0m[2025-01-18T14:31:38.469019] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T14:31:38.485666] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T14:31:38.501209] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T14:31:38.517906] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T14:31:38.530900] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T14:31:38.585553] [POD_MGR] Pod flink-jobmanager-7d7c784b74-cwppm deleted
[0m[2025-01-18T14:31:40.440787] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:31:42.355519] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:31:42.355599] Reloading playbook: application/kafka
[0m[2025-01-18T14:31:48.322566] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T14:32:29.339008] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T14:32:29.339562] [EXPERIMENT] Run 3 completed. Start: 1737210438, End: 1737210749
[0m[2025-01-18T14:32:29.339570] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T14:32:39.340607] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T14:32:41.262979] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:32:43.190838] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:32:43.190941] [SCALING] Setting up experiment.


[0m[2025-01-18T14:32:43.190954] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:32:43.196450] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:32:43.212535] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T14:32:43.230790] [SCALING] Statefulset name to scale : flink-2000m-4096
[0m[2025-01-18T14:32:43.240349] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 1 replica.
[0m[2025-01-18T14:32:48.249739] [FLK_MGR] Running job.
[0m[2025-01-18T14:32:48.249774] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T14:32:48.628862] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-7bj8w
[0m[2025-01-18T14:32:52.737284] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 91399d06bec51d91711ebe6f2c6498cf

[0m[2025-01-18T14:32:52.737341] [FLK_MGR] Running job id: 91399d06bec51d91711ebe6f2c6498cf
[0m[2025-01-18T14:32:52.737354] [FLK_MGR] Getting job info.
[0m[2025-01-18T14:32:52.754428] [FLK_MGR] Job plan response: {"plan":{"jid":"91399d06bec51d91711ebe6f2c6498cf","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T14:32:52.754597] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T14:32:54.587139] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-7bj8w
[0m[2025-01-18T14:32:56.049907] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 14:32:51 : 91399d06bec51d91711ebe6f2c6498cf : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T14:32:56.049969] [FLK_MGR] Running jobs: ['91399d06bec51d91711ebe6f2c6498cf']
[0m[2025-01-18T14:32:56.049976] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T14:32:56.049985] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T14:36:56.073870] [SCALING] Scaling started.
[0m[2025-01-18T14:36:56.073979] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T14:36:56.087569] [SCALING] Scaling finished.
[0m[2025-01-18T14:36:56.087590] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:36:56.109427] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:36:56.128236] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T14:36:56.151006] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 0 replica.
[0m[2025-01-18T14:37:01.175196] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T14:37:01.188707] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T14:37:01.202339] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T14:37:01.216613] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T14:37:01.230453] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T14:37:01.263840] [POD_MGR] Pod flink-jobmanager-7d7c784b74-7bj8w deleted
[0m[2025-01-18T14:37:03.168698] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:37:05.074877] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:37:05.074950] Reloading playbook: application/kafka
[0m[2025-01-18T14:37:11.068160] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T14:37:52.097542] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T14:37:52.097740] [EXPERIMENT] Run 4 completed. Start: 1737210759, End: 1737211072
[0m[2025-01-18T14:37:52.097746] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T14:38:02.098794] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T14:38:04.033854] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:38:05.945989] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:38:05.946240] [SCALING] Setting up experiment.


[0m[2025-01-18T14:38:05.946356] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:38:05.953344] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:38:05.972388] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T14:38:05.991189] [SCALING] Statefulset name to scale : flink-2000m-4096
[0m[2025-01-18T14:38:06.003954] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 1 replica.
[0m[2025-01-18T14:38:11.015305] [FLK_MGR] Running job.
[0m[2025-01-18T14:38:11.015340] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T14:38:11.411260] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-lbwdb
[0m[2025-01-18T14:38:15.482418] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9187d07a97a6ebdbe1ee534ceea2abec

[0m[2025-01-18T14:38:15.482477] [FLK_MGR] Running job id: 9187d07a97a6ebdbe1ee534ceea2abec
[0m[2025-01-18T14:38:15.482486] [FLK_MGR] Getting job info.
[0m[2025-01-18T14:38:15.502628] [FLK_MGR] Job plan response: {"plan":{"jid":"9187d07a97a6ebdbe1ee534ceea2abec","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T14:38:15.502767] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T14:38:15.876007] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-lbwdb
[0m[2025-01-18T14:38:17.307244] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 14:38:14 : 9187d07a97a6ebdbe1ee534ceea2abec : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T14:38:17.307308] [FLK_MGR] Running jobs: ['9187d07a97a6ebdbe1ee534ceea2abec']
[0m[2025-01-18T14:38:17.307317] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T14:38:17.307330] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T14:42:17.330531] [SCALING] Scaling started.
[0m[2025-01-18T14:42:17.330580] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T14:42:17.343983] [SCALING] Scaling finished.
[0m[2025-01-18T14:42:17.344008] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:42:17.362706] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:42:17.380841] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T14:42:17.403181] [STS_MGR] StatefulSet flink-2000m-4096 scaled to 0 replica.
[0m[2025-01-18T14:42:22.423493] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T14:42:22.438092] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T14:42:22.452557] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T14:42:22.466679] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T14:42:22.480583] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T14:42:22.507197] [POD_MGR] Pod flink-jobmanager-7d7c784b74-lbwdb deleted
[0m[2025-01-18T14:42:24.388652] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:42:26.354658] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:42:26.354754] Reloading playbook: application/kafka
[0m[2025-01-18T14:42:32.328048] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T14:43:13.300606] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T14:43:13.300809] [EXPERIMENT] Run 5 completed. Start: 1737211082, End: 1737211393
[0m[2025-01-18T14:43:13.300816] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T14:43:25.561622] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T14:43:25.561698] [RESOURCE_E] Running experiment with 2000m cores and 8192 memory.
[0m[2025-01-18T14:43:32.862819] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T14:43:32.862900] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T14:43:34.805266] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:43:36.762440] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:43:36.762522] [SCALING] Setting up experiment.


[0m[2025-01-18T14:43:36.762532] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:43:36.768749] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:43:36.786719] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T14:43:36.805617] [SCALING] Statefulset name to scale : flink-2000m-8192
[0m[2025-01-18T14:43:36.816025] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 1 replica.
[0m[2025-01-18T14:43:41.827835] [FLK_MGR] Running job.
[0m[2025-01-18T14:43:41.827863] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T14:43:42.207334] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-pcht8
[0m[2025-01-18T14:43:46.239153] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f04ee86636d4dd57b1bae0ae12417b3d

[0m[2025-01-18T14:43:46.239198] [FLK_MGR] Running job id: f04ee86636d4dd57b1bae0ae12417b3d
[0m[2025-01-18T14:43:46.239207] [FLK_MGR] Getting job info.
[0m[2025-01-18T14:43:46.259134] [FLK_MGR] Job plan response: {"plan":{"jid":"f04ee86636d4dd57b1bae0ae12417b3d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T14:43:46.259287] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T14:43:46.639556] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-pcht8
[0m[2025-01-18T14:43:48.071727] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 14:43:45 : f04ee86636d4dd57b1bae0ae12417b3d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T14:43:48.071794] [FLK_MGR] Running jobs: ['f04ee86636d4dd57b1bae0ae12417b3d']
[0m[2025-01-18T14:43:48.071802] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T14:43:48.071816] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T14:47:48.095642] [SCALING] Scaling started.
[0m[2025-01-18T14:47:48.095706] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T14:47:48.110574] [SCALING] Scaling finished.
[0m[2025-01-18T14:47:48.110603] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:47:48.128453] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:47:48.145380] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T14:47:48.167807] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 0 replica.
[0m[2025-01-18T14:47:53.190046] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T14:47:53.205580] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T14:47:53.219239] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T14:47:53.233752] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T14:47:53.246878] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T14:47:53.277700] [POD_MGR] Pod flink-jobmanager-7d7c784b74-pcht8 deleted
[0m[2025-01-18T14:47:55.181447] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:47:57.161919] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:47:57.162039] Reloading playbook: application/kafka
[0m[2025-01-18T14:48:03.136821] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T14:48:44.134000] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T14:48:44.134263] [EXPERIMENT] Run 1 completed. Start: 1737211412, End: 1737211724
[0m[2025-01-18T14:48:44.134269] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T14:48:54.135196] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T14:48:56.064247] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:48:57.952445] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:48:57.952520] [SCALING] Setting up experiment.


[0m[2025-01-18T14:48:57.952533] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:48:57.957432] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:48:57.972741] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T14:48:57.988551] [SCALING] Statefulset name to scale : flink-2000m-8192
[0m[2025-01-18T14:48:57.998170] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 1 replica.
[0m[2025-01-18T14:49:03.008573] [FLK_MGR] Running job.
[0m[2025-01-18T14:49:03.008607] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T14:49:03.390657] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-fjh7z
[0m[2025-01-18T14:49:07.450288] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID d139b201ac711e8548bb80b7e8705533

[0m[2025-01-18T14:49:07.450337] [FLK_MGR] Running job id: d139b201ac711e8548bb80b7e8705533
[0m[2025-01-18T14:49:07.450346] [FLK_MGR] Getting job info.
[0m[2025-01-18T14:49:07.467737] [FLK_MGR] Job plan response: {"plan":{"jid":"d139b201ac711e8548bb80b7e8705533","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T14:49:07.467880] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T14:49:07.905465] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-fjh7z
[0m[2025-01-18T14:49:09.340517] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 14:49:06 : d139b201ac711e8548bb80b7e8705533 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T14:49:09.340586] [FLK_MGR] Running jobs: ['d139b201ac711e8548bb80b7e8705533']
[0m[2025-01-18T14:49:09.340593] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T14:49:09.340606] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T14:53:09.363582] [SCALING] Scaling started.
[0m[2025-01-18T14:53:09.363720] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T14:53:09.377236] [SCALING] Scaling finished.
[0m[2025-01-18T14:53:09.377271] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:53:09.395078] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:53:09.412965] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T14:53:09.435905] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 0 replica.
[0m[2025-01-18T14:53:14.455280] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T14:53:14.468596] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T14:53:14.481683] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T14:53:14.495779] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T14:53:14.509287] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T14:53:14.545922] [POD_MGR] Pod flink-jobmanager-7d7c784b74-fjh7z deleted
[0m[2025-01-18T14:53:16.446708] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:53:18.372138] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:53:18.372213] Reloading playbook: application/kafka
[0m[2025-01-18T14:53:24.294844] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T14:54:05.330952] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T14:54:05.331192] [EXPERIMENT] Run 2 completed. Start: 1737211734, End: 1737212045
[0m[2025-01-18T14:54:05.331198] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T14:54:15.332212] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T14:54:17.266561] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:54:19.191719] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:54:19.191803] [SCALING] Setting up experiment.


[0m[2025-01-18T14:54:19.191814] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:54:19.197313] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:54:19.213809] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T14:54:19.229487] [SCALING] Statefulset name to scale : flink-2000m-8192
[0m[2025-01-18T14:54:19.240228] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 1 replica.
[0m[2025-01-18T14:54:24.250357] [FLK_MGR] Running job.
[0m[2025-01-18T14:54:24.250390] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T14:54:24.631307] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-v9jh6
[0m[2025-01-18T14:54:28.690483] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0f1f686c1597ce3f3b8abc1c835543a2

[0m[2025-01-18T14:54:28.690529] [FLK_MGR] Running job id: 0f1f686c1597ce3f3b8abc1c835543a2
[0m[2025-01-18T14:54:28.690536] [FLK_MGR] Getting job info.
[0m[2025-01-18T14:54:28.707481] [FLK_MGR] Job plan response: {"plan":{"jid":"0f1f686c1597ce3f3b8abc1c835543a2","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T14:54:28.707618] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T14:54:29.088028] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-v9jh6
[0m[2025-01-18T14:54:30.527578] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 14:54:27 : 0f1f686c1597ce3f3b8abc1c835543a2 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T14:54:30.527648] [FLK_MGR] Running jobs: ['0f1f686c1597ce3f3b8abc1c835543a2']
[0m[2025-01-18T14:54:30.527655] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T14:54:30.527668] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T14:58:30.550708] [SCALING] Scaling started.
[0m[2025-01-18T14:58:30.550818] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T14:58:30.567640] [SCALING] Scaling finished.
[0m[2025-01-18T14:58:30.567673] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:58:30.586491] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:58:30.605195] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T14:58:30.628419] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 0 replica.
[0m[2025-01-18T14:58:40.656060] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T14:58:40.671514] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T14:58:40.688784] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T14:58:40.702531] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T14:58:40.716112] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T14:58:40.738737] [POD_MGR] Pod flink-jobmanager-7d7c784b74-v9jh6 deleted
[0m[2025-01-18T14:58:42.708805] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:58:44.638985] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T14:58:44.639069] Reloading playbook: application/kafka
[0m[2025-01-18T14:58:50.626980] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T14:59:31.650028] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T14:59:31.650297] [EXPERIMENT] Run 3 completed. Start: 1737212055, End: 1737212371
[0m[2025-01-18T14:59:31.650304] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T14:59:41.651319] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T14:59:43.554748] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:59:45.478484] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T14:59:45.478580] [SCALING] Setting up experiment.


[0m[2025-01-18T14:59:45.478594] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T14:59:45.484061] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T14:59:45.499475] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T14:59:45.514848] [SCALING] Statefulset name to scale : flink-2000m-8192
[0m[2025-01-18T14:59:45.525018] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 1 replica.
[0m[2025-01-18T14:59:50.535952] [FLK_MGR] Running job.
[0m[2025-01-18T14:59:50.535992] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T14:59:50.930151] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-g9zkh
[0m[2025-01-18T14:59:55.069292] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 601cd37f27400ec21e68ac2b28d4ef44

[0m[2025-01-18T14:59:55.069339] [FLK_MGR] Running job id: 601cd37f27400ec21e68ac2b28d4ef44
[0m[2025-01-18T14:59:55.069346] [FLK_MGR] Getting job info.
[0m[2025-01-18T14:59:55.086709] [FLK_MGR] Job plan response: {"plan":{"jid":"601cd37f27400ec21e68ac2b28d4ef44","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T14:59:55.086853] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T14:59:55.481322] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-g9zkh
[0m[2025-01-18T14:59:56.922328] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 14:59:54 : 601cd37f27400ec21e68ac2b28d4ef44 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T14:59:56.922397] [FLK_MGR] Running jobs: ['601cd37f27400ec21e68ac2b28d4ef44']
[0m[2025-01-18T14:59:56.922406] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T14:59:56.922419] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T15:03:56.945662] [SCALING] Scaling started.
[0m[2025-01-18T15:03:56.945764] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T15:03:56.957737] [SCALING] Scaling finished.
[0m[2025-01-18T15:03:56.957762] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:03:56.977694] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:03:56.994566] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T15:03:57.015181] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 0 replica.
[0m[2025-01-18T15:04:02.036796] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T15:04:02.052299] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T15:04:02.066342] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T15:04:02.081193] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T15:04:02.095228] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T15:04:02.120986] [POD_MGR] Pod flink-jobmanager-7d7c784b74-g9zkh deleted
[0m[2025-01-18T15:04:04.069468] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:04:05.993332] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:04:05.993422] Reloading playbook: application/kafka
[0m[2025-01-18T15:04:12.030258] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T15:04:53.030172] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T15:04:53.030788] [EXPERIMENT] Run 4 completed. Start: 1737212381, End: 1737212693
[0m[2025-01-18T15:04:53.030798] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T15:05:03.031853] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T15:05:04.980152] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:05:06.892726] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:05:06.892843] [SCALING] Setting up experiment.


[0m[2025-01-18T15:05:06.892858] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:05:06.898877] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:05:06.917294] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T15:05:06.935031] [SCALING] Statefulset name to scale : flink-2000m-8192
[0m[2025-01-18T15:05:06.945924] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 1 replica.
[0m[2025-01-18T15:05:11.957964] [FLK_MGR] Running job.
[0m[2025-01-18T15:05:11.957996] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T15:05:12.341661] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-sxbr2
[0m[2025-01-18T15:05:16.458828] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b7d844f8e9f2b279f9ac2cb8ddb41399

[0m[2025-01-18T15:05:16.458874] [FLK_MGR] Running job id: b7d844f8e9f2b279f9ac2cb8ddb41399
[0m[2025-01-18T15:05:16.458883] [FLK_MGR] Getting job info.
[0m[2025-01-18T15:05:16.475175] [FLK_MGR] Job plan response: {"plan":{"jid":"b7d844f8e9f2b279f9ac2cb8ddb41399","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T15:05:16.475360] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T15:05:18.426028] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sxbr2
[0m[2025-01-18T15:05:19.874679] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 15:05:15 : b7d844f8e9f2b279f9ac2cb8ddb41399 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T15:05:19.874733] [FLK_MGR] Running jobs: ['b7d844f8e9f2b279f9ac2cb8ddb41399']
[0m[2025-01-18T15:05:19.874741] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T15:05:19.874748] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T15:09:19.898531] [SCALING] Scaling started.
[0m[2025-01-18T15:09:19.898631] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T15:09:19.910511] [SCALING] Scaling finished.
[0m[2025-01-18T15:09:19.910541] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:09:19.930828] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:09:19.949959] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T15:09:19.973906] [STS_MGR] StatefulSet flink-2000m-8192 scaled to 0 replica.
[0m[2025-01-18T15:09:24.998935] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T15:09:25.013152] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T15:09:25.028761] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T15:09:25.045153] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T15:09:25.058375] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T15:09:25.087592] [POD_MGR] Pod flink-jobmanager-7d7c784b74-sxbr2 deleted
[0m[2025-01-18T15:09:27.010298] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:09:28.955433] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:09:28.955517] Reloading playbook: application/kafka
[0m[2025-01-18T15:09:34.983105] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T15:10:15.973039] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T15:10:15.974035] [EXPERIMENT] Run 5 completed. Start: 1737212703, End: 1737213015
[0m[2025-01-18T15:10:15.974071] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T15:10:28.262740] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T15:10:28.262829] [RESOURCE_E] Running experiment with 2000m cores and 16384 memory.
[0m[2025-01-18T15:10:35.561750] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T15:10:35.561999] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T15:10:37.486504] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:10:39.426132] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:10:39.426228] [SCALING] Setting up experiment.


[0m[2025-01-18T15:10:39.426241] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:10:39.432152] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:10:39.449451] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T15:10:39.467345] [SCALING] Statefulset name to scale : flink-2000m-16384
[0m[2025-01-18T15:10:39.478118] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 1 replica.
[0m[2025-01-18T15:10:44.487855] [FLK_MGR] Running job.
[0m[2025-01-18T15:10:44.487938] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T15:10:44.893795] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-7dzmd
[0m[2025-01-18T15:10:49.070749] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6d2ce80aee32498502b1255be971f722

[0m[2025-01-18T15:10:49.070813] [FLK_MGR] Running job id: 6d2ce80aee32498502b1255be971f722
[0m[2025-01-18T15:10:49.070824] [FLK_MGR] Getting job info.
[0m[2025-01-18T15:10:49.089269] [FLK_MGR] Job plan response: {"plan":{"jid":"6d2ce80aee32498502b1255be971f722","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T15:10:49.089428] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T15:10:49.463471] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-7dzmd
[0m[2025-01-18T15:10:50.907721] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 15:10:48 : 6d2ce80aee32498502b1255be971f722 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T15:10:50.907814] [FLK_MGR] Running jobs: ['6d2ce80aee32498502b1255be971f722']
[0m[2025-01-18T15:10:50.907823] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T15:10:50.907840] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T15:14:50.930089] [SCALING] Scaling started.
[0m[2025-01-18T15:14:50.930197] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T15:14:50.943821] [SCALING] Scaling finished.
[0m[2025-01-18T15:14:50.943861] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:14:50.963257] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:14:50.980107] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T15:14:51.002829] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 0 replica.
[0m[2025-01-18T15:14:56.022953] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T15:14:56.035971] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T15:14:56.050647] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T15:14:56.065496] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T15:14:56.079714] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T15:14:56.115113] [POD_MGR] Pod flink-jobmanager-7d7c784b74-7dzmd deleted
[0m[2025-01-18T15:14:58.035295] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:15:00.031634] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:15:00.031712] Reloading playbook: application/kafka
[0m[2025-01-18T15:15:06.092077] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T15:15:47.160828] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T15:15:47.161033] [EXPERIMENT] Run 1 completed. Start: 1737213035, End: 1737213347
[0m[2025-01-18T15:15:47.161041] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T15:15:57.161954] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T15:15:59.077768] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:16:01.015561] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:16:01.015659] [SCALING] Setting up experiment.


[0m[2025-01-18T15:16:01.015669] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:16:01.021473] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:16:01.039052] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T15:16:01.057817] [SCALING] Statefulset name to scale : flink-2000m-16384
[0m[2025-01-18T15:16:01.068360] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 1 replica.
[0m[2025-01-18T15:16:06.078957] [FLK_MGR] Running job.
[0m[2025-01-18T15:16:06.078982] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T15:16:06.475713] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-ctqr2
[0m[2025-01-18T15:16:10.517919] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 1c0e79521caae1ed1c521080c45cc6db

[0m[2025-01-18T15:16:10.517974] [FLK_MGR] Running job id: 1c0e79521caae1ed1c521080c45cc6db
[0m[2025-01-18T15:16:10.517986] [FLK_MGR] Getting job info.
[0m[2025-01-18T15:16:10.534680] [FLK_MGR] Job plan response: {"plan":{"jid":"1c0e79521caae1ed1c521080c45cc6db","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T15:16:10.534833] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T15:16:10.920558] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-ctqr2
[0m[2025-01-18T15:16:12.356266] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 15:16:09 : 1c0e79521caae1ed1c521080c45cc6db : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T15:16:12.356357] [FLK_MGR] Running jobs: ['1c0e79521caae1ed1c521080c45cc6db']
[0m[2025-01-18T15:16:12.356369] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T15:16:12.356394] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T15:20:12.382280] [SCALING] Scaling started.
[0m[2025-01-18T15:20:12.382427] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T15:20:12.399985] [SCALING] Scaling finished.
[0m[2025-01-18T15:20:12.400028] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:20:12.419121] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:20:12.439251] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T15:20:12.461602] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 0 replica.
[0m[2025-01-18T15:20:17.482741] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T15:20:17.496767] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T15:20:17.511568] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T15:20:17.526831] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T15:20:17.542052] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T15:20:17.565538] [POD_MGR] Pod flink-jobmanager-7d7c784b74-ctqr2 deleted
[0m[2025-01-18T15:20:19.501311] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:20:21.460820] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:20:21.460912] Reloading playbook: application/kafka
[0m[2025-01-18T15:20:27.478663] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T15:21:08.468988] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T15:21:08.469494] [EXPERIMENT] Run 2 completed. Start: 1737213357, End: 1737213668
[0m[2025-01-18T15:21:08.469503] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T15:21:18.470607] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T15:21:20.394613] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:21:22.345630] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:21:22.345740] [SCALING] Setting up experiment.


[0m[2025-01-18T15:21:22.345751] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:21:22.351659] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:21:22.370940] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T15:21:22.388491] [SCALING] Statefulset name to scale : flink-2000m-16384
[0m[2025-01-18T15:21:22.400747] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 1 replica.
[0m[2025-01-18T15:21:27.412665] [FLK_MGR] Running job.
[0m[2025-01-18T15:21:27.412714] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T15:21:27.814232] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-pd95x
[0m[2025-01-18T15:21:31.923323] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 33de9733adc1b4638351df3a6481d321

[0m[2025-01-18T15:21:31.923388] [FLK_MGR] Running job id: 33de9733adc1b4638351df3a6481d321
[0m[2025-01-18T15:21:31.923399] [FLK_MGR] Getting job info.
[0m[2025-01-18T15:21:31.941470] [FLK_MGR] Job plan response: {"plan":{"jid":"33de9733adc1b4638351df3a6481d321","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T15:21:31.941637] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T15:21:32.338523] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-pd95x
[0m[2025-01-18T15:21:33.759854] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 15:21:30 : 33de9733adc1b4638351df3a6481d321 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T15:21:33.759914] [FLK_MGR] Running jobs: ['33de9733adc1b4638351df3a6481d321']
[0m[2025-01-18T15:21:33.759923] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T15:21:33.759937] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T15:25:33.783520] [SCALING] Scaling started.
[0m[2025-01-18T15:25:33.783637] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T15:25:33.796456] [SCALING] Scaling finished.
[0m[2025-01-18T15:25:33.796482] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:25:33.816004] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:25:33.831877] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T15:25:33.854415] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 0 replica.
[0m[2025-01-18T15:25:43.881585] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T15:25:43.898886] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T15:25:43.914952] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T15:25:43.930027] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T15:25:43.943898] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T15:25:43.965108] [POD_MGR] Pod flink-jobmanager-7d7c784b74-pd95x deleted
[0m[2025-01-18T15:25:45.902068] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:25:47.869420] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:25:47.869499] Reloading playbook: application/kafka
[0m[2025-01-18T15:25:53.868642] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T15:26:34.881696] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T15:26:34.882006] [EXPERIMENT] Run 3 completed. Start: 1737213678, End: 1737213994
[0m[2025-01-18T15:26:34.882013] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T15:26:44.883254] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T15:26:46.811229] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:26:48.758131] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:26:48.758234] [SCALING] Setting up experiment.


[0m[2025-01-18T15:26:48.758249] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:26:48.765376] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:26:48.781358] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T15:26:48.798451] [SCALING] Statefulset name to scale : flink-2000m-16384
[0m[2025-01-18T15:26:48.809012] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 1 replica.
[0m[2025-01-18T15:26:53.820455] [FLK_MGR] Running job.
[0m[2025-01-18T15:26:53.820484] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T15:26:54.213199] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-b7cjt
[0m[2025-01-18T15:26:58.313536] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b6b5f9f289feafa489a9dabe76e659ee

[0m[2025-01-18T15:26:58.313585] [FLK_MGR] Running job id: b6b5f9f289feafa489a9dabe76e659ee
[0m[2025-01-18T15:26:58.313595] [FLK_MGR] Getting job info.
[0m[2025-01-18T15:26:58.332962] [FLK_MGR] Job plan response: {"plan":{"jid":"b6b5f9f289feafa489a9dabe76e659ee","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T15:26:58.333110] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T15:26:58.729282] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-b7cjt
[0m[2025-01-18T15:27:00.182294] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 15:26:57 : b6b5f9f289feafa489a9dabe76e659ee : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T15:27:00.182412] [FLK_MGR] Running jobs: ['b6b5f9f289feafa489a9dabe76e659ee']
[0m[2025-01-18T15:27:00.182424] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T15:27:00.182462] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T15:31:00.206040] [SCALING] Scaling started.
[0m[2025-01-18T15:31:00.206178] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T15:31:00.222895] [SCALING] Scaling finished.
[0m[2025-01-18T15:31:00.222933] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:31:00.241401] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:31:00.258024] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T15:31:00.278308] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 0 replica.
[0m[2025-01-18T15:31:05.297558] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T15:31:05.311146] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T15:31:05.324855] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T15:31:05.341888] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T15:31:05.355752] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T15:31:05.389979] [POD_MGR] Pod flink-jobmanager-7d7c784b74-b7cjt deleted
[0m[2025-01-18T15:31:07.328946] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:31:09.258871] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:31:09.258962] Reloading playbook: application/kafka
[0m[2025-01-18T15:31:15.278126] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T15:31:56.241436] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T15:31:56.241949] [EXPERIMENT] Run 4 completed. Start: 1737214004, End: 1737214316
[0m[2025-01-18T15:31:56.241957] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T15:32:06.242960] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T15:32:08.177021] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:32:10.126393] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:32:10.126498] [SCALING] Setting up experiment.


[0m[2025-01-18T15:32:10.126510] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:32:10.132779] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:32:10.152109] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T15:32:10.170325] [SCALING] Statefulset name to scale : flink-2000m-16384
[0m[2025-01-18T15:32:10.182712] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 1 replica.
[0m[2025-01-18T15:32:15.194893] [FLK_MGR] Running job.
[0m[2025-01-18T15:32:15.194927] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T15:32:15.581058] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xc8mf
[0m[2025-01-18T15:32:19.694365] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5c9456a513b2ea42fe757c073ad8fe42

[0m[2025-01-18T15:32:19.694426] [FLK_MGR] Running job id: 5c9456a513b2ea42fe757c073ad8fe42
[0m[2025-01-18T15:32:19.694435] [FLK_MGR] Getting job info.
[0m[2025-01-18T15:32:19.713557] [FLK_MGR] Job plan response: {"plan":{"jid":"5c9456a513b2ea42fe757c073ad8fe42","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T15:32:19.713707] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T15:32:20.159354] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xc8mf
[0m[2025-01-18T15:32:21.623841] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 15:32:18 : 5c9456a513b2ea42fe757c073ad8fe42 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T15:32:21.623937] [FLK_MGR] Running jobs: ['5c9456a513b2ea42fe757c073ad8fe42']
[0m[2025-01-18T15:32:21.623946] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T15:32:21.623959] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T15:36:21.647437] [SCALING] Scaling started.
[0m[2025-01-18T15:36:21.647508] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T15:36:21.662161] [SCALING] Scaling finished.
[0m[2025-01-18T15:36:21.662184] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:36:21.682477] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:36:21.699277] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T15:36:21.719746] [STS_MGR] StatefulSet flink-2000m-16384 scaled to 0 replica.
[0m[2025-01-18T15:36:26.741328] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T15:36:26.754643] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T15:36:26.767706] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T15:36:26.780634] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T15:36:26.793447] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T15:36:26.833578] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xc8mf deleted
[0m[2025-01-18T15:36:28.751134] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:36:30.810477] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:36:30.810590] Reloading playbook: application/kafka
[0m[2025-01-18T15:36:36.798252] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T15:37:17.833109] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T15:37:17.833477] [EXPERIMENT] Run 5 completed. Start: 1737214326, End: 1737214637
[0m[2025-01-18T15:37:17.833485] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T15:37:30.117279] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T15:37:30.117369] [RESOURCE_E] Running experiment with 2000m cores and 32768 memory.
[0m[2025-01-18T15:37:37.441598] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T15:37:37.441710] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T15:37:39.363893] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:37:41.315336] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:37:41.315426] [SCALING] Setting up experiment.


[0m[2025-01-18T15:37:41.315438] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:37:41.321406] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:37:41.339282] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T15:37:41.356772] [SCALING] Statefulset name to scale : flink-2000m-32768
[0m[2025-01-18T15:37:41.367601] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 1 replica.
[0m[2025-01-18T15:38:56.455912] [FLK_MGR] Running job.
[0m[2025-01-18T15:38:56.455956] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T15:38:56.838256] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-5mvgf
[0m[2025-01-18T15:39:00.907332] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 55b80b75507a65fe9fdd60b0164dee09

[0m[2025-01-18T15:39:00.907386] [FLK_MGR] Running job id: 55b80b75507a65fe9fdd60b0164dee09
[0m[2025-01-18T15:39:00.907394] [FLK_MGR] Getting job info.
[0m[2025-01-18T15:39:00.922606] [FLK_MGR] Job plan response: {"plan":{"jid":"55b80b75507a65fe9fdd60b0164dee09","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T15:39:00.922742] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T15:39:02.782833] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-5mvgf
[0m[2025-01-18T15:39:04.207251] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 15:38:59 : 55b80b75507a65fe9fdd60b0164dee09 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T15:39:04.207311] [FLK_MGR] Running jobs: ['55b80b75507a65fe9fdd60b0164dee09']
[0m[2025-01-18T15:39:04.207319] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T15:39:04.207327] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T15:43:04.229990] [SCALING] Scaling started.
[0m[2025-01-18T15:43:04.230038] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T15:43:04.241834] [SCALING] Scaling finished.
[0m[2025-01-18T15:43:04.241855] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:43:04.259720] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:43:04.276354] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T15:43:04.297049] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 0 replica.
[0m[2025-01-18T15:43:04.314209] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T15:43:04.327391] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T15:43:04.340986] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T15:43:04.354458] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T15:43:04.367363] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T15:43:04.399339] [POD_MGR] Pod flink-jobmanager-7d7c784b74-5mvgf deleted
[0m[2025-01-18T15:43:06.308629] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:43:08.241291] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:43:08.241369] Reloading playbook: application/kafka
[0m[2025-01-18T15:43:14.151704] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T15:43:55.141094] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T15:43:55.141361] [EXPERIMENT] Run 1 completed. Start: 1737214657, End: 1737215035
[0m[2025-01-18T15:43:55.141368] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T15:44:05.142385] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T15:44:07.031416] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:44:08.956575] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:44:08.956668] [SCALING] Setting up experiment.


[0m[2025-01-18T15:44:08.956683] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:44:08.963793] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:44:08.981889] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T15:44:08.998503] [SCALING] Statefulset name to scale : flink-2000m-32768
[0m[2025-01-18T15:44:09.009135] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 1 replica.
[0m[2025-01-18T15:45:24.094810] [FLK_MGR] Running job.
[0m[2025-01-18T15:45:24.094922] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T15:45:24.490152] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jt4lt
[0m[2025-01-18T15:45:28.483698] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9fe0ff2c6e622c6df2a730b3597842bc

[0m[2025-01-18T15:45:28.483747] [FLK_MGR] Running job id: 9fe0ff2c6e622c6df2a730b3597842bc
[0m[2025-01-18T15:45:28.483754] [FLK_MGR] Getting job info.
[0m[2025-01-18T15:45:28.499814] [FLK_MGR] Job plan response: {"plan":{"jid":"9fe0ff2c6e622c6df2a730b3597842bc","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T15:45:28.499954] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T15:45:28.877463] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jt4lt
[0m[2025-01-18T15:45:30.296203] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 15:45:27 : 9fe0ff2c6e622c6df2a730b3597842bc : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T15:45:30.296277] [FLK_MGR] Running jobs: ['9fe0ff2c6e622c6df2a730b3597842bc']
[0m[2025-01-18T15:45:30.296285] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T15:45:30.296298] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T15:49:30.319200] [SCALING] Scaling started.
[0m[2025-01-18T15:49:30.319306] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T15:49:30.333948] [SCALING] Scaling finished.
[0m[2025-01-18T15:49:30.333978] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:49:30.352726] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:49:30.369507] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T15:49:30.393724] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 0 replica.
[0m[2025-01-18T15:49:30.410596] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T15:49:30.425094] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T15:49:30.439263] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T15:49:30.452271] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T15:49:30.467152] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T15:49:30.490516] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jt4lt deleted
[0m[2025-01-18T15:49:32.533957] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:49:34.489925] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:49:34.490027] Reloading playbook: application/kafka
[0m[2025-01-18T15:49:40.479732] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T15:50:21.527740] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T15:50:21.527989] [EXPERIMENT] Run 2 completed. Start: 1737215045, End: 1737215421
[0m[2025-01-18T15:50:21.527997] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T15:50:31.529083] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T15:50:33.454519] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:50:35.368319] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:50:35.368518] [SCALING] Setting up experiment.


[0m[2025-01-18T15:50:35.368567] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:50:35.374079] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:50:35.391108] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T15:50:35.408435] [SCALING] Statefulset name to scale : flink-2000m-32768
[0m[2025-01-18T15:50:35.432608] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 1 replica.
[0m[2025-01-18T15:51:50.518961] [FLK_MGR] Running job.
[0m[2025-01-18T15:51:50.519052] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T15:51:50.915960] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-2f84x
[0m[2025-01-18T15:51:54.934619] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8a6b3e295d421ff8d6273ff887638c2c

[0m[2025-01-18T15:51:54.934667] [FLK_MGR] Running job id: 8a6b3e295d421ff8d6273ff887638c2c
[0m[2025-01-18T15:51:54.934676] [FLK_MGR] Getting job info.
[0m[2025-01-18T15:51:54.949965] [FLK_MGR] Job plan response: {"plan":{"jid":"8a6b3e295d421ff8d6273ff887638c2c","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T15:51:54.950105] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T15:51:55.321817] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-2f84x
[0m[2025-01-18T15:51:56.767977] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 15:51:53 : 8a6b3e295d421ff8d6273ff887638c2c : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T15:51:56.768040] [FLK_MGR] Running jobs: ['8a6b3e295d421ff8d6273ff887638c2c']
[0m[2025-01-18T15:51:56.768048] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T15:51:56.768058] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T15:55:56.791460] [SCALING] Scaling started.
[0m[2025-01-18T15:55:56.791567] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T15:55:56.805208] [SCALING] Scaling finished.
[0m[2025-01-18T15:55:56.805233] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:55:56.825297] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:55:56.842440] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T15:55:56.869117] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 0 replica.
[0m[2025-01-18T15:55:56.888042] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T15:55:56.902322] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T15:55:56.916933] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T15:55:56.930626] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T15:55:56.943586] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T15:55:56.966947] [POD_MGR] Pod flink-jobmanager-7d7c784b74-2f84x deleted
[0m[2025-01-18T15:55:58.913959] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:56:00.883225] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T15:56:00.883324] Reloading playbook: application/kafka
[0m[2025-01-18T15:56:06.854252] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T15:56:47.886751] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T15:56:47.887031] [EXPERIMENT] Run 3 completed. Start: 1737215431, End: 1737215807
[0m[2025-01-18T15:56:47.887038] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T15:56:57.888092] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T15:56:59.812073] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:57:01.722884] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T15:57:01.722967] [SCALING] Setting up experiment.


[0m[2025-01-18T15:57:01.722981] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T15:57:01.741731] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T15:57:01.769245] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T15:57:01.791427] [SCALING] Statefulset name to scale : flink-2000m-32768
[0m[2025-01-18T15:57:01.801385] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 1 replica.
[0m[2025-01-18T15:58:16.890816] [FLK_MGR] Running job.
[0m[2025-01-18T15:58:16.890934] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T15:58:17.296318] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-gmvmp
[0m[2025-01-18T15:58:21.395131] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 823eb1f2700aa59039addb55908a0bf6

[0m[2025-01-18T15:58:21.395179] [FLK_MGR] Running job id: 823eb1f2700aa59039addb55908a0bf6
[0m[2025-01-18T15:58:21.395187] [FLK_MGR] Getting job info.
[0m[2025-01-18T15:58:21.411930] [FLK_MGR] Job plan response: {"plan":{"jid":"823eb1f2700aa59039addb55908a0bf6","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T15:58:21.412076] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T15:58:21.786906] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-gmvmp
[0m[2025-01-18T15:58:23.231984] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 15:58:20 : 823eb1f2700aa59039addb55908a0bf6 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T15:58:23.232046] [FLK_MGR] Running jobs: ['823eb1f2700aa59039addb55908a0bf6']
[0m[2025-01-18T15:58:23.232055] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T15:58:23.232068] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T16:02:23.254549] [SCALING] Scaling started.
[0m[2025-01-18T16:02:23.254606] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T16:02:23.269667] [SCALING] Scaling finished.
[0m[2025-01-18T16:02:23.269698] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:02:23.287438] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:02:23.304654] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T16:02:23.329173] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 0 replica.
[0m[2025-01-18T16:02:23.344278] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T16:02:23.357656] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T16:02:23.371181] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T16:02:23.384718] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T16:02:23.398503] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T16:02:23.422884] [POD_MGR] Pod flink-jobmanager-7d7c784b74-gmvmp deleted
[0m[2025-01-18T16:02:25.372476] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:02:27.351188] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:02:27.351285] Reloading playbook: application/kafka
[0m[2025-01-18T16:02:33.358897] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T16:03:14.363005] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T16:03:14.363280] [EXPERIMENT] Run 4 completed. Start: 1737215817, End: 1737216194
[0m[2025-01-18T16:03:14.363287] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T16:03:24.364516] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T16:03:26.264285] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:03:28.206627] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:03:28.206724] [SCALING] Setting up experiment.


[0m[2025-01-18T16:03:28.206735] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:03:28.212801] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:03:28.230423] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T16:03:28.246404] [SCALING] Statefulset name to scale : flink-2000m-32768
[0m[2025-01-18T16:03:28.256477] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 1 replica.
[0m[2025-01-18T16:04:43.343039] [FLK_MGR] Running job.
[0m[2025-01-18T16:04:43.343125] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T16:04:43.729893] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xxr4v
[0m[2025-01-18T16:04:47.818404] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6cfeae05793e615ff1fba89700a41f7d

[0m[2025-01-18T16:04:47.818454] [FLK_MGR] Running job id: 6cfeae05793e615ff1fba89700a41f7d
[0m[2025-01-18T16:04:47.818463] [FLK_MGR] Getting job info.
[0m[2025-01-18T16:04:47.834449] [FLK_MGR] Job plan response: {"plan":{"jid":"6cfeae05793e615ff1fba89700a41f7d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T16:04:47.834604] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T16:04:48.214112] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xxr4v
[0m[2025-01-18T16:04:49.629090] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 16:04:46 : 6cfeae05793e615ff1fba89700a41f7d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T16:04:49.629162] [FLK_MGR] Running jobs: ['6cfeae05793e615ff1fba89700a41f7d']
[0m[2025-01-18T16:04:49.629170] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T16:04:49.629184] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T16:08:49.654438] [SCALING] Scaling started.
[0m[2025-01-18T16:08:49.654565] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T16:08:49.668945] [SCALING] Scaling finished.
[0m[2025-01-18T16:08:49.668980] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:08:49.688947] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:08:49.708794] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T16:08:49.730792] [STS_MGR] StatefulSet flink-2000m-32768 scaled to 0 replica.
[0m[2025-01-18T16:08:49.746501] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T16:08:49.762608] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T16:08:49.777092] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T16:08:49.790421] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T16:08:49.803268] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T16:08:49.839154] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xxr4v deleted
[0m[2025-01-18T16:08:51.770914] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:08:53.708320] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:08:53.708407] Reloading playbook: application/kafka
[0m[2025-01-18T16:08:59.643710] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T16:09:40.717573] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T16:09:40.717985] [EXPERIMENT] Run 5 completed. Start: 1737216204, End: 1737216580
[0m[2025-01-18T16:09:40.717993] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T16:09:52.968282] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T16:09:52.968380] [RESOURCE_E] Running experiment with 4000m cores and 1024 memory.
[0m[2025-01-18T16:10:00.255757] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T16:10:00.255849] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T16:10:02.199948] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:10:04.127395] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:10:04.127649] [SCALING] Setting up experiment.


[0m[2025-01-18T16:10:04.127756] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:10:04.133926] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:10:04.150638] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T16:10:04.167972] [SCALING] Statefulset name to scale : flink-4000m-1024
[0m[2025-01-18T16:10:04.177540] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 1 replica.
[0m[2025-01-18T16:10:09.188292] [FLK_MGR] Running job.
[0m[2025-01-18T16:10:09.188330] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T16:10:09.586901] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-wgjrn
[0m[2025-01-18T16:10:13.693421] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 4432d779dabdc6086207d5ac8b323333

[0m[2025-01-18T16:10:13.693472] [FLK_MGR] Running job id: 4432d779dabdc6086207d5ac8b323333
[0m[2025-01-18T16:10:13.693480] [FLK_MGR] Getting job info.
[0m[2025-01-18T16:10:13.712276] [FLK_MGR] Job plan response: {"plan":{"jid":"4432d779dabdc6086207d5ac8b323333","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T16:10:13.712420] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T16:10:14.085610] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-wgjrn
[0m[2025-01-18T16:10:15.533796] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 16:10:12 : 4432d779dabdc6086207d5ac8b323333 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T16:10:15.533862] [FLK_MGR] Running jobs: ['4432d779dabdc6086207d5ac8b323333']
[0m[2025-01-18T16:10:15.533870] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T16:10:15.533881] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T16:14:15.557443] [SCALING] Scaling started.
[0m[2025-01-18T16:14:15.557726] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T16:14:15.572602] [SCALING] Scaling finished.
[0m[2025-01-18T16:14:15.572642] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:14:15.591478] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:14:15.607773] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T16:14:15.629628] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 0 replica.
[0m[2025-01-18T16:14:20.650629] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T16:14:20.664854] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T16:14:20.679682] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T16:14:20.694778] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T16:14:20.711247] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T16:14:20.736325] [POD_MGR] Pod flink-jobmanager-7d7c784b74-wgjrn deleted
[0m[2025-01-18T16:14:22.672106] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:14:24.622535] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:14:24.622626] Reloading playbook: application/kafka
[0m[2025-01-18T16:14:30.574420] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T16:15:11.584106] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T16:15:11.584456] [EXPERIMENT] Run 1 completed. Start: 1737216600, End: 1737216911
[0m[2025-01-18T16:15:11.584464] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T16:15:21.585597] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T16:15:23.502641] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:15:25.434589] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:15:25.434697] [SCALING] Setting up experiment.


[0m[2025-01-18T16:15:25.434710] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:15:25.440544] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:15:25.462092] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T16:15:25.478761] [SCALING] Statefulset name to scale : flink-4000m-1024
[0m[2025-01-18T16:15:25.488504] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 1 replica.
[0m[2025-01-18T16:15:30.498526] [FLK_MGR] Running job.
[0m[2025-01-18T16:15:30.498559] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T16:15:30.887247] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-h4ktv
[0m[2025-01-18T16:15:34.972968] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 89abeddde914ce79ddb142ad6dae76c6

[0m[2025-01-18T16:15:34.973017] [FLK_MGR] Running job id: 89abeddde914ce79ddb142ad6dae76c6
[0m[2025-01-18T16:15:34.973025] [FLK_MGR] Getting job info.
[0m[2025-01-18T16:15:34.991651] [FLK_MGR] Job plan response: {"plan":{"jid":"89abeddde914ce79ddb142ad6dae76c6","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T16:15:34.991792] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T16:15:36.858021] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-h4ktv
[0m[2025-01-18T16:15:38.310642] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 16:15:34 : 89abeddde914ce79ddb142ad6dae76c6 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T16:15:38.310699] [FLK_MGR] Running jobs: ['89abeddde914ce79ddb142ad6dae76c6']
[0m[2025-01-18T16:15:38.310707] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T16:15:38.310714] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T16:19:38.333914] [SCALING] Scaling started.
[0m[2025-01-18T16:19:38.333963] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T16:19:38.347505] [SCALING] Scaling finished.
[0m[2025-01-18T16:19:38.347525] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:19:38.365732] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:19:38.384454] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T16:19:38.404354] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 0 replica.
[0m[2025-01-18T16:19:43.424928] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T16:19:43.439581] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T16:19:43.452740] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T16:19:43.468092] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T16:19:43.482532] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T16:19:43.509016] [POD_MGR] Pod flink-jobmanager-7d7c784b74-h4ktv deleted
[0m[2025-01-18T16:19:45.418215] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:19:47.330068] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:19:47.330163] Reloading playbook: application/kafka
[0m[2025-01-18T16:19:53.320408] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T16:20:34.351950] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T16:20:34.352793] [EXPERIMENT] Run 2 completed. Start: 1737216921, End: 1737217234
[0m[2025-01-18T16:20:34.352805] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T16:20:44.353784] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T16:20:46.255400] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:20:48.212192] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:20:48.212271] [SCALING] Setting up experiment.


[0m[2025-01-18T16:20:48.212284] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:20:48.218435] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:20:48.236276] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T16:20:48.254353] [SCALING] Statefulset name to scale : flink-4000m-1024
[0m[2025-01-18T16:20:48.264365] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 1 replica.
[0m[2025-01-18T16:20:53.274291] [FLK_MGR] Running job.
[0m[2025-01-18T16:20:53.274317] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T16:20:53.651289] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mcpk2
[0m[2025-01-18T16:20:57.701626] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 7049ac4e2e034bbd59fa3eb8c9b24682

[0m[2025-01-18T16:20:57.701678] [FLK_MGR] Running job id: 7049ac4e2e034bbd59fa3eb8c9b24682
[0m[2025-01-18T16:20:57.701684] [FLK_MGR] Getting job info.
[0m[2025-01-18T16:20:57.718769] [FLK_MGR] Job plan response: {"plan":{"jid":"7049ac4e2e034bbd59fa3eb8c9b24682","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T16:20:57.718901] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T16:20:58.097837] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mcpk2
[0m[2025-01-18T16:20:59.510258] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 16:20:56 : 7049ac4e2e034bbd59fa3eb8c9b24682 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T16:20:59.510316] [FLK_MGR] Running jobs: ['7049ac4e2e034bbd59fa3eb8c9b24682']
[0m[2025-01-18T16:20:59.510325] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T16:20:59.510337] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T16:24:59.533302] [SCALING] Scaling started.
[0m[2025-01-18T16:24:59.533357] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T16:24:59.548345] [SCALING] Scaling finished.
[0m[2025-01-18T16:24:59.548369] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:24:59.565844] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:24:59.583881] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T16:24:59.608467] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 0 replica.
[0m[2025-01-18T16:25:09.634853] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T16:25:09.647601] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T16:25:09.660994] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T16:25:09.675559] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T16:25:09.689284] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T16:25:09.713883] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mcpk2 deleted
[0m[2025-01-18T16:25:11.676797] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:25:13.592227] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:25:13.592301] Reloading playbook: application/kafka
[0m[2025-01-18T16:25:19.542434] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T16:26:00.527723] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T16:26:00.528479] [EXPERIMENT] Run 3 completed. Start: 1737217244, End: 1737217560
[0m[2025-01-18T16:26:00.528485] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T16:26:10.529492] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T16:26:12.448738] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:26:14.369342] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:26:14.369434] [SCALING] Setting up experiment.


[0m[2025-01-18T16:26:14.369446] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:26:14.374656] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:26:14.391319] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T16:26:14.407999] [SCALING] Statefulset name to scale : flink-4000m-1024
[0m[2025-01-18T16:26:14.417770] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 1 replica.
[0m[2025-01-18T16:26:19.428854] [FLK_MGR] Running job.
[0m[2025-01-18T16:26:19.428888] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T16:26:19.806423] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-j8tkq
[0m[2025-01-18T16:26:23.919237] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID c283744f70125f6fb3cf0f17b845236e

[0m[2025-01-18T16:26:23.919289] [FLK_MGR] Running job id: c283744f70125f6fb3cf0f17b845236e
[0m[2025-01-18T16:26:23.919298] [FLK_MGR] Getting job info.
[0m[2025-01-18T16:26:23.936478] [FLK_MGR] Job plan response: {"plan":{"jid":"c283744f70125f6fb3cf0f17b845236e","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T16:26:23.936670] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T16:26:24.311251] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-j8tkq
[0m[2025-01-18T16:26:25.740229] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 16:26:22 : c283744f70125f6fb3cf0f17b845236e : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T16:26:25.740291] [FLK_MGR] Running jobs: ['c283744f70125f6fb3cf0f17b845236e']
[0m[2025-01-18T16:26:25.740301] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T16:26:25.740313] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T16:30:25.763721] [SCALING] Scaling started.
[0m[2025-01-18T16:30:25.763770] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T16:30:25.777861] [SCALING] Scaling finished.
[0m[2025-01-18T16:30:25.777889] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:30:25.798520] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:30:25.816116] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T16:30:25.837456] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 0 replica.
[0m[2025-01-18T16:30:30.859411] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T16:30:30.873384] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T16:30:30.889726] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T16:30:30.902618] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T16:30:30.915965] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T16:30:30.949289] [POD_MGR] Pod flink-jobmanager-7d7c784b74-j8tkq deleted
[0m[2025-01-18T16:30:32.871074] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:30:34.922512] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:30:34.922592] Reloading playbook: application/kafka
[0m[2025-01-18T16:30:40.927039] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T16:31:21.922660] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T16:31:21.922883] [EXPERIMENT] Run 4 completed. Start: 1737217570, End: 1737217881
[0m[2025-01-18T16:31:21.922890] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T16:31:31.923894] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T16:31:33.838270] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:31:35.742119] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:31:35.742222] [SCALING] Setting up experiment.


[0m[2025-01-18T16:31:35.742234] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:31:35.748434] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:31:35.767228] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T16:31:35.783712] [SCALING] Statefulset name to scale : flink-4000m-1024
[0m[2025-01-18T16:31:35.794810] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 1 replica.
[0m[2025-01-18T16:31:40.804786] [FLK_MGR] Running job.
[0m[2025-01-18T16:31:40.804812] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T16:31:41.191246] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-shsps
[0m[2025-01-18T16:31:45.278679] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8c4c97b3dc7a902652ce04acd247bde1

[0m[2025-01-18T16:31:45.278727] [FLK_MGR] Running job id: 8c4c97b3dc7a902652ce04acd247bde1
[0m[2025-01-18T16:31:45.278736] [FLK_MGR] Getting job info.
[0m[2025-01-18T16:31:45.295706] [FLK_MGR] Job plan response: {"plan":{"jid":"8c4c97b3dc7a902652ce04acd247bde1","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T16:31:45.295845] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T16:31:45.673414] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-shsps
[0m[2025-01-18T16:31:47.120729] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 16:31:44 : 8c4c97b3dc7a902652ce04acd247bde1 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T16:31:47.120790] [FLK_MGR] Running jobs: ['8c4c97b3dc7a902652ce04acd247bde1']
[0m[2025-01-18T16:31:47.120797] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T16:31:47.120808] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T16:35:47.144643] [SCALING] Scaling started.
[0m[2025-01-18T16:35:47.144700] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T16:35:47.161776] [SCALING] Scaling finished.
[0m[2025-01-18T16:35:47.161807] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:35:47.183273] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:35:47.199621] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T16:35:47.222850] [STS_MGR] StatefulSet flink-4000m-1024 scaled to 0 replica.
[0m[2025-01-18T16:35:52.244391] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T16:35:52.259486] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T16:35:52.275438] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T16:35:52.289937] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T16:35:52.303681] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T16:35:52.337644] [POD_MGR] Pod flink-jobmanager-7d7c784b74-shsps deleted
[0m[2025-01-18T16:35:54.243555] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:35:56.228163] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:35:56.228259] Reloading playbook: application/kafka
[0m[2025-01-18T16:36:02.240408] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T16:36:43.208785] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T16:36:43.209015] [EXPERIMENT] Run 5 completed. Start: 1737217891, End: 1737218203
[0m[2025-01-18T16:36:43.209022] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T16:36:55.500324] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T16:36:55.500408] [RESOURCE_E] Running experiment with 4000m cores and 2048 memory.
[0m[2025-01-18T16:37:02.788160] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T16:37:02.788243] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T16:37:04.702679] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:37:06.656500] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:37:06.656590] [SCALING] Setting up experiment.


[0m[2025-01-18T16:37:06.656601] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:37:06.663818] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:37:06.681054] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T16:37:06.699503] [SCALING] Statefulset name to scale : flink-4000m-2048
[0m[2025-01-18T16:37:06.712308] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 1 replica.
[0m[2025-01-18T16:37:11.722365] [FLK_MGR] Running job.
[0m[2025-01-18T16:37:11.722395] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T16:37:12.105156] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-2q96z
[0m[2025-01-18T16:37:16.150395] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 330e091fad883abdc387d3117dda81ca

[0m[2025-01-18T16:37:16.150469] [FLK_MGR] Running job id: 330e091fad883abdc387d3117dda81ca
[0m[2025-01-18T16:37:16.150481] [FLK_MGR] Getting job info.
[0m[2025-01-18T16:37:16.172473] [FLK_MGR] Job plan response: {"plan":{"jid":"330e091fad883abdc387d3117dda81ca","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T16:37:16.172622] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T16:37:16.589272] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-2q96z
[0m[2025-01-18T16:37:18.003228] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 16:37:15 : 330e091fad883abdc387d3117dda81ca : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T16:37:18.003287] [FLK_MGR] Running jobs: ['330e091fad883abdc387d3117dda81ca']
[0m[2025-01-18T16:37:18.003295] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T16:37:18.003312] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T16:41:18.026501] [SCALING] Scaling started.
[0m[2025-01-18T16:41:18.026570] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T16:41:18.042428] [SCALING] Scaling finished.
[0m[2025-01-18T16:41:18.042462] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:41:18.059398] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:41:18.076068] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T16:41:18.099162] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 0 replica.
[0m[2025-01-18T16:41:23.121288] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T16:41:23.135820] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T16:41:23.150068] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T16:41:23.164274] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T16:41:23.181392] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T16:41:23.212150] [POD_MGR] Pod flink-jobmanager-7d7c784b74-2q96z deleted
[0m[2025-01-18T16:41:25.096462] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:41:27.036880] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:41:27.037001] Reloading playbook: application/kafka
[0m[2025-01-18T16:41:33.096260] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T16:42:14.124748] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T16:42:14.125055] [EXPERIMENT] Run 1 completed. Start: 1737218222, End: 1737218534
[0m[2025-01-18T16:42:14.125070] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T16:42:24.126037] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T16:42:26.044189] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:42:27.942577] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:42:27.942654] [SCALING] Setting up experiment.


[0m[2025-01-18T16:42:27.942664] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:42:27.947965] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:42:27.965584] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T16:42:27.982582] [SCALING] Statefulset name to scale : flink-4000m-2048
[0m[2025-01-18T16:42:27.992903] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 1 replica.
[0m[2025-01-18T16:42:33.003700] [FLK_MGR] Running job.
[0m[2025-01-18T16:42:33.003726] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T16:42:33.393293] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-7plvf
[0m[2025-01-18T16:42:37.430919] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8b4a73fbc109d89160de0cc2f3374bf6

[0m[2025-01-18T16:42:37.430976] [FLK_MGR] Running job id: 8b4a73fbc109d89160de0cc2f3374bf6
[0m[2025-01-18T16:42:37.430985] [FLK_MGR] Getting job info.
[0m[2025-01-18T16:42:37.449956] [FLK_MGR] Job plan response: {"plan":{"jid":"8b4a73fbc109d89160de0cc2f3374bf6","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T16:42:37.450110] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T16:42:37.830389] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-7plvf
[0m[2025-01-18T16:42:39.268141] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 16:42:36 : 8b4a73fbc109d89160de0cc2f3374bf6 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T16:42:39.268212] [FLK_MGR] Running jobs: ['8b4a73fbc109d89160de0cc2f3374bf6']
[0m[2025-01-18T16:42:39.268222] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T16:42:39.268236] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T16:46:39.291081] [SCALING] Scaling started.
[0m[2025-01-18T16:46:39.291194] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T16:46:39.306121] [SCALING] Scaling finished.
[0m[2025-01-18T16:46:39.306151] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:46:39.324085] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:46:39.342918] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T16:46:39.364043] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 0 replica.
[0m[2025-01-18T16:46:49.389104] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T16:46:49.403988] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T16:46:49.418041] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T16:46:49.431886] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T16:46:49.446144] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T16:46:49.472380] [POD_MGR] Pod flink-jobmanager-7d7c784b74-7plvf deleted
[0m[2025-01-18T16:46:51.414559] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:46:53.320391] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:46:53.320484] Reloading playbook: application/kafka
[0m[2025-01-18T16:46:59.363956] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T16:47:40.355183] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T16:47:40.355416] [EXPERIMENT] Run 2 completed. Start: 1737218544, End: 1737218860
[0m[2025-01-18T16:47:40.355423] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T16:47:50.356399] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T16:47:52.270146] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:47:54.183593] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:47:54.183678] [SCALING] Setting up experiment.


[0m[2025-01-18T16:47:54.183689] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:47:54.189050] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:47:54.207190] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T16:47:54.223511] [SCALING] Statefulset name to scale : flink-4000m-2048
[0m[2025-01-18T16:47:54.236366] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 1 replica.
[0m[2025-01-18T16:47:59.248784] [FLK_MGR] Running job.
[0m[2025-01-18T16:47:59.248867] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T16:47:59.635685] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-6k82z
[0m[2025-01-18T16:48:03.758646] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID e5d5445d7e1ceeba3094b71218328711

[0m[2025-01-18T16:48:03.758696] [FLK_MGR] Running job id: e5d5445d7e1ceeba3094b71218328711
[0m[2025-01-18T16:48:03.758704] [FLK_MGR] Getting job info.
[0m[2025-01-18T16:48:03.775758] [FLK_MGR] Job plan response: {"plan":{"jid":"e5d5445d7e1ceeba3094b71218328711","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T16:48:03.775908] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T16:48:05.581350] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-6k82z
[0m[2025-01-18T16:48:07.004360] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 16:48:02 : e5d5445d7e1ceeba3094b71218328711 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T16:48:07.004417] [FLK_MGR] Running jobs: ['e5d5445d7e1ceeba3094b71218328711']
[0m[2025-01-18T16:48:07.004424] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T16:48:07.004433] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T16:52:07.032293] [SCALING] Scaling started.
[0m[2025-01-18T16:52:07.032387] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T16:52:07.047321] [SCALING] Scaling finished.
[0m[2025-01-18T16:52:07.047341] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:52:07.065237] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:52:07.085218] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T16:52:07.107621] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 0 replica.
[0m[2025-01-18T16:52:12.129790] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T16:52:12.145859] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T16:52:12.161727] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T16:52:12.176412] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T16:52:12.191470] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T16:52:12.224037] [POD_MGR] Pod flink-jobmanager-7d7c784b74-6k82z deleted
[0m[2025-01-18T16:52:14.154946] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:52:16.223646] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:52:16.223749] Reloading playbook: application/kafka
[0m[2025-01-18T16:52:22.239403] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T16:53:03.220652] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T16:53:03.220883] [EXPERIMENT] Run 3 completed. Start: 1737218870, End: 1737219183
[0m[2025-01-18T16:53:03.220890] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T16:53:13.221885] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T16:53:15.127565] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:53:17.012663] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:53:17.012750] [SCALING] Setting up experiment.


[0m[2025-01-18T16:53:17.012760] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:53:17.018798] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:53:17.035712] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T16:53:17.053763] [SCALING] Statefulset name to scale : flink-4000m-2048
[0m[2025-01-18T16:53:17.064384] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 1 replica.
[0m[2025-01-18T16:53:22.074265] [FLK_MGR] Running job.
[0m[2025-01-18T16:53:22.074294] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T16:53:22.458863] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-p4g49
[0m[2025-01-18T16:53:26.566367] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 69355c0326e16dcd474f062a401cd7d2

[0m[2025-01-18T16:53:26.566961] [FLK_MGR] Running job id: 69355c0326e16dcd474f062a401cd7d2
[0m[2025-01-18T16:53:26.566999] [FLK_MGR] Getting job info.
[0m[2025-01-18T16:53:26.583829] [FLK_MGR] Job plan response: {"plan":{"jid":"69355c0326e16dcd474f062a401cd7d2","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T16:53:26.584004] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T16:53:26.961610] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-p4g49
[0m[2025-01-18T16:53:28.388444] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 16:53:25 : 69355c0326e16dcd474f062a401cd7d2 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T16:53:28.388501] [FLK_MGR] Running jobs: ['69355c0326e16dcd474f062a401cd7d2']
[0m[2025-01-18T16:53:28.388509] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T16:53:28.388522] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T16:57:28.410810] [SCALING] Scaling started.
[0m[2025-01-18T16:57:28.410944] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T16:57:28.423326] [SCALING] Scaling finished.
[0m[2025-01-18T16:57:28.423350] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:57:28.441198] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:57:28.456901] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T16:57:28.482251] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 0 replica.
[0m[2025-01-18T16:57:33.503926] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T16:57:33.518837] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T16:57:33.533324] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T16:57:33.547867] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T16:57:33.562085] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T16:57:33.590180] [POD_MGR] Pod flink-jobmanager-7d7c784b74-p4g49 deleted
[0m[2025-01-18T16:57:35.476318] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:57:37.457674] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T16:57:37.457780] Reloading playbook: application/kafka
[0m[2025-01-18T16:57:43.508671] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T16:58:24.456426] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T16:58:24.456664] [EXPERIMENT] Run 4 completed. Start: 1737219193, End: 1737219504
[0m[2025-01-18T16:58:24.456672] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T16:58:34.457573] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T16:58:36.365570] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:58:38.271688] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T16:58:38.271765] [SCALING] Setting up experiment.


[0m[2025-01-18T16:58:38.271779] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T16:58:38.277738] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T16:58:38.294127] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T16:58:38.310671] [SCALING] Statefulset name to scale : flink-4000m-2048
[0m[2025-01-18T16:58:38.323114] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 1 replica.
[0m[2025-01-18T16:58:43.334904] [FLK_MGR] Running job.
[0m[2025-01-18T16:58:43.334933] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T16:58:43.710982] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-m259w
[0m[2025-01-18T16:58:47.839204] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID bdf53565f94c45b417823f354f672092

[0m[2025-01-18T16:58:47.839268] [FLK_MGR] Running job id: bdf53565f94c45b417823f354f672092
[0m[2025-01-18T16:58:47.839281] [FLK_MGR] Getting job info.
[0m[2025-01-18T16:58:47.858534] [FLK_MGR] Job plan response: {"plan":{"jid":"bdf53565f94c45b417823f354f672092","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T16:58:47.858675] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T16:58:48.294253] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-m259w
[0m[2025-01-18T16:58:49.715370] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 16:58:46 : bdf53565f94c45b417823f354f672092 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T16:58:49.715429] [FLK_MGR] Running jobs: ['bdf53565f94c45b417823f354f672092']
[0m[2025-01-18T16:58:49.715436] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T16:58:49.715449] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T17:02:49.738425] [SCALING] Scaling started.
[0m[2025-01-18T17:02:49.738530] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T17:02:49.753094] [SCALING] Scaling finished.
[0m[2025-01-18T17:02:49.753205] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:02:49.772621] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:02:49.789213] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T17:02:49.812517] [STS_MGR] StatefulSet flink-4000m-2048 scaled to 0 replica.
[0m[2025-01-18T17:02:54.836563] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T17:02:54.851443] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T17:02:54.867606] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T17:02:54.882537] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T17:02:54.897444] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T17:02:54.922273] [POD_MGR] Pod flink-jobmanager-7d7c784b74-m259w deleted
[0m[2025-01-18T17:02:56.824051] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:02:58.734089] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:02:58.734175] Reloading playbook: application/kafka
[0m[2025-01-18T17:03:04.645890] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T17:03:45.690145] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T17:03:45.690404] [EXPERIMENT] Run 5 completed. Start: 1737219514, End: 1737219825
[0m[2025-01-18T17:03:45.690411] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T17:03:57.963344] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T17:03:57.963501] [RESOURCE_E] Running experiment with 4000m cores and 4096 memory.
[0m[2025-01-18T17:04:05.262526] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T17:04:05.262616] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T17:04:07.154965] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:04:09.071899] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:04:09.071979] [SCALING] Setting up experiment.


[0m[2025-01-18T17:04:09.071990] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:04:09.076970] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:04:09.093103] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T17:04:09.107968] [SCALING] Statefulset name to scale : flink-4000m-4096
[0m[2025-01-18T17:04:09.119494] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 1 replica.
[0m[2025-01-18T17:04:14.130174] [FLK_MGR] Running job.
[0m[2025-01-18T17:04:14.130252] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T17:04:14.516250] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-k78k4
[0m[2025-01-18T17:04:18.604194] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 3b5aeada93d5e4b5ba56dc01166b01ad

[0m[2025-01-18T17:04:18.604239] [FLK_MGR] Running job id: 3b5aeada93d5e4b5ba56dc01166b01ad
[0m[2025-01-18T17:04:18.604248] [FLK_MGR] Getting job info.
[0m[2025-01-18T17:04:18.625184] [FLK_MGR] Job plan response: {"plan":{"jid":"3b5aeada93d5e4b5ba56dc01166b01ad","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T17:04:18.625324] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T17:04:19.005891] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-k78k4
[0m[2025-01-18T17:04:20.453788] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 17:04:17 : 3b5aeada93d5e4b5ba56dc01166b01ad : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T17:04:20.453851] [FLK_MGR] Running jobs: ['3b5aeada93d5e4b5ba56dc01166b01ad']
[0m[2025-01-18T17:04:20.453859] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T17:04:20.453871] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T17:08:20.476729] [SCALING] Scaling started.
[0m[2025-01-18T17:08:20.476849] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T17:08:20.491107] [SCALING] Scaling finished.
[0m[2025-01-18T17:08:20.491137] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:08:20.509016] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:08:20.525663] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T17:08:20.548506] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 0 replica.
[0m[2025-01-18T17:08:25.568329] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T17:08:25.583004] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T17:08:25.599591] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T17:08:25.614081] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T17:08:25.627684] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T17:08:25.664187] [POD_MGR] Pod flink-jobmanager-7d7c784b74-k78k4 deleted
[0m[2025-01-18T17:08:27.615091] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:08:29.704992] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:08:29.705083] Reloading playbook: application/kafka
[0m[2025-01-18T17:08:35.729392] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T17:09:16.723789] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T17:09:16.724056] [EXPERIMENT] Run 1 completed. Start: 1737219845, End: 1737220156
[0m[2025-01-18T17:09:16.724062] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T17:09:26.724981] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T17:09:28.614048] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:09:30.540145] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:09:30.540237] [SCALING] Setting up experiment.


[0m[2025-01-18T17:09:30.540247] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:09:30.546136] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:09:30.563563] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T17:09:30.580238] [SCALING] Statefulset name to scale : flink-4000m-4096
[0m[2025-01-18T17:09:30.592225] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 1 replica.
[0m[2025-01-18T17:09:35.604082] [FLK_MGR] Running job.
[0m[2025-01-18T17:09:35.604129] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T17:09:36.001099] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-prngm
[0m[2025-01-18T17:09:40.106003] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6109d8536a6c85791db8081304905fc3

[0m[2025-01-18T17:09:40.106086] [FLK_MGR] Running job id: 6109d8536a6c85791db8081304905fc3
[0m[2025-01-18T17:09:40.106098] [FLK_MGR] Getting job info.
[0m[2025-01-18T17:09:40.127272] [FLK_MGR] Job plan response: {"plan":{"jid":"6109d8536a6c85791db8081304905fc3","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T17:09:40.127434] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T17:09:40.509354] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-prngm
[0m[2025-01-18T17:09:41.950911] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 17:09:39 : 6109d8536a6c85791db8081304905fc3 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T17:09:41.950973] [FLK_MGR] Running jobs: ['6109d8536a6c85791db8081304905fc3']
[0m[2025-01-18T17:09:41.950980] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T17:09:41.950992] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T17:13:41.973471] [SCALING] Scaling started.
[0m[2025-01-18T17:13:41.973570] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T17:13:41.985742] [SCALING] Scaling finished.
[0m[2025-01-18T17:13:41.985771] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:13:42.003849] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:13:42.023266] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T17:13:42.050130] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 0 replica.
[0m[2025-01-18T17:13:47.068764] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T17:13:47.081453] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T17:13:47.094021] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T17:13:47.107597] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T17:13:47.120213] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T17:13:47.156876] [POD_MGR] Pod flink-jobmanager-7d7c784b74-prngm deleted
[0m[2025-01-18T17:13:49.107232] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:13:51.085134] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:13:51.085238] Reloading playbook: application/kafka
[0m[2025-01-18T17:13:57.036575] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T17:14:38.069995] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T17:14:38.070264] [EXPERIMENT] Run 2 completed. Start: 1737220166, End: 1737220478
[0m[2025-01-18T17:14:38.070271] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T17:14:48.071175] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T17:14:49.990702] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:14:51.886582] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:14:51.886679] [SCALING] Setting up experiment.


[0m[2025-01-18T17:14:51.886689] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:14:51.892303] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:14:51.909762] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T17:14:51.925346] [SCALING] Statefulset name to scale : flink-4000m-4096
[0m[2025-01-18T17:14:51.934733] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 1 replica.
[0m[2025-01-18T17:14:56.943956] [FLK_MGR] Running job.
[0m[2025-01-18T17:14:56.943984] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T17:14:57.336087] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-wf4kx
[0m[2025-01-18T17:15:01.381052] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 46f70134f44cd740850d081ae4978544

[0m[2025-01-18T17:15:01.381106] [FLK_MGR] Running job id: 46f70134f44cd740850d081ae4978544
[0m[2025-01-18T17:15:01.381114] [FLK_MGR] Getting job info.
[0m[2025-01-18T17:15:01.400045] [FLK_MGR] Job plan response: {"plan":{"jid":"46f70134f44cd740850d081ae4978544","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T17:15:01.400202] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T17:15:01.782909] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-wf4kx
[0m[2025-01-18T17:15:03.220082] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 17:15:00 : 46f70134f44cd740850d081ae4978544 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T17:15:03.220150] [FLK_MGR] Running jobs: ['46f70134f44cd740850d081ae4978544']
[0m[2025-01-18T17:15:03.220161] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T17:15:03.220179] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T17:19:03.242390] [SCALING] Scaling started.
[0m[2025-01-18T17:19:03.242518] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T17:19:03.258028] [SCALING] Scaling finished.
[0m[2025-01-18T17:19:03.258068] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:19:03.277187] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:19:03.295071] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T17:19:03.318657] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 0 replica.
[0m[2025-01-18T17:19:08.339906] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T17:19:08.353663] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T17:19:08.368285] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T17:19:08.383384] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T17:19:08.397684] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T17:19:08.424813] [POD_MGR] Pod flink-jobmanager-7d7c784b74-wf4kx deleted
[0m[2025-01-18T17:19:10.348920] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:19:12.347347] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:19:12.347434] Reloading playbook: application/kafka
[0m[2025-01-18T17:19:18.307711] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T17:19:59.340143] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T17:19:59.340436] [EXPERIMENT] Run 3 completed. Start: 1737220488, End: 1737220799
[0m[2025-01-18T17:19:59.340443] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T17:20:09.341430] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T17:20:11.261100] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:20:13.191851] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:20:13.191959] [SCALING] Setting up experiment.


[0m[2025-01-18T17:20:13.191969] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:20:13.197422] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:20:13.214837] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T17:20:13.231885] [SCALING] Statefulset name to scale : flink-4000m-4096
[0m[2025-01-18T17:20:13.243303] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 1 replica.
[0m[2025-01-18T17:20:18.253404] [FLK_MGR] Running job.
[0m[2025-01-18T17:20:18.253439] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T17:20:20.121210] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-7kx46
[0m[2025-01-18T17:20:24.262698] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 02fc2a88a6f59b2c2ab733a48a66873f

[0m[2025-01-18T17:20:24.262745] [FLK_MGR] Running job id: 02fc2a88a6f59b2c2ab733a48a66873f
[0m[2025-01-18T17:20:24.262753] [FLK_MGR] Getting job info.
[0m[2025-01-18T17:20:24.279218] [FLK_MGR] Job plan response: {"plan":{"jid":"02fc2a88a6f59b2c2ab733a48a66873f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T17:20:24.279353] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T17:20:24.677823] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-7kx46
[0m[2025-01-18T17:20:26.086378] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 17:20:23 : 02fc2a88a6f59b2c2ab733a48a66873f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T17:20:26.086433] [FLK_MGR] Running jobs: ['02fc2a88a6f59b2c2ab733a48a66873f']
[0m[2025-01-18T17:20:26.086441] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T17:20:26.086455] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T17:24:26.110320] [SCALING] Scaling started.
[0m[2025-01-18T17:24:26.110370] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T17:24:26.125522] [SCALING] Scaling finished.
[0m[2025-01-18T17:24:26.125551] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:24:26.145704] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:24:26.164353] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T17:24:26.185134] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 0 replica.
[0m[2025-01-18T17:24:31.205647] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T17:24:31.219617] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T17:24:31.235536] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T17:24:31.250059] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T17:24:31.263945] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T17:24:31.288675] [POD_MGR] Pod flink-jobmanager-7d7c784b74-7kx46 deleted
[0m[2025-01-18T17:24:33.234650] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:24:35.139404] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:24:35.139487] Reloading playbook: application/kafka
[0m[2025-01-18T17:24:41.103608] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T17:25:22.113854] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T17:25:22.114114] [EXPERIMENT] Run 4 completed. Start: 1737220809, End: 1737221122
[0m[2025-01-18T17:25:22.114121] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T17:25:32.115174] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T17:25:34.037091] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:25:35.955318] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:25:35.955403] [SCALING] Setting up experiment.


[0m[2025-01-18T17:25:35.955414] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:25:35.961186] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:25:35.977910] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T17:25:35.994706] [SCALING] Statefulset name to scale : flink-4000m-4096
[0m[2025-01-18T17:25:36.005524] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 1 replica.
[0m[2025-01-18T17:25:41.018657] [FLK_MGR] Running job.
[0m[2025-01-18T17:25:41.018695] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T17:25:41.398001] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-55z92
[0m[2025-01-18T17:25:45.517391] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 39f81fca7217ff126fa821a2bf3e9759

[0m[2025-01-18T17:25:45.517460] [FLK_MGR] Running job id: 39f81fca7217ff126fa821a2bf3e9759
[0m[2025-01-18T17:25:45.517467] [FLK_MGR] Getting job info.
[0m[2025-01-18T17:25:45.536043] [FLK_MGR] Job plan response: {"plan":{"jid":"39f81fca7217ff126fa821a2bf3e9759","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T17:25:45.536203] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T17:25:45.929237] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-55z92
[0m[2025-01-18T17:25:47.362593] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 17:25:44 : 39f81fca7217ff126fa821a2bf3e9759 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T17:25:47.362649] [FLK_MGR] Running jobs: ['39f81fca7217ff126fa821a2bf3e9759']
[0m[2025-01-18T17:25:47.362656] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T17:25:47.362668] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T17:29:47.385419] [SCALING] Scaling started.
[0m[2025-01-18T17:29:47.385469] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T17:29:47.398407] [SCALING] Scaling finished.
[0m[2025-01-18T17:29:47.398446] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:29:47.417295] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:29:47.433178] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T17:29:47.453768] [STS_MGR] StatefulSet flink-4000m-4096 scaled to 0 replica.
[0m[2025-01-18T17:29:57.481528] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T17:29:57.494607] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T17:29:57.508210] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T17:29:57.521005] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T17:29:57.534724] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T17:29:57.573463] [POD_MGR] Pod flink-jobmanager-7d7c784b74-55z92 deleted
[0m[2025-01-18T17:29:59.449370] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:30:01.387151] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:30:01.387234] Reloading playbook: application/kafka
[0m[2025-01-18T17:30:07.465598] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T17:30:48.438325] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T17:30:48.438511] [EXPERIMENT] Run 5 completed. Start: 1737221132, End: 1737221448
[0m[2025-01-18T17:30:48.438517] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T17:31:00.693134] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T17:31:00.693215] [RESOURCE_E] Running experiment with 4000m cores and 8192 memory.
[0m[2025-01-18T17:31:08.018334] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T17:31:08.018433] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T17:31:09.914450] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:31:11.834537] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:31:11.834622] [SCALING] Setting up experiment.


[0m[2025-01-18T17:31:11.834636] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:31:11.840243] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:31:11.856869] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T17:31:11.872783] [SCALING] Statefulset name to scale : flink-4000m-8192
[0m[2025-01-18T17:31:11.882983] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 1 replica.
[0m[2025-01-18T17:31:16.893837] [FLK_MGR] Running job.
[0m[2025-01-18T17:31:16.893879] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T17:31:17.293610] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-vsqzm
[0m[2025-01-18T17:31:21.316374] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID ace741c8cdd626352d528b6e97e12073

[0m[2025-01-18T17:31:21.316424] [FLK_MGR] Running job id: ace741c8cdd626352d528b6e97e12073
[0m[2025-01-18T17:31:21.316435] [FLK_MGR] Getting job info.
[0m[2025-01-18T17:31:21.333898] [FLK_MGR] Job plan response: {"plan":{"jid":"ace741c8cdd626352d528b6e97e12073","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T17:31:21.334037] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T17:31:21.717627] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-vsqzm
[0m[2025-01-18T17:31:23.175213] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 17:31:20 : ace741c8cdd626352d528b6e97e12073 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T17:31:23.175282] [FLK_MGR] Running jobs: ['ace741c8cdd626352d528b6e97e12073']
[0m[2025-01-18T17:31:23.175290] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T17:31:23.175302] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T17:35:23.198071] [SCALING] Scaling started.
[0m[2025-01-18T17:35:23.198132] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T17:35:23.211635] [SCALING] Scaling finished.
[0m[2025-01-18T17:35:23.211668] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:35:23.230506] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:35:23.247019] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T17:35:23.271279] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 0 replica.
[0m[2025-01-18T17:35:28.292021] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T17:35:28.305856] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T17:35:28.319097] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T17:35:28.333228] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T17:35:28.346122] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T17:35:28.381241] [POD_MGR] Pod flink-jobmanager-7d7c784b74-vsqzm deleted
[0m[2025-01-18T17:35:30.302768] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:35:32.280373] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:35:32.280445] Reloading playbook: application/kafka
[0m[2025-01-18T17:35:38.260588] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T17:36:19.299505] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T17:36:19.299784] [EXPERIMENT] Run 1 completed. Start: 1737221468, End: 1737221779
[0m[2025-01-18T17:36:19.299792] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T17:36:29.300812] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T17:36:31.201674] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:36:33.117200] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:36:33.117280] [SCALING] Setting up experiment.


[0m[2025-01-18T17:36:33.117291] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:36:33.124270] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:36:33.144037] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T17:36:33.160938] [SCALING] Statefulset name to scale : flink-4000m-8192
[0m[2025-01-18T17:36:33.171601] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 1 replica.
[0m[2025-01-18T17:36:38.182504] [FLK_MGR] Running job.
[0m[2025-01-18T17:36:38.182530] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T17:36:38.568084] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-9vzlc
[0m[2025-01-18T17:36:42.689351] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 55e7639db6eecedfb225109d3a8dfeb3

[0m[2025-01-18T17:36:42.689398] [FLK_MGR] Running job id: 55e7639db6eecedfb225109d3a8dfeb3
[0m[2025-01-18T17:36:42.689408] [FLK_MGR] Getting job info.
[0m[2025-01-18T17:36:42.707318] [FLK_MGR] Job plan response: {"plan":{"jid":"55e7639db6eecedfb225109d3a8dfeb3","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T17:36:42.707461] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T17:36:43.105387] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-9vzlc
[0m[2025-01-18T17:36:44.520505] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 17:36:41 : 55e7639db6eecedfb225109d3a8dfeb3 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T17:36:44.520580] [FLK_MGR] Running jobs: ['55e7639db6eecedfb225109d3a8dfeb3']
[0m[2025-01-18T17:36:44.520589] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T17:36:44.520603] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T17:40:44.543089] [SCALING] Scaling started.
[0m[2025-01-18T17:40:44.543199] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T17:40:44.556578] [SCALING] Scaling finished.
[0m[2025-01-18T17:40:44.556603] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:40:44.576004] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:40:44.594913] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T17:40:44.616095] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 0 replica.
[0m[2025-01-18T17:40:54.645094] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T17:40:54.660683] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T17:40:54.674726] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T17:40:54.689906] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T17:40:54.704936] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T17:40:54.733477] [POD_MGR] Pod flink-jobmanager-7d7c784b74-9vzlc deleted
[0m[2025-01-18T17:40:56.665713] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:40:58.635862] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:40:58.635944] Reloading playbook: application/kafka
[0m[2025-01-18T17:41:04.530241] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T17:41:45.581506] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T17:41:45.581779] [EXPERIMENT] Run 2 completed. Start: 1737221789, End: 1737222105
[0m[2025-01-18T17:41:45.581785] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T17:41:55.582753] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T17:41:57.506338] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:41:59.432479] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:41:59.432573] [SCALING] Setting up experiment.


[0m[2025-01-18T17:41:59.432586] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:41:59.438979] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:41:59.455699] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T17:41:59.471305] [SCALING] Statefulset name to scale : flink-4000m-8192
[0m[2025-01-18T17:41:59.482430] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 1 replica.
[0m[2025-01-18T17:42:04.493940] [FLK_MGR] Running job.
[0m[2025-01-18T17:42:04.493983] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T17:42:04.894240] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xmmn6
[0m[2025-01-18T17:42:08.966759] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 356f52b2b928521a881299b7074424f4

[0m[2025-01-18T17:42:08.966827] [FLK_MGR] Running job id: 356f52b2b928521a881299b7074424f4
[0m[2025-01-18T17:42:08.966836] [FLK_MGR] Getting job info.
[0m[2025-01-18T17:42:08.985160] [FLK_MGR] Job plan response: {"plan":{"jid":"356f52b2b928521a881299b7074424f4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T17:42:08.985316] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T17:42:09.383341] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xmmn6
[0m[2025-01-18T17:42:10.824805] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 17:42:07 : 356f52b2b928521a881299b7074424f4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T17:42:10.824864] [FLK_MGR] Running jobs: ['356f52b2b928521a881299b7074424f4']
[0m[2025-01-18T17:42:10.824872] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T17:42:10.824884] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T17:46:10.846924] [SCALING] Scaling started.
[0m[2025-01-18T17:46:10.847038] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T17:46:10.863322] [SCALING] Scaling finished.
[0m[2025-01-18T17:46:10.863352] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:46:10.880731] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:46:10.899831] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T17:46:10.926996] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 0 replica.
[0m[2025-01-18T17:46:15.950831] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T17:46:15.966818] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T17:46:15.982829] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T17:46:15.997472] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T17:46:16.012313] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T17:46:16.047537] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xmmn6 deleted
[0m[2025-01-18T17:46:18.042250] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:46:19.994188] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:46:19.994269] Reloading playbook: application/kafka
[0m[2025-01-18T17:46:25.932837] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T17:47:06.941526] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T17:47:06.941788] [EXPERIMENT] Run 3 completed. Start: 1737222115, End: 1737222426
[0m[2025-01-18T17:47:06.941794] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T17:47:16.942795] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T17:47:18.824454] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:47:20.778853] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:47:20.778954] [SCALING] Setting up experiment.


[0m[2025-01-18T17:47:20.778966] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:47:20.785383] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:47:20.804014] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T17:47:20.824450] [SCALING] Statefulset name to scale : flink-4000m-8192
[0m[2025-01-18T17:47:20.836376] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 1 replica.
[0m[2025-01-18T17:47:25.847861] [FLK_MGR] Running job.
[0m[2025-01-18T17:47:25.847888] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T17:47:26.238054] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-7xpxx
[0m[2025-01-18T17:47:30.404600] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a5f2c67741368551b1bef3f4d62e4af0

[0m[2025-01-18T17:47:30.404652] [FLK_MGR] Running job id: a5f2c67741368551b1bef3f4d62e4af0
[0m[2025-01-18T17:47:30.404662] [FLK_MGR] Getting job info.
[0m[2025-01-18T17:47:30.424168] [FLK_MGR] Job plan response: {"plan":{"jid":"a5f2c67741368551b1bef3f4d62e4af0","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T17:47:30.424322] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T17:47:30.807953] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-7xpxx
[0m[2025-01-18T17:47:32.238370] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 17:47:29 : a5f2c67741368551b1bef3f4d62e4af0 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T17:47:32.238430] [FLK_MGR] Running jobs: ['a5f2c67741368551b1bef3f4d62e4af0']
[0m[2025-01-18T17:47:32.238439] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T17:47:32.238452] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T17:51:32.261105] [SCALING] Scaling started.
[0m[2025-01-18T17:51:32.261172] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T17:51:32.275062] [SCALING] Scaling finished.
[0m[2025-01-18T17:51:32.275095] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:51:32.295318] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:51:32.312453] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T17:51:32.335297] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 0 replica.
[0m[2025-01-18T17:51:37.356464] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T17:51:37.370937] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T17:51:37.386008] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T17:51:37.399462] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T17:51:37.412967] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T17:51:37.454244] [POD_MGR] Pod flink-jobmanager-7d7c784b74-7xpxx deleted
[0m[2025-01-18T17:51:39.353081] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:51:41.292070] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:51:41.292138] Reloading playbook: application/kafka
[0m[2025-01-18T17:51:47.260520] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T17:52:28.282911] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T17:52:28.283163] [EXPERIMENT] Run 4 completed. Start: 1737222436, End: 1737222748
[0m[2025-01-18T17:52:28.283170] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T17:52:38.284205] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T17:52:40.201070] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:52:42.148820] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:52:42.148906] [SCALING] Setting up experiment.


[0m[2025-01-18T17:52:42.148917] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:52:42.154450] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:52:42.172106] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T17:52:42.190793] [SCALING] Statefulset name to scale : flink-4000m-8192
[0m[2025-01-18T17:52:42.201056] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 1 replica.
[0m[2025-01-18T17:52:47.211204] [FLK_MGR] Running job.
[0m[2025-01-18T17:52:47.211227] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T17:52:49.035069] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-p56xg
[0m[2025-01-18T17:52:53.192486] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 1927e8f3ad783f5e396641d900aa4fc1

[0m[2025-01-18T17:52:53.192546] [FLK_MGR] Running job id: 1927e8f3ad783f5e396641d900aa4fc1
[0m[2025-01-18T17:52:53.192554] [FLK_MGR] Getting job info.
[0m[2025-01-18T17:52:53.209937] [FLK_MGR] Job plan response: {"plan":{"jid":"1927e8f3ad783f5e396641d900aa4fc1","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T17:52:53.210103] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T17:52:53.589537] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-p56xg
[0m[2025-01-18T17:52:55.031747] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 17:52:52 : 1927e8f3ad783f5e396641d900aa4fc1 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T17:52:55.031823] [FLK_MGR] Running jobs: ['1927e8f3ad783f5e396641d900aa4fc1']
[0m[2025-01-18T17:52:55.031833] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T17:52:55.031848] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T17:56:55.057884] [SCALING] Scaling started.
[0m[2025-01-18T17:56:55.058033] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T17:56:55.073386] [SCALING] Scaling finished.
[0m[2025-01-18T17:56:55.073426] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:56:55.095743] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:56:55.115467] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T17:56:55.137078] [STS_MGR] StatefulSet flink-4000m-8192 scaled to 0 replica.
[0m[2025-01-18T17:57:00.156843] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T17:57:00.170620] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T17:57:00.185103] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T17:57:00.199187] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T17:57:00.214266] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T17:57:00.254767] [POD_MGR] Pod flink-jobmanager-7d7c784b74-p56xg deleted
[0m[2025-01-18T17:57:02.169020] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:57:04.107581] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T17:57:04.107711] Reloading playbook: application/kafka
[0m[2025-01-18T17:57:10.071133] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T17:57:51.031991] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T17:57:51.032358] [EXPERIMENT] Run 5 completed. Start: 1737222758, End: 1737223071
[0m[2025-01-18T17:57:51.032387] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T17:58:03.314686] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T17:58:03.314822] [RESOURCE_E] Running experiment with 4000m cores and 16384 memory.
[0m[2025-01-18T17:58:10.595927] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T17:58:10.596022] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T17:58:12.529184] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:58:14.444301] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T17:58:14.444383] [SCALING] Setting up experiment.


[0m[2025-01-18T17:58:14.444394] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T17:58:14.449841] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T17:58:14.466604] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T17:58:14.484214] [SCALING] Statefulset name to scale : flink-4000m-16384
[0m[2025-01-18T17:58:14.494346] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 1 replica.
[0m[2025-01-18T17:58:19.504923] [FLK_MGR] Running job.
[0m[2025-01-18T17:58:19.504956] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T17:58:19.913254] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-cc9nr
[0m[2025-01-18T17:58:24.009032] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 104f3032da6db3663c2db27f18317a05

[0m[2025-01-18T17:58:24.009107] [FLK_MGR] Running job id: 104f3032da6db3663c2db27f18317a05
[0m[2025-01-18T17:58:24.009114] [FLK_MGR] Getting job info.
[0m[2025-01-18T17:58:24.027055] [FLK_MGR] Job plan response: {"plan":{"jid":"104f3032da6db3663c2db27f18317a05","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T17:58:24.027247] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T17:58:24.428233] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-cc9nr
[0m[2025-01-18T17:58:25.883331] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 17:58:23 : 104f3032da6db3663c2db27f18317a05 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T17:58:25.883394] [FLK_MGR] Running jobs: ['104f3032da6db3663c2db27f18317a05']
[0m[2025-01-18T17:58:25.883402] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T17:58:25.883416] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T18:02:25.906763] [SCALING] Scaling started.
[0m[2025-01-18T18:02:25.906895] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T18:02:25.920410] [SCALING] Scaling finished.
[0m[2025-01-18T18:02:25.920438] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:02:25.940280] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:02:25.956923] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T18:02:25.979519] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 0 replica.
[0m[2025-01-18T18:02:36.006122] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T18:02:36.019786] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T18:02:36.034479] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T18:02:36.048456] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T18:02:36.061500] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T18:02:36.083462] [POD_MGR] Pod flink-jobmanager-7d7c784b74-cc9nr deleted
[0m[2025-01-18T18:02:38.040673] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:02:39.991107] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:02:39.991188] Reloading playbook: application/kafka
[0m[2025-01-18T18:02:46.010417] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T18:03:27.013380] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T18:03:27.013670] [EXPERIMENT] Run 1 completed. Start: 1737223090, End: 1737223407
[0m[2025-01-18T18:03:27.013677] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T18:03:37.014710] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T18:03:38.938495] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:03:40.875445] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:03:40.875541] [SCALING] Setting up experiment.


[0m[2025-01-18T18:03:40.875551] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:03:40.881107] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:03:40.900560] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T18:03:40.915399] [SCALING] Statefulset name to scale : flink-4000m-16384
[0m[2025-01-18T18:03:40.925339] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 1 replica.
[0m[2025-01-18T18:03:45.935475] [FLK_MGR] Running job.
[0m[2025-01-18T18:03:45.935508] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T18:03:46.328418] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-gmxfv
[0m[2025-01-18T18:03:50.436113] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID d0498efbacd95446c4102c97f8b9fd02

[0m[2025-01-18T18:03:50.436163] [FLK_MGR] Running job id: d0498efbacd95446c4102c97f8b9fd02
[0m[2025-01-18T18:03:50.436172] [FLK_MGR] Getting job info.
[0m[2025-01-18T18:03:50.456203] [FLK_MGR] Job plan response: {"plan":{"jid":"d0498efbacd95446c4102c97f8b9fd02","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T18:03:50.456361] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T18:03:50.858261] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-gmxfv
[0m[2025-01-18T18:03:52.292430] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 18:03:49 : d0498efbacd95446c4102c97f8b9fd02 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T18:03:52.292507] [FLK_MGR] Running jobs: ['d0498efbacd95446c4102c97f8b9fd02']
[0m[2025-01-18T18:03:52.292515] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T18:03:52.292528] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T18:07:52.315719] [SCALING] Scaling started.
[0m[2025-01-18T18:07:52.315799] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T18:07:52.329419] [SCALING] Scaling finished.
[0m[2025-01-18T18:07:52.329447] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:07:52.348826] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:07:52.367920] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T18:07:52.391911] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 0 replica.
[0m[2025-01-18T18:07:57.413695] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T18:07:57.427711] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T18:07:57.441646] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T18:07:57.455432] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T18:07:57.470598] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T18:07:57.506823] [POD_MGR] Pod flink-jobmanager-7d7c784b74-gmxfv deleted
[0m[2025-01-18T18:07:59.448853] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:08:01.473691] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:08:01.473797] Reloading playbook: application/kafka
[0m[2025-01-18T18:08:07.516715] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T18:08:48.571740] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T18:08:48.572584] [EXPERIMENT] Run 2 completed. Start: 1737223417, End: 1737223728
[0m[2025-01-18T18:08:48.572597] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T18:08:58.573608] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T18:09:00.491197] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:09:02.457095] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:09:02.457198] [SCALING] Setting up experiment.


[0m[2025-01-18T18:09:02.457210] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:09:02.463282] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:09:02.480241] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T18:09:02.497637] [SCALING] Statefulset name to scale : flink-4000m-16384
[0m[2025-01-18T18:09:02.508681] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 1 replica.
[0m[2025-01-18T18:09:07.518146] [FLK_MGR] Running job.
[0m[2025-01-18T18:09:07.518196] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T18:09:07.910150] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-t4jmw
[0m[2025-01-18T18:09:12.101766] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6e136d9d4522c97ae51a46ac6dc17d66

[0m[2025-01-18T18:09:12.101865] [FLK_MGR] Running job id: 6e136d9d4522c97ae51a46ac6dc17d66
[0m[2025-01-18T18:09:12.101898] [FLK_MGR] Getting job info.
[0m[2025-01-18T18:09:12.120251] [FLK_MGR] Job plan response: {"plan":{"jid":"6e136d9d4522c97ae51a46ac6dc17d66","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T18:09:12.120459] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T18:09:12.531559] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-t4jmw
[0m[2025-01-18T18:09:13.976322] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 18:09:11 : 6e136d9d4522c97ae51a46ac6dc17d66 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T18:09:13.976382] [FLK_MGR] Running jobs: ['6e136d9d4522c97ae51a46ac6dc17d66']
[0m[2025-01-18T18:09:13.976390] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T18:09:13.976401] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T18:13:13.999068] [SCALING] Scaling started.
[0m[2025-01-18T18:13:13.999126] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T18:13:14.013761] [SCALING] Scaling finished.
[0m[2025-01-18T18:13:14.013792] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:13:14.032932] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:13:14.050828] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T18:13:14.075855] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 0 replica.
[0m[2025-01-18T18:13:19.098264] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T18:13:19.113423] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T18:13:19.127662] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T18:13:19.143846] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T18:13:19.158446] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T18:13:19.182282] [POD_MGR] Pod flink-jobmanager-7d7c784b74-t4jmw deleted
[0m[2025-01-18T18:13:21.130120] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:13:23.066832] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:13:23.066917] Reloading playbook: application/kafka
[0m[2025-01-18T18:13:29.117894] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T18:14:10.177235] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T18:14:10.177492] [EXPERIMENT] Run 3 completed. Start: 1737223738, End: 1737224050
[0m[2025-01-18T18:14:10.177500] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T18:14:20.178608] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T18:14:22.104200] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:14:24.050579] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:14:24.050666] [SCALING] Setting up experiment.


[0m[2025-01-18T18:14:24.050680] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:14:24.056714] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:14:24.073800] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T18:14:24.089020] [SCALING] Statefulset name to scale : flink-4000m-16384
[0m[2025-01-18T18:14:24.098742] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 1 replica.
[0m[2025-01-18T18:14:29.108387] [FLK_MGR] Running job.
[0m[2025-01-18T18:14:29.108415] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T18:14:29.495412] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-thcp7
[0m[2025-01-18T18:14:33.570197] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 00e1c940910ed1d40b28dd0358e32199

[0m[2025-01-18T18:14:33.570273] [FLK_MGR] Running job id: 00e1c940910ed1d40b28dd0358e32199
[0m[2025-01-18T18:14:33.570281] [FLK_MGR] Getting job info.
[0m[2025-01-18T18:14:33.589611] [FLK_MGR] Job plan response: {"plan":{"jid":"00e1c940910ed1d40b28dd0358e32199","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T18:14:33.589769] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T18:14:33.974001] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-thcp7
[0m[2025-01-18T18:14:35.385124] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 18:14:32 : 00e1c940910ed1d40b28dd0358e32199 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T18:14:35.385223] [FLK_MGR] Running jobs: ['00e1c940910ed1d40b28dd0358e32199']
[0m[2025-01-18T18:14:35.385231] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T18:14:35.385242] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T18:18:35.409706] [SCALING] Scaling started.
[0m[2025-01-18T18:18:35.409789] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T18:18:35.423881] [SCALING] Scaling finished.
[0m[2025-01-18T18:18:35.423918] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:18:35.444752] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:18:35.463489] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T18:18:35.485372] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 0 replica.
[0m[2025-01-18T18:18:40.508670] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T18:18:40.521727] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T18:18:40.535151] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T18:18:40.548615] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T18:18:40.562801] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T18:18:40.598574] [POD_MGR] Pod flink-jobmanager-7d7c784b74-thcp7 deleted
[0m[2025-01-18T18:18:42.555198] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:18:44.424367] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:18:44.424453] Reloading playbook: application/kafka
[0m[2025-01-18T18:18:50.401784] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T18:19:31.411359] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T18:19:31.412211] [EXPERIMENT] Run 4 completed. Start: 1737224060, End: 1737224371
[0m[2025-01-18T18:19:31.412222] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T18:19:41.413454] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T18:19:43.352386] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:19:45.264993] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:19:45.265095] [SCALING] Setting up experiment.


[0m[2025-01-18T18:19:45.265107] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:19:45.271886] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:19:45.288935] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T18:19:45.305736] [SCALING] Statefulset name to scale : flink-4000m-16384
[0m[2025-01-18T18:19:45.330343] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 1 replica.
[0m[2025-01-18T18:19:50.340885] [FLK_MGR] Running job.
[0m[2025-01-18T18:19:50.340916] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T18:19:50.735856] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-z2fjf
[0m[2025-01-18T18:19:54.935118] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9e4f8535aa60a72c7eaad4f2c5bcaeec

[0m[2025-01-18T18:19:54.935185] [FLK_MGR] Running job id: 9e4f8535aa60a72c7eaad4f2c5bcaeec
[0m[2025-01-18T18:19:54.935198] [FLK_MGR] Getting job info.
[0m[2025-01-18T18:19:54.954819] [FLK_MGR] Job plan response: {"plan":{"jid":"9e4f8535aa60a72c7eaad4f2c5bcaeec","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T18:19:54.954961] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T18:19:55.333655] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-z2fjf
[0m[2025-01-18T18:19:56.772468] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 18:19:53 : 9e4f8535aa60a72c7eaad4f2c5bcaeec : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T18:19:56.772571] [FLK_MGR] Running jobs: ['9e4f8535aa60a72c7eaad4f2c5bcaeec']
[0m[2025-01-18T18:19:56.772580] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T18:19:56.772594] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T18:23:56.796333] [SCALING] Scaling started.
[0m[2025-01-18T18:23:56.796480] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T18:23:56.810116] [SCALING] Scaling finished.
[0m[2025-01-18T18:23:56.810145] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:23:56.826880] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:23:56.842220] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T18:23:56.866315] [STS_MGR] StatefulSet flink-4000m-16384 scaled to 0 replica.
[0m[2025-01-18T18:24:01.889265] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T18:24:01.904821] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T18:24:01.918722] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T18:24:01.933909] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T18:24:01.948043] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T18:24:01.980812] [POD_MGR] Pod flink-jobmanager-7d7c784b74-z2fjf deleted
[0m[2025-01-18T18:24:03.922054] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:24:05.869234] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:24:05.869308] Reloading playbook: application/kafka
[0m[2025-01-18T18:24:11.890016] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T18:24:52.901958] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T18:24:52.902179] [EXPERIMENT] Run 5 completed. Start: 1737224381, End: 1737224692
[0m[2025-01-18T18:24:52.902185] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T18:25:05.145297] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T18:25:05.145376] [RESOURCE_E] Running experiment with 4000m cores and 32768 memory.
[0m[2025-01-18T18:25:12.331161] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T18:25:12.331241] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T18:25:14.240495] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:25:16.204540] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:25:16.204619] [SCALING] Setting up experiment.


[0m[2025-01-18T18:25:16.204630] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:25:16.210307] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:25:16.227563] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T18:25:16.245139] [SCALING] Statefulset name to scale : flink-4000m-32768
[0m[2025-01-18T18:25:16.255268] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 1 replica.
[0m[2025-01-18T18:26:31.339168] [FLK_MGR] Running job.
[0m[2025-01-18T18:26:31.339261] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T18:26:33.228755] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-sgwt7
[0m[2025-01-18T18:26:37.289474] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f3a50dbfa7d1758c5c953ff0d8345595

[0m[2025-01-18T18:26:37.289524] [FLK_MGR] Running job id: f3a50dbfa7d1758c5c953ff0d8345595
[0m[2025-01-18T18:26:37.289532] [FLK_MGR] Getting job info.
[0m[2025-01-18T18:26:37.305514] [FLK_MGR] Job plan response: {"plan":{"jid":"f3a50dbfa7d1758c5c953ff0d8345595","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T18:26:37.305663] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T18:26:37.681053] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sgwt7
[0m[2025-01-18T18:26:39.083603] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 18:26:36 : f3a50dbfa7d1758c5c953ff0d8345595 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T18:26:39.083654] [FLK_MGR] Running jobs: ['f3a50dbfa7d1758c5c953ff0d8345595']
[0m[2025-01-18T18:26:39.083662] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T18:26:39.083674] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T18:30:39.107642] [SCALING] Scaling started.
[0m[2025-01-18T18:30:39.107733] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T18:30:39.120894] [SCALING] Scaling finished.
[0m[2025-01-18T18:30:39.120918] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:30:39.140169] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:30:39.156707] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T18:30:39.176501] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 0 replica.
[0m[2025-01-18T18:30:39.192421] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T18:30:39.205714] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T18:30:39.218708] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T18:30:39.232149] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T18:30:39.246212] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T18:30:39.276713] [POD_MGR] Pod flink-jobmanager-7d7c784b74-sgwt7 deleted
[0m[2025-01-18T18:30:41.196177] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:30:43.179602] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:30:43.179693] Reloading playbook: application/kafka
[0m[2025-01-18T18:30:49.170657] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T18:31:30.161153] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T18:31:30.161351] [EXPERIMENT] Run 1 completed. Start: 1737224712, End: 1737225090
[0m[2025-01-18T18:31:30.161358] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T18:31:40.162474] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T18:31:42.074942] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:31:43.994661] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:31:43.994747] [SCALING] Setting up experiment.


[0m[2025-01-18T18:31:43.994758] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:31:44.000308] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:31:44.017206] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T18:31:44.033258] [SCALING] Statefulset name to scale : flink-4000m-32768
[0m[2025-01-18T18:31:44.045235] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 1 replica.
[0m[2025-01-18T18:32:59.132250] [FLK_MGR] Running job.
[0m[2025-01-18T18:32:59.132348] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T18:32:59.515245] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-k959h
[0m[2025-01-18T18:33:03.563553] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0adfdf0ce8b246dd8bcbc4de74a4082b

[0m[2025-01-18T18:33:03.563600] [FLK_MGR] Running job id: 0adfdf0ce8b246dd8bcbc4de74a4082b
[0m[2025-01-18T18:33:03.563609] [FLK_MGR] Getting job info.
[0m[2025-01-18T18:33:03.579676] [FLK_MGR] Job plan response: {"plan":{"jid":"0adfdf0ce8b246dd8bcbc4de74a4082b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T18:33:03.579824] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T18:33:03.972200] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-k959h
[0m[2025-01-18T18:33:05.401679] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 18:33:02 : 0adfdf0ce8b246dd8bcbc4de74a4082b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T18:33:05.401750] [FLK_MGR] Running jobs: ['0adfdf0ce8b246dd8bcbc4de74a4082b']
[0m[2025-01-18T18:33:05.401759] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T18:33:05.401772] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T18:37:05.424101] [SCALING] Scaling started.
[0m[2025-01-18T18:37:05.424202] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T18:37:05.436869] [SCALING] Scaling finished.
[0m[2025-01-18T18:37:05.436894] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:37:05.455576] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:37:05.476288] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T18:37:05.500803] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 0 replica.
[0m[2025-01-18T18:37:05.518285] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T18:37:05.532549] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T18:37:05.546194] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T18:37:05.560418] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T18:37:05.573967] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T18:37:05.596488] [POD_MGR] Pod flink-jobmanager-7d7c784b74-k959h deleted
[0m[2025-01-18T18:37:07.531789] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:37:09.499686] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:37:09.499762] Reloading playbook: application/kafka
[0m[2025-01-18T18:37:15.526065] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T18:37:56.447363] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T18:37:56.447609] [EXPERIMENT] Run 2 completed. Start: 1737225100, End: 1737225476
[0m[2025-01-18T18:37:56.447616] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T18:38:06.448627] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T18:38:08.357947] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:38:10.262048] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:38:10.262131] [SCALING] Setting up experiment.


[0m[2025-01-18T18:38:10.262141] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:38:10.267258] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:38:10.282874] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T18:38:10.298551] [SCALING] Statefulset name to scale : flink-4000m-32768
[0m[2025-01-18T18:38:10.308946] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 1 replica.
[0m[2025-01-18T18:39:25.395755] [FLK_MGR] Running job.
[0m[2025-01-18T18:39:25.395807] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T18:39:25.799774] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-csrrd
[0m[2025-01-18T18:39:29.894941] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 463b5c304bd02a333fbae87ba7d522b7

[0m[2025-01-18T18:39:29.894996] [FLK_MGR] Running job id: 463b5c304bd02a333fbae87ba7d522b7
[0m[2025-01-18T18:39:29.895008] [FLK_MGR] Getting job info.
[0m[2025-01-18T18:39:29.911532] [FLK_MGR] Job plan response: {"plan":{"jid":"463b5c304bd02a333fbae87ba7d522b7","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T18:39:29.911683] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T18:39:30.284281] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-csrrd
[0m[2025-01-18T18:39:31.720443] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 18:39:28 : 463b5c304bd02a333fbae87ba7d522b7 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T18:39:31.720502] [FLK_MGR] Running jobs: ['463b5c304bd02a333fbae87ba7d522b7']
[0m[2025-01-18T18:39:31.720510] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T18:39:31.720523] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T18:43:31.744797] [SCALING] Scaling started.
[0m[2025-01-18T18:43:31.744920] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T18:43:31.759718] [SCALING] Scaling finished.
[0m[2025-01-18T18:43:31.759741] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:43:31.781686] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:43:31.798814] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T18:43:31.819853] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 0 replica.
[0m[2025-01-18T18:43:31.837198] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T18:43:31.852064] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T18:43:31.866157] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T18:43:31.881147] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T18:43:31.896308] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T18:43:31.928121] [POD_MGR] Pod flink-jobmanager-7d7c784b74-csrrd deleted
[0m[2025-01-18T18:43:33.834123] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:43:35.794683] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:43:35.794757] Reloading playbook: application/kafka
[0m[2025-01-18T18:43:41.841587] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T18:44:22.854925] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T18:44:22.855186] [EXPERIMENT] Run 3 completed. Start: 1737225486, End: 1737225862
[0m[2025-01-18T18:44:22.855193] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T18:44:32.856327] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T18:44:34.771692] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:44:36.723330] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:44:36.723418] [SCALING] Setting up experiment.


[0m[2025-01-18T18:44:36.723428] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:44:36.729461] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:44:36.746308] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T18:44:36.762633] [SCALING] Statefulset name to scale : flink-4000m-32768
[0m[2025-01-18T18:44:36.772935] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 1 replica.
[0m[2025-01-18T18:45:51.857701] [FLK_MGR] Running job.
[0m[2025-01-18T18:45:51.857749] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T18:45:52.247078] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-n4vjw
[0m[2025-01-18T18:45:56.338991] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fed60f1710a5d4166fc301a31f7d6cf0

[0m[2025-01-18T18:45:56.339037] [FLK_MGR] Running job id: fed60f1710a5d4166fc301a31f7d6cf0
[0m[2025-01-18T18:45:56.339046] [FLK_MGR] Getting job info.
[0m[2025-01-18T18:45:56.356650] [FLK_MGR] Job plan response: {"plan":{"jid":"fed60f1710a5d4166fc301a31f7d6cf0","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T18:45:56.356788] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T18:45:56.730026] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-n4vjw
[0m[2025-01-18T18:45:58.173940] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 18:45:55 : fed60f1710a5d4166fc301a31f7d6cf0 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T18:45:58.173999] [FLK_MGR] Running jobs: ['fed60f1710a5d4166fc301a31f7d6cf0']
[0m[2025-01-18T18:45:58.174006] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T18:45:58.174018] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T18:49:58.198010] [SCALING] Scaling started.
[0m[2025-01-18T18:49:58.198120] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T18:49:58.212306] [SCALING] Scaling finished.
[0m[2025-01-18T18:49:58.212332] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:49:58.229533] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:49:58.245302] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T18:49:58.265852] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 0 replica.
[0m[2025-01-18T18:49:58.281046] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T18:49:58.294191] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T18:49:58.306665] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T18:49:58.319260] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T18:49:58.331560] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T18:49:58.361977] [POD_MGR] Pod flink-jobmanager-7d7c784b74-n4vjw deleted
[0m[2025-01-18T18:50:00.276547] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:50:02.176452] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:50:02.176531] Reloading playbook: application/kafka
[0m[2025-01-18T18:50:08.130989] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T18:50:49.167544] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T18:50:49.167777] [EXPERIMENT] Run 4 completed. Start: 1737225872, End: 1737226249
[0m[2025-01-18T18:50:49.167784] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T18:50:59.168815] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T18:51:01.097289] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:51:03.061626] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:51:03.061772] [SCALING] Setting up experiment.


[0m[2025-01-18T18:51:03.061822] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:51:03.067914] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:51:03.084563] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T18:51:03.100866] [SCALING] Statefulset name to scale : flink-4000m-32768
[0m[2025-01-18T18:51:03.112161] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 1 replica.
[0m[2025-01-18T18:52:18.200157] [FLK_MGR] Running job.
[0m[2025-01-18T18:52:18.200200] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T18:52:18.580992] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-krtp9
[0m[2025-01-18T18:52:22.590028] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 4d4c70a77e08d5a68b8574cccde54471

[0m[2025-01-18T18:52:22.590074] [FLK_MGR] Running job id: 4d4c70a77e08d5a68b8574cccde54471
[0m[2025-01-18T18:52:22.590081] [FLK_MGR] Getting job info.
[0m[2025-01-18T18:52:22.606234] [FLK_MGR] Job plan response: {"plan":{"jid":"4d4c70a77e08d5a68b8574cccde54471","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T18:52:22.606374] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T18:52:22.979183] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-krtp9
[0m[2025-01-18T18:52:24.409677] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 18:52:21 : 4d4c70a77e08d5a68b8574cccde54471 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T18:52:24.409737] [FLK_MGR] Running jobs: ['4d4c70a77e08d5a68b8574cccde54471']
[0m[2025-01-18T18:52:24.409744] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T18:52:24.409756] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T18:56:24.432842] [SCALING] Scaling started.
[0m[2025-01-18T18:56:24.432893] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T18:56:24.445381] [SCALING] Scaling finished.
[0m[2025-01-18T18:56:24.445403] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:56:24.462696] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:56:24.479327] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T18:56:24.501288] [STS_MGR] StatefulSet flink-4000m-32768 scaled to 0 replica.
[0m[2025-01-18T18:56:24.517622] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T18:56:24.530935] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T18:56:24.544138] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T18:56:24.556740] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T18:56:24.568653] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T18:56:24.594962] [POD_MGR] Pod flink-jobmanager-7d7c784b74-krtp9 deleted
[0m[2025-01-18T18:56:26.571375] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:56:28.520976] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T18:56:28.521082] Reloading playbook: application/kafka
[0m[2025-01-18T18:56:34.540334] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T18:57:15.543193] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T18:57:15.543498] [EXPERIMENT] Run 5 completed. Start: 1737226259, End: 1737226635
[0m[2025-01-18T18:57:15.543505] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T18:57:27.783815] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T18:57:27.783913] [RESOURCE_E] Running experiment with 8000m cores and 1024 memory.
[0m[2025-01-18T18:57:35.065476] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T18:57:35.065576] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T18:57:36.961569] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:57:38.874315] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T18:57:38.874401] [SCALING] Setting up experiment.


[0m[2025-01-18T18:57:38.874411] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T18:57:38.880197] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T18:57:38.896328] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T18:57:38.913364] [SCALING] Statefulset name to scale : flink-8000m-1024
[0m[2025-01-18T18:57:38.935734] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 1 replica.
[0m[2025-01-18T18:57:43.947000] [FLK_MGR] Running job.
[0m[2025-01-18T18:57:43.947046] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T18:57:44.361655] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-ptmwg
[0m[2025-01-18T18:57:48.507352] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID afb09907612492932f3420a18f90f0de

[0m[2025-01-18T18:57:48.507419] [FLK_MGR] Running job id: afb09907612492932f3420a18f90f0de
[0m[2025-01-18T18:57:48.507428] [FLK_MGR] Getting job info.
[0m[2025-01-18T18:57:48.526954] [FLK_MGR] Job plan response: {"plan":{"jid":"afb09907612492932f3420a18f90f0de","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T18:57:48.527130] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T18:57:48.911499] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-ptmwg
[0m[2025-01-18T18:57:50.346752] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 18:57:47 : afb09907612492932f3420a18f90f0de : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T18:57:50.346839] [FLK_MGR] Running jobs: ['afb09907612492932f3420a18f90f0de']
[0m[2025-01-18T18:57:50.346851] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T18:57:50.346882] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T19:01:50.371930] [SCALING] Scaling started.
[0m[2025-01-18T19:01:50.372120] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T19:01:50.387541] [SCALING] Scaling finished.
[0m[2025-01-18T19:01:50.387574] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:01:50.406379] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:01:50.424388] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T19:01:50.448814] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 0 replica.
[0m[2025-01-18T19:02:00.475781] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T19:02:00.491552] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T19:02:00.506429] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T19:02:00.519505] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T19:02:00.534989] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T19:02:00.559789] [POD_MGR] Pod flink-jobmanager-7d7c784b74-ptmwg deleted
[0m[2025-01-18T19:02:02.606018] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:02:04.545896] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:02:04.545994] Reloading playbook: application/kafka
[0m[2025-01-18T19:02:10.548587] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T19:02:51.575985] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T19:02:51.576277] [EXPERIMENT] Run 1 completed. Start: 1737226655, End: 1737226971
[0m[2025-01-18T19:02:51.576284] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T19:03:01.577171] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T19:03:03.487297] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:03:05.442694] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:03:05.442788] [SCALING] Setting up experiment.


[0m[2025-01-18T19:03:05.442799] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:03:05.448205] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:03:05.465327] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T19:03:05.482389] [SCALING] Statefulset name to scale : flink-8000m-1024
[0m[2025-01-18T19:03:05.492861] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 1 replica.
[0m[2025-01-18T19:03:10.503820] [FLK_MGR] Running job.
[0m[2025-01-18T19:03:10.503853] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T19:03:12.413974] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-gdzl8
[0m[2025-01-18T19:03:16.514739] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5a53814e6d630b6c8544ea7913c3beb1

[0m[2025-01-18T19:03:16.514783] [FLK_MGR] Running job id: 5a53814e6d630b6c8544ea7913c3beb1
[0m[2025-01-18T19:03:16.514789] [FLK_MGR] Getting job info.
[0m[2025-01-18T19:03:16.533830] [FLK_MGR] Job plan response: {"plan":{"jid":"5a53814e6d630b6c8544ea7913c3beb1","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T19:03:16.534028] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T19:03:16.929780] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-gdzl8
[0m[2025-01-18T19:03:18.370957] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 19:03:15 : 5a53814e6d630b6c8544ea7913c3beb1 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T19:03:18.371024] [FLK_MGR] Running jobs: ['5a53814e6d630b6c8544ea7913c3beb1']
[0m[2025-01-18T19:03:18.371033] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T19:03:18.371045] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T19:07:18.393150] [SCALING] Scaling started.
[0m[2025-01-18T19:07:18.393206] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T19:07:18.406723] [SCALING] Scaling finished.
[0m[2025-01-18T19:07:18.406748] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:07:18.426163] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:07:18.447374] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T19:07:18.469938] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 0 replica.
[0m[2025-01-18T19:07:28.500057] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T19:07:28.513991] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T19:07:28.529497] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T19:07:28.544226] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T19:07:28.559068] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T19:07:28.585101] [POD_MGR] Pod flink-jobmanager-7d7c784b74-gdzl8 deleted
[0m[2025-01-18T19:07:30.520175] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:07:32.483414] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:07:32.483486] Reloading playbook: application/kafka
[0m[2025-01-18T19:07:38.418580] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T19:08:19.417610] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T19:08:19.417852] [EXPERIMENT] Run 2 completed. Start: 1737226981, End: 1737227299
[0m[2025-01-18T19:08:19.417859] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T19:08:29.418819] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T19:08:31.345595] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:08:33.255082] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:08:33.255164] [SCALING] Setting up experiment.


[0m[2025-01-18T19:08:33.255174] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:08:33.260345] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:08:33.275876] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T19:08:33.291467] [SCALING] Statefulset name to scale : flink-8000m-1024
[0m[2025-01-18T19:08:33.300924] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 1 replica.
[0m[2025-01-18T19:08:38.310493] [FLK_MGR] Running job.
[0m[2025-01-18T19:08:38.310521] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T19:08:38.714792] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-sfstj
[0m[2025-01-18T19:08:42.828547] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 60d0383d85d79e6731cd39e493bd02b8

[0m[2025-01-18T19:08:42.828597] [FLK_MGR] Running job id: 60d0383d85d79e6731cd39e493bd02b8
[0m[2025-01-18T19:08:42.828609] [FLK_MGR] Getting job info.
[0m[2025-01-18T19:08:42.846673] [FLK_MGR] Job plan response: {"plan":{"jid":"60d0383d85d79e6731cd39e493bd02b8","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T19:08:42.846867] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T19:08:43.222391] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sfstj
[0m[2025-01-18T19:08:44.649268] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 19:08:41 : 60d0383d85d79e6731cd39e493bd02b8 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T19:08:44.649328] [FLK_MGR] Running jobs: ['60d0383d85d79e6731cd39e493bd02b8']
[0m[2025-01-18T19:08:44.649335] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T19:08:44.649348] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T19:12:44.672902] [SCALING] Scaling started.
[0m[2025-01-18T19:12:44.673002] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T19:12:44.687472] [SCALING] Scaling finished.
[0m[2025-01-18T19:12:44.687496] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:12:44.707738] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:12:44.726896] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T19:12:44.749650] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 0 replica.
[0m[2025-01-18T19:12:49.770054] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T19:12:49.783710] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T19:12:49.796761] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T19:12:49.812301] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T19:12:49.825824] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T19:12:49.861215] [POD_MGR] Pod flink-jobmanager-7d7c784b74-sfstj deleted
[0m[2025-01-18T19:12:51.774115] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:12:53.778359] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:12:53.778439] Reloading playbook: application/kafka
[0m[2025-01-18T19:12:59.790442] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T19:13:40.744072] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T19:13:40.744271] [EXPERIMENT] Run 3 completed. Start: 1737227309, End: 1737227620
[0m[2025-01-18T19:13:40.744279] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T19:13:50.745310] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T19:13:52.683489] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:13:54.609773] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:13:54.609865] [SCALING] Setting up experiment.


[0m[2025-01-18T19:13:54.609876] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:13:54.615742] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:13:54.632059] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T19:13:54.649540] [SCALING] Statefulset name to scale : flink-8000m-1024
[0m[2025-01-18T19:13:54.660185] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 1 replica.
[0m[2025-01-18T19:13:59.672166] [FLK_MGR] Running job.
[0m[2025-01-18T19:13:59.672215] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T19:14:00.060813] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-pb77d
[0m[2025-01-18T19:14:04.137625] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 52ff954ec15ffb738ecbbf96338eb634

[0m[2025-01-18T19:14:04.137673] [FLK_MGR] Running job id: 52ff954ec15ffb738ecbbf96338eb634
[0m[2025-01-18T19:14:04.137683] [FLK_MGR] Getting job info.
[0m[2025-01-18T19:14:04.154057] [FLK_MGR] Job plan response: {"plan":{"jid":"52ff954ec15ffb738ecbbf96338eb634","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T19:14:04.154186] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T19:14:04.536134] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-pb77d
[0m[2025-01-18T19:14:05.971335] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 19:14:03 : 52ff954ec15ffb738ecbbf96338eb634 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T19:14:05.971395] [FLK_MGR] Running jobs: ['52ff954ec15ffb738ecbbf96338eb634']
[0m[2025-01-18T19:14:05.971403] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T19:14:05.971415] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T19:18:05.993981] [SCALING] Scaling started.
[0m[2025-01-18T19:18:05.994038] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T19:18:06.007503] [SCALING] Scaling finished.
[0m[2025-01-18T19:18:06.007532] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:18:06.026400] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:18:06.045695] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T19:18:06.066840] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 0 replica.
[0m[2025-01-18T19:18:16.092369] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T19:18:16.105521] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T19:18:16.118699] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T19:18:16.131862] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T19:18:16.145272] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T19:18:16.179392] [POD_MGR] Pod flink-jobmanager-7d7c784b74-pb77d deleted
[0m[2025-01-18T19:18:18.127240] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:18:20.072888] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:18:20.072963] Reloading playbook: application/kafka
[0m[2025-01-18T19:18:26.048103] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T19:19:06.986765] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T19:19:06.987017] [EXPERIMENT] Run 4 completed. Start: 1737227630, End: 1737227946
[0m[2025-01-18T19:19:06.987024] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T19:19:16.988059] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T19:19:18.906833] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:19:20.876973] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:19:20.877145] [SCALING] Setting up experiment.


[0m[2025-01-18T19:19:20.877195] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:19:20.882535] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:19:20.897750] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T19:19:20.914094] [SCALING] Statefulset name to scale : flink-8000m-1024
[0m[2025-01-18T19:19:20.925440] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 1 replica.
[0m[2025-01-18T19:19:25.935839] [FLK_MGR] Running job.
[0m[2025-01-18T19:19:25.935867] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T19:19:26.312257] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mpj8t
[0m[2025-01-18T19:19:30.330034] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b36b5e8d72caedf5bb214a343b6331eb

[0m[2025-01-18T19:19:30.330088] [FLK_MGR] Running job id: b36b5e8d72caedf5bb214a343b6331eb
[0m[2025-01-18T19:19:30.330096] [FLK_MGR] Getting job info.
[0m[2025-01-18T19:19:30.349377] [FLK_MGR] Job plan response: {"plan":{"jid":"b36b5e8d72caedf5bb214a343b6331eb","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T19:19:30.349518] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T19:19:30.730912] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mpj8t
[0m[2025-01-18T19:19:32.182910] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 19:19:29 : b36b5e8d72caedf5bb214a343b6331eb : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T19:19:32.182972] [FLK_MGR] Running jobs: ['b36b5e8d72caedf5bb214a343b6331eb']
[0m[2025-01-18T19:19:32.182980] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T19:19:32.182993] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T19:23:32.206221] [SCALING] Scaling started.
[0m[2025-01-18T19:23:32.206285] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T19:23:32.219647] [SCALING] Scaling finished.
[0m[2025-01-18T19:23:32.219671] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:23:32.238800] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:23:32.256641] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T19:23:32.280551] [STS_MGR] StatefulSet flink-8000m-1024 scaled to 0 replica.
[0m[2025-01-18T19:23:42.309240] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T19:23:42.324510] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T19:23:42.337824] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T19:23:42.351188] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T19:23:42.364568] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T19:23:42.387627] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mpj8t deleted
[0m[2025-01-18T19:23:44.282609] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:23:46.205189] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:23:46.205277] Reloading playbook: application/kafka
[0m[2025-01-18T19:23:52.264538] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T19:24:33.270671] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T19:24:33.270927] [EXPERIMENT] Run 5 completed. Start: 1737227956, End: 1737228273
[0m[2025-01-18T19:24:33.270934] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T19:24:45.544833] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T19:24:45.544946] [RESOURCE_E] Running experiment with 8000m cores and 2048 memory.
[0m[2025-01-18T19:24:52.835378] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T19:24:52.835464] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T19:24:54.771890] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:24:56.681398] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:24:56.681486] [SCALING] Setting up experiment.


[0m[2025-01-18T19:24:56.681500] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:24:56.687308] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:24:56.704017] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T19:24:56.723141] [SCALING] Statefulset name to scale : flink-8000m-2048
[0m[2025-01-18T19:24:56.732756] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 1 replica.
[0m[2025-01-18T19:25:01.742533] [FLK_MGR] Running job.
[0m[2025-01-18T19:25:01.742562] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T19:25:02.146632] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-x7clx
[0m[2025-01-18T19:25:06.199501] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f6795c683a6a374d2cd3bc8e717cca8b

[0m[2025-01-18T19:25:06.199550] [FLK_MGR] Running job id: f6795c683a6a374d2cd3bc8e717cca8b
[0m[2025-01-18T19:25:06.199558] [FLK_MGR] Getting job info.
[0m[2025-01-18T19:25:06.218514] [FLK_MGR] Job plan response: {"plan":{"jid":"f6795c683a6a374d2cd3bc8e717cca8b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T19:25:06.218653] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T19:25:06.593963] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-x7clx
[0m[2025-01-18T19:25:08.045610] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 19:25:05 : f6795c683a6a374d2cd3bc8e717cca8b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T19:25:08.045670] [FLK_MGR] Running jobs: ['f6795c683a6a374d2cd3bc8e717cca8b']
[0m[2025-01-18T19:25:08.045679] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T19:25:08.045690] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T19:29:08.068093] [SCALING] Scaling started.
[0m[2025-01-18T19:29:08.068206] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T19:29:08.081045] [SCALING] Scaling finished.
[0m[2025-01-18T19:29:08.081077] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:29:08.099893] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:29:08.117661] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T19:29:08.138971] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 0 replica.
[0m[2025-01-18T19:29:13.157853] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T19:29:13.171394] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T19:29:13.184122] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T19:29:13.196671] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T19:29:13.209037] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T19:29:13.230436] [POD_MGR] Pod flink-jobmanager-7d7c784b74-x7clx deleted
[0m[2025-01-18T19:29:15.110374] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:29:17.083413] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:29:17.083493] Reloading playbook: application/kafka
[0m[2025-01-18T19:29:23.036240] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T19:30:04.039720] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T19:30:04.040002] [EXPERIMENT] Run 1 completed. Start: 1737228292, End: 1737228604
[0m[2025-01-18T19:30:04.040009] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T19:30:14.041032] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T19:30:15.967966] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:30:17.875707] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:30:17.875801] [SCALING] Setting up experiment.


[0m[2025-01-18T19:30:17.875816] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:30:17.881518] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:30:17.897812] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T19:30:17.917352] [SCALING] Statefulset name to scale : flink-8000m-2048
[0m[2025-01-18T19:30:17.928460] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 1 replica.
[0m[2025-01-18T19:30:22.938073] [FLK_MGR] Running job.
[0m[2025-01-18T19:30:22.938100] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T19:30:23.324762] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-q2zg5
[0m[2025-01-18T19:30:27.388400] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID d7fbd291fa85977abb8c6dda3f680215

[0m[2025-01-18T19:30:27.388534] [FLK_MGR] Running job id: d7fbd291fa85977abb8c6dda3f680215
[0m[2025-01-18T19:30:27.388544] [FLK_MGR] Getting job info.
[0m[2025-01-18T19:30:27.409051] [FLK_MGR] Job plan response: {"plan":{"jid":"d7fbd291fa85977abb8c6dda3f680215","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T19:30:27.409427] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T19:30:27.798181] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-q2zg5
[0m[2025-01-18T19:30:29.238616] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 19:30:26 : d7fbd291fa85977abb8c6dda3f680215 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T19:30:29.238674] [FLK_MGR] Running jobs: ['d7fbd291fa85977abb8c6dda3f680215']
[0m[2025-01-18T19:30:29.238683] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T19:30:29.238696] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T19:34:29.261233] [SCALING] Scaling started.
[0m[2025-01-18T19:34:29.261352] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T19:34:29.275407] [SCALING] Scaling finished.
[0m[2025-01-18T19:34:29.275452] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:34:29.295127] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:34:29.314271] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T19:34:29.336436] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 0 replica.
[0m[2025-01-18T19:34:34.357421] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T19:34:34.372502] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T19:34:34.386730] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T19:34:34.401340] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T19:34:34.417561] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T19:34:34.455082] [POD_MGR] Pod flink-jobmanager-7d7c784b74-q2zg5 deleted
[0m[2025-01-18T19:34:36.334262] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:34:38.284631] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:34:38.284714] Reloading playbook: application/kafka
[0m[2025-01-18T19:34:44.250923] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T19:35:25.239655] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T19:35:25.239913] [EXPERIMENT] Run 2 completed. Start: 1737228614, End: 1737228925
[0m[2025-01-18T19:35:25.239919] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T19:35:35.240980] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T19:35:37.167524] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:35:39.118207] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:35:39.118288] [SCALING] Setting up experiment.


[0m[2025-01-18T19:35:39.118299] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:35:39.124424] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:35:39.140207] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T19:35:39.156814] [SCALING] Statefulset name to scale : flink-8000m-2048
[0m[2025-01-18T19:35:39.167111] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 1 replica.
[0m[2025-01-18T19:35:44.178137] [FLK_MGR] Running job.
[0m[2025-01-18T19:35:44.178164] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T19:35:46.035635] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-tt7xf
[0m[2025-01-18T19:35:50.002611] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f1dce0391bd8b49783acfcba1ec05c8f

[0m[2025-01-18T19:35:50.002689] [FLK_MGR] Running job id: f1dce0391bd8b49783acfcba1ec05c8f
[0m[2025-01-18T19:35:50.002699] [FLK_MGR] Getting job info.
[0m[2025-01-18T19:35:50.020606] [FLK_MGR] Job plan response: {"plan":{"jid":"f1dce0391bd8b49783acfcba1ec05c8f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T19:35:50.020761] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T19:35:50.393386] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-tt7xf
[0m[2025-01-18T19:35:51.842577] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 19:35:49 : f1dce0391bd8b49783acfcba1ec05c8f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T19:35:51.842634] [FLK_MGR] Running jobs: ['f1dce0391bd8b49783acfcba1ec05c8f']
[0m[2025-01-18T19:35:51.842642] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T19:35:51.842650] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T19:39:51.865864] [SCALING] Scaling started.
[0m[2025-01-18T19:39:51.865968] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T19:39:51.879912] [SCALING] Scaling finished.
[0m[2025-01-18T19:39:51.879933] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:39:51.898442] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:39:51.916179] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T19:39:51.936422] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 0 replica.
[0m[2025-01-18T19:39:56.959375] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T19:39:56.976452] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T19:39:56.991242] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T19:39:57.005186] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T19:39:57.020386] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T19:39:57.053050] [POD_MGR] Pod flink-jobmanager-7d7c784b74-tt7xf deleted
[0m[2025-01-18T19:39:58.971791] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:40:00.864585] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:40:00.864660] Reloading playbook: application/kafka
[0m[2025-01-18T19:40:06.855620] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T19:40:47.859008] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T19:40:47.859269] [EXPERIMENT] Run 3 completed. Start: 1737228935, End: 1737229247
[0m[2025-01-18T19:40:47.859275] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T19:40:57.860340] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T19:40:59.791683] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:41:01.691694] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:41:01.691783] [SCALING] Setting up experiment.


[0m[2025-01-18T19:41:01.691797] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:41:01.704497] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:41:01.729617] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T19:41:01.748624] [SCALING] Statefulset name to scale : flink-8000m-2048
[0m[2025-01-18T19:41:01.758726] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 1 replica.
[0m[2025-01-18T19:41:06.769704] [FLK_MGR] Running job.
[0m[2025-01-18T19:41:06.769742] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T19:41:07.181317] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-kshjz
[0m[2025-01-18T19:41:11.195397] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 6f2e62ddde0fa219f17d97f162772e79

[0m[2025-01-18T19:41:11.195464] [FLK_MGR] Running job id: 6f2e62ddde0fa219f17d97f162772e79
[0m[2025-01-18T19:41:11.195492] [FLK_MGR] Getting job info.
[0m[2025-01-18T19:41:11.213615] [FLK_MGR] Job plan response: {"plan":{"jid":"6f2e62ddde0fa219f17d97f162772e79","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T19:41:11.213788] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T19:41:11.615114] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-kshjz
[0m[2025-01-18T19:41:13.036800] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 19:41:10 : 6f2e62ddde0fa219f17d97f162772e79 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T19:41:13.036865] [FLK_MGR] Running jobs: ['6f2e62ddde0fa219f17d97f162772e79']
[0m[2025-01-18T19:41:13.036873] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T19:41:13.036887] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T19:45:13.061190] [SCALING] Scaling started.
[0m[2025-01-18T19:45:13.061427] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T19:45:13.076035] [SCALING] Scaling finished.
[0m[2025-01-18T19:45:13.076066] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:45:13.093320] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:45:13.111434] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T19:45:13.135779] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 0 replica.
[0m[2025-01-18T19:45:18.156259] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T19:45:18.169725] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T19:45:18.184040] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T19:45:18.197574] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T19:45:18.211562] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T19:45:18.245547] [POD_MGR] Pod flink-jobmanager-7d7c784b74-kshjz deleted
[0m[2025-01-18T19:45:20.177568] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:45:22.164037] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:45:22.164153] Reloading playbook: application/kafka
[0m[2025-01-18T19:45:28.191614] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T19:46:09.219723] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T19:46:09.220114] [EXPERIMENT] Run 4 completed. Start: 1737229257, End: 1737229569
[0m[2025-01-18T19:46:09.220121] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T19:46:19.221093] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T19:46:21.131621] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:46:23.031978] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:46:23.032069] [SCALING] Setting up experiment.


[0m[2025-01-18T19:46:23.032081] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:46:23.037927] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:46:23.057311] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T19:46:23.089123] [SCALING] Statefulset name to scale : flink-8000m-2048
[0m[2025-01-18T19:46:23.100709] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 1 replica.
[0m[2025-01-18T19:46:28.119382] [FLK_MGR] Running job.
[0m[2025-01-18T19:46:28.119411] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T19:46:28.512469] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-v5gr8
[0m[2025-01-18T19:46:32.617069] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b00d774438d28c2e484669c215aa5965

[0m[2025-01-18T19:46:32.617125] [FLK_MGR] Running job id: b00d774438d28c2e484669c215aa5965
[0m[2025-01-18T19:46:32.617134] [FLK_MGR] Getting job info.
[0m[2025-01-18T19:46:32.635850] [FLK_MGR] Job plan response: {"plan":{"jid":"b00d774438d28c2e484669c215aa5965","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T19:46:32.636005] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T19:46:33.022905] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-v5gr8
[0m[2025-01-18T19:46:34.472995] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 19:46:31 : b00d774438d28c2e484669c215aa5965 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T19:46:34.473056] [FLK_MGR] Running jobs: ['b00d774438d28c2e484669c215aa5965']
[0m[2025-01-18T19:46:34.473076] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T19:46:34.473101] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T19:50:34.498628] [SCALING] Scaling started.
[0m[2025-01-18T19:50:34.498683] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T19:50:34.511248] [SCALING] Scaling finished.
[0m[2025-01-18T19:50:34.511272] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:50:34.528960] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:50:34.545730] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T19:50:34.569517] [STS_MGR] StatefulSet flink-8000m-2048 scaled to 0 replica.
[0m[2025-01-18T19:50:39.589679] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T19:50:39.605309] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T19:50:39.620042] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T19:50:39.632932] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T19:50:39.647527] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T19:50:39.677440] [POD_MGR] Pod flink-jobmanager-7d7c784b74-v5gr8 deleted
[0m[2025-01-18T19:50:41.602375] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:50:43.563188] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:50:43.563264] Reloading playbook: application/kafka
[0m[2025-01-18T19:50:49.562534] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T19:51:30.537007] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T19:51:30.537259] [EXPERIMENT] Run 5 completed. Start: 1737229579, End: 1737229890
[0m[2025-01-18T19:51:30.537266] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T19:51:42.779646] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T19:51:42.779736] [RESOURCE_E] Running experiment with 8000m cores and 4096 memory.
[0m[2025-01-18T19:51:50.077725] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T19:51:50.077803] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T19:51:51.999143] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:51:53.944408] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:51:53.944483] [SCALING] Setting up experiment.


[0m[2025-01-18T19:51:53.944497] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:51:53.950342] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:51:53.967331] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T19:51:53.984361] [SCALING] Statefulset name to scale : flink-8000m-4096
[0m[2025-01-18T19:51:53.994577] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 1 replica.
[0m[2025-01-18T19:51:59.004428] [FLK_MGR] Running job.
[0m[2025-01-18T19:51:59.004458] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T19:51:59.394805] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xfgqs
[0m[2025-01-18T19:52:03.521632] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 2c42794bb6eab1119c893fb59f76aa2a

[0m[2025-01-18T19:52:03.521683] [FLK_MGR] Running job id: 2c42794bb6eab1119c893fb59f76aa2a
[0m[2025-01-18T19:52:03.521691] [FLK_MGR] Getting job info.
[0m[2025-01-18T19:52:03.540355] [FLK_MGR] Job plan response: {"plan":{"jid":"2c42794bb6eab1119c893fb59f76aa2a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T19:52:03.540486] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T19:52:03.912248] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xfgqs
[0m[2025-01-18T19:52:05.324486] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 19:52:02 : 2c42794bb6eab1119c893fb59f76aa2a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T19:52:05.324548] [FLK_MGR] Running jobs: ['2c42794bb6eab1119c893fb59f76aa2a']
[0m[2025-01-18T19:52:05.324555] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T19:52:05.324570] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T19:56:05.346694] [SCALING] Scaling started.
[0m[2025-01-18T19:56:05.346804] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T19:56:05.359123] [SCALING] Scaling finished.
[0m[2025-01-18T19:56:05.359148] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:56:05.378062] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:56:05.395432] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T19:56:05.416755] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 0 replica.
[0m[2025-01-18T19:56:10.438743] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T19:56:10.455543] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T19:56:10.471154] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T19:56:10.486613] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T19:56:10.500476] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T19:56:10.524251] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xfgqs deleted
[0m[2025-01-18T19:56:12.440316] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:56:14.414794] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T19:56:14.414865] Reloading playbook: application/kafka
[0m[2025-01-18T19:56:20.366253] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T19:57:01.379074] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T19:57:01.379327] [EXPERIMENT] Run 1 completed. Start: 1737229910, End: 1737230221
[0m[2025-01-18T19:57:01.379333] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T19:57:11.380302] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T19:57:13.296540] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:57:15.217542] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T19:57:15.217626] [SCALING] Setting up experiment.


[0m[2025-01-18T19:57:15.217637] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T19:57:15.223174] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T19:57:15.240656] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T19:57:15.257453] [SCALING] Statefulset name to scale : flink-8000m-4096
[0m[2025-01-18T19:57:15.268879] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 1 replica.
[0m[2025-01-18T19:57:20.279452] [FLK_MGR] Running job.
[0m[2025-01-18T19:57:20.279479] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T19:57:20.667051] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-nbmtt
[0m[2025-01-18T19:57:24.763231] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID bc0cd01d5c27263e42377d1ef6a5b3eb

[0m[2025-01-18T19:57:24.763339] [FLK_MGR] Running job id: bc0cd01d5c27263e42377d1ef6a5b3eb
[0m[2025-01-18T19:57:24.763359] [FLK_MGR] Getting job info.
[0m[2025-01-18T19:57:24.782610] [FLK_MGR] Job plan response: {"plan":{"jid":"bc0cd01d5c27263e42377d1ef6a5b3eb","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T19:57:24.782792] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T19:57:25.178074] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-nbmtt
[0m[2025-01-18T19:57:26.608784] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 19:57:23 : bc0cd01d5c27263e42377d1ef6a5b3eb : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T19:57:26.608844] [FLK_MGR] Running jobs: ['bc0cd01d5c27263e42377d1ef6a5b3eb']
[0m[2025-01-18T19:57:26.608852] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T19:57:26.608865] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T20:01:26.632910] [SCALING] Scaling started.
[0m[2025-01-18T20:01:26.632964] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T20:01:26.647359] [SCALING] Scaling finished.
[0m[2025-01-18T20:01:26.647382] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:01:26.668231] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:01:26.686862] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T20:01:26.712187] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 0 replica.
[0m[2025-01-18T20:01:36.738206] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T20:01:36.754147] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T20:01:36.769533] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T20:01:36.783646] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T20:01:36.800738] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T20:01:36.839873] [POD_MGR] Pod flink-jobmanager-7d7c784b74-nbmtt deleted
[0m[2025-01-18T20:01:38.762434] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:01:40.710833] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:01:40.710926] Reloading playbook: application/kafka
[0m[2025-01-18T20:01:46.770610] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T20:02:27.788003] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T20:02:27.788350] [EXPERIMENT] Run 2 completed. Start: 1737230231, End: 1737230547
[0m[2025-01-18T20:02:27.788358] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T20:02:37.789612] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T20:02:39.699781] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:02:41.629885] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:02:41.629985] [SCALING] Setting up experiment.


[0m[2025-01-18T20:02:41.629997] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:02:41.635892] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:02:41.653615] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T20:02:41.671505] [SCALING] Statefulset name to scale : flink-8000m-4096
[0m[2025-01-18T20:02:41.682414] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 1 replica.
[0m[2025-01-18T20:02:46.694747] [FLK_MGR] Running job.
[0m[2025-01-18T20:02:46.694778] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T20:02:47.122427] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-665j6
[0m[2025-01-18T20:02:51.202986] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 453c34e0615eded885359256d6f39dca

[0m[2025-01-18T20:02:51.203037] [FLK_MGR] Running job id: 453c34e0615eded885359256d6f39dca
[0m[2025-01-18T20:02:51.203046] [FLK_MGR] Getting job info.
[0m[2025-01-18T20:02:51.224059] [FLK_MGR] Job plan response: {"plan":{"jid":"453c34e0615eded885359256d6f39dca","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T20:02:51.224208] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T20:02:51.622185] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-665j6
[0m[2025-01-18T20:02:53.067764] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 20:02:50 : 453c34e0615eded885359256d6f39dca : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T20:02:53.067830] [FLK_MGR] Running jobs: ['453c34e0615eded885359256d6f39dca']
[0m[2025-01-18T20:02:53.067841] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T20:02:53.067870] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T20:06:53.090272] [SCALING] Scaling started.
[0m[2025-01-18T20:06:53.090401] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T20:06:53.105682] [SCALING] Scaling finished.
[0m[2025-01-18T20:06:53.105707] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:06:53.125764] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:06:53.145012] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T20:06:53.167397] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 0 replica.
[0m[2025-01-18T20:06:58.189091] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T20:06:58.204468] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T20:06:58.221651] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T20:06:58.235272] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T20:06:58.249495] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T20:06:58.286586] [POD_MGR] Pod flink-jobmanager-7d7c784b74-665j6 deleted
[0m[2025-01-18T20:07:00.168154] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:07:02.067926] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:07:02.068025] Reloading playbook: application/kafka
[0m[2025-01-18T20:07:08.122226] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T20:07:49.097425] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T20:07:49.097799] [EXPERIMENT] Run 3 completed. Start: 1737230557, End: 1737230869
[0m[2025-01-18T20:07:49.097826] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T20:07:59.098949] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T20:08:01.071764] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:08:03.019559] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:08:03.019661] [SCALING] Setting up experiment.


[0m[2025-01-18T20:08:03.019673] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:08:03.025592] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:08:03.042862] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T20:08:03.060079] [SCALING] Statefulset name to scale : flink-8000m-4096
[0m[2025-01-18T20:08:03.070183] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 1 replica.
[0m[2025-01-18T20:08:08.081516] [FLK_MGR] Running job.
[0m[2025-01-18T20:08:08.081550] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T20:08:08.499490] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-q5tmh
[0m[2025-01-18T20:08:12.553639] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8ed04bf7393a28e823e8ebef9d72e4d6

[0m[2025-01-18T20:08:12.553699] [FLK_MGR] Running job id: 8ed04bf7393a28e823e8ebef9d72e4d6
[0m[2025-01-18T20:08:12.553710] [FLK_MGR] Getting job info.
[0m[2025-01-18T20:08:12.572367] [FLK_MGR] Job plan response: {"plan":{"jid":"8ed04bf7393a28e823e8ebef9d72e4d6","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T20:08:12.572527] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T20:08:14.427999] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-q5tmh
[0m[2025-01-18T20:08:15.856472] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 20:08:11 : 8ed04bf7393a28e823e8ebef9d72e4d6 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T20:08:15.856543] [FLK_MGR] Running jobs: ['8ed04bf7393a28e823e8ebef9d72e4d6']
[0m[2025-01-18T20:08:15.856552] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T20:08:15.856559] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T20:12:15.881664] [SCALING] Scaling started.
[0m[2025-01-18T20:12:15.881771] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T20:12:15.895629] [SCALING] Scaling finished.
[0m[2025-01-18T20:12:15.895649] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:12:15.916231] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:12:15.934341] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T20:12:15.958301] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 0 replica.
[0m[2025-01-18T20:12:20.977853] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T20:12:20.991773] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T20:12:21.006097] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T20:12:21.020323] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T20:12:21.034137] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T20:12:21.065106] [POD_MGR] Pod flink-jobmanager-7d7c784b74-q5tmh deleted
[0m[2025-01-18T20:12:23.034165] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:12:24.957383] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:12:24.957487] Reloading playbook: application/kafka
[0m[2025-01-18T20:12:30.906138] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T20:13:11.856489] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T20:13:11.856713] [EXPERIMENT] Run 4 completed. Start: 1737230879, End: 1737231191
[0m[2025-01-18T20:13:11.856720] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T20:13:21.857604] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T20:13:23.766183] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:13:25.661772] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:13:25.661851] [SCALING] Setting up experiment.


[0m[2025-01-18T20:13:25.661862] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:13:25.667205] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:13:25.684116] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T20:13:25.701861] [SCALING] Statefulset name to scale : flink-8000m-4096
[0m[2025-01-18T20:13:25.713594] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 1 replica.
[0m[2025-01-18T20:13:30.724675] [FLK_MGR] Running job.
[0m[2025-01-18T20:13:30.724701] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T20:13:31.114081] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-wjkbx
[0m[2025-01-18T20:13:35.204416] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5f39d91a66f62b13b8fe3a6e3bf738c7

[0m[2025-01-18T20:13:35.204462] [FLK_MGR] Running job id: 5f39d91a66f62b13b8fe3a6e3bf738c7
[0m[2025-01-18T20:13:35.204469] [FLK_MGR] Getting job info.
[0m[2025-01-18T20:13:35.222640] [FLK_MGR] Job plan response: {"plan":{"jid":"5f39d91a66f62b13b8fe3a6e3bf738c7","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T20:13:35.222863] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T20:13:35.629621] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-wjkbx
[0m[2025-01-18T20:13:37.063826] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 20:13:34 : 5f39d91a66f62b13b8fe3a6e3bf738c7 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T20:13:37.063884] [FLK_MGR] Running jobs: ['5f39d91a66f62b13b8fe3a6e3bf738c7']
[0m[2025-01-18T20:13:37.063892] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T20:13:37.063905] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T20:17:37.086959] [SCALING] Scaling started.
[0m[2025-01-18T20:17:37.087068] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T20:17:37.103740] [SCALING] Scaling finished.
[0m[2025-01-18T20:17:37.103770] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:17:37.120660] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:17:37.153134] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T20:17:37.176845] [STS_MGR] StatefulSet flink-8000m-4096 scaled to 0 replica.
[0m[2025-01-18T20:17:47.204836] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T20:17:47.218315] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T20:17:47.231274] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T20:17:47.245689] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T20:17:47.260347] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T20:17:47.296956] [POD_MGR] Pod flink-jobmanager-7d7c784b74-wjkbx deleted
[0m[2025-01-18T20:17:49.223456] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:17:51.216203] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:17:51.216278] Reloading playbook: application/kafka
[0m[2025-01-18T20:17:57.206543] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T20:18:38.259930] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T20:18:38.260208] [EXPERIMENT] Run 5 completed. Start: 1737231201, End: 1737231518
[0m[2025-01-18T20:18:38.260215] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T20:18:50.522661] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T20:18:50.522742] [RESOURCE_E] Running experiment with 8000m cores and 8192 memory.
[0m[2025-01-18T20:18:57.808656] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T20:18:57.808734] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T20:18:59.740441] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:19:01.661273] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:19:01.661357] [SCALING] Setting up experiment.


[0m[2025-01-18T20:19:01.661371] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:19:01.667506] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:19:01.684772] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T20:19:01.702263] [SCALING] Statefulset name to scale : flink-8000m-8192
[0m[2025-01-18T20:19:01.712570] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 1 replica.
[0m[2025-01-18T20:19:06.723425] [FLK_MGR] Running job.
[0m[2025-01-18T20:19:06.723452] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T20:19:07.112933] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mhmtg
[0m[2025-01-18T20:19:11.166481] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 7215aa20ef47b11f8a71d2be7ac48e82

[0m[2025-01-18T20:19:11.166535] [FLK_MGR] Running job id: 7215aa20ef47b11f8a71d2be7ac48e82
[0m[2025-01-18T20:19:11.166546] [FLK_MGR] Getting job info.
[0m[2025-01-18T20:19:11.183870] [FLK_MGR] Job plan response: {"plan":{"jid":"7215aa20ef47b11f8a71d2be7ac48e82","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T20:19:11.184068] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T20:19:11.569677] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mhmtg
[0m[2025-01-18T20:19:13.014487] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 20:19:10 : 7215aa20ef47b11f8a71d2be7ac48e82 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T20:19:13.014560] [FLK_MGR] Running jobs: ['7215aa20ef47b11f8a71d2be7ac48e82']
[0m[2025-01-18T20:19:13.014568] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T20:19:13.014583] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T20:23:13.036516] [SCALING] Scaling started.
[0m[2025-01-18T20:23:13.036576] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T20:23:13.051296] [SCALING] Scaling finished.
[0m[2025-01-18T20:23:13.051328] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:23:13.073322] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:23:13.090813] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T20:23:13.117635] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 0 replica.
[0m[2025-01-18T20:23:18.137936] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T20:23:18.151798] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T20:23:18.165173] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T20:23:18.178395] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T20:23:18.191676] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T20:23:18.213884] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mhmtg deleted
[0m[2025-01-18T20:23:20.155827] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:23:22.164582] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:23:22.164657] Reloading playbook: application/kafka
[0m[2025-01-18T20:23:28.129911] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T20:24:09.109015] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T20:24:09.109274] [EXPERIMENT] Run 1 completed. Start: 1737231537, End: 1737231849
[0m[2025-01-18T20:24:09.109281] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T20:24:19.110376] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T20:24:21.048687] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:24:22.969303] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:24:22.969382] [SCALING] Setting up experiment.


[0m[2025-01-18T20:24:22.969395] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:24:22.974631] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:24:22.990442] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T20:24:23.007646] [SCALING] Statefulset name to scale : flink-8000m-8192
[0m[2025-01-18T20:24:23.017592] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 1 replica.
[0m[2025-01-18T20:24:28.026616] [FLK_MGR] Running job.
[0m[2025-01-18T20:24:28.026642] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T20:24:28.405350] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-cxc64
[0m[2025-01-18T20:24:32.469867] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f55fc5d3318628542ca1b7926ca6b134

[0m[2025-01-18T20:24:32.469926] [FLK_MGR] Running job id: f55fc5d3318628542ca1b7926ca6b134
[0m[2025-01-18T20:24:32.469935] [FLK_MGR] Getting job info.
[0m[2025-01-18T20:24:32.488444] [FLK_MGR] Job plan response: {"plan":{"jid":"f55fc5d3318628542ca1b7926ca6b134","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T20:24:32.488616] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T20:24:32.870577] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-cxc64
[0m[2025-01-18T20:24:34.308101] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 20:24:31 : f55fc5d3318628542ca1b7926ca6b134 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T20:24:34.308157] [FLK_MGR] Running jobs: ['f55fc5d3318628542ca1b7926ca6b134']
[0m[2025-01-18T20:24:34.308166] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T20:24:34.308177] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T20:28:34.333722] [SCALING] Scaling started.
[0m[2025-01-18T20:28:34.333779] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T20:28:34.348156] [SCALING] Scaling finished.
[0m[2025-01-18T20:28:34.348207] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:28:34.368501] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:28:34.385788] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T20:28:34.408539] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 0 replica.
[0m[2025-01-18T20:28:39.429818] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T20:28:39.443449] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T20:28:39.459323] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T20:28:39.474995] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T20:28:39.491431] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T20:28:39.525045] [POD_MGR] Pod flink-jobmanager-7d7c784b74-cxc64 deleted
[0m[2025-01-18T20:28:41.469257] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:28:43.369734] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:28:43.369816] Reloading playbook: application/kafka
[0m[2025-01-18T20:28:49.270699] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T20:29:30.251614] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T20:29:30.251963] [EXPERIMENT] Run 2 completed. Start: 1737231859, End: 1737232170
[0m[2025-01-18T20:29:30.251972] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T20:29:40.252896] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T20:29:42.182966] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:29:44.119625] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:29:44.119725] [SCALING] Setting up experiment.


[0m[2025-01-18T20:29:44.119739] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:29:44.125318] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:29:44.141863] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T20:29:44.157390] [SCALING] Statefulset name to scale : flink-8000m-8192
[0m[2025-01-18T20:29:44.166701] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 1 replica.
[0m[2025-01-18T20:29:49.176757] [FLK_MGR] Running job.
[0m[2025-01-18T20:29:49.176784] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T20:29:49.557367] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-2pww6
[0m[2025-01-18T20:29:53.640405] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0b350f29f7f2d4ba51b30c1f815313b9

[0m[2025-01-18T20:29:53.640462] [FLK_MGR] Running job id: 0b350f29f7f2d4ba51b30c1f815313b9
[0m[2025-01-18T20:29:53.640469] [FLK_MGR] Getting job info.
[0m[2025-01-18T20:29:53.658987] [FLK_MGR] Job plan response: {"plan":{"jid":"0b350f29f7f2d4ba51b30c1f815313b9","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T20:29:53.659129] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T20:29:54.040337] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-2pww6
[0m[2025-01-18T20:29:55.486716] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 20:29:52 : 0b350f29f7f2d4ba51b30c1f815313b9 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T20:29:55.486788] [FLK_MGR] Running jobs: ['0b350f29f7f2d4ba51b30c1f815313b9']
[0m[2025-01-18T20:29:55.486797] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T20:29:55.486809] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T20:33:55.509592] [SCALING] Scaling started.
[0m[2025-01-18T20:33:55.509707] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T20:33:55.523330] [SCALING] Scaling finished.
[0m[2025-01-18T20:33:55.523363] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:33:55.542205] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:33:55.559885] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T20:33:55.581777] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 0 replica.
[0m[2025-01-18T20:34:00.603250] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T20:34:00.616481] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T20:34:00.631939] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T20:34:00.647473] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T20:34:00.661988] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T20:34:00.687575] [POD_MGR] Pod flink-jobmanager-7d7c784b74-2pww6 deleted
[0m[2025-01-18T20:34:02.626571] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:34:04.609608] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:34:04.609685] Reloading playbook: application/kafka
[0m[2025-01-18T20:34:10.583158] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T20:34:51.575044] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T20:34:51.575324] [EXPERIMENT] Run 3 completed. Start: 1737232180, End: 1737232491
[0m[2025-01-18T20:34:51.575331] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T20:35:01.576288] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T20:35:03.495537] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:35:05.407378] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:35:05.407474] [SCALING] Setting up experiment.


[0m[2025-01-18T20:35:05.407488] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:35:05.413627] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:35:05.429877] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T20:35:05.445358] [SCALING] Statefulset name to scale : flink-8000m-8192
[0m[2025-01-18T20:35:05.456642] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 1 replica.
[0m[2025-01-18T20:35:10.467579] [FLK_MGR] Running job.
[0m[2025-01-18T20:35:10.467621] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T20:35:10.863481] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-htbkx
[0m[2025-01-18T20:35:15.036479] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID be4a1ffa90c48a576f035ea989375ec0

[0m[2025-01-18T20:35:15.036546] [FLK_MGR] Running job id: be4a1ffa90c48a576f035ea989375ec0
[0m[2025-01-18T20:35:15.036555] [FLK_MGR] Getting job info.
[0m[2025-01-18T20:35:15.057972] [FLK_MGR] Job plan response: {"plan":{"jid":"be4a1ffa90c48a576f035ea989375ec0","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T20:35:15.058231] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T20:35:15.465466] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-htbkx
[0m[2025-01-18T20:35:16.901209] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 20:35:14 : be4a1ffa90c48a576f035ea989375ec0 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T20:35:16.901274] [FLK_MGR] Running jobs: ['be4a1ffa90c48a576f035ea989375ec0']
[0m[2025-01-18T20:35:16.901281] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T20:35:16.901295] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T20:39:16.923881] [SCALING] Scaling started.
[0m[2025-01-18T20:39:16.923939] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T20:39:16.935686] [SCALING] Scaling finished.
[0m[2025-01-18T20:39:16.935710] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:39:16.956032] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:39:16.973725] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T20:39:16.995856] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 0 replica.
[0m[2025-01-18T20:39:22.016541] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T20:39:22.030753] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T20:39:22.046736] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T20:39:22.060704] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T20:39:22.075408] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T20:39:22.106164] [POD_MGR] Pod flink-jobmanager-7d7c784b74-htbkx deleted
[0m[2025-01-18T20:39:24.014708] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:39:25.931562] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:39:25.931653] Reloading playbook: application/kafka
[0m[2025-01-18T20:39:31.901333] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T20:40:12.896561] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T20:40:12.896900] [EXPERIMENT] Run 4 completed. Start: 1737232501, End: 1737232812
[0m[2025-01-18T20:40:12.896908] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T20:40:22.898103] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T20:40:24.805571] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:40:26.736278] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:40:26.736381] [SCALING] Setting up experiment.


[0m[2025-01-18T20:40:26.736392] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:40:26.743407] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:40:26.760069] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T20:40:26.776745] [SCALING] Statefulset name to scale : flink-8000m-8192
[0m[2025-01-18T20:40:26.786748] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 1 replica.
[0m[2025-01-18T20:40:31.796667] [FLK_MGR] Running job.
[0m[2025-01-18T20:40:31.796694] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T20:40:33.621096] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mxxvc
[0m[2025-01-18T20:40:37.637202] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 2e173d7bfc2ce9795ac1fc2eff95652a

[0m[2025-01-18T20:40:37.637251] [FLK_MGR] Running job id: 2e173d7bfc2ce9795ac1fc2eff95652a
[0m[2025-01-18T20:40:37.637259] [FLK_MGR] Getting job info.
[0m[2025-01-18T20:40:37.653886] [FLK_MGR] Job plan response: {"plan":{"jid":"2e173d7bfc2ce9795ac1fc2eff95652a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T20:40:37.654029] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T20:40:38.031082] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mxxvc
[0m[2025-01-18T20:40:39.457155] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 20:40:36 : 2e173d7bfc2ce9795ac1fc2eff95652a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T20:40:39.457211] [FLK_MGR] Running jobs: ['2e173d7bfc2ce9795ac1fc2eff95652a']
[0m[2025-01-18T20:40:39.457220] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T20:40:39.457233] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T20:44:39.480183] [SCALING] Scaling started.
[0m[2025-01-18T20:44:39.480235] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T20:44:39.493766] [SCALING] Scaling finished.
[0m[2025-01-18T20:44:39.493800] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:44:39.512782] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:44:39.531657] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T20:44:39.554571] [STS_MGR] StatefulSet flink-8000m-8192 scaled to 0 replica.
[0m[2025-01-18T20:44:49.582197] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T20:44:49.596121] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T20:44:49.610303] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T20:44:49.623494] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T20:44:49.637074] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T20:44:49.660780] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mxxvc deleted
[0m[2025-01-18T20:44:51.606597] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:44:53.573893] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:44:53.573963] Reloading playbook: application/kafka
[0m[2025-01-18T20:44:59.529541] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T20:45:40.533042] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T20:45:40.533241] [EXPERIMENT] Run 5 completed. Start: 1737232822, End: 1737233140
[0m[2025-01-18T20:45:40.533249] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T20:45:52.777795] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T20:45:52.777895] [RESOURCE_E] Running experiment with 8000m cores and 16384 memory.
[0m[2025-01-18T20:46:00.056395] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T20:46:00.056475] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T20:46:01.959950] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:46:03.906853] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:46:03.906927] [SCALING] Setting up experiment.


[0m[2025-01-18T20:46:03.906937] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:46:03.912653] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:46:03.930970] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T20:46:03.949738] [SCALING] Statefulset name to scale : flink-8000m-16384
[0m[2025-01-18T20:46:03.959818] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 1 replica.
[0m[2025-01-18T20:46:08.970374] [FLK_MGR] Running job.
[0m[2025-01-18T20:46:08.970403] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T20:46:09.346345] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-692nw
[0m[2025-01-18T20:46:13.487650] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID ceafb1d76c71b78e07a321e54f42fe4f

[0m[2025-01-18T20:46:13.487712] [FLK_MGR] Running job id: ceafb1d76c71b78e07a321e54f42fe4f
[0m[2025-01-18T20:46:13.487719] [FLK_MGR] Getting job info.
[0m[2025-01-18T20:46:13.505273] [FLK_MGR] Job plan response: {"plan":{"jid":"ceafb1d76c71b78e07a321e54f42fe4f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T20:46:13.505391] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T20:46:13.912184] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-692nw
[0m[2025-01-18T20:46:15.352262] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 20:46:12 : ceafb1d76c71b78e07a321e54f42fe4f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T20:46:15.352324] [FLK_MGR] Running jobs: ['ceafb1d76c71b78e07a321e54f42fe4f']
[0m[2025-01-18T20:46:15.352332] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T20:46:15.352342] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T20:50:15.374737] [SCALING] Scaling started.
[0m[2025-01-18T20:50:15.374780] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T20:50:15.388493] [SCALING] Scaling finished.
[0m[2025-01-18T20:50:15.388522] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:50:15.406476] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:50:15.423936] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T20:50:15.447241] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 0 replica.
[0m[2025-01-18T20:50:20.469245] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T20:50:20.486473] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T20:50:20.501729] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T20:50:20.514517] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T20:50:20.528542] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T20:50:20.579536] [POD_MGR] Pod flink-jobmanager-7d7c784b74-692nw deleted
[0m[2025-01-18T20:50:22.476521] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:50:24.393782] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:50:24.393863] Reloading playbook: application/kafka
[0m[2025-01-18T20:50:30.374589] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T20:51:11.388716] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T20:51:11.388978] [EXPERIMENT] Run 1 completed. Start: 1737233160, End: 1737233471
[0m[2025-01-18T20:51:11.388984] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T20:51:21.389853] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T20:51:23.290864] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:51:25.184696] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:51:25.184787] [SCALING] Setting up experiment.


[0m[2025-01-18T20:51:25.184801] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:51:25.190032] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:51:25.205507] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T20:51:25.221536] [SCALING] Statefulset name to scale : flink-8000m-16384
[0m[2025-01-18T20:51:25.232875] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 1 replica.
[0m[2025-01-18T20:51:30.243032] [FLK_MGR] Running job.
[0m[2025-01-18T20:51:30.243067] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T20:51:30.645671] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-t8rrc
[0m[2025-01-18T20:51:34.682726] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID d4fce1dee464748e73e9a2a06b874803

[0m[2025-01-18T20:51:34.682784] [FLK_MGR] Running job id: d4fce1dee464748e73e9a2a06b874803
[0m[2025-01-18T20:51:34.682794] [FLK_MGR] Getting job info.
[0m[2025-01-18T20:51:34.701802] [FLK_MGR] Job plan response: {"plan":{"jid":"d4fce1dee464748e73e9a2a06b874803","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T20:51:34.701955] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T20:51:35.083277] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-t8rrc
[0m[2025-01-18T20:51:36.517820] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 20:51:33 : d4fce1dee464748e73e9a2a06b874803 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T20:51:36.517881] [FLK_MGR] Running jobs: ['d4fce1dee464748e73e9a2a06b874803']
[0m[2025-01-18T20:51:36.517888] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T20:51:36.517904] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T20:55:36.539636] [SCALING] Scaling started.
[0m[2025-01-18T20:55:36.539694] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T20:55:36.553917] [SCALING] Scaling finished.
[0m[2025-01-18T20:55:36.553949] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:55:36.572414] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:55:36.588841] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T20:55:36.608603] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 0 replica.
[0m[2025-01-18T20:55:41.629495] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T20:55:41.643829] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T20:55:41.658085] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T20:55:41.673728] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T20:55:41.688248] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T20:55:41.720250] [POD_MGR] Pod flink-jobmanager-7d7c784b74-t8rrc deleted
[0m[2025-01-18T20:55:43.643264] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:55:45.585146] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T20:55:45.585241] Reloading playbook: application/kafka
[0m[2025-01-18T20:55:51.525645] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T20:56:32.556004] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T20:56:32.556249] [EXPERIMENT] Run 2 completed. Start: 1737233481, End: 1737233792
[0m[2025-01-18T20:56:32.556257] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T20:56:42.557224] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T20:56:44.456346] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:56:46.401705] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T20:56:46.401793] [SCALING] Setting up experiment.


[0m[2025-01-18T20:56:46.401807] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T20:56:46.407192] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T20:56:46.423388] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T20:56:46.441047] [SCALING] Statefulset name to scale : flink-8000m-16384
[0m[2025-01-18T20:56:46.452165] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 1 replica.
[0m[2025-01-18T20:56:51.463558] [FLK_MGR] Running job.
[0m[2025-01-18T20:56:51.463643] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T20:56:51.848073] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mhwvz
[0m[2025-01-18T20:56:55.922594] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 055a96162be9f0c1d2c22ca4163daa21

[0m[2025-01-18T20:56:55.922675] [FLK_MGR] Running job id: 055a96162be9f0c1d2c22ca4163daa21
[0m[2025-01-18T20:56:55.922686] [FLK_MGR] Getting job info.
[0m[2025-01-18T20:56:55.939319] [FLK_MGR] Job plan response: {"plan":{"jid":"055a96162be9f0c1d2c22ca4163daa21","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T20:56:55.939585] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T20:56:56.326024] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mhwvz
[0m[2025-01-18T20:56:57.786063] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 20:56:54 : 055a96162be9f0c1d2c22ca4163daa21 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T20:56:57.786121] [FLK_MGR] Running jobs: ['055a96162be9f0c1d2c22ca4163daa21']
[0m[2025-01-18T20:56:57.786128] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T20:56:57.786139] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T21:00:57.808107] [SCALING] Scaling started.
[0m[2025-01-18T21:00:57.808164] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T21:00:57.822353] [SCALING] Scaling finished.
[0m[2025-01-18T21:00:57.822376] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:00:57.841875] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:00:57.858629] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T21:00:57.879891] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 0 replica.
[0m[2025-01-18T21:01:02.903210] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T21:01:02.918316] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T21:01:02.933142] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T21:01:02.947061] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T21:01:02.960868] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T21:01:02.982816] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mhwvz deleted
[0m[2025-01-18T21:01:04.928337] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:01:06.911536] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:01:06.911621] Reloading playbook: application/kafka
[0m[2025-01-18T21:01:12.952061] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T21:01:53.972114] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T21:01:53.972358] [EXPERIMENT] Run 3 completed. Start: 1737233802, End: 1737234113
[0m[2025-01-18T21:01:53.972364] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T21:02:03.973410] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T21:02:05.891089] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:02:07.794194] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:02:07.794295] [SCALING] Setting up experiment.


[0m[2025-01-18T21:02:07.794307] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:02:07.800878] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:02:07.819620] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T21:02:07.836108] [SCALING] Statefulset name to scale : flink-8000m-16384
[0m[2025-01-18T21:02:07.846162] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 1 replica.
[0m[2025-01-18T21:02:12.857439] [FLK_MGR] Running job.
[0m[2025-01-18T21:02:12.857467] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T21:02:13.244279] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-9z8qx
[0m[2025-01-18T21:02:17.323493] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID bd29e75635ce439d7133a44adaaa27c1

[0m[2025-01-18T21:02:17.323602] [FLK_MGR] Running job id: bd29e75635ce439d7133a44adaaa27c1
[0m[2025-01-18T21:02:17.323622] [FLK_MGR] Getting job info.
[0m[2025-01-18T21:02:17.343900] [FLK_MGR] Job plan response: {"plan":{"jid":"bd29e75635ce439d7133a44adaaa27c1","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T21:02:17.344100] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T21:02:17.739805] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-9z8qx
[0m[2025-01-18T21:02:19.179732] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 21:02:16 : bd29e75635ce439d7133a44adaaa27c1 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T21:02:19.179795] [FLK_MGR] Running jobs: ['bd29e75635ce439d7133a44adaaa27c1']
[0m[2025-01-18T21:02:19.179803] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T21:02:19.179816] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T21:06:19.203919] [SCALING] Scaling started.
[0m[2025-01-18T21:06:19.203968] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T21:06:19.217513] [SCALING] Scaling finished.
[0m[2025-01-18T21:06:19.217540] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:06:19.237151] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:06:19.256412] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T21:06:19.279682] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 0 replica.
[0m[2025-01-18T21:06:29.308020] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T21:06:29.324417] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T21:06:29.340400] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T21:06:29.355060] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T21:06:29.370057] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T21:06:29.406890] [POD_MGR] Pod flink-jobmanager-7d7c784b74-9z8qx deleted
[0m[2025-01-18T21:06:31.347376] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:06:33.307780] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:06:33.307872] Reloading playbook: application/kafka
[0m[2025-01-18T21:06:39.290864] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T21:07:20.267730] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T21:07:20.267953] [EXPERIMENT] Run 4 completed. Start: 1737234123, End: 1737234440
[0m[2025-01-18T21:07:20.267960] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T21:07:30.269098] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T21:07:32.195314] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:07:34.130275] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:07:34.130363] [SCALING] Setting up experiment.


[0m[2025-01-18T21:07:34.130372] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:07:34.136513] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:07:34.153876] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T21:07:34.171405] [SCALING] Statefulset name to scale : flink-8000m-16384
[0m[2025-01-18T21:07:34.181936] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 1 replica.
[0m[2025-01-18T21:07:39.192187] [FLK_MGR] Running job.
[0m[2025-01-18T21:07:39.192221] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T21:07:39.581621] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-q7779
[0m[2025-01-18T21:07:43.674449] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 71f4e10fc926b6c763256d63244e6353

[0m[2025-01-18T21:07:43.674511] [FLK_MGR] Running job id: 71f4e10fc926b6c763256d63244e6353
[0m[2025-01-18T21:07:43.674526] [FLK_MGR] Getting job info.
[0m[2025-01-18T21:07:43.693316] [FLK_MGR] Job plan response: {"plan":{"jid":"71f4e10fc926b6c763256d63244e6353","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T21:07:43.693471] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T21:07:44.085669] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-q7779
[0m[2025-01-18T21:07:45.498899] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 21:07:42 : 71f4e10fc926b6c763256d63244e6353 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T21:07:45.498960] [FLK_MGR] Running jobs: ['71f4e10fc926b6c763256d63244e6353']
[0m[2025-01-18T21:07:45.498969] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T21:07:45.498988] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T21:11:45.520935] [SCALING] Scaling started.
[0m[2025-01-18T21:11:45.520992] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T21:11:45.536535] [SCALING] Scaling finished.
[0m[2025-01-18T21:11:45.536575] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:11:45.558546] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:11:45.577077] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T21:11:45.601159] [STS_MGR] StatefulSet flink-8000m-16384 scaled to 0 replica.
[0m[2025-01-18T21:11:55.629264] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T21:11:55.643426] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T21:11:55.659009] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T21:11:55.684011] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T21:11:55.703883] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T21:11:55.746416] [POD_MGR] Pod flink-jobmanager-7d7c784b74-q7779 deleted
[0m[2025-01-18T21:11:57.703591] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:11:59.612189] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:11:59.612269] Reloading playbook: application/kafka
[0m[2025-01-18T21:12:05.636647] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T21:12:46.671420] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T21:12:46.671850] [EXPERIMENT] Run 5 completed. Start: 1737234450, End: 1737234766
[0m[2025-01-18T21:12:46.671858] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T21:12:58.971025] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T21:12:58.971116] [RESOURCE_E] Running experiment with 8000m cores and 32768 memory.
[0m[2025-01-18T21:13:06.276183] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T21:13:06.276270] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T21:13:08.215096] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:13:10.119726] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:13:10.119830] [SCALING] Setting up experiment.


[0m[2025-01-18T21:13:10.119841] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:13:10.125547] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:13:10.142841] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T21:13:10.159502] [SCALING] Statefulset name to scale : flink-8000m-32768
[0m[2025-01-18T21:13:10.171264] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 1 replica.
[0m[2025-01-18T21:14:25.263606] [FLK_MGR] Running job.
[0m[2025-01-18T21:14:25.263662] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T21:14:27.123877] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-9lhfm
[0m[2025-01-18T21:14:31.209638] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID d7967430de7ba456f4ad9f1946094f38

[0m[2025-01-18T21:14:31.209682] [FLK_MGR] Running job id: d7967430de7ba456f4ad9f1946094f38
[0m[2025-01-18T21:14:31.209690] [FLK_MGR] Getting job info.
[0m[2025-01-18T21:14:31.227916] [FLK_MGR] Job plan response: {"plan":{"jid":"d7967430de7ba456f4ad9f1946094f38","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T21:14:31.228051] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T21:14:31.601326] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-9lhfm
[0m[2025-01-18T21:14:33.043331] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 21:14:30 : d7967430de7ba456f4ad9f1946094f38 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T21:14:33.043395] [FLK_MGR] Running jobs: ['d7967430de7ba456f4ad9f1946094f38']
[0m[2025-01-18T21:14:33.043403] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T21:14:33.043413] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T21:18:33.067191] [SCALING] Scaling started.
[0m[2025-01-18T21:18:33.067291] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T21:18:33.083318] [SCALING] Scaling finished.
[0m[2025-01-18T21:18:33.083348] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:18:33.103051] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:18:33.121713] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T21:18:33.144097] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 0 replica.
[0m[2025-01-18T21:18:33.161639] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T21:18:33.176158] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T21:18:33.189091] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T21:18:33.203525] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T21:18:33.216591] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T21:18:33.252060] [POD_MGR] Pod flink-jobmanager-7d7c784b74-9lhfm deleted
[0m[2025-01-18T21:18:35.227023] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:18:37.168097] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:18:37.168189] Reloading playbook: application/kafka
[0m[2025-01-18T21:18:43.227749] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T21:19:24.220232] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T21:19:24.220412] [EXPERIMENT] Run 1 completed. Start: 1737234786, End: 1737235164
[0m[2025-01-18T21:19:24.220420] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T21:19:34.221438] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T21:19:36.115171] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:19:38.062908] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:19:38.062995] [SCALING] Setting up experiment.


[0m[2025-01-18T21:19:38.063006] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:19:38.068301] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:19:38.084962] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T21:19:38.104600] [SCALING] Statefulset name to scale : flink-8000m-32768
[0m[2025-01-18T21:19:38.114395] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 1 replica.
[0m[2025-01-18T21:20:53.204007] [FLK_MGR] Running job.
[0m[2025-01-18T21:20:53.204105] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T21:20:53.603599] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-kgpqq
[0m[2025-01-18T21:20:57.717135] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 462ffcff0d52eb96adf33a295201ca7c

[0m[2025-01-18T21:20:57.717194] [FLK_MGR] Running job id: 462ffcff0d52eb96adf33a295201ca7c
[0m[2025-01-18T21:20:57.717206] [FLK_MGR] Getting job info.
[0m[2025-01-18T21:20:57.735121] [FLK_MGR] Job plan response: {"plan":{"jid":"462ffcff0d52eb96adf33a295201ca7c","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T21:20:57.735277] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T21:20:58.114406] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-kgpqq
[0m[2025-01-18T21:20:59.550252] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 21:20:56 : 462ffcff0d52eb96adf33a295201ca7c : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T21:20:59.550329] [FLK_MGR] Running jobs: ['462ffcff0d52eb96adf33a295201ca7c']
[0m[2025-01-18T21:20:59.550338] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T21:20:59.550349] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T21:24:59.575278] [SCALING] Scaling started.
[0m[2025-01-18T21:24:59.575403] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T21:24:59.588793] [SCALING] Scaling finished.
[0m[2025-01-18T21:24:59.588829] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:24:59.608445] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:24:59.626391] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T21:24:59.650524] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 0 replica.
[0m[2025-01-18T21:24:59.665514] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T21:24:59.680776] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T21:24:59.695277] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T21:24:59.707695] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T21:24:59.720439] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T21:24:59.743275] [POD_MGR] Pod flink-jobmanager-7d7c784b74-kgpqq deleted
[0m[2025-01-18T21:25:01.686951] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:25:03.679439] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:25:03.679525] Reloading playbook: application/kafka
[0m[2025-01-18T21:25:09.718198] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T21:25:50.712648] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T21:25:50.712938] [EXPERIMENT] Run 2 completed. Start: 1737235174, End: 1737235550
[0m[2025-01-18T21:25:50.712945] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T21:26:00.714041] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T21:26:02.649432] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:26:04.583794] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:26:04.583893] [SCALING] Setting up experiment.


[0m[2025-01-18T21:26:04.583917] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:26:04.590016] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:26:04.605559] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T21:26:04.620569] [SCALING] Statefulset name to scale : flink-8000m-32768
[0m[2025-01-18T21:26:04.630484] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 1 replica.
[0m[2025-01-18T21:27:19.714244] [FLK_MGR] Running job.
[0m[2025-01-18T21:27:19.714360] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T21:27:20.110954] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xtzmd
[0m[2025-01-18T21:27:24.170767] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9e731a87ed3732e28dfd49a8c4d21be4

[0m[2025-01-18T21:27:24.170820] [FLK_MGR] Running job id: 9e731a87ed3732e28dfd49a8c4d21be4
[0m[2025-01-18T21:27:24.170831] [FLK_MGR] Getting job info.
[0m[2025-01-18T21:27:24.189268] [FLK_MGR] Job plan response: {"plan":{"jid":"9e731a87ed3732e28dfd49a8c4d21be4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T21:27:24.189406] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T21:27:24.572745] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xtzmd
[0m[2025-01-18T21:27:26.020729] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 21:27:23 : 9e731a87ed3732e28dfd49a8c4d21be4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T21:27:26.020788] [FLK_MGR] Running jobs: ['9e731a87ed3732e28dfd49a8c4d21be4']
[0m[2025-01-18T21:27:26.020796] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T21:27:26.020818] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T21:31:26.043198] [SCALING] Scaling started.
[0m[2025-01-18T21:31:26.043260] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T21:31:26.056286] [SCALING] Scaling finished.
[0m[2025-01-18T21:31:26.056329] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:31:26.074214] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:31:26.091842] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T21:31:26.114531] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 0 replica.
[0m[2025-01-18T21:31:26.130141] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T21:31:26.144224] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T21:31:26.157657] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T21:31:26.170924] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T21:31:26.183396] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T21:31:26.216898] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xtzmd deleted
[0m[2025-01-18T21:31:28.123207] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:31:30.029918] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:31:30.030013] Reloading playbook: application/kafka
[0m[2025-01-18T21:31:36.066011] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T21:32:17.078472] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T21:32:17.079209] [EXPERIMENT] Run 3 completed. Start: 1737235560, End: 1737235937
[0m[2025-01-18T21:32:17.079236] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T21:32:27.080252] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T21:32:29.027838] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:32:30.934637] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:32:30.934740] [SCALING] Setting up experiment.


[0m[2025-01-18T21:32:30.934751] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:32:30.940987] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:32:30.959404] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T21:32:30.978051] [SCALING] Statefulset name to scale : flink-8000m-32768
[0m[2025-01-18T21:32:30.989440] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 1 replica.
[0m[2025-01-18T21:33:46.079242] [FLK_MGR] Running job.
[0m[2025-01-18T21:33:46.079347] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T21:33:46.466113] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-69nvd
[0m[2025-01-18T21:33:50.487955] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 3a0837e5a57d63ca1aec29a5e5dcc43d

[0m[2025-01-18T21:33:50.488001] [FLK_MGR] Running job id: 3a0837e5a57d63ca1aec29a5e5dcc43d
[0m[2025-01-18T21:33:50.488011] [FLK_MGR] Getting job info.
[0m[2025-01-18T21:33:50.505342] [FLK_MGR] Job plan response: {"plan":{"jid":"3a0837e5a57d63ca1aec29a5e5dcc43d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T21:33:50.505480] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T21:33:50.884080] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-69nvd
[0m[2025-01-18T21:33:52.324529] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 21:33:49 : 3a0837e5a57d63ca1aec29a5e5dcc43d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T21:33:52.324591] [FLK_MGR] Running jobs: ['3a0837e5a57d63ca1aec29a5e5dcc43d']
[0m[2025-01-18T21:33:52.324599] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T21:33:52.324610] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T21:37:52.347661] [SCALING] Scaling started.
[0m[2025-01-18T21:37:52.347718] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T21:37:52.360532] [SCALING] Scaling finished.
[0m[2025-01-18T21:37:52.360577] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:37:52.378594] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:37:52.396389] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T21:37:52.419763] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 0 replica.
[0m[2025-01-18T21:37:52.436834] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T21:37:52.451711] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T21:37:52.467536] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T21:37:52.483752] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T21:37:52.497985] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T21:37:52.532980] [POD_MGR] Pod flink-jobmanager-7d7c784b74-69nvd deleted
[0m[2025-01-18T21:37:54.460708] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:37:56.454494] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:37:56.454576] Reloading playbook: application/kafka
[0m[2025-01-18T21:38:02.451520] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T21:38:43.478484] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T21:38:43.478919] [EXPERIMENT] Run 4 completed. Start: 1737235947, End: 1737236323
[0m[2025-01-18T21:38:43.478926] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T21:38:53.479932] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T21:38:55.403762] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:38:57.334867] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:38:57.334976] [SCALING] Setting up experiment.


[0m[2025-01-18T21:38:57.334990] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:38:57.342379] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:38:57.359794] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T21:38:57.376856] [SCALING] Statefulset name to scale : flink-8000m-32768
[0m[2025-01-18T21:38:57.388377] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 1 replica.
[0m[2025-01-18T21:40:12.480926] [FLK_MGR] Running job.
[0m[2025-01-18T21:40:12.480984] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T21:40:12.878234] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-qs4k9
[0m[2025-01-18T21:40:16.935191] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a03662d530d0fbb4f5a8ae2059424c40

[0m[2025-01-18T21:40:16.935247] [FLK_MGR] Running job id: a03662d530d0fbb4f5a8ae2059424c40
[0m[2025-01-18T21:40:16.935257] [FLK_MGR] Getting job info.
[0m[2025-01-18T21:40:16.951893] [FLK_MGR] Job plan response: {"plan":{"jid":"a03662d530d0fbb4f5a8ae2059424c40","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T21:40:16.952035] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T21:40:17.343777] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-qs4k9
[0m[2025-01-18T21:40:18.776977] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 21:40:15 : a03662d530d0fbb4f5a8ae2059424c40 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T21:40:18.777052] [FLK_MGR] Running jobs: ['a03662d530d0fbb4f5a8ae2059424c40']
[0m[2025-01-18T21:40:18.777060] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T21:40:18.777079] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T21:44:18.800585] [SCALING] Scaling started.
[0m[2025-01-18T21:44:18.800650] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T21:44:18.815178] [SCALING] Scaling finished.
[0m[2025-01-18T21:44:18.815204] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:44:18.839178] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:44:18.855480] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T21:44:18.891179] [STS_MGR] StatefulSet flink-8000m-32768 scaled to 0 replica.
[0m[2025-01-18T21:44:18.906362] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T21:44:18.919337] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T21:44:18.931714] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T21:44:18.944465] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T21:44:18.956846] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T21:44:18.977870] [POD_MGR] Pod flink-jobmanager-7d7c784b74-qs4k9 deleted
[0m[2025-01-18T21:44:20.897150] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:44:22.894486] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:44:22.894580] Reloading playbook: application/kafka
[0m[2025-01-18T21:44:28.929843] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T21:45:09.927975] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T21:45:09.928820] [EXPERIMENT] Run 5 completed. Start: 1737236333, End: 1737236709
[0m[2025-01-18T21:45:09.928846] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T21:45:22.195382] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T21:45:22.195500] [RESOURCE_E] Running experiment with 16000m cores and 1024 memory.
[0m[2025-01-18T21:45:29.499837] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T21:45:29.499936] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T21:45:31.406979] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:45:33.352678] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:45:33.352771] [SCALING] Setting up experiment.


[0m[2025-01-18T21:45:33.352786] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:45:33.359785] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:45:33.377771] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T21:45:33.394155] [SCALING] Statefulset name to scale : flink-16000m-1024
[0m[2025-01-18T21:45:33.405681] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 1 replica.
[0m[2025-01-18T21:46:48.498818] [FLK_MGR] Running job.
[0m[2025-01-18T21:46:48.498873] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T21:46:48.882013] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-k94rk
[0m[2025-01-18T21:46:52.925165] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5621efc442b1f7960e0e3a1a574ad5fa

[0m[2025-01-18T21:46:52.925238] [FLK_MGR] Running job id: 5621efc442b1f7960e0e3a1a574ad5fa
[0m[2025-01-18T21:46:52.925253] [FLK_MGR] Getting job info.
[0m[2025-01-18T21:46:52.943251] [FLK_MGR] Job plan response: {"plan":{"jid":"5621efc442b1f7960e0e3a1a574ad5fa","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T21:46:52.943408] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T21:46:53.325035] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-k94rk
[0m[2025-01-18T21:46:54.770128] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 21:46:51 : 5621efc442b1f7960e0e3a1a574ad5fa : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T21:46:54.770189] [FLK_MGR] Running jobs: ['5621efc442b1f7960e0e3a1a574ad5fa']
[0m[2025-01-18T21:46:54.770197] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T21:46:54.770215] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T21:50:54.794424] [SCALING] Scaling started.
[0m[2025-01-18T21:50:54.794532] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T21:50:54.809335] [SCALING] Scaling finished.
[0m[2025-01-18T21:50:54.809362] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:50:54.827305] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:50:54.845831] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T21:50:54.867654] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 0 replica.
[0m[2025-01-18T21:50:54.882360] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T21:50:54.896561] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T21:50:54.910384] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T21:50:54.925162] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T21:50:54.938814] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T21:50:54.972694] [POD_MGR] Pod flink-jobmanager-7d7c784b74-k94rk deleted
[0m[2025-01-18T21:50:56.852594] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:50:58.844354] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:50:58.844443] Reloading playbook: application/kafka
[0m[2025-01-18T21:51:04.885699] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T21:51:45.922968] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T21:51:45.924286] [EXPERIMENT] Run 1 completed. Start: 1737236729, End: 1737237105
[0m[2025-01-18T21:51:45.924313] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T21:51:55.926016] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T21:51:57.856717] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:51:59.757540] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:51:59.757638] [SCALING] Setting up experiment.


[0m[2025-01-18T21:51:59.757650] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:51:59.763677] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:51:59.781563] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T21:51:59.798297] [SCALING] Statefulset name to scale : flink-16000m-1024
[0m[2025-01-18T21:51:59.807902] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 1 replica.
[0m[2025-01-18T21:53:14.901786] [FLK_MGR] Running job.
[0m[2025-01-18T21:53:14.901846] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T21:53:17.488819] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-qftkq
[0m[2025-01-18T21:53:21.533338] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 038b319f8ec67181cb134e8b5cb84e21

[0m[2025-01-18T21:53:21.533408] [FLK_MGR] Running job id: 038b319f8ec67181cb134e8b5cb84e21
[0m[2025-01-18T21:53:21.533418] [FLK_MGR] Getting job info.
[0m[2025-01-18T21:53:21.551967] [FLK_MGR] Job plan response: {"plan":{"jid":"038b319f8ec67181cb134e8b5cb84e21","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T21:53:21.552110] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T21:53:21.922719] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-qftkq
[0m[2025-01-18T21:53:23.355643] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 21:53:20 : 038b319f8ec67181cb134e8b5cb84e21 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T21:53:23.355704] [FLK_MGR] Running jobs: ['038b319f8ec67181cb134e8b5cb84e21']
[0m[2025-01-18T21:53:23.355712] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T21:53:23.355723] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T21:57:23.378009] [SCALING] Scaling started.
[0m[2025-01-18T21:57:23.378062] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T21:57:23.391564] [SCALING] Scaling finished.
[0m[2025-01-18T21:57:23.391590] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:57:23.409638] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:57:23.428078] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T21:57:23.448817] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 0 replica.
[0m[2025-01-18T21:57:23.463310] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T21:57:23.480431] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T21:57:23.493960] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T21:57:23.507277] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T21:57:23.520267] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T21:57:23.544295] [POD_MGR] Pod flink-jobmanager-7d7c784b74-qftkq deleted
[0m[2025-01-18T21:57:25.450132] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:57:27.485082] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T21:57:27.485184] Reloading playbook: application/kafka
[0m[2025-01-18T21:57:33.474891] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T21:58:14.459065] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T21:58:14.459310] [EXPERIMENT] Run 2 completed. Start: 1737237115, End: 1737237494
[0m[2025-01-18T21:58:14.459316] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T21:58:24.460226] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T21:58:26.382720] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:58:28.316244] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T21:58:28.316336] [SCALING] Setting up experiment.


[0m[2025-01-18T21:58:28.316347] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T21:58:28.321824] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T21:58:28.339613] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T21:58:28.356788] [SCALING] Statefulset name to scale : flink-16000m-1024
[0m[2025-01-18T21:58:28.367150] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 1 replica.
[0m[2025-01-18T21:59:43.460088] [FLK_MGR] Running job.
[0m[2025-01-18T21:59:43.460206] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T21:59:43.848131] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-bpxxb
[0m[2025-01-18T21:59:47.904783] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0c3dd513a3447af75a11df6dd06a6a6c

[0m[2025-01-18T21:59:47.904851] [FLK_MGR] Running job id: 0c3dd513a3447af75a11df6dd06a6a6c
[0m[2025-01-18T21:59:47.904858] [FLK_MGR] Getting job info.
[0m[2025-01-18T21:59:47.923330] [FLK_MGR] Job plan response: {"plan":{"jid":"0c3dd513a3447af75a11df6dd06a6a6c","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T21:59:47.923499] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T21:59:48.311174] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-bpxxb
[0m[2025-01-18T21:59:49.754107] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 21:59:46 : 0c3dd513a3447af75a11df6dd06a6a6c : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T21:59:49.754183] [FLK_MGR] Running jobs: ['0c3dd513a3447af75a11df6dd06a6a6c']
[0m[2025-01-18T21:59:49.754196] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T21:59:49.754212] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T22:03:49.778509] [SCALING] Scaling started.
[0m[2025-01-18T22:03:49.778570] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T22:03:49.792105] [SCALING] Scaling finished.
[0m[2025-01-18T22:03:49.792132] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:03:49.811703] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:03:49.829851] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T22:03:49.854988] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 0 replica.
[0m[2025-01-18T22:03:49.870517] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T22:03:49.883303] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T22:03:49.896155] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T22:03:49.908079] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T22:03:49.919720] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T22:03:49.940809] [POD_MGR] Pod flink-jobmanager-7d7c784b74-bpxxb deleted
[0m[2025-01-18T22:03:51.856735] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:03:53.825641] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:03:53.825730] Reloading playbook: application/kafka
[0m[2025-01-18T22:03:59.800390] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T22:04:40.751480] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T22:04:40.751952] [EXPERIMENT] Run 3 completed. Start: 1737237504, End: 1737237880
[0m[2025-01-18T22:04:40.751979] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T22:04:50.753140] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T22:04:52.707674] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:04:54.619668] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:04:54.619762] [SCALING] Setting up experiment.


[0m[2025-01-18T22:04:54.619774] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:04:54.625794] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:04:54.642727] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T22:04:54.659548] [SCALING] Statefulset name to scale : flink-16000m-1024
[0m[2025-01-18T22:04:54.670013] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 1 replica.
[0m[2025-01-18T22:06:09.755358] [FLK_MGR] Running job.
[0m[2025-01-18T22:06:09.755498] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T22:06:10.146260] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-hw45k
[0m[2025-01-18T22:06:14.251891] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f565b03175e218a729aaffee5be375c8

[0m[2025-01-18T22:06:14.251948] [FLK_MGR] Running job id: f565b03175e218a729aaffee5be375c8
[0m[2025-01-18T22:06:14.251957] [FLK_MGR] Getting job info.
[0m[2025-01-18T22:06:14.270063] [FLK_MGR] Job plan response: {"plan":{"jid":"f565b03175e218a729aaffee5be375c8","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T22:06:14.270204] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T22:06:14.653943] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-hw45k
[0m[2025-01-18T22:06:16.103635] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 22:06:13 : f565b03175e218a729aaffee5be375c8 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T22:06:16.103702] [FLK_MGR] Running jobs: ['f565b03175e218a729aaffee5be375c8']
[0m[2025-01-18T22:06:16.103712] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T22:06:16.103726] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T22:10:16.127336] [SCALING] Scaling started.
[0m[2025-01-18T22:10:16.127447] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T22:10:16.139656] [SCALING] Scaling finished.
[0m[2025-01-18T22:10:16.139683] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:10:16.157026] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:10:16.172750] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T22:10:16.194153] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 0 replica.
[0m[2025-01-18T22:10:16.212111] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T22:10:16.225106] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T22:10:16.238266] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T22:10:16.250842] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T22:10:16.263733] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T22:10:16.288059] [POD_MGR] Pod flink-jobmanager-7d7c784b74-hw45k deleted
[0m[2025-01-18T22:10:18.172908] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:10:20.149170] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:10:20.149257] Reloading playbook: application/kafka
[0m[2025-01-18T22:10:26.166823] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T22:11:07.206661] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T22:11:07.206891] [EXPERIMENT] Run 4 completed. Start: 1737237890, End: 1737238267
[0m[2025-01-18T22:11:07.206897] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T22:11:17.207784] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T22:11:19.086608] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:11:20.989489] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:11:20.989579] [SCALING] Setting up experiment.


[0m[2025-01-18T22:11:20.989590] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:11:20.995062] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:11:21.010699] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T22:11:21.027674] [SCALING] Statefulset name to scale : flink-16000m-1024
[0m[2025-01-18T22:11:21.037827] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 1 replica.
[0m[2025-01-18T22:12:36.129593] [FLK_MGR] Running job.
[0m[2025-01-18T22:12:36.129679] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T22:12:36.523234] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-swq79
[0m[2025-01-18T22:12:40.573697] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID bc941ced7305e593009f3964fec464ed

[0m[2025-01-18T22:12:40.573786] [FLK_MGR] Running job id: bc941ced7305e593009f3964fec464ed
[0m[2025-01-18T22:12:40.573797] [FLK_MGR] Getting job info.
[0m[2025-01-18T22:12:40.591099] [FLK_MGR] Job plan response: {"plan":{"jid":"bc941ced7305e593009f3964fec464ed","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T22:12:40.591274] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T22:12:40.989742] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-swq79
[0m[2025-01-18T22:12:42.432352] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 22:12:39 : bc941ced7305e593009f3964fec464ed : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T22:12:42.432428] [FLK_MGR] Running jobs: ['bc941ced7305e593009f3964fec464ed']
[0m[2025-01-18T22:12:42.432438] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T22:12:42.432453] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T22:16:42.455719] [SCALING] Scaling started.
[0m[2025-01-18T22:16:42.455778] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T22:16:42.471385] [SCALING] Scaling finished.
[0m[2025-01-18T22:16:42.471413] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:16:42.490865] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:16:42.506451] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T22:16:42.527000] [STS_MGR] StatefulSet flink-16000m-1024 scaled to 0 replica.
[0m[2025-01-18T22:16:42.545562] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T22:16:42.558448] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T22:16:42.570982] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T22:16:42.585334] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T22:16:42.597526] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T22:16:42.626574] [POD_MGR] Pod flink-jobmanager-7d7c784b74-swq79 deleted
[0m[2025-01-18T22:16:44.559727] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:16:46.539903] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:16:46.540000] Reloading playbook: application/kafka
[0m[2025-01-18T22:16:52.566057] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T22:17:33.567259] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T22:17:33.567725] [EXPERIMENT] Run 5 completed. Start: 1737238277, End: 1737238653
[0m[2025-01-18T22:17:33.567733] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T22:17:45.844325] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T22:17:45.844415] [RESOURCE_E] Running experiment with 16000m cores and 2048 memory.
[0m[2025-01-18T22:17:53.141402] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T22:17:53.141486] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T22:17:55.052573] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:17:56.954573] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:17:56.954662] [SCALING] Setting up experiment.


[0m[2025-01-18T22:17:56.954677] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:17:56.962549] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:17:56.979499] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T22:17:56.998864] [SCALING] Statefulset name to scale : flink-16000m-2048
[0m[2025-01-18T22:17:57.010016] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 1 replica.
[0m[2025-01-18T22:19:12.101174] [FLK_MGR] Running job.
[0m[2025-01-18T22:19:12.101221] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T22:19:12.489167] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mjsc8
[0m[2025-01-18T22:19:16.528834] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 3ecdeb8b0841b9a36c97a6c8b520cd1e

[0m[2025-01-18T22:19:16.528897] [FLK_MGR] Running job id: 3ecdeb8b0841b9a36c97a6c8b520cd1e
[0m[2025-01-18T22:19:16.528909] [FLK_MGR] Getting job info.
[0m[2025-01-18T22:19:16.549484] [FLK_MGR] Job plan response: {"plan":{"jid":"3ecdeb8b0841b9a36c97a6c8b520cd1e","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T22:19:16.549652] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T22:19:16.953796] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mjsc8
[0m[2025-01-18T22:19:18.403390] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 22:19:15 : 3ecdeb8b0841b9a36c97a6c8b520cd1e : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T22:19:18.403483] [FLK_MGR] Running jobs: ['3ecdeb8b0841b9a36c97a6c8b520cd1e']
[0m[2025-01-18T22:19:18.403495] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T22:19:18.403523] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T22:23:18.428137] [SCALING] Scaling started.
[0m[2025-01-18T22:23:18.428314] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T22:23:18.443054] [SCALING] Scaling finished.
[0m[2025-01-18T22:23:18.443086] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:23:18.462138] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:23:18.479773] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T22:23:18.503049] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 0 replica.
[0m[2025-01-18T22:23:18.519063] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T22:23:18.533434] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T22:23:18.548118] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T22:23:18.562181] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T22:23:18.577716] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T22:23:18.602414] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mjsc8 deleted
[0m[2025-01-18T22:23:20.535171] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:23:22.578963] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:23:22.579047] Reloading playbook: application/kafka
[0m[2025-01-18T22:23:28.585804] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T22:24:09.525816] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T22:24:09.526261] [EXPERIMENT] Run 1 completed. Start: 1737238673, End: 1737239049
[0m[2025-01-18T22:24:09.526270] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T22:24:19.527344] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T22:24:21.456348] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:24:23.380363] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:24:23.380460] [SCALING] Setting up experiment.


[0m[2025-01-18T22:24:23.380471] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:24:23.385915] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:24:23.402167] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T22:24:23.418860] [SCALING] Statefulset name to scale : flink-16000m-2048
[0m[2025-01-18T22:24:23.430870] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 1 replica.
[0m[2025-01-18T22:25:38.519777] [FLK_MGR] Running job.
[0m[2025-01-18T22:25:38.519873] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T22:25:38.913791] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-qszsz
[0m[2025-01-18T22:25:43.054876] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID e197f7bd1a00367f8feba773cfc1ca4a

[0m[2025-01-18T22:25:43.054928] [FLK_MGR] Running job id: e197f7bd1a00367f8feba773cfc1ca4a
[0m[2025-01-18T22:25:43.054938] [FLK_MGR] Getting job info.
[0m[2025-01-18T22:25:43.072207] [FLK_MGR] Job plan response: {"plan":{"jid":"e197f7bd1a00367f8feba773cfc1ca4a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T22:25:43.072359] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T22:25:43.468829] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-qszsz
[0m[2025-01-18T22:25:44.915480] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 22:25:42 : e197f7bd1a00367f8feba773cfc1ca4a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T22:25:44.915561] [FLK_MGR] Running jobs: ['e197f7bd1a00367f8feba773cfc1ca4a']
[0m[2025-01-18T22:25:44.915572] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T22:25:44.915601] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T22:29:44.938246] [SCALING] Scaling started.
[0m[2025-01-18T22:29:44.938381] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T22:29:44.952382] [SCALING] Scaling finished.
[0m[2025-01-18T22:29:44.952418] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:29:44.971059] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:29:44.986245] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T22:29:45.007353] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 0 replica.
[0m[2025-01-18T22:29:45.023151] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T22:29:45.035350] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T22:29:45.048409] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T22:29:45.061427] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T22:29:45.073678] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T22:29:45.095471] [POD_MGR] Pod flink-jobmanager-7d7c784b74-qszsz deleted
[0m[2025-01-18T22:29:47.014546] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:29:48.900516] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:29:48.900594] Reloading playbook: application/kafka
[0m[2025-01-18T22:29:54.831332] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T22:30:35.762489] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T22:30:35.762973] [EXPERIMENT] Run 2 completed. Start: 1737239059, End: 1737239435
[0m[2025-01-18T22:30:35.762982] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T22:30:45.763968] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T22:30:47.660456] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:30:49.584743] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:30:49.584862] [SCALING] Setting up experiment.


[0m[2025-01-18T22:30:49.584874] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:30:49.590789] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:30:49.606754] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T22:30:49.622691] [SCALING] Statefulset name to scale : flink-16000m-2048
[0m[2025-01-18T22:30:49.633127] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 1 replica.
[0m[2025-01-18T22:32:04.718860] [FLK_MGR] Running job.
[0m[2025-01-18T22:32:04.718912] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T22:32:06.680324] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-2q567
[0m[2025-01-18T22:32:10.697653] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID cce9e21db54139a266f16f553731f151

[0m[2025-01-18T22:32:10.697695] [FLK_MGR] Running job id: cce9e21db54139a266f16f553731f151
[0m[2025-01-18T22:32:10.697702] [FLK_MGR] Getting job info.
[0m[2025-01-18T22:32:10.714700] [FLK_MGR] Job plan response: {"plan":{"jid":"cce9e21db54139a266f16f553731f151","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T22:32:10.714835] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T22:32:11.100368] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-2q567
[0m[2025-01-18T22:32:12.524579] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 22:32:09 : cce9e21db54139a266f16f553731f151 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T22:32:12.524646] [FLK_MGR] Running jobs: ['cce9e21db54139a266f16f553731f151']
[0m[2025-01-18T22:32:12.524654] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T22:32:12.524794] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T22:36:12.547763] [SCALING] Scaling started.
[0m[2025-01-18T22:36:12.547853] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T22:36:12.561284] [SCALING] Scaling finished.
[0m[2025-01-18T22:36:12.561311] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:36:12.580969] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:36:12.597238] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T22:36:12.618552] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 0 replica.
[0m[2025-01-18T22:36:12.634156] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T22:36:12.648140] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T22:36:12.659931] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T22:36:12.674062] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T22:36:12.687142] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T22:36:12.714574] [POD_MGR] Pod flink-jobmanager-7d7c784b74-2q567 deleted
[0m[2025-01-18T22:36:14.620347] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:36:16.634099] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:36:16.634192] Reloading playbook: application/kafka
[0m[2025-01-18T22:36:22.667074] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T22:37:03.663914] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T22:37:03.664119] [EXPERIMENT] Run 3 completed. Start: 1737239445, End: 1737239823
[0m[2025-01-18T22:37:03.664125] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T22:37:13.665166] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T22:37:15.547601] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:37:17.472822] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:37:17.472936] [SCALING] Setting up experiment.


[0m[2025-01-18T22:37:17.472950] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:37:17.479396] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:37:17.499073] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T22:37:17.514615] [SCALING] Statefulset name to scale : flink-16000m-2048
[0m[2025-01-18T22:37:17.524376] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 1 replica.
[0m[2025-01-18T22:38:32.611930] [FLK_MGR] Running job.
[0m[2025-01-18T22:38:32.611981] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T22:38:32.993665] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-5tl7j
[0m[2025-01-18T22:38:37.030234] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fa1abd42b7e6315e4c854f42ea74ce43

[0m[2025-01-18T22:38:37.030295] [FLK_MGR] Running job id: fa1abd42b7e6315e4c854f42ea74ce43
[0m[2025-01-18T22:38:37.030303] [FLK_MGR] Getting job info.
[0m[2025-01-18T22:38:37.047276] [FLK_MGR] Job plan response: {"plan":{"jid":"fa1abd42b7e6315e4c854f42ea74ce43","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T22:38:37.047436] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T22:38:37.436127] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-5tl7j
[0m[2025-01-18T22:38:38.848850] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 22:38:36 : fa1abd42b7e6315e4c854f42ea74ce43 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T22:38:38.848911] [FLK_MGR] Running jobs: ['fa1abd42b7e6315e4c854f42ea74ce43']
[0m[2025-01-18T22:38:38.848920] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T22:38:38.848933] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T22:42:38.872203] [SCALING] Scaling started.
[0m[2025-01-18T22:42:38.872315] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T22:42:38.886171] [SCALING] Scaling finished.
[0m[2025-01-18T22:42:38.886199] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:42:38.907242] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:42:38.923711] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T22:42:38.944052] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 0 replica.
[0m[2025-01-18T22:42:38.960055] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T22:42:38.972574] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T22:42:38.984723] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T22:42:38.998160] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T22:42:39.011627] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T22:42:39.036272] [POD_MGR] Pod flink-jobmanager-7d7c784b74-5tl7j deleted
[0m[2025-01-18T22:42:41.027918] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:42:42.980557] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:42:42.980635] Reloading playbook: application/kafka
[0m[2025-01-18T22:42:48.955554] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T22:43:29.923360] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T22:43:29.923614] [EXPERIMENT] Run 4 completed. Start: 1737239833, End: 1737240209
[0m[2025-01-18T22:43:29.923622] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T22:43:39.924609] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T22:43:41.839333] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:43:43.764308] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:43:43.764463] [SCALING] Setting up experiment.


[0m[2025-01-18T22:43:43.764512] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:43:43.769735] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:43:43.784659] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T22:43:43.800237] [SCALING] Statefulset name to scale : flink-16000m-2048
[0m[2025-01-18T22:43:43.810752] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 1 replica.
[0m[2025-01-18T22:44:58.895948] [FLK_MGR] Running job.
[0m[2025-01-18T22:44:58.896034] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T22:44:59.275882] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-x792b
[0m[2025-01-18T22:45:03.299907] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 37d229bf554efcbf7def2341fd9c1719

[0m[2025-01-18T22:45:03.299957] [FLK_MGR] Running job id: 37d229bf554efcbf7def2341fd9c1719
[0m[2025-01-18T22:45:03.299964] [FLK_MGR] Getting job info.
[0m[2025-01-18T22:45:03.315907] [FLK_MGR] Job plan response: {"plan":{"jid":"37d229bf554efcbf7def2341fd9c1719","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T22:45:03.316041] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T22:45:03.690048] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-x792b
[0m[2025-01-18T22:45:05.123355] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 22:45:02 : 37d229bf554efcbf7def2341fd9c1719 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T22:45:05.123427] [FLK_MGR] Running jobs: ['37d229bf554efcbf7def2341fd9c1719']
[0m[2025-01-18T22:45:05.123436] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T22:45:05.123450] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T22:49:05.148734] [SCALING] Scaling started.
[0m[2025-01-18T22:49:05.148838] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T22:49:05.161501] [SCALING] Scaling finished.
[0m[2025-01-18T22:49:05.161533] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:49:05.179646] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:49:05.197042] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T22:49:05.219931] [STS_MGR] StatefulSet flink-16000m-2048 scaled to 0 replica.
[0m[2025-01-18T22:49:05.233712] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T22:49:05.248184] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T22:49:05.261518] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T22:49:05.275036] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T22:49:05.288285] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T22:49:05.314607] [POD_MGR] Pod flink-jobmanager-7d7c784b74-x792b deleted
[0m[2025-01-18T22:49:07.226407] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:49:09.225520] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:49:09.225600] Reloading playbook: application/kafka
[0m[2025-01-18T22:49:15.176360] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T22:49:56.151033] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T22:49:56.151302] [EXPERIMENT] Run 5 completed. Start: 1737240219, End: 1737240596
[0m[2025-01-18T22:49:56.151308] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T22:50:08.432185] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T22:50:08.432277] [RESOURCE_E] Running experiment with 16000m cores and 4096 memory.
[0m[2025-01-18T22:50:15.703097] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T22:50:15.703182] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T22:50:17.608014] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:50:19.542069] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:50:19.542156] [SCALING] Setting up experiment.


[0m[2025-01-18T22:50:19.542170] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:50:19.547834] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:50:19.564578] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T22:50:19.580535] [SCALING] Statefulset name to scale : flink-16000m-4096
[0m[2025-01-18T22:50:19.589833] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 1 replica.
[0m[2025-01-18T22:51:34.673841] [FLK_MGR] Running job.
[0m[2025-01-18T22:51:34.673889] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T22:51:35.056724] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-8ppxd
[0m[2025-01-18T22:51:39.118951] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 719a491a0656ce2933814cc32777a831

[0m[2025-01-18T22:51:39.119001] [FLK_MGR] Running job id: 719a491a0656ce2933814cc32777a831
[0m[2025-01-18T22:51:39.119010] [FLK_MGR] Getting job info.
[0m[2025-01-18T22:51:39.135269] [FLK_MGR] Job plan response: {"plan":{"jid":"719a491a0656ce2933814cc32777a831","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T22:51:39.135404] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T22:51:39.513606] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-8ppxd
[0m[2025-01-18T22:51:40.943817] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 22:51:38 : 719a491a0656ce2933814cc32777a831 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T22:51:40.943908] [FLK_MGR] Running jobs: ['719a491a0656ce2933814cc32777a831']
[0m[2025-01-18T22:51:40.943916] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T22:51:40.943930] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T22:55:40.966691] [SCALING] Scaling started.
[0m[2025-01-18T22:55:40.966749] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T22:55:40.981766] [SCALING] Scaling finished.
[0m[2025-01-18T22:55:40.981798] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:55:41.002479] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:55:41.018154] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T22:55:41.038488] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 0 replica.
[0m[2025-01-18T22:55:41.053547] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T22:55:41.066796] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T22:55:41.080284] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T22:55:41.093724] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T22:55:41.106484] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T22:55:41.127796] [POD_MGR] Pod flink-jobmanager-7d7c784b74-8ppxd deleted
[0m[2025-01-18T22:55:42.999664] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:55:44.959942] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T22:55:44.960022] Reloading playbook: application/kafka
[0m[2025-01-18T22:55:50.869462] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T22:56:31.785226] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T22:56:31.785520] [EXPERIMENT] Run 1 completed. Start: 1737240615, End: 1737240991
[0m[2025-01-18T22:56:31.785528] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T22:56:41.786675] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T22:56:43.734860] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:56:45.647045] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T22:56:45.647145] [SCALING] Setting up experiment.


[0m[2025-01-18T22:56:45.647155] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T22:56:45.652827] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T22:56:45.668556] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T22:56:45.683638] [SCALING] Statefulset name to scale : flink-16000m-4096
[0m[2025-01-18T22:56:45.693196] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 1 replica.
[0m[2025-01-18T22:58:00.786988] [FLK_MGR] Running job.
[0m[2025-01-18T22:58:00.787046] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T22:58:01.171077] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-n7b2x
[0m[2025-01-18T22:58:05.208659] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9b0afac17e18a829e718b65b85d472ac

[0m[2025-01-18T22:58:05.208712] [FLK_MGR] Running job id: 9b0afac17e18a829e718b65b85d472ac
[0m[2025-01-18T22:58:05.208722] [FLK_MGR] Getting job info.
[0m[2025-01-18T22:58:05.227123] [FLK_MGR] Job plan response: {"plan":{"jid":"9b0afac17e18a829e718b65b85d472ac","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T22:58:05.227290] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T22:58:05.610694] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-n7b2x
[0m[2025-01-18T22:58:07.044983] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 22:58:04 : 9b0afac17e18a829e718b65b85d472ac : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T22:58:07.045045] [FLK_MGR] Running jobs: ['9b0afac17e18a829e718b65b85d472ac']
[0m[2025-01-18T22:58:07.045053] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T22:58:07.045069] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T23:02:07.068512] [SCALING] Scaling started.
[0m[2025-01-18T23:02:07.068571] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T23:02:07.084530] [SCALING] Scaling finished.
[0m[2025-01-18T23:02:07.084559] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:02:07.103705] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:02:07.123292] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T23:02:07.145246] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 0 replica.
[0m[2025-01-18T23:02:07.162144] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T23:02:07.179066] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T23:02:07.193867] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T23:02:07.208247] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T23:02:07.220918] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T23:02:07.245379] [POD_MGR] Pod flink-jobmanager-7d7c784b74-n7b2x deleted
[0m[2025-01-18T23:02:09.166818] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:02:11.187736] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:02:11.187809] Reloading playbook: application/kafka
[0m[2025-01-18T23:02:17.182794] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T23:02:58.206949] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T23:02:58.207195] [EXPERIMENT] Run 2 completed. Start: 1737241001, End: 1737241378
[0m[2025-01-18T23:02:58.207201] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T23:03:08.208196] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T23:03:10.128483] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:03:12.072607] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:03:12.072712] [SCALING] Setting up experiment.


[0m[2025-01-18T23:03:12.072726] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:03:12.078964] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:03:12.095167] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T23:03:12.110691] [SCALING] Statefulset name to scale : flink-16000m-4096
[0m[2025-01-18T23:03:12.121931] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 1 replica.
[0m[2025-01-18T23:04:27.210535] [FLK_MGR] Running job.
[0m[2025-01-18T23:04:27.210576] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T23:04:27.596670] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-q2bgv
[0m[2025-01-18T23:04:31.641849] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 11bf331a192a3ae87958055336b35c1b

[0m[2025-01-18T23:04:31.641899] [FLK_MGR] Running job id: 11bf331a192a3ae87958055336b35c1b
[0m[2025-01-18T23:04:31.641906] [FLK_MGR] Getting job info.
[0m[2025-01-18T23:04:31.660124] [FLK_MGR] Job plan response: {"plan":{"jid":"11bf331a192a3ae87958055336b35c1b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T23:04:31.660260] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T23:04:32.037054] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-q2bgv
[0m[2025-01-18T23:04:33.494476] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 23:04:30 : 11bf331a192a3ae87958055336b35c1b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T23:04:33.494539] [FLK_MGR] Running jobs: ['11bf331a192a3ae87958055336b35c1b']
[0m[2025-01-18T23:04:33.494547] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T23:04:33.494556] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T23:08:33.516989] [SCALING] Scaling started.
[0m[2025-01-18T23:08:33.517119] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T23:08:33.532325] [SCALING] Scaling finished.
[0m[2025-01-18T23:08:33.532348] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:08:33.550271] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:08:33.569365] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T23:08:33.590974] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 0 replica.
[0m[2025-01-18T23:08:33.605473] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T23:08:33.619380] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T23:08:33.633054] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T23:08:33.646193] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T23:08:33.658686] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T23:08:33.691091] [POD_MGR] Pod flink-jobmanager-7d7c784b74-q2bgv deleted
[0m[2025-01-18T23:08:35.629596] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:08:37.648829] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:08:37.648918] Reloading playbook: application/kafka
[0m[2025-01-18T23:08:43.644668] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T23:09:24.703301] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T23:09:24.703825] [EXPERIMENT] Run 3 completed. Start: 1737241388, End: 1737241764
[0m[2025-01-18T23:09:24.703835] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T23:09:34.704978] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T23:09:36.625814] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:09:38.579520] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:09:38.579614] [SCALING] Setting up experiment.


[0m[2025-01-18T23:09:38.579625] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:09:38.588604] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:09:38.619430] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T23:09:38.636236] [SCALING] Statefulset name to scale : flink-16000m-4096
[0m[2025-01-18T23:09:38.647164] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 1 replica.
[0m[2025-01-18T23:10:53.735236] [FLK_MGR] Running job.
[0m[2025-01-18T23:10:53.735332] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T23:10:55.717421] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xjxj4
[0m[2025-01-18T23:10:59.725306] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5826e70aa5d1b86a9371981ac7a44080

[0m[2025-01-18T23:10:59.725354] [FLK_MGR] Running job id: 5826e70aa5d1b86a9371981ac7a44080
[0m[2025-01-18T23:10:59.725361] [FLK_MGR] Getting job info.
[0m[2025-01-18T23:10:59.742671] [FLK_MGR] Job plan response: {"plan":{"jid":"5826e70aa5d1b86a9371981ac7a44080","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T23:10:59.742804] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T23:11:00.117951] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xjxj4
[0m[2025-01-18T23:11:01.542871] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 23:10:58 : 5826e70aa5d1b86a9371981ac7a44080 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T23:11:01.542937] [FLK_MGR] Running jobs: ['5826e70aa5d1b86a9371981ac7a44080']
[0m[2025-01-18T23:11:01.542944] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T23:11:01.542953] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T23:15:01.565707] [SCALING] Scaling started.
[0m[2025-01-18T23:15:01.565762] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T23:15:01.578024] [SCALING] Scaling finished.
[0m[2025-01-18T23:15:01.578049] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:15:01.596084] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:15:01.612417] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T23:15:01.634231] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 0 replica.
[0m[2025-01-18T23:15:01.649871] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T23:15:01.662380] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T23:15:01.675076] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T23:15:01.688203] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T23:15:01.702038] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T23:15:01.733558] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xjxj4 deleted
[0m[2025-01-18T23:15:03.626361] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:15:05.549308] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:15:05.549387] Reloading playbook: application/kafka
[0m[2025-01-18T23:15:11.496899] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T23:15:52.463936] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T23:15:52.464287] [EXPERIMENT] Run 4 completed. Start: 1737241774, End: 1737242152
[0m[2025-01-18T23:15:52.464318] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T23:16:02.465308] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T23:16:04.384099] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:16:06.294681] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:16:06.294916] [SCALING] Setting up experiment.


[0m[2025-01-18T23:16:06.295013] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:16:06.300749] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:16:06.317017] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T23:16:06.332669] [SCALING] Statefulset name to scale : flink-16000m-4096
[0m[2025-01-18T23:16:06.343099] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 1 replica.
[0m[2025-01-18T23:17:21.428694] [FLK_MGR] Running job.
[0m[2025-01-18T23:17:21.428735] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T23:17:21.829545] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-hvwrz
[0m[2025-01-18T23:17:25.961175] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 17350b882a9d746caede44fb95b8afa3

[0m[2025-01-18T23:17:25.961220] [FLK_MGR] Running job id: 17350b882a9d746caede44fb95b8afa3
[0m[2025-01-18T23:17:25.961229] [FLK_MGR] Getting job info.
[0m[2025-01-18T23:17:25.977822] [FLK_MGR] Job plan response: {"plan":{"jid":"17350b882a9d746caede44fb95b8afa3","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T23:17:25.977953] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T23:17:26.352413] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-hvwrz
[0m[2025-01-18T23:17:27.784826] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 23:17:24 : 17350b882a9d746caede44fb95b8afa3 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T23:17:27.784887] [FLK_MGR] Running jobs: ['17350b882a9d746caede44fb95b8afa3']
[0m[2025-01-18T23:17:27.784893] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T23:17:27.784917] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T23:21:27.808774] [SCALING] Scaling started.
[0m[2025-01-18T23:21:27.808834] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T23:21:27.824124] [SCALING] Scaling finished.
[0m[2025-01-18T23:21:27.824152] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:21:27.841629] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:21:27.857708] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T23:21:27.878649] [STS_MGR] StatefulSet flink-16000m-4096 scaled to 0 replica.
[0m[2025-01-18T23:21:27.893462] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T23:21:27.908398] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T23:21:27.922149] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T23:21:27.935886] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T23:21:27.949341] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T23:21:27.973268] [POD_MGR] Pod flink-jobmanager-7d7c784b74-hvwrz deleted
[0m[2025-01-18T23:21:29.860218] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:21:31.815402] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:21:31.815502] Reloading playbook: application/kafka
[0m[2025-01-18T23:21:37.832127] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T23:22:18.825177] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T23:22:18.825483] [EXPERIMENT] Run 5 completed. Start: 1737242162, End: 1737242538
[0m[2025-01-18T23:22:18.825491] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T23:22:31.133642] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T23:22:31.133743] [RESOURCE_E] Running experiment with 16000m cores and 8192 memory.
[0m[2025-01-18T23:22:38.428802] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T23:22:38.428925] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T23:22:40.346807] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:22:42.285895] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:22:42.286068] [SCALING] Setting up experiment.


[0m[2025-01-18T23:22:42.286091] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:22:42.295873] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:22:42.313316] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T23:22:42.331683] [SCALING] Statefulset name to scale : flink-16000m-8192
[0m[2025-01-18T23:22:42.342718] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 1 replica.
[0m[2025-01-18T23:23:57.428780] [FLK_MGR] Running job.
[0m[2025-01-18T23:23:57.428859] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T23:23:57.826069] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-pdmhr
[0m[2025-01-18T23:24:01.927396] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f4f3665f789016e3ab1528cc1fc59914

[0m[2025-01-18T23:24:01.927448] [FLK_MGR] Running job id: f4f3665f789016e3ab1528cc1fc59914
[0m[2025-01-18T23:24:01.927456] [FLK_MGR] Getting job info.
[0m[2025-01-18T23:24:01.945197] [FLK_MGR] Job plan response: {"plan":{"jid":"f4f3665f789016e3ab1528cc1fc59914","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T23:24:01.945341] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T23:24:02.329802] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-pdmhr
[0m[2025-01-18T23:24:03.778221] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 23:24:00 : f4f3665f789016e3ab1528cc1fc59914 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T23:24:03.778279] [FLK_MGR] Running jobs: ['f4f3665f789016e3ab1528cc1fc59914']
[0m[2025-01-18T23:24:03.778288] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T23:24:03.778307] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T23:28:03.801634] [SCALING] Scaling started.
[0m[2025-01-18T23:28:03.801752] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T23:28:03.816653] [SCALING] Scaling finished.
[0m[2025-01-18T23:28:03.816677] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:28:03.836485] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:28:03.852669] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T23:28:03.873772] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 0 replica.
[0m[2025-01-18T23:28:03.889114] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T23:28:03.903237] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T23:28:03.916851] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T23:28:03.930018] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T23:28:03.944506] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T23:28:03.976181] [POD_MGR] Pod flink-jobmanager-7d7c784b74-pdmhr deleted
[0m[2025-01-18T23:28:05.918771] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:28:07.851831] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:28:07.851919] Reloading playbook: application/kafka
[0m[2025-01-18T23:28:13.833235] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T23:28:54.838716] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T23:28:54.839023] [EXPERIMENT] Run 1 completed. Start: 1737242558, End: 1737242934
[0m[2025-01-18T23:28:54.839030] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T23:29:04.840028] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-18T23:29:06.771879] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:29:08.727633] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:29:08.727733] [SCALING] Setting up experiment.


[0m[2025-01-18T23:29:08.727745] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:29:08.733089] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:29:08.748498] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T23:29:08.764582] [SCALING] Statefulset name to scale : flink-16000m-8192
[0m[2025-01-18T23:29:08.774817] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 1 replica.
[0m[2025-01-18T23:30:23.863979] [FLK_MGR] Running job.
[0m[2025-01-18T23:30:23.864083] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T23:30:24.251293] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-fc2p2
[0m[2025-01-18T23:30:28.323435] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 532529db5dc2d9ad101582a0b4a3229e

[0m[2025-01-18T23:30:28.323486] [FLK_MGR] Running job id: 532529db5dc2d9ad101582a0b4a3229e
[0m[2025-01-18T23:30:28.323495] [FLK_MGR] Getting job info.
[0m[2025-01-18T23:30:28.340346] [FLK_MGR] Job plan response: {"plan":{"jid":"532529db5dc2d9ad101582a0b4a3229e","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T23:30:28.340483] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T23:30:28.737238] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-fc2p2
[0m[2025-01-18T23:30:30.179915] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 23:30:27 : 532529db5dc2d9ad101582a0b4a3229e : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T23:30:30.179976] [FLK_MGR] Running jobs: ['532529db5dc2d9ad101582a0b4a3229e']
[0m[2025-01-18T23:30:30.179983] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T23:30:30.179996] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T23:34:30.202921] [SCALING] Scaling started.
[0m[2025-01-18T23:34:30.202985] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T23:34:30.214754] [SCALING] Scaling finished.
[0m[2025-01-18T23:34:30.214780] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:34:30.235239] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:34:30.253418] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T23:34:30.274441] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 0 replica.
[0m[2025-01-18T23:34:30.290129] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T23:34:30.305027] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T23:34:30.319095] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T23:34:30.332654] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T23:34:30.345545] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T23:34:30.367620] [POD_MGR] Pod flink-jobmanager-7d7c784b74-fc2p2 deleted
[0m[2025-01-18T23:34:32.298586] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:34:34.255138] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:34:34.255215] Reloading playbook: application/kafka
[0m[2025-01-18T23:34:40.218157] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T23:35:21.164252] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T23:35:21.164506] [EXPERIMENT] Run 2 completed. Start: 1737242944, End: 1737243321
[0m[2025-01-18T23:35:21.164513] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T23:35:31.165510] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-18T23:35:33.101578] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:35:35.023759] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:35:35.023896] [SCALING] Setting up experiment.


[0m[2025-01-18T23:35:35.023944] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:35:35.029311] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:35:35.045623] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T23:35:35.062471] [SCALING] Statefulset name to scale : flink-16000m-8192
[0m[2025-01-18T23:35:35.072651] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 1 replica.
[0m[2025-01-18T23:36:50.160213] [FLK_MGR] Running job.
[0m[2025-01-18T23:36:50.160269] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T23:36:50.543800] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-6b8ls
[0m[2025-01-18T23:36:54.614131] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fe002d484f2bb5dfe692ae6255c3f6b8

[0m[2025-01-18T23:36:54.614183] [FLK_MGR] Running job id: fe002d484f2bb5dfe692ae6255c3f6b8
[0m[2025-01-18T23:36:54.614191] [FLK_MGR] Getting job info.
[0m[2025-01-18T23:36:54.630394] [FLK_MGR] Job plan response: {"plan":{"jid":"fe002d484f2bb5dfe692ae6255c3f6b8","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T23:36:54.630528] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T23:36:55.015665] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-6b8ls
[0m[2025-01-18T23:36:56.467674] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 23:36:53 : fe002d484f2bb5dfe692ae6255c3f6b8 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T23:36:56.467732] [FLK_MGR] Running jobs: ['fe002d484f2bb5dfe692ae6255c3f6b8']
[0m[2025-01-18T23:36:56.467739] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T23:36:56.467752] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T23:40:56.490427] [SCALING] Scaling started.
[0m[2025-01-18T23:40:56.490532] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T23:40:56.505241] [SCALING] Scaling finished.
[0m[2025-01-18T23:40:56.505267] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:40:56.523518] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:40:56.542898] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T23:40:56.565074] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 0 replica.
[0m[2025-01-18T23:40:56.580091] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T23:40:56.595403] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T23:40:56.609463] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T23:40:56.622865] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T23:40:56.635995] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T23:40:56.660547] [POD_MGR] Pod flink-jobmanager-7d7c784b74-6b8ls deleted
[0m[2025-01-18T23:40:58.636018] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:41:00.537231] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:41:00.537323] Reloading playbook: application/kafka
[0m[2025-01-18T23:41:06.535655] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T23:41:47.573041] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T23:41:47.573314] [EXPERIMENT] Run 3 completed. Start: 1737243331, End: 1737243707
[0m[2025-01-18T23:41:47.573321] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T23:41:57.574304] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-18T23:41:59.515231] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:42:01.421293] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:42:01.421406] [SCALING] Setting up experiment.


[0m[2025-01-18T23:42:01.421419] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:42:01.427794] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:42:01.445627] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T23:42:01.461439] [SCALING] Statefulset name to scale : flink-16000m-8192
[0m[2025-01-18T23:42:01.472208] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 1 replica.
[0m[2025-01-18T23:43:16.564268] [FLK_MGR] Running job.
[0m[2025-01-18T23:43:16.564366] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T23:43:16.953999] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-fks6z
[0m[2025-01-18T23:43:21.039401] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 42fa6ff45be4cee16da2323079b27980

[0m[2025-01-18T23:43:21.039450] [FLK_MGR] Running job id: 42fa6ff45be4cee16da2323079b27980
[0m[2025-01-18T23:43:21.039458] [FLK_MGR] Getting job info.
[0m[2025-01-18T23:43:21.056175] [FLK_MGR] Job plan response: {"plan":{"jid":"42fa6ff45be4cee16da2323079b27980","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T23:43:21.056315] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T23:43:21.439181] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-fks6z
[0m[2025-01-18T23:43:22.893860] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 23:43:20 : 42fa6ff45be4cee16da2323079b27980 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T23:43:22.893943] [FLK_MGR] Running jobs: ['42fa6ff45be4cee16da2323079b27980']
[0m[2025-01-18T23:43:22.893952] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T23:43:22.893966] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T23:47:22.915661] [SCALING] Scaling started.
[0m[2025-01-18T23:47:22.915782] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T23:47:22.930095] [SCALING] Scaling finished.
[0m[2025-01-18T23:47:22.930127] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:47:22.946516] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:47:22.962224] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T23:47:22.982302] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 0 replica.
[0m[2025-01-18T23:47:22.998295] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T23:47:23.012179] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T23:47:23.026001] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T23:47:23.038365] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T23:47:23.050630] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T23:47:23.079702] [POD_MGR] Pod flink-jobmanager-7d7c784b74-fks6z deleted
[0m[2025-01-18T23:47:25.030971] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:47:26.955548] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:47:26.955624] Reloading playbook: application/kafka
[0m[2025-01-18T23:47:32.908266] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T23:48:13.920078] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T23:48:13.920384] [EXPERIMENT] Run 4 completed. Start: 1737243717, End: 1737244093
[0m[2025-01-18T23:48:13.920391] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T23:48:23.921359] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-18T23:48:25.847677] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:48:27.779166] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:48:27.779247] [SCALING] Setting up experiment.


[0m[2025-01-18T23:48:27.779261] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:48:27.786904] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:48:27.803586] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T23:48:27.819928] [SCALING] Statefulset name to scale : flink-16000m-8192
[0m[2025-01-18T23:48:27.830206] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 1 replica.
[0m[2025-01-18T23:49:42.919728] [FLK_MGR] Running job.
[0m[2025-01-18T23:49:42.919826] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T23:49:44.755793] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-62b7f
[0m[2025-01-18T23:49:48.802371] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 1158d6560d1ec8a013850adff7742455

[0m[2025-01-18T23:49:48.802415] [FLK_MGR] Running job id: 1158d6560d1ec8a013850adff7742455
[0m[2025-01-18T23:49:48.802423] [FLK_MGR] Getting job info.
[0m[2025-01-18T23:49:48.817774] [FLK_MGR] Job plan response: {"plan":{"jid":"1158d6560d1ec8a013850adff7742455","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T23:49:48.817906] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T23:49:49.188537] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-62b7f
[0m[2025-01-18T23:49:50.603683] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 23:49:47 : 1158d6560d1ec8a013850adff7742455 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T23:49:50.603737] [FLK_MGR] Running jobs: ['1158d6560d1ec8a013850adff7742455']
[0m[2025-01-18T23:49:50.603744] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T23:49:50.603755] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-18T23:53:50.626299] [SCALING] Scaling started.
[0m[2025-01-18T23:53:50.626350] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-18T23:53:50.639654] [SCALING] Scaling finished.
[0m[2025-01-18T23:53:50.639684] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:53:50.657147] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:53:50.675697] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-18T23:53:50.697627] [STS_MGR] StatefulSet flink-16000m-8192 scaled to 0 replica.
[0m[2025-01-18T23:53:50.713603] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-18T23:53:50.727169] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-18T23:53:50.741053] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-18T23:53:50.754830] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-18T23:53:50.767613] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-18T23:53:50.790021] [POD_MGR] Pod flink-jobmanager-7d7c784b74-62b7f deleted
[0m[2025-01-18T23:53:52.721575] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:53:54.688342] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-18T23:53:54.688428] Reloading playbook: application/kafka
[0m[2025-01-18T23:54:00.724254] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-18T23:54:41.627499] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-18T23:54:41.627703] [EXPERIMENT] Run 5 completed. Start: 1737244103, End: 1737244481
[0m[2025-01-18T23:54:41.627710] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-18T23:54:53.921563] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-18T23:54:53.921644] [RESOURCE_E] Running experiment with 16000m cores and 16384 memory.
[0m[2025-01-18T23:55:01.188773] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-18T23:55:01.188849] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-18T23:55:03.130157] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:55:05.049464] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-18T23:55:05.049690] [SCALING] Setting up experiment.


[0m[2025-01-18T23:55:05.049803] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-18T23:55:05.056194] [NODE_MGR] Resetting state labels.
[0m[2025-01-18T23:55:05.073391] [SCALING] First node: virtual-158-0-2

[0m[2025-01-18T23:55:05.088058] [SCALING] Statefulset name to scale : flink-16000m-16384
[0m[2025-01-18T23:55:05.097239] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 1 replica.
[0m[2025-01-18T23:56:20.183015] [FLK_MGR] Running job.
[0m[2025-01-18T23:56:20.183106] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-18T23:56:20.561413] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-77x2q
[0m[2025-01-18T23:56:24.593988] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8dd950d8035ed33d6ca036f74411cca1

[0m[2025-01-18T23:56:24.594036] [FLK_MGR] Running job id: 8dd950d8035ed33d6ca036f74411cca1
[0m[2025-01-18T23:56:24.594043] [FLK_MGR] Getting job info.
[0m[2025-01-18T23:56:24.611639] [FLK_MGR] Job plan response: {"plan":{"jid":"8dd950d8035ed33d6ca036f74411cca1","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-18T23:56:24.611781] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-18T23:56:25.013433] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-77x2q
[0m[2025-01-18T23:56:26.431961] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
18.01.2025 23:56:23 : 8dd950d8035ed33d6ca036f74411cca1 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-18T23:56:26.432016] [FLK_MGR] Running jobs: ['8dd950d8035ed33d6ca036f74411cca1']
[0m[2025-01-18T23:56:26.432024] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-18T23:56:26.432036] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T00:00:26.454558] [SCALING] Scaling started.
[0m[2025-01-19T00:00:26.454610] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T00:00:26.469453] [SCALING] Scaling finished.
[0m[2025-01-19T00:00:26.469479] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:00:26.487374] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:00:26.503471] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T00:00:26.526920] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 0 replica.
[0m[2025-01-19T00:00:26.543248] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T00:00:26.557389] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T00:00:26.571335] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T00:00:26.583952] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T00:00:26.596257] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T00:00:26.622901] [POD_MGR] Pod flink-jobmanager-7d7c784b74-77x2q deleted
[0m[2025-01-19T00:00:28.536676] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:00:30.498209] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:00:30.498302] Reloading playbook: application/kafka
[0m[2025-01-19T00:00:36.529987] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T00:01:17.545970] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T00:01:17.546539] [EXPERIMENT] Run 1 completed. Start: 1737244501, End: 1737244877
[0m[2025-01-19T00:01:17.546548] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T00:01:27.547625] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-19T00:01:29.480156] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:01:31.411423] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:01:31.411542] [SCALING] Setting up experiment.


[0m[2025-01-19T00:01:31.411554] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:01:31.417756] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:01:31.435335] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T00:01:31.453242] [SCALING] Statefulset name to scale : flink-16000m-16384
[0m[2025-01-19T00:01:31.463605] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 1 replica.
[0m[2025-01-19T00:02:46.550546] [FLK_MGR] Running job.
[0m[2025-01-19T00:02:46.550637] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T00:02:46.930942] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-sltw4
[0m[2025-01-19T00:02:50.938889] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID e94907fd64a6deee92db625779813766

[0m[2025-01-19T00:02:50.938937] [FLK_MGR] Running job id: e94907fd64a6deee92db625779813766
[0m[2025-01-19T00:02:50.938946] [FLK_MGR] Getting job info.
[0m[2025-01-19T00:02:50.957340] [FLK_MGR] Job plan response: {"plan":{"jid":"e94907fd64a6deee92db625779813766","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T00:02:50.957480] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T00:02:51.348508] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sltw4
[0m[2025-01-19T00:02:52.784242] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 00:02:49 : e94907fd64a6deee92db625779813766 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T00:02:52.784301] [FLK_MGR] Running jobs: ['e94907fd64a6deee92db625779813766']
[0m[2025-01-19T00:02:52.784309] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T00:02:52.784322] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T00:06:52.808604] [SCALING] Scaling started.
[0m[2025-01-19T00:06:52.808656] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T00:06:52.822190] [SCALING] Scaling finished.
[0m[2025-01-19T00:06:52.822214] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:06:52.841830] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:06:52.857902] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T00:06:52.879440] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 0 replica.
[0m[2025-01-19T00:06:52.895740] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T00:06:52.909370] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T00:06:52.922776] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T00:06:52.936308] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T00:06:52.949843] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T00:06:52.971183] [POD_MGR] Pod flink-jobmanager-7d7c784b74-sltw4 deleted
[0m[2025-01-19T00:06:54.894073] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:06:56.842291] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:06:56.842390] Reloading playbook: application/kafka
[0m[2025-01-19T00:07:02.858049] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T00:07:43.869408] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T00:07:43.869722] [EXPERIMENT] Run 2 completed. Start: 1737244887, End: 1737245263
[0m[2025-01-19T00:07:43.869729] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T00:07:53.870854] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-19T00:07:55.769636] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:07:57.690978] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:07:57.691077] [SCALING] Setting up experiment.


[0m[2025-01-19T00:07:57.691089] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:07:57.696593] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:07:57.714659] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T00:07:57.733930] [SCALING] Statefulset name to scale : flink-16000m-16384
[0m[2025-01-19T00:07:57.747080] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 1 replica.
[0m[2025-01-19T00:09:12.835638] [FLK_MGR] Running job.
[0m[2025-01-19T00:09:12.835687] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T00:09:13.220897] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-rb4q2
[0m[2025-01-19T00:09:17.259978] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 143483287ca72ff9f81846641aac5ffe

[0m[2025-01-19T00:09:17.260055] [FLK_MGR] Running job id: 143483287ca72ff9f81846641aac5ffe
[0m[2025-01-19T00:09:17.260066] [FLK_MGR] Getting job info.
[0m[2025-01-19T00:09:17.276255] [FLK_MGR] Job plan response: {"plan":{"jid":"143483287ca72ff9f81846641aac5ffe","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T00:09:17.276434] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T00:09:17.654442] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-rb4q2
[0m[2025-01-19T00:09:19.064716] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 00:09:16 : 143483287ca72ff9f81846641aac5ffe : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T00:09:19.064774] [FLK_MGR] Running jobs: ['143483287ca72ff9f81846641aac5ffe']
[0m[2025-01-19T00:09:19.064783] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T00:09:19.064795] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T00:13:19.087674] [SCALING] Scaling started.
[0m[2025-01-19T00:13:19.087730] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T00:13:19.104480] [SCALING] Scaling finished.
[0m[2025-01-19T00:13:19.104528] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:13:19.136891] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:13:19.156574] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T00:13:19.179363] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 0 replica.
[0m[2025-01-19T00:13:19.195489] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T00:13:19.208201] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T00:13:19.220734] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T00:13:19.233361] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T00:13:19.248022] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T00:13:19.283234] [POD_MGR] Pod flink-jobmanager-7d7c784b74-rb4q2 deleted
[0m[2025-01-19T00:13:21.212989] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:13:23.200909] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:13:23.200985] Reloading playbook: application/kafka
[0m[2025-01-19T00:13:29.175045] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T00:14:10.168416] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T00:14:10.169306] [EXPERIMENT] Run 3 completed. Start: 1737245273, End: 1737245650
[0m[2025-01-19T00:14:10.169332] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T00:14:20.170353] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-19T00:14:22.091072] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:14:24.029399] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:14:24.029480] [SCALING] Setting up experiment.


[0m[2025-01-19T00:14:24.029489] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:14:24.034356] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:14:24.049662] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T00:14:24.067457] [SCALING] Statefulset name to scale : flink-16000m-16384
[0m[2025-01-19T00:14:24.076882] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 1 replica.
[0m[2025-01-19T00:15:39.165158] [FLK_MGR] Running job.
[0m[2025-01-19T00:15:39.165249] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T00:15:39.546360] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-tjxzf
[0m[2025-01-19T00:15:43.609825] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 955d70ad3b8fcf6b28940a8ed4ed28cf

[0m[2025-01-19T00:15:43.609876] [FLK_MGR] Running job id: 955d70ad3b8fcf6b28940a8ed4ed28cf
[0m[2025-01-19T00:15:43.609885] [FLK_MGR] Getting job info.
[0m[2025-01-19T00:15:43.628010] [FLK_MGR] Job plan response: {"plan":{"jid":"955d70ad3b8fcf6b28940a8ed4ed28cf","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T00:15:43.628187] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T00:15:44.007028] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-tjxzf
[0m[2025-01-19T00:15:45.432868] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 00:15:42 : 955d70ad3b8fcf6b28940a8ed4ed28cf : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T00:15:45.432929] [FLK_MGR] Running jobs: ['955d70ad3b8fcf6b28940a8ed4ed28cf']
[0m[2025-01-19T00:15:45.432936] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T00:15:45.432949] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T00:19:45.456024] [SCALING] Scaling started.
[0m[2025-01-19T00:19:45.456081] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T00:19:45.470305] [SCALING] Scaling finished.
[0m[2025-01-19T00:19:45.470344] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:19:45.491019] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:19:45.509921] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T00:19:45.530705] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 0 replica.
[0m[2025-01-19T00:19:45.548487] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T00:19:45.562145] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T00:19:45.575925] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T00:19:45.589592] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T00:19:45.603090] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T00:19:45.630772] [POD_MGR] Pod flink-jobmanager-7d7c784b74-tjxzf deleted
[0m[2025-01-19T00:19:47.549804] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:19:49.531218] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:19:49.531314] Reloading playbook: application/kafka
[0m[2025-01-19T00:19:55.548641] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T00:20:36.503623] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T00:20:36.503869] [EXPERIMENT] Run 4 completed. Start: 1737245660, End: 1737246036
[0m[2025-01-19T00:20:36.503876] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T00:20:46.504941] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-19T00:20:48.428431] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:20:50.386644] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:20:50.386736] [SCALING] Setting up experiment.


[0m[2025-01-19T00:20:50.386748] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:20:50.392678] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:20:50.409633] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T00:20:50.428049] [SCALING] Statefulset name to scale : flink-16000m-16384
[0m[2025-01-19T00:20:50.439910] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 1 replica.
[0m[2025-01-19T00:22:05.530217] [FLK_MGR] Running job.
[0m[2025-01-19T00:22:05.530272] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T00:22:05.922650] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-zsfvc
[0m[2025-01-19T00:22:10.032633] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9cb992a2f43073d3ac878a1626f3d729

[0m[2025-01-19T00:22:10.032716] [FLK_MGR] Running job id: 9cb992a2f43073d3ac878a1626f3d729
[0m[2025-01-19T00:22:10.032734] [FLK_MGR] Getting job info.
[0m[2025-01-19T00:22:10.051744] [FLK_MGR] Job plan response: {"plan":{"jid":"9cb992a2f43073d3ac878a1626f3d729","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T00:22:10.051900] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T00:22:10.441956] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-zsfvc
[0m[2025-01-19T00:22:11.884781] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 00:22:09 : 9cb992a2f43073d3ac878a1626f3d729 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T00:22:11.884840] [FLK_MGR] Running jobs: ['9cb992a2f43073d3ac878a1626f3d729']
[0m[2025-01-19T00:22:11.884848] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T00:22:11.884861] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T00:26:11.908753] [SCALING] Scaling started.
[0m[2025-01-19T00:26:11.908867] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T00:26:11.921248] [SCALING] Scaling finished.
[0m[2025-01-19T00:26:11.921273] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:26:11.937650] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:26:11.953407] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T00:26:11.975540] [STS_MGR] StatefulSet flink-16000m-16384 scaled to 0 replica.
[0m[2025-01-19T00:26:11.990552] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T00:26:12.003827] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T00:26:12.017285] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T00:26:12.030430] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T00:26:12.043120] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T00:26:12.068382] [POD_MGR] Pod flink-jobmanager-7d7c784b74-zsfvc deleted
[0m[2025-01-19T00:26:14.031232] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:26:16.017102] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:26:16.017192] Reloading playbook: application/kafka
[0m[2025-01-19T00:26:21.969885] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T00:27:02.938171] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T00:27:02.938437] [EXPERIMENT] Run 5 completed. Start: 1737246046, End: 1737246422
[0m[2025-01-19T00:27:02.938443] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T00:27:15.099450] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-19T00:27:15.099558] [RESOURCE_E] Running experiment with 16000m cores and 32768 memory.
[0m[2025-01-19T00:27:22.403742] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-19T00:27:22.403863] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-19T00:27:24.317291] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:27:26.269781] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:27:26.269891] [SCALING] Setting up experiment.


[0m[2025-01-19T00:27:26.269903] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:27:26.277022] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:27:26.294148] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T00:27:26.310581] [SCALING] Statefulset name to scale : flink-16000m-32768
[0m[2025-01-19T00:27:26.320986] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 1 replica.
[0m[2025-01-19T00:28:41.404387] [FLK_MGR] Running job.
[0m[2025-01-19T00:28:41.404459] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T00:28:43.822349] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-n2txd
[0m[2025-01-19T00:28:47.875126] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 8f94857a52d16116c005714b6b79f0b4

[0m[2025-01-19T00:28:47.875173] [FLK_MGR] Running job id: 8f94857a52d16116c005714b6b79f0b4
[0m[2025-01-19T00:28:47.875181] [FLK_MGR] Getting job info.
[0m[2025-01-19T00:28:47.893127] [FLK_MGR] Job plan response: {"plan":{"jid":"8f94857a52d16116c005714b6b79f0b4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T00:28:47.893274] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T00:28:48.264992] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-n2txd
[0m[2025-01-19T00:28:49.684352] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 00:28:46 : 8f94857a52d16116c005714b6b79f0b4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T00:28:49.684408] [FLK_MGR] Running jobs: ['8f94857a52d16116c005714b6b79f0b4']
[0m[2025-01-19T00:28:49.684415] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T00:28:49.684550] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T00:32:49.710466] [SCALING] Scaling started.
[0m[2025-01-19T00:32:49.710573] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T00:32:49.724203] [SCALING] Scaling finished.
[0m[2025-01-19T00:32:49.724232] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:32:49.743095] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:32:49.759972] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T00:32:49.783746] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 0 replica.
[0m[2025-01-19T00:32:49.798270] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T00:32:49.811896] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T00:32:49.824209] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T00:32:49.836546] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T00:32:49.849392] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T00:32:49.884146] [POD_MGR] Pod flink-jobmanager-7d7c784b74-n2txd deleted
[0m[2025-01-19T00:32:51.836357] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:32:53.778337] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:32:53.778464] Reloading playbook: application/kafka
[0m[2025-01-19T00:32:59.745323] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T00:33:40.781300] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T00:33:40.781563] [EXPERIMENT] Run 1 completed. Start: 1737246442, End: 1737246820
[0m[2025-01-19T00:33:40.781572] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T00:33:50.782627] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-19T00:33:52.701453] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:33:54.628545] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:33:54.628639] [SCALING] Setting up experiment.


[0m[2025-01-19T00:33:54.628660] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:33:54.634182] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:33:54.650118] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T00:33:54.666670] [SCALING] Statefulset name to scale : flink-16000m-32768
[0m[2025-01-19T00:33:54.678213] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 1 replica.
[0m[2025-01-19T00:35:09.767889] [FLK_MGR] Running job.
[0m[2025-01-19T00:35:09.767992] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T00:35:10.155096] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-t2mrp
[0m[2025-01-19T00:35:14.251932] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a6954520de7e7bb729e7a7a484d95784

[0m[2025-01-19T00:35:14.251985] [FLK_MGR] Running job id: a6954520de7e7bb729e7a7a484d95784
[0m[2025-01-19T00:35:14.251994] [FLK_MGR] Getting job info.
[0m[2025-01-19T00:35:14.271336] [FLK_MGR] Job plan response: {"plan":{"jid":"a6954520de7e7bb729e7a7a484d95784","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T00:35:14.271490] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T00:35:14.656318] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-t2mrp
[0m[2025-01-19T00:35:16.087929] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 00:35:13 : a6954520de7e7bb729e7a7a484d95784 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T00:35:16.087994] [FLK_MGR] Running jobs: ['a6954520de7e7bb729e7a7a484d95784']
[0m[2025-01-19T00:35:16.088003] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T00:35:16.088017] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T00:39:16.111722] [SCALING] Scaling started.
[0m[2025-01-19T00:39:16.111786] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T00:39:16.126527] [SCALING] Scaling finished.
[0m[2025-01-19T00:39:16.126569] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:39:16.148378] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:39:16.172073] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T00:39:16.195046] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 0 replica.
[0m[2025-01-19T00:39:16.210649] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T00:39:16.222845] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T00:39:16.235565] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T00:39:16.247618] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T00:39:16.261163] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T00:39:16.283463] [POD_MGR] Pod flink-jobmanager-7d7c784b74-t2mrp deleted
[0m[2025-01-19T00:39:18.193539] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:39:20.189341] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:39:20.189431] Reloading playbook: application/kafka
[0m[2025-01-19T00:39:26.162061] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T00:40:07.154975] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T00:40:07.155290] [EXPERIMENT] Run 2 completed. Start: 1737246830, End: 1737247207
[0m[2025-01-19T00:40:07.155297] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T00:40:17.156313] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-19T00:40:19.048993] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:40:20.969845] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:40:20.969933] [SCALING] Setting up experiment.


[0m[2025-01-19T00:40:20.969945] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:40:20.975777] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:40:20.992965] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T00:40:21.010400] [SCALING] Statefulset name to scale : flink-16000m-32768
[0m[2025-01-19T00:40:21.020638] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 1 replica.
[0m[2025-01-19T00:41:36.108720] [FLK_MGR] Running job.
[0m[2025-01-19T00:41:36.108773] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T00:41:36.514482] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-h7qgp
[0m[2025-01-19T00:41:40.518460] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID b3192a1d36420f3f84d60a02d2f8f868

[0m[2025-01-19T00:41:40.518513] [FLK_MGR] Running job id: b3192a1d36420f3f84d60a02d2f8f868
[0m[2025-01-19T00:41:40.518523] [FLK_MGR] Getting job info.
[0m[2025-01-19T00:41:40.535206] [FLK_MGR] Job plan response: {"plan":{"jid":"b3192a1d36420f3f84d60a02d2f8f868","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T00:41:40.535368] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T00:41:40.928806] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-h7qgp
[0m[2025-01-19T00:41:42.385806] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 00:41:39 : b3192a1d36420f3f84d60a02d2f8f868 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T00:41:42.385870] [FLK_MGR] Running jobs: ['b3192a1d36420f3f84d60a02d2f8f868']
[0m[2025-01-19T00:41:42.385879] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T00:41:42.385900] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T00:45:42.408460] [SCALING] Scaling started.
[0m[2025-01-19T00:45:42.408518] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T00:45:42.423820] [SCALING] Scaling finished.
[0m[2025-01-19T00:45:42.423873] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:45:42.443220] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:45:42.460950] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T00:45:42.482544] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 0 replica.
[0m[2025-01-19T00:45:42.499692] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T00:45:42.513380] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T00:45:42.527007] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T00:45:42.539990] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T00:45:42.553406] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T00:45:42.580931] [POD_MGR] Pod flink-jobmanager-7d7c784b74-h7qgp deleted
[0m[2025-01-19T00:45:44.489448] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:45:46.479945] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:45:46.480029] Reloading playbook: application/kafka
[0m[2025-01-19T00:45:52.503659] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T00:46:33.506869] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T00:46:33.507133] [EXPERIMENT] Run 3 completed. Start: 1737247217, End: 1737247593
[0m[2025-01-19T00:46:33.507140] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T00:46:43.508248] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-19T00:46:45.411859] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:46:47.315619] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:46:47.315719] [SCALING] Setting up experiment.


[0m[2025-01-19T00:46:47.315729] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:46:47.322196] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:46:47.339651] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T00:46:47.363527] [SCALING] Statefulset name to scale : flink-16000m-32768
[0m[2025-01-19T00:46:47.380953] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 1 replica.
[0m[2025-01-19T00:48:02.473010] [FLK_MGR] Running job.
[0m[2025-01-19T00:48:02.473142] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T00:48:02.876312] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-2vx8m
[0m[2025-01-19T00:48:06.974651] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0012cab849c0d00d24b1270ab6361ef0

[0m[2025-01-19T00:48:06.974700] [FLK_MGR] Running job id: 0012cab849c0d00d24b1270ab6361ef0
[0m[2025-01-19T00:48:06.974711] [FLK_MGR] Getting job info.
[0m[2025-01-19T00:48:06.989908] [FLK_MGR] Job plan response: {"plan":{"jid":"0012cab849c0d00d24b1270ab6361ef0","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T00:48:06.990062] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T00:48:07.385895] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-2vx8m
[0m[2025-01-19T00:48:08.829315] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 00:48:06 : 0012cab849c0d00d24b1270ab6361ef0 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T00:48:08.829379] [FLK_MGR] Running jobs: ['0012cab849c0d00d24b1270ab6361ef0']
[0m[2025-01-19T00:48:08.829387] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T00:48:08.829402] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T00:52:08.852346] [SCALING] Scaling started.
[0m[2025-01-19T00:52:08.852460] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T00:52:08.865490] [SCALING] Scaling finished.
[0m[2025-01-19T00:52:08.865516] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:52:08.883662] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:52:08.900342] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T00:52:08.924085] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 0 replica.
[0m[2025-01-19T00:52:08.940808] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T00:52:08.954285] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T00:52:08.968477] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T00:52:08.983984] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T00:52:08.997044] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T00:52:09.020561] [POD_MGR] Pod flink-jobmanager-7d7c784b74-2vx8m deleted
[0m[2025-01-19T00:52:10.928864] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:52:12.939138] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:52:12.939230] Reloading playbook: application/kafka
[0m[2025-01-19T00:52:18.948676] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T00:52:59.932996] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T00:52:59.933823] [EXPERIMENT] Run 4 completed. Start: 1737247603, End: 1737247979
[0m[2025-01-19T00:52:59.933887] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T00:53:09.935143] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-19T00:53:11.823028] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:53:13.765170] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:53:13.765276] [SCALING] Setting up experiment.


[0m[2025-01-19T00:53:13.765289] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:53:13.771282] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:53:13.801008] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T00:53:13.819856] [SCALING] Statefulset name to scale : flink-16000m-32768
[0m[2025-01-19T00:53:13.830524] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 1 replica.
[0m[2025-01-19T00:54:28.913668] [FLK_MGR] Running job.
[0m[2025-01-19T00:54:28.913732] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T00:54:29.303677] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-pp4wh
[0m[2025-01-19T00:54:33.390613] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 88c2f8928d9fd4ac9b6ed6910c3283b8

[0m[2025-01-19T00:54:33.390667] [FLK_MGR] Running job id: 88c2f8928d9fd4ac9b6ed6910c3283b8
[0m[2025-01-19T00:54:33.390676] [FLK_MGR] Getting job info.
[0m[2025-01-19T00:54:33.407299] [FLK_MGR] Job plan response: {"plan":{"jid":"88c2f8928d9fd4ac9b6ed6910c3283b8","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T00:54:33.407439] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T00:54:33.802558] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-pp4wh
[0m[2025-01-19T00:54:35.228375] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 00:54:32 : 88c2f8928d9fd4ac9b6ed6910c3283b8 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T00:54:35.228438] [FLK_MGR] Running jobs: ['88c2f8928d9fd4ac9b6ed6910c3283b8']
[0m[2025-01-19T00:54:35.228447] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T00:54:35.228461] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T00:58:35.251344] [SCALING] Scaling started.
[0m[2025-01-19T00:58:35.251446] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T00:58:35.264276] [SCALING] Scaling finished.
[0m[2025-01-19T00:58:35.264312] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:58:35.281447] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:58:35.297354] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T00:58:35.320551] [STS_MGR] StatefulSet flink-16000m-32768 scaled to 0 replica.
[0m[2025-01-19T00:58:35.336076] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T00:58:35.350594] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T00:58:35.364954] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T00:58:35.379091] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T00:58:35.392597] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T00:58:35.417246] [POD_MGR] Pod flink-jobmanager-7d7c784b74-pp4wh deleted
[0m[2025-01-19T00:58:37.358939] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:58:39.275154] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T00:58:39.275246] Reloading playbook: application/kafka
[0m[2025-01-19T00:58:45.299746] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T00:59:26.299202] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T00:59:26.300108] [EXPERIMENT] Run 5 completed. Start: 1737247989, End: 1737248366
[0m[2025-01-19T00:59:26.300136] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T00:59:38.596922] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-19T00:59:38.597069] [RESOURCE_E] Running experiment with 32000m cores and 1024 memory.
[0m[2025-01-19T00:59:45.881569] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-19T00:59:45.881674] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-19T00:59:47.807493] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:59:49.757351] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T00:59:49.757437] [SCALING] Setting up experiment.


[0m[2025-01-19T00:59:49.757451] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T00:59:49.763836] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T00:59:49.780802] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T00:59:49.795849] [SCALING] Statefulset name to scale : flink-32000m-1024
[0m[2025-01-19T00:59:49.805797] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 1 replica.
[0m[2025-01-19T01:01:04.894387] [FLK_MGR] Running job.
[0m[2025-01-19T01:01:04.894482] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T01:01:05.277697] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-ggkwt
[0m[2025-01-19T01:01:09.445235] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 88d556ab5a49cfc7f1359afa9121d329

[0m[2025-01-19T01:01:09.445284] [FLK_MGR] Running job id: 88d556ab5a49cfc7f1359afa9121d329
[0m[2025-01-19T01:01:09.445292] [FLK_MGR] Getting job info.
[0m[2025-01-19T01:01:09.462443] [FLK_MGR] Job plan response: {"plan":{"jid":"88d556ab5a49cfc7f1359afa9121d329","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T01:01:09.462585] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T01:01:09.837564] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-ggkwt
[0m[2025-01-19T01:01:11.279165] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 01:01:08 : 88d556ab5a49cfc7f1359afa9121d329 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T01:01:11.279225] [FLK_MGR] Running jobs: ['88d556ab5a49cfc7f1359afa9121d329']
[0m[2025-01-19T01:01:11.279232] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T01:01:11.279246] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T01:05:11.301704] [SCALING] Scaling started.
[0m[2025-01-19T01:05:11.301812] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T01:05:11.315874] [SCALING] Scaling finished.
[0m[2025-01-19T01:05:11.315916] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:05:11.336041] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:05:11.352411] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T01:05:11.374501] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 0 replica.
[0m[2025-01-19T01:05:11.389735] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T01:05:11.403181] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T01:05:11.418241] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T01:05:11.431020] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T01:05:11.443140] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T01:05:11.478013] [POD_MGR] Pod flink-jobmanager-7d7c784b74-ggkwt deleted
[0m[2025-01-19T01:05:13.414264] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:05:15.401403] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:05:15.401491] Reloading playbook: application/kafka
[0m[2025-01-19T01:05:21.408482] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T01:06:02.424242] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T01:06:02.424478] [EXPERIMENT] Run 1 completed. Start: 1737248385, End: 1737248762
[0m[2025-01-19T01:06:02.424484] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T01:06:12.425377] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-19T01:06:14.326707] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:06:16.271435] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:06:16.271698] [SCALING] Setting up experiment.


[0m[2025-01-19T01:06:16.271745] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:06:16.277201] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:06:16.292985] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T01:06:16.308365] [SCALING] Statefulset name to scale : flink-32000m-1024
[0m[2025-01-19T01:06:16.317830] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 1 replica.
[0m[2025-01-19T01:07:31.404453] [FLK_MGR] Running job.
[0m[2025-01-19T01:07:31.404491] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T01:07:33.346516] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-rx87d
[0m[2025-01-19T01:07:37.471107] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID cf7853dcbeefa993d64b38e5f73d7f87

[0m[2025-01-19T01:07:37.471163] [FLK_MGR] Running job id: cf7853dcbeefa993d64b38e5f73d7f87
[0m[2025-01-19T01:07:37.471172] [FLK_MGR] Getting job info.
[0m[2025-01-19T01:07:37.489234] [FLK_MGR] Job plan response: {"plan":{"jid":"cf7853dcbeefa993d64b38e5f73d7f87","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T01:07:37.489380] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T01:07:37.862857] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-rx87d
[0m[2025-01-19T01:07:39.277731] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 01:07:36 : cf7853dcbeefa993d64b38e5f73d7f87 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T01:07:39.277786] [FLK_MGR] Running jobs: ['cf7853dcbeefa993d64b38e5f73d7f87']
[0m[2025-01-19T01:07:39.277793] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T01:07:39.277804] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T01:11:39.300296] [SCALING] Scaling started.
[0m[2025-01-19T01:11:39.300393] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T01:11:39.313050] [SCALING] Scaling finished.
[0m[2025-01-19T01:11:39.313871] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:11:39.331539] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:11:39.349769] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T01:11:39.371246] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 0 replica.
[0m[2025-01-19T01:11:39.387952] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T01:11:39.402098] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T01:11:39.414948] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T01:11:39.427465] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T01:11:39.441030] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T01:11:39.461796] [POD_MGR] Pod flink-jobmanager-7d7c784b74-rx87d deleted
[0m[2025-01-19T01:11:41.427315] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:11:43.402212] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:11:43.402303] Reloading playbook: application/kafka
[0m[2025-01-19T01:11:49.434255] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T01:12:30.495079] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T01:12:30.495346] [EXPERIMENT] Run 2 completed. Start: 1737248772, End: 1737249150
[0m[2025-01-19T01:12:30.495352] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T01:12:40.496470] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-19T01:12:42.457435] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:12:44.398056] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:12:44.398156] [SCALING] Setting up experiment.


[0m[2025-01-19T01:12:44.398166] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:12:44.403670] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:12:44.420414] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T01:12:44.437028] [SCALING] Statefulset name to scale : flink-32000m-1024
[0m[2025-01-19T01:12:44.449393] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 1 replica.
[0m[2025-01-19T01:13:59.536489] [FLK_MGR] Running job.
[0m[2025-01-19T01:13:59.536535] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T01:13:59.914377] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-x5tv2
[0m[2025-01-19T01:14:03.983071] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID f466389479df5514794720e8e4a94c81

[0m[2025-01-19T01:14:03.983121] [FLK_MGR] Running job id: f466389479df5514794720e8e4a94c81
[0m[2025-01-19T01:14:03.983128] [FLK_MGR] Getting job info.
[0m[2025-01-19T01:14:04.001228] [FLK_MGR] Job plan response: {"plan":{"jid":"f466389479df5514794720e8e4a94c81","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T01:14:04.001367] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T01:14:04.381388] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-x5tv2
[0m[2025-01-19T01:14:05.815461] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 01:14:03 : f466389479df5514794720e8e4a94c81 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T01:14:05.815525] [FLK_MGR] Running jobs: ['f466389479df5514794720e8e4a94c81']
[0m[2025-01-19T01:14:05.815534] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T01:14:05.815552] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T01:18:05.837812] [SCALING] Scaling started.
[0m[2025-01-19T01:18:05.837871] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T01:18:05.851678] [SCALING] Scaling finished.
[0m[2025-01-19T01:18:05.851707] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:18:05.872267] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:18:05.891315] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T01:18:05.915153] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 0 replica.
[0m[2025-01-19T01:18:05.931051] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T01:18:05.945045] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T01:18:05.958774] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T01:18:05.972486] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T01:18:05.986067] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T01:18:06.019508] [POD_MGR] Pod flink-jobmanager-7d7c784b74-x5tv2 deleted
[0m[2025-01-19T01:18:07.987604] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:18:09.951442] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:18:09.951536] Reloading playbook: application/kafka
[0m[2025-01-19T01:18:15.964046] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T01:18:56.956615] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T01:18:56.956920] [EXPERIMENT] Run 3 completed. Start: 1737249160, End: 1737249536
[0m[2025-01-19T01:18:56.956927] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T01:19:06.958024] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-19T01:19:08.882132] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:19:10.794125] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:19:10.794218] [SCALING] Setting up experiment.


[0m[2025-01-19T01:19:10.794229] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:19:10.800360] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:19:10.817412] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T01:19:10.832696] [SCALING] Statefulset name to scale : flink-32000m-1024
[0m[2025-01-19T01:19:10.842313] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 1 replica.
[0m[2025-01-19T01:20:25.929372] [FLK_MGR] Running job.
[0m[2025-01-19T01:20:25.929457] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T01:20:26.311869] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-h5q6c
[0m[2025-01-19T01:20:30.334269] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 092754e303dd93d8f6c8ba386bc1062d

[0m[2025-01-19T01:20:30.334320] [FLK_MGR] Running job id: 092754e303dd93d8f6c8ba386bc1062d
[0m[2025-01-19T01:20:30.334328] [FLK_MGR] Getting job info.
[0m[2025-01-19T01:20:30.350050] [FLK_MGR] Job plan response: {"plan":{"jid":"092754e303dd93d8f6c8ba386bc1062d","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T01:20:30.350200] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T01:20:30.727245] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-h5q6c
[0m[2025-01-19T01:20:32.169724] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 01:20:29 : 092754e303dd93d8f6c8ba386bc1062d : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T01:20:32.169785] [FLK_MGR] Running jobs: ['092754e303dd93d8f6c8ba386bc1062d']
[0m[2025-01-19T01:20:32.169795] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T01:20:32.169807] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T01:24:32.195126] [SCALING] Scaling started.
[0m[2025-01-19T01:24:32.195179] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T01:24:32.210267] [SCALING] Scaling finished.
[0m[2025-01-19T01:24:32.210309] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:24:32.229704] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:24:32.247169] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T01:24:32.267917] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 0 replica.
[0m[2025-01-19T01:24:32.283625] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T01:24:32.299616] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T01:24:32.314150] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T01:24:32.328900] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T01:24:32.341721] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T01:24:32.377746] [POD_MGR] Pod flink-jobmanager-7d7c784b74-h5q6c deleted
[0m[2025-01-19T01:24:34.320136] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:24:36.231271] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:24:36.231349] Reloading playbook: application/kafka
[0m[2025-01-19T01:24:42.271475] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T01:25:23.248302] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T01:25:23.248524] [EXPERIMENT] Run 4 completed. Start: 1737249546, End: 1737249923
[0m[2025-01-19T01:25:23.248530] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T01:25:33.249598] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-19T01:25:35.195927] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:25:37.140320] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:25:37.140394] [SCALING] Setting up experiment.


[0m[2025-01-19T01:25:37.140407] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:25:37.146460] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:25:37.163303] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T01:25:37.182858] [SCALING] Statefulset name to scale : flink-32000m-1024
[0m[2025-01-19T01:25:37.194277] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 1 replica.
[0m[2025-01-19T01:26:52.276639] [FLK_MGR] Running job.
[0m[2025-01-19T01:26:52.276768] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T01:26:52.661566] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jh2tw
[0m[2025-01-19T01:26:56.697966] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 504eef7ec02b7a94b673e8511f2d0cba

[0m[2025-01-19T01:26:56.698013] [FLK_MGR] Running job id: 504eef7ec02b7a94b673e8511f2d0cba
[0m[2025-01-19T01:26:56.698021] [FLK_MGR] Getting job info.
[0m[2025-01-19T01:26:56.716489] [FLK_MGR] Job plan response: {"plan":{"jid":"504eef7ec02b7a94b673e8511f2d0cba","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T01:26:56.716628] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T01:26:57.089539] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jh2tw
[0m[2025-01-19T01:26:58.498704] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 01:26:55 : 504eef7ec02b7a94b673e8511f2d0cba : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T01:26:58.498771] [FLK_MGR] Running jobs: ['504eef7ec02b7a94b673e8511f2d0cba']
[0m[2025-01-19T01:26:58.498786] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T01:26:58.498804] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T01:30:58.521734] [SCALING] Scaling started.
[0m[2025-01-19T01:30:58.521860] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T01:30:58.537956] [SCALING] Scaling finished.
[0m[2025-01-19T01:30:58.537995] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:30:58.556587] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:30:58.573013] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T01:30:58.596955] [STS_MGR] StatefulSet flink-32000m-1024 scaled to 0 replica.
[0m[2025-01-19T01:30:58.613881] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T01:30:58.628341] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T01:30:58.642569] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T01:30:58.656799] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T01:30:58.671186] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T01:30:58.695476] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jh2tw deleted
[0m[2025-01-19T01:31:00.577307] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:31:02.517046] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:31:02.517149] Reloading playbook: application/kafka
[0m[2025-01-19T01:31:08.504930] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T01:31:49.481697] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T01:31:49.481952] [EXPERIMENT] Run 5 completed. Start: 1737249933, End: 1737250309
[0m[2025-01-19T01:31:49.481959] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T01:32:01.745722] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-19T01:32:01.745804] [RESOURCE_E] Running experiment with 32000m cores and 2048 memory.
[0m[2025-01-19T01:32:09.066927] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-19T01:32:09.067022] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-19T01:32:10.966944] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:32:12.899356] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:32:12.899452] [SCALING] Setting up experiment.


[0m[2025-01-19T01:32:12.899462] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:32:12.904597] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:32:12.919964] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T01:32:12.936685] [SCALING] Statefulset name to scale : flink-32000m-2048
[0m[2025-01-19T01:32:12.947069] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 1 replica.
[0m[2025-01-19T01:33:28.034172] [FLK_MGR] Running job.
[0m[2025-01-19T01:33:28.034224] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T01:33:28.418914] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-5g5t7
[0m[2025-01-19T01:33:32.493134] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 06bab49b766d8eacf219e4d97ac6a97f

[0m[2025-01-19T01:33:32.493196] [FLK_MGR] Running job id: 06bab49b766d8eacf219e4d97ac6a97f
[0m[2025-01-19T01:33:32.493207] [FLK_MGR] Getting job info.
[0m[2025-01-19T01:33:32.512098] [FLK_MGR] Job plan response: {"plan":{"jid":"06bab49b766d8eacf219e4d97ac6a97f","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T01:33:32.512251] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T01:33:32.916709] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-5g5t7
[0m[2025-01-19T01:33:34.349221] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 01:33:31 : 06bab49b766d8eacf219e4d97ac6a97f : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T01:33:34.349279] [FLK_MGR] Running jobs: ['06bab49b766d8eacf219e4d97ac6a97f']
[0m[2025-01-19T01:33:34.349287] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T01:33:34.349306] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T01:37:34.371830] [SCALING] Scaling started.
[0m[2025-01-19T01:37:34.371945] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T01:37:34.387337] [SCALING] Scaling finished.
[0m[2025-01-19T01:37:34.387375] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:37:34.406524] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:37:34.422930] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T01:37:34.444017] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 0 replica.
[0m[2025-01-19T01:37:34.459766] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T01:37:34.474554] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T01:37:34.489313] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T01:37:34.504354] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T01:37:34.517782] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T01:37:34.554915] [POD_MGR] Pod flink-jobmanager-7d7c784b74-5g5t7 deleted
[0m[2025-01-19T01:37:36.455110] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:37:38.406299] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:37:38.406387] Reloading playbook: application/kafka
[0m[2025-01-19T01:37:44.457876] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T01:38:25.432757] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T01:38:25.433003] [EXPERIMENT] Run 1 completed. Start: 1737250329, End: 1737250705
[0m[2025-01-19T01:38:25.433011] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T01:38:35.433958] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-19T01:38:37.357246] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:38:39.281452] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:38:39.281543] [SCALING] Setting up experiment.


[0m[2025-01-19T01:38:39.281554] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:38:39.287103] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:38:39.302991] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T01:38:39.320112] [SCALING] Statefulset name to scale : flink-32000m-2048
[0m[2025-01-19T01:38:39.329825] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 1 replica.
[0m[2025-01-19T01:39:54.415368] [FLK_MGR] Running job.
[0m[2025-01-19T01:39:54.415454] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T01:39:54.801040] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-n695t
[0m[2025-01-19T01:39:58.917874] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 64ed5b59798f90527b8baaa7353e5226

[0m[2025-01-19T01:39:58.917927] [FLK_MGR] Running job id: 64ed5b59798f90527b8baaa7353e5226
[0m[2025-01-19T01:39:58.917935] [FLK_MGR] Getting job info.
[0m[2025-01-19T01:39:58.933424] [FLK_MGR] Job plan response: {"plan":{"jid":"64ed5b59798f90527b8baaa7353e5226","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T01:39:58.933561] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T01:39:59.306711] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-n695t
[0m[2025-01-19T01:40:00.721903] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 01:39:57 : 64ed5b59798f90527b8baaa7353e5226 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T01:40:00.721970] [FLK_MGR] Running jobs: ['64ed5b59798f90527b8baaa7353e5226']
[0m[2025-01-19T01:40:00.721977] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T01:40:00.721988] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T01:44:00.744893] [SCALING] Scaling started.
[0m[2025-01-19T01:44:00.744945] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T01:44:00.760573] [SCALING] Scaling finished.
[0m[2025-01-19T01:44:00.760611] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:44:00.779553] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:44:00.796897] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T01:44:00.821781] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 0 replica.
[0m[2025-01-19T01:44:00.837592] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T01:44:00.851088] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T01:44:00.865355] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T01:44:00.878234] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T01:44:00.890717] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T01:44:00.915446] [POD_MGR] Pod flink-jobmanager-7d7c784b74-n695t deleted
[0m[2025-01-19T01:44:02.858259] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:44:04.886224] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:44:04.886301] Reloading playbook: application/kafka
[0m[2025-01-19T01:44:10.819144] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T01:44:51.870360] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T01:44:51.870639] [EXPERIMENT] Run 2 completed. Start: 1737250715, End: 1737251091
[0m[2025-01-19T01:44:51.870646] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T01:45:01.871666] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-19T01:45:03.765823] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:45:05.701530] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:45:05.701616] [SCALING] Setting up experiment.


[0m[2025-01-19T01:45:05.701626] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:45:05.706900] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:45:05.723141] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T01:45:05.740444] [SCALING] Statefulset name to scale : flink-32000m-2048
[0m[2025-01-19T01:45:05.750783] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 1 replica.
[0m[2025-01-19T01:46:20.840103] [FLK_MGR] Running job.
[0m[2025-01-19T01:46:20.840197] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T01:46:22.721748] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mj8kq
[0m[2025-01-19T01:46:26.813684] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fd73dcea6c490b3334eed1020315bad4

[0m[2025-01-19T01:46:26.813742] [FLK_MGR] Running job id: fd73dcea6c490b3334eed1020315bad4
[0m[2025-01-19T01:46:26.813750] [FLK_MGR] Getting job info.
[0m[2025-01-19T01:46:26.832157] [FLK_MGR] Job plan response: {"plan":{"jid":"fd73dcea6c490b3334eed1020315bad4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T01:46:26.832294] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T01:46:27.211890] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mj8kq
[0m[2025-01-19T01:46:28.636446] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 01:46:25 : fd73dcea6c490b3334eed1020315bad4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T01:46:28.636502] [FLK_MGR] Running jobs: ['fd73dcea6c490b3334eed1020315bad4']
[0m[2025-01-19T01:46:28.636510] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T01:46:28.636521] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T01:50:28.659635] [SCALING] Scaling started.
[0m[2025-01-19T01:50:28.659685] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T01:50:28.672407] [SCALING] Scaling finished.
[0m[2025-01-19T01:50:28.672447] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:50:28.690589] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:50:28.706892] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T01:50:28.728866] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 0 replica.
[0m[2025-01-19T01:50:28.746568] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T01:50:28.760425] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T01:50:28.773462] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T01:50:28.786630] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T01:50:28.798973] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T01:50:28.829481] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mj8kq deleted
[0m[2025-01-19T01:50:30.764258] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:50:32.721769] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:50:32.721864] Reloading playbook: application/kafka
[0m[2025-01-19T01:50:38.784210] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T01:51:19.772951] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T01:51:19.773162] [EXPERIMENT] Run 3 completed. Start: 1737251101, End: 1737251479
[0m[2025-01-19T01:51:19.773169] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T01:51:29.774165] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-19T01:51:31.682923] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:51:33.615718] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:51:33.615799] [SCALING] Setting up experiment.


[0m[2025-01-19T01:51:33.615809] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:51:33.620724] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:51:33.635807] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T01:51:33.651032] [SCALING] Statefulset name to scale : flink-32000m-2048
[0m[2025-01-19T01:51:33.666596] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 1 replica.
[0m[2025-01-19T01:52:48.752349] [FLK_MGR] Running job.
[0m[2025-01-19T01:52:48.752398] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T01:52:49.135601] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-pslhd
[0m[2025-01-19T01:52:53.122607] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0ba2801fe183f2ef8288be4898001566

[0m[2025-01-19T01:52:53.122652] [FLK_MGR] Running job id: 0ba2801fe183f2ef8288be4898001566
[0m[2025-01-19T01:52:53.122660] [FLK_MGR] Getting job info.
[0m[2025-01-19T01:52:53.140357] [FLK_MGR] Job plan response: {"plan":{"jid":"0ba2801fe183f2ef8288be4898001566","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T01:52:53.140494] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T01:52:53.514465] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-pslhd
[0m[2025-01-19T01:52:54.957789] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 01:52:52 : 0ba2801fe183f2ef8288be4898001566 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T01:52:54.957857] [FLK_MGR] Running jobs: ['0ba2801fe183f2ef8288be4898001566']
[0m[2025-01-19T01:52:54.957865] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T01:52:54.957877] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T01:56:54.980982] [SCALING] Scaling started.
[0m[2025-01-19T01:56:54.981113] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T01:56:54.993494] [SCALING] Scaling finished.
[0m[2025-01-19T01:56:54.993519] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:56:55.015995] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:56:55.031602] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T01:56:55.056688] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 0 replica.
[0m[2025-01-19T01:56:55.071741] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T01:56:55.085885] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T01:56:55.100098] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T01:56:55.112990] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T01:56:55.127882] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T01:56:55.155925] [POD_MGR] Pod flink-jobmanager-7d7c784b74-pslhd deleted
[0m[2025-01-19T01:56:57.120326] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:56:59.017775] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T01:56:59.017849] Reloading playbook: application/kafka
[0m[2025-01-19T01:57:04.924185] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T01:57:45.954356] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T01:57:45.954606] [EXPERIMENT] Run 4 completed. Start: 1737251489, End: 1737251865
[0m[2025-01-19T01:57:45.954612] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T01:57:55.955702] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-19T01:57:57.855844] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:57:59.789600] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T01:57:59.789682] [SCALING] Setting up experiment.


[0m[2025-01-19T01:57:59.789693] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T01:57:59.795110] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T01:57:59.810311] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T01:57:59.827120] [SCALING] Statefulset name to scale : flink-32000m-2048
[0m[2025-01-19T01:57:59.838543] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 1 replica.
[0m[2025-01-19T01:59:14.929522] [FLK_MGR] Running job.
[0m[2025-01-19T01:59:14.929564] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T01:59:15.312703] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-mzb9s
[0m[2025-01-19T01:59:19.440930] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9f2c87b1c89c64c54477d0a114128260

[0m[2025-01-19T01:59:19.440985] [FLK_MGR] Running job id: 9f2c87b1c89c64c54477d0a114128260
[0m[2025-01-19T01:59:19.440994] [FLK_MGR] Getting job info.
[0m[2025-01-19T01:59:19.458322] [FLK_MGR] Job plan response: {"plan":{"jid":"9f2c87b1c89c64c54477d0a114128260","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T01:59:19.458457] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T01:59:19.844457] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-mzb9s
[0m[2025-01-19T01:59:21.280228] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 01:59:18 : 9f2c87b1c89c64c54477d0a114128260 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T01:59:21.280297] [FLK_MGR] Running jobs: ['9f2c87b1c89c64c54477d0a114128260']
[0m[2025-01-19T01:59:21.280306] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T01:59:21.280320] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T02:03:21.303510] [SCALING] Scaling started.
[0m[2025-01-19T02:03:21.303619] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T02:03:21.318595] [SCALING] Scaling finished.
[0m[2025-01-19T02:03:21.318636] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:03:21.338317] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:03:21.355974] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T02:03:21.376155] [STS_MGR] StatefulSet flink-32000m-2048 scaled to 0 replica.
[0m[2025-01-19T02:03:21.390960] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T02:03:21.404953] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T02:03:21.418661] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T02:03:21.431098] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T02:03:21.444313] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T02:03:21.473324] [POD_MGR] Pod flink-jobmanager-7d7c784b74-mzb9s deleted
[0m[2025-01-19T02:03:23.379791] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:03:25.323396] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:03:25.323478] Reloading playbook: application/kafka
[0m[2025-01-19T02:03:31.344261] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T02:04:12.362608] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T02:04:12.362864] [EXPERIMENT] Run 5 completed. Start: 1737251875, End: 1737252252
[0m[2025-01-19T02:04:12.362872] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T02:04:24.644118] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-19T02:04:24.644212] [RESOURCE_E] Running experiment with 32000m cores and 4096 memory.
[0m[2025-01-19T02:04:31.899090] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-19T02:04:31.899187] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-19T02:04:33.806740] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:04:35.701615] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:04:35.701702] [SCALING] Setting up experiment.


[0m[2025-01-19T02:04:35.701713] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:04:35.707636] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:04:35.724021] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T02:04:35.741000] [SCALING] Statefulset name to scale : flink-32000m-4096
[0m[2025-01-19T02:04:35.752650] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 1 replica.
[0m[2025-01-19T02:05:50.846284] [FLK_MGR] Running job.
[0m[2025-01-19T02:05:50.846328] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T02:05:51.228779] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-7cflh
[0m[2025-01-19T02:05:55.306324] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 4e3dad993eee8fc076e23dd8b9eded83

[0m[2025-01-19T02:05:55.306384] [FLK_MGR] Running job id: 4e3dad993eee8fc076e23dd8b9eded83
[0m[2025-01-19T02:05:55.306393] [FLK_MGR] Getting job info.
[0m[2025-01-19T02:05:55.324490] [FLK_MGR] Job plan response: {"plan":{"jid":"4e3dad993eee8fc076e23dd8b9eded83","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T02:05:55.324643] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T02:05:55.716489] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-7cflh
[0m[2025-01-19T02:05:57.181525] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 02:05:54 : 4e3dad993eee8fc076e23dd8b9eded83 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T02:05:57.181620] [FLK_MGR] Running jobs: ['4e3dad993eee8fc076e23dd8b9eded83']
[0m[2025-01-19T02:05:57.181630] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T02:05:57.181653] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T02:09:57.205527] [SCALING] Scaling started.
[0m[2025-01-19T02:09:57.205623] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T02:09:57.227236] [SCALING] Scaling finished.
[0m[2025-01-19T02:09:57.227269] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:09:57.246004] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:09:57.262434] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T02:09:57.290771] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 0 replica.
[0m[2025-01-19T02:09:57.317396] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T02:09:57.331559] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T02:09:57.344985] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T02:09:57.358684] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T02:09:57.378196] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T02:09:57.408621] [POD_MGR] Pod flink-jobmanager-7d7c784b74-7cflh deleted
[0m[2025-01-19T02:09:59.310700] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:10:01.210927] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:10:01.211006] Reloading playbook: application/kafka
[0m[2025-01-19T02:10:07.218355] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T02:10:48.200400] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T02:10:48.200648] [EXPERIMENT] Run 1 completed. Start: 1737252271, End: 1737252648
[0m[2025-01-19T02:10:48.200655] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T02:10:58.201651] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-19T02:11:00.099504] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:11:02.023934] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:11:02.024034] [SCALING] Setting up experiment.


[0m[2025-01-19T02:11:02.024045] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:11:02.029582] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:11:02.046214] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T02:11:02.061480] [SCALING] Statefulset name to scale : flink-32000m-4096
[0m[2025-01-19T02:11:02.072094] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 1 replica.
[0m[2025-01-19T02:12:17.158017] [FLK_MGR] Running job.
[0m[2025-01-19T02:12:17.158057] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T02:12:17.549853] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-ktqn7
[0m[2025-01-19T02:12:21.579483] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID d43d9447368b8fe754e1192cce1f3b0e

[0m[2025-01-19T02:12:21.579553] [FLK_MGR] Running job id: d43d9447368b8fe754e1192cce1f3b0e
[0m[2025-01-19T02:12:21.579571] [FLK_MGR] Getting job info.
[0m[2025-01-19T02:12:21.598745] [FLK_MGR] Job plan response: {"plan":{"jid":"d43d9447368b8fe754e1192cce1f3b0e","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T02:12:21.598895] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T02:12:21.978160] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-ktqn7
[0m[2025-01-19T02:12:23.425879] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 02:12:20 : d43d9447368b8fe754e1192cce1f3b0e : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T02:12:23.425998] [FLK_MGR] Running jobs: ['d43d9447368b8fe754e1192cce1f3b0e']
[0m[2025-01-19T02:12:23.426008] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T02:12:23.426030] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T02:16:23.449090] [SCALING] Scaling started.
[0m[2025-01-19T02:16:23.449209] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T02:16:23.462366] [SCALING] Scaling finished.
[0m[2025-01-19T02:16:23.462387] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:16:23.494384] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:16:23.516097] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T02:16:23.537286] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 0 replica.
[0m[2025-01-19T02:16:23.551298] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T02:16:23.565698] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T02:16:23.578747] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T02:16:23.591841] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T02:16:23.605338] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T02:16:23.633472] [POD_MGR] Pod flink-jobmanager-7d7c784b74-ktqn7 deleted
[0m[2025-01-19T02:16:25.529884] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:16:27.518168] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:16:27.518243] Reloading playbook: application/kafka
[0m[2025-01-19T02:16:33.507401] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T02:17:14.535334] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T02:17:14.535609] [EXPERIMENT] Run 2 completed. Start: 1737252658, End: 1737253034
[0m[2025-01-19T02:17:14.535616] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T02:17:24.536629] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-19T02:17:26.475920] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:17:28.411886] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:17:28.411970] [SCALING] Setting up experiment.


[0m[2025-01-19T02:17:28.411981] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:17:28.417407] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:17:28.433979] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T02:17:28.450171] [SCALING] Statefulset name to scale : flink-32000m-4096
[0m[2025-01-19T02:17:28.460630] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 1 replica.
[0m[2025-01-19T02:18:43.551286] [FLK_MGR] Running job.
[0m[2025-01-19T02:18:43.551332] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T02:18:43.942887] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-57lkh
[0m[2025-01-19T02:18:47.974499] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9b6c2c31c00ea38e552dbde35514c79b

[0m[2025-01-19T02:18:47.974592] [FLK_MGR] Running job id: 9b6c2c31c00ea38e552dbde35514c79b
[0m[2025-01-19T02:18:47.974606] [FLK_MGR] Getting job info.
[0m[2025-01-19T02:18:47.994360] [FLK_MGR] Job plan response: {"plan":{"jid":"9b6c2c31c00ea38e552dbde35514c79b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T02:18:47.994565] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T02:18:48.380013] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-57lkh
[0m[2025-01-19T02:18:49.809226] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 02:18:47 : 9b6c2c31c00ea38e552dbde35514c79b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T02:18:49.809314] [FLK_MGR] Running jobs: ['9b6c2c31c00ea38e552dbde35514c79b']
[0m[2025-01-19T02:18:49.809324] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T02:18:49.809347] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T02:22:49.834408] [SCALING] Scaling started.
[0m[2025-01-19T02:22:49.834534] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T02:22:49.851698] [SCALING] Scaling finished.
[0m[2025-01-19T02:22:49.851743] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:22:49.869844] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:22:49.888735] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T02:22:49.912066] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 0 replica.
[0m[2025-01-19T02:22:49.928127] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T02:22:49.942024] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T02:22:49.954857] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T02:22:49.967149] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T02:22:49.981531] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T02:22:50.008945] [POD_MGR] Pod flink-jobmanager-7d7c784b74-57lkh deleted
[0m[2025-01-19T02:22:51.918628] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:22:53.955074] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:22:53.955170] Reloading playbook: application/kafka
[0m[2025-01-19T02:22:59.905683] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T02:23:40.927006] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T02:23:40.927289] [EXPERIMENT] Run 3 completed. Start: 1737253044, End: 1737253420
[0m[2025-01-19T02:23:40.927296] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T02:23:50.928317] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-19T02:23:52.835825] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:23:54.753762] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:23:54.753845] [SCALING] Setting up experiment.


[0m[2025-01-19T02:23:54.753856] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:23:54.759463] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:23:54.774903] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T02:23:54.794312] [SCALING] Statefulset name to scale : flink-32000m-4096
[0m[2025-01-19T02:23:54.803931] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 1 replica.
[0m[2025-01-19T02:25:09.894490] [FLK_MGR] Running job.
[0m[2025-01-19T02:25:09.894546] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T02:25:11.854749] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-8b6b4
[0m[2025-01-19T02:25:15.932902] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fbbcd248d9447f2dfd64f6e1afbc119c

[0m[2025-01-19T02:25:15.932945] [FLK_MGR] Running job id: fbbcd248d9447f2dfd64f6e1afbc119c
[0m[2025-01-19T02:25:15.932953] [FLK_MGR] Getting job info.
[0m[2025-01-19T02:25:15.952012] [FLK_MGR] Job plan response: {"plan":{"jid":"fbbcd248d9447f2dfd64f6e1afbc119c","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T02:25:15.952154] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T02:25:16.328595] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-8b6b4
[0m[2025-01-19T02:25:17.772998] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 02:25:14 : fbbcd248d9447f2dfd64f6e1afbc119c : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T02:25:17.773054] [FLK_MGR] Running jobs: ['fbbcd248d9447f2dfd64f6e1afbc119c']
[0m[2025-01-19T02:25:17.773065] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T02:25:17.773088] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T02:29:17.797559] [SCALING] Scaling started.
[0m[2025-01-19T02:29:17.797649] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T02:29:17.811453] [SCALING] Scaling finished.
[0m[2025-01-19T02:29:17.811483] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:29:17.828428] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:29:17.844915] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T02:29:17.866795] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 0 replica.
[0m[2025-01-19T02:29:17.881283] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T02:29:17.894476] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T02:29:17.908439] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T02:29:17.920582] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T02:29:17.936166] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T02:29:17.963348] [POD_MGR] Pod flink-jobmanager-7d7c784b74-8b6b4 deleted
[0m[2025-01-19T02:29:19.891529] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:29:21.828092] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:29:21.828167] Reloading playbook: application/kafka
[0m[2025-01-19T02:29:27.810255] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T02:30:08.772284] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T02:30:08.772727] [EXPERIMENT] Run 4 completed. Start: 1737253430, End: 1737253808
[0m[2025-01-19T02:30:08.772736] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T02:30:18.773810] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-19T02:30:20.698778] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:30:22.628866] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:30:22.628944] [SCALING] Setting up experiment.


[0m[2025-01-19T02:30:22.628955] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:30:22.634391] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:30:22.649953] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T02:30:22.666957] [SCALING] Statefulset name to scale : flink-32000m-4096
[0m[2025-01-19T02:30:22.678264] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 1 replica.
[0m[2025-01-19T02:31:37.764939] [FLK_MGR] Running job.
[0m[2025-01-19T02:31:37.764980] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T02:31:38.168910] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-cwrdk
[0m[2025-01-19T02:31:42.237637] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9940da301acb02d218e3bf7cebe4df60

[0m[2025-01-19T02:31:42.237695] [FLK_MGR] Running job id: 9940da301acb02d218e3bf7cebe4df60
[0m[2025-01-19T02:31:42.237704] [FLK_MGR] Getting job info.
[0m[2025-01-19T02:31:42.254188] [FLK_MGR] Job plan response: {"plan":{"jid":"9940da301acb02d218e3bf7cebe4df60","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T02:31:42.254347] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T02:31:42.652373] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-cwrdk
[0m[2025-01-19T02:31:44.098969] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 02:31:41 : 9940da301acb02d218e3bf7cebe4df60 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T02:31:44.099055] [FLK_MGR] Running jobs: ['9940da301acb02d218e3bf7cebe4df60']
[0m[2025-01-19T02:31:44.099062] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T02:31:44.099076] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T02:35:44.122597] [SCALING] Scaling started.
[0m[2025-01-19T02:35:44.122718] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T02:35:44.135859] [SCALING] Scaling finished.
[0m[2025-01-19T02:35:44.135884] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:35:44.152758] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:35:44.171771] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T02:35:44.194239] [STS_MGR] StatefulSet flink-32000m-4096 scaled to 0 replica.
[0m[2025-01-19T02:35:44.207957] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T02:35:44.221447] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T02:35:44.234626] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T02:35:44.246969] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T02:35:44.259100] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T02:35:44.294980] [POD_MGR] Pod flink-jobmanager-7d7c784b74-cwrdk deleted
[0m[2025-01-19T02:35:46.262165] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:35:48.199354] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:35:48.199427] Reloading playbook: application/kafka
[0m[2025-01-19T02:35:54.168683] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T02:36:35.134451] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T02:36:35.134680] [EXPERIMENT] Run 5 completed. Start: 1737253818, End: 1737254195
[0m[2025-01-19T02:36:35.134686] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T02:36:47.382897] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-19T02:36:47.383000] [RESOURCE_E] Running experiment with 32000m cores and 8192 memory.
[0m[2025-01-19T02:36:54.701278] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-19T02:36:54.701464] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-19T02:36:56.631020] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:36:58.591343] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:36:58.591419] [SCALING] Setting up experiment.


[0m[2025-01-19T02:36:58.591429] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:36:58.597165] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:36:58.613557] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T02:36:58.630914] [SCALING] Statefulset name to scale : flink-32000m-8192
[0m[2025-01-19T02:36:58.641054] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 1 replica.
[0m[2025-01-19T02:38:13.726726] [FLK_MGR] Running job.
[0m[2025-01-19T02:38:13.726821] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T02:38:14.111877] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-s9qkw
[0m[2025-01-19T02:38:18.208998] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 0f0c73c6df428b0f325314272eaa189e

[0m[2025-01-19T02:38:18.209055] [FLK_MGR] Running job id: 0f0c73c6df428b0f325314272eaa189e
[0m[2025-01-19T02:38:18.209068] [FLK_MGR] Getting job info.
[0m[2025-01-19T02:38:18.225558] [FLK_MGR] Job plan response: {"plan":{"jid":"0f0c73c6df428b0f325314272eaa189e","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T02:38:18.225760] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T02:38:18.617554] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-s9qkw
[0m[2025-01-19T02:38:20.059095] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 02:38:17 : 0f0c73c6df428b0f325314272eaa189e : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T02:38:20.059153] [FLK_MGR] Running jobs: ['0f0c73c6df428b0f325314272eaa189e']
[0m[2025-01-19T02:38:20.059161] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T02:38:20.059173] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T02:42:20.081954] [SCALING] Scaling started.
[0m[2025-01-19T02:42:20.082067] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T02:42:20.095319] [SCALING] Scaling finished.
[0m[2025-01-19T02:42:20.095343] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:42:20.114296] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:42:20.133353] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T02:42:20.155999] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 0 replica.
[0m[2025-01-19T02:42:20.171498] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T02:42:20.184441] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T02:42:20.197986] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T02:42:20.210534] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T02:42:20.222598] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T02:42:20.247519] [POD_MGR] Pod flink-jobmanager-7d7c784b74-s9qkw deleted
[0m[2025-01-19T02:42:22.212762] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:42:24.133760] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:42:24.133853] Reloading playbook: application/kafka
[0m[2025-01-19T02:42:30.143511] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T02:43:11.128085] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T02:43:11.128379] [EXPERIMENT] Run 1 completed. Start: 1737254214, End: 1737254591
[0m[2025-01-19T02:43:11.128386] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T02:43:21.129347] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-19T02:43:23.079092] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:43:24.979541] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:43:24.979633] [SCALING] Setting up experiment.


[0m[2025-01-19T02:43:24.979644] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:43:24.985341] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:43:25.001659] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T02:43:25.019257] [SCALING] Statefulset name to scale : flink-32000m-8192
[0m[2025-01-19T02:43:25.030936] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 1 replica.
[0m[2025-01-19T02:44:40.121555] [FLK_MGR] Running job.
[0m[2025-01-19T02:44:40.121626] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T02:44:40.510883] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-xq2kc
[0m[2025-01-19T02:44:44.625871] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 629949d4d5c753a8a4e6142b46f7af21

[0m[2025-01-19T02:44:44.625923] [FLK_MGR] Running job id: 629949d4d5c753a8a4e6142b46f7af21
[0m[2025-01-19T02:44:44.625931] [FLK_MGR] Getting job info.
[0m[2025-01-19T02:44:44.643828] [FLK_MGR] Job plan response: {"plan":{"jid":"629949d4d5c753a8a4e6142b46f7af21","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T02:44:44.643986] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T02:44:45.016168] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-xq2kc
[0m[2025-01-19T02:44:46.447442] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 02:44:43 : 629949d4d5c753a8a4e6142b46f7af21 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T02:44:46.447513] [FLK_MGR] Running jobs: ['629949d4d5c753a8a4e6142b46f7af21']
[0m[2025-01-19T02:44:46.447520] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T02:44:46.447532] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T02:48:46.470524] [SCALING] Scaling started.
[0m[2025-01-19T02:48:46.470637] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T02:48:46.483311] [SCALING] Scaling finished.
[0m[2025-01-19T02:48:46.483336] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:48:46.502642] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:48:46.520497] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T02:48:46.541732] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 0 replica.
[0m[2025-01-19T02:48:46.557080] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T02:48:46.569320] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T02:48:46.581793] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T02:48:46.596162] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T02:48:46.608959] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T02:48:46.636597] [POD_MGR] Pod flink-jobmanager-7d7c784b74-xq2kc deleted
[0m[2025-01-19T02:48:48.544525] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:48:50.514781] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:48:50.514863] Reloading playbook: application/kafka
[0m[2025-01-19T02:48:56.479329] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T02:49:37.449238] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T02:49:37.449483] [EXPERIMENT] Run 2 completed. Start: 1737254601, End: 1737254977
[0m[2025-01-19T02:49:37.449490] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T02:49:47.450451] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-19T02:49:49.353292] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:49:51.284493] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:49:51.284576] [SCALING] Setting up experiment.


[0m[2025-01-19T02:49:51.284601] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:49:51.291362] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:49:51.307144] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T02:49:51.323724] [SCALING] Statefulset name to scale : flink-32000m-8192
[0m[2025-01-19T02:49:51.334720] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 1 replica.
[0m[2025-01-19T02:51:06.415485] [FLK_MGR] Running job.
[0m[2025-01-19T02:51:06.415556] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T02:51:06.823435] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-pqm5k
[0m[2025-01-19T02:51:10.901606] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 3103fed56b6abe7ae9745be3b5199373

[0m[2025-01-19T02:51:10.901664] [FLK_MGR] Running job id: 3103fed56b6abe7ae9745be3b5199373
[0m[2025-01-19T02:51:10.901675] [FLK_MGR] Getting job info.
[0m[2025-01-19T02:51:10.918955] [FLK_MGR] Job plan response: {"plan":{"jid":"3103fed56b6abe7ae9745be3b5199373","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T02:51:10.919095] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T02:51:11.301355] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-pqm5k
[0m[2025-01-19T02:51:12.758427] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 02:51:09 : 3103fed56b6abe7ae9745be3b5199373 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T02:51:12.758488] [FLK_MGR] Running jobs: ['3103fed56b6abe7ae9745be3b5199373']
[0m[2025-01-19T02:51:12.758495] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T02:51:12.758508] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T02:55:12.781803] [SCALING] Scaling started.
[0m[2025-01-19T02:55:12.781919] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T02:55:12.795035] [SCALING] Scaling finished.
[0m[2025-01-19T02:55:12.795060] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:55:12.812626] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:55:12.828611] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T02:55:12.848845] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 0 replica.
[0m[2025-01-19T02:55:12.862698] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T02:55:12.877138] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T02:55:12.890558] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T02:55:12.903525] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T02:55:12.916561] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T02:55:12.940715] [POD_MGR] Pod flink-jobmanager-7d7c784b74-pqm5k deleted
[0m[2025-01-19T02:55:14.847866] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:55:16.825600] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T02:55:16.825686] Reloading playbook: application/kafka
[0m[2025-01-19T02:55:22.983426] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T02:56:03.915255] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T02:56:03.915559] [EXPERIMENT] Run 3 completed. Start: 1737254987, End: 1737255363
[0m[2025-01-19T02:56:03.915567] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T02:56:13.916514] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-19T02:56:15.831435] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:56:17.794793] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T02:56:17.794877] [SCALING] Setting up experiment.


[0m[2025-01-19T02:56:17.794891] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T02:56:17.800974] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T02:56:17.817718] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T02:56:17.834429] [SCALING] Statefulset name to scale : flink-32000m-8192
[0m[2025-01-19T02:56:17.845199] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 1 replica.
[0m[2025-01-19T02:57:32.935836] [FLK_MGR] Running job.
[0m[2025-01-19T02:57:32.935934] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T02:57:33.330648] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-cvdlc
[0m[2025-01-19T02:57:37.369495] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 1ba9b41efb761fa805f7a990f5f539b4

[0m[2025-01-19T02:57:37.369550] [FLK_MGR] Running job id: 1ba9b41efb761fa805f7a990f5f539b4
[0m[2025-01-19T02:57:37.369559] [FLK_MGR] Getting job info.
[0m[2025-01-19T02:57:37.388376] [FLK_MGR] Job plan response: {"plan":{"jid":"1ba9b41efb761fa805f7a990f5f539b4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T02:57:37.388532] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T02:57:37.767752] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-cvdlc
[0m[2025-01-19T02:57:39.193741] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 02:57:36 : 1ba9b41efb761fa805f7a990f5f539b4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T02:57:39.193832] [FLK_MGR] Running jobs: ['1ba9b41efb761fa805f7a990f5f539b4']
[0m[2025-01-19T02:57:39.193840] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T02:57:39.193867] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T03:01:39.217911] [SCALING] Scaling started.
[0m[2025-01-19T03:01:39.218085] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T03:01:39.237521] [SCALING] Scaling finished.
[0m[2025-01-19T03:01:39.237562] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:01:39.256499] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:01:39.274384] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T03:01:39.298445] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 0 replica.
[0m[2025-01-19T03:01:39.314475] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T03:01:39.328444] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T03:01:39.342704] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T03:01:39.356126] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T03:01:39.370263] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T03:01:39.404684] [POD_MGR] Pod flink-jobmanager-7d7c784b74-cvdlc deleted
[0m[2025-01-19T03:01:41.305031] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:01:43.200250] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:01:43.200330] Reloading playbook: application/kafka
[0m[2025-01-19T03:01:49.102627] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T03:02:30.082024] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T03:02:30.082252] [EXPERIMENT] Run 4 completed. Start: 1737255373, End: 1737255750
[0m[2025-01-19T03:02:30.082260] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T03:02:40.083338] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-19T03:02:42.019633] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:02:43.924785] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:02:43.924876] [SCALING] Setting up experiment.


[0m[2025-01-19T03:02:43.924887] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:02:43.930534] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:02:43.947214] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T03:02:43.964777] [SCALING] Statefulset name to scale : flink-32000m-8192
[0m[2025-01-19T03:02:43.976167] [STS_MGR] StatefulSet flink-32000m-8192 scaled to 1 replica.
[0m[2025-01-19T03:03:59.059235] [FLK_MGR] Running job.
[0m[2025-01-19T03:03:59.059276] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T03:04:00.920654] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-nrx7m
[0;31m[2025-01-19T03:04:00.926709] [ERROR] [POD_MGR] Error executing command on pod flink-jobmanager-7d7c784b74-nrx7m: (0)
Reason: Handshake status 400 Bad Request -+-+- {'audit-id': 'dd457508-522c-44ca-a530-dfc158a055c9', 'cache-control': 'no-cache, private', 'content-type': 'application/json', 'date': 'Sun, 19 Jan 2025 03:04:00 GMT', 'content-length': '182'} -+-+- b'{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"pod flink-jobmanager-7d7c784b74-nrx7m does not have a host assigned","reason":"BadRequest","code":400}\n'
[0m
[0m[2025-01-19T03:04:00.938637] [FLK_MGR] Job run response: None
[0;31m[2025-01-19T03:04:00.938683] [ERROR] [FLK_MGR] Error while running job: expected string or bytes-like object, got 'NoneType'[0m
[0;31m[2025-01-19T03:04:00.938693] [ERROR] [SCALING] Error scaling first taskmanager and starting job[0m
[0;31m[2025-01-19T03:04:00.938700] [ERROR] [SCALING] Error setting up experiment.[0m
[0m[2025-01-19T03:04:00.938717] [EXPERIMENT] Exiting run 5
[0m[2025-01-19T03:04:03.210013] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-19T03:04:03.210098] [RESOURCE_E] Running experiment with 32000m cores and 16384 memory.
[0m[2025-01-19T03:04:10.496315] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-19T03:04:10.496398] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-19T03:04:12.396453] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:04:14.282186] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:04:14.282270] [SCALING] Setting up experiment.


[0m[2025-01-19T03:04:14.282381] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:04:14.303776] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:04:14.318256] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T03:04:14.334065] [SCALING] Statefulset name to scale : flink-32000m-16384
[0m[2025-01-19T03:04:14.344753] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 1 replica.
[0m[2025-01-19T03:05:29.427843] [FLK_MGR] Running job.
[0m[2025-01-19T03:05:29.427943] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T03:05:29.814112] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-nrx7m
[0m[2025-01-19T03:05:33.937785] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 435dc3762a1a3a9adf6b523286d155ee

[0m[2025-01-19T03:05:33.937833] [FLK_MGR] Running job id: 435dc3762a1a3a9adf6b523286d155ee
[0m[2025-01-19T03:05:33.937841] [FLK_MGR] Getting job info.
[0m[2025-01-19T03:05:33.954139] [FLK_MGR] Job plan response: {"plan":{"jid":"435dc3762a1a3a9adf6b523286d155ee","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T03:05:33.954279] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T03:05:34.337416] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-nrx7m
[0m[2025-01-19T03:05:35.740879] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 03:05:32 : 435dc3762a1a3a9adf6b523286d155ee : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T03:05:35.740946] [FLK_MGR] Running jobs: ['435dc3762a1a3a9adf6b523286d155ee']
[0m[2025-01-19T03:05:35.740954] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T03:05:35.740969] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T03:09:35.764621] [SCALING] Scaling started.
[0m[2025-01-19T03:09:35.764729] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T03:09:35.778072] [SCALING] Scaling finished.
[0m[2025-01-19T03:09:35.778114] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:09:35.797450] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:09:35.815083] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T03:09:35.834758] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 0 replica.
[0m[2025-01-19T03:09:35.849912] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T03:09:35.863565] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T03:09:35.876858] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T03:09:35.889623] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T03:09:35.902624] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T03:09:35.934580] [POD_MGR] Pod flink-jobmanager-7d7c784b74-nrx7m deleted
[0m[2025-01-19T03:09:37.839592] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:09:39.766406] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:09:39.766474] Reloading playbook: application/kafka
[0m[2025-01-19T03:09:45.813203] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T03:10:26.891357] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T03:10:26.892182] [EXPERIMENT] Run 1 completed. Start: 1737255850, End: 1737256226
[0m[2025-01-19T03:10:26.892210] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T03:10:36.893248] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-19T03:10:38.793417] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:10:40.746205] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:10:40.746298] [SCALING] Setting up experiment.


[0m[2025-01-19T03:10:40.746309] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:10:40.752039] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:10:40.769439] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T03:10:40.788782] [SCALING] Statefulset name to scale : flink-32000m-16384
[0m[2025-01-19T03:10:40.802138] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 1 replica.
[0m[2025-01-19T03:11:55.889978] [FLK_MGR] Running job.
[0m[2025-01-19T03:11:55.890022] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T03:11:56.274161] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-7wsjk
[0m[2025-01-19T03:12:00.406372] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 62b041a1f42ed2d5a17b4aa356d897be

[0m[2025-01-19T03:12:00.406437] [FLK_MGR] Running job id: 62b041a1f42ed2d5a17b4aa356d897be
[0m[2025-01-19T03:12:00.406448] [FLK_MGR] Getting job info.
[0m[2025-01-19T03:12:00.427586] [FLK_MGR] Job plan response: {"plan":{"jid":"62b041a1f42ed2d5a17b4aa356d897be","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T03:12:00.427741] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T03:12:00.814462] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-7wsjk
[0m[2025-01-19T03:12:02.242594] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 03:11:59 : 62b041a1f42ed2d5a17b4aa356d897be : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T03:12:02.242653] [FLK_MGR] Running jobs: ['62b041a1f42ed2d5a17b4aa356d897be']
[0m[2025-01-19T03:12:02.242661] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T03:12:02.242675] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T03:16:02.265752] [SCALING] Scaling started.
[0m[2025-01-19T03:16:02.265811] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T03:16:02.278582] [SCALING] Scaling finished.
[0m[2025-01-19T03:16:02.278614] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:16:02.298115] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:16:02.315666] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T03:16:02.338972] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 0 replica.
[0m[2025-01-19T03:16:02.355331] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T03:16:02.368823] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T03:16:02.382539] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T03:16:02.397188] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T03:16:02.409929] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T03:16:02.432453] [POD_MGR] Pod flink-jobmanager-7d7c784b74-7wsjk deleted
[0m[2025-01-19T03:16:04.364616] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:16:06.401212] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:16:06.401354] Reloading playbook: application/kafka
[0m[2025-01-19T03:16:12.471980] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T03:16:53.449609] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T03:16:53.449847] [EXPERIMENT] Run 2 completed. Start: 1737256236, End: 1737256613
[0m[2025-01-19T03:16:53.449855] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T03:17:03.450868] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-19T03:17:05.356039] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:17:07.293456] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:17:07.293544] [SCALING] Setting up experiment.


[0m[2025-01-19T03:17:07.293554] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:17:07.299071] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:17:07.315267] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T03:17:07.332947] [SCALING] Statefulset name to scale : flink-32000m-16384
[0m[2025-01-19T03:17:07.343398] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 1 replica.
[0m[2025-01-19T03:18:22.425569] [FLK_MGR] Running job.
[0m[2025-01-19T03:18:22.425611] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T03:18:22.804178] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-84525
[0m[2025-01-19T03:18:26.901274] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 1c345481f913188736330616d3e6d44b

[0m[2025-01-19T03:18:26.901328] [FLK_MGR] Running job id: 1c345481f913188736330616d3e6d44b
[0m[2025-01-19T03:18:26.901335] [FLK_MGR] Getting job info.
[0m[2025-01-19T03:18:26.919166] [FLK_MGR] Job plan response: {"plan":{"jid":"1c345481f913188736330616d3e6d44b","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T03:18:26.919382] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T03:18:27.314320] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-84525
[0m[2025-01-19T03:18:28.754704] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 03:18:25 : 1c345481f913188736330616d3e6d44b : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T03:18:28.754773] [FLK_MGR] Running jobs: ['1c345481f913188736330616d3e6d44b']
[0m[2025-01-19T03:18:28.754780] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T03:18:28.754793] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T03:22:28.778707] [SCALING] Scaling started.
[0m[2025-01-19T03:22:28.778822] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T03:22:28.796164] [SCALING] Scaling finished.
[0m[2025-01-19T03:22:28.796190] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:22:28.815731] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:22:28.834591] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T03:22:28.855605] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 0 replica.
[0m[2025-01-19T03:22:28.872301] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T03:22:28.887411] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T03:22:28.901927] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T03:22:28.914840] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T03:22:28.927242] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T03:22:28.947598] [POD_MGR] Pod flink-jobmanager-7d7c784b74-84525 deleted
[0m[2025-01-19T03:22:30.868496] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:22:32.855187] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:22:32.855267] Reloading playbook: application/kafka
[0m[2025-01-19T03:22:38.804184] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T03:23:19.810563] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T03:23:19.810843] [EXPERIMENT] Run 3 completed. Start: 1737256623, End: 1737256999
[0m[2025-01-19T03:23:19.810849] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T03:23:29.811832] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-19T03:23:31.729188] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:23:33.666317] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:23:33.666403] [SCALING] Setting up experiment.


[0m[2025-01-19T03:23:33.666414] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:23:33.672904] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:23:33.689876] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T03:23:33.706559] [SCALING] Statefulset name to scale : flink-32000m-16384
[0m[2025-01-19T03:23:33.717967] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 1 replica.
[0m[2025-01-19T03:24:48.806267] [FLK_MGR] Running job.
[0m[2025-01-19T03:24:48.806313] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T03:24:49.208909] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-tjnbj
[0m[2025-01-19T03:24:53.299647] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 89249c56fa4d544dcc2ccd9e8ff1dde4

[0m[2025-01-19T03:24:53.299705] [FLK_MGR] Running job id: 89249c56fa4d544dcc2ccd9e8ff1dde4
[0m[2025-01-19T03:24:53.299716] [FLK_MGR] Getting job info.
[0m[2025-01-19T03:24:53.316656] [FLK_MGR] Job plan response: {"plan":{"jid":"89249c56fa4d544dcc2ccd9e8ff1dde4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T03:24:53.316808] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T03:24:53.703459] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-tjnbj
[0m[2025-01-19T03:24:55.151196] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 03:24:52 : 89249c56fa4d544dcc2ccd9e8ff1dde4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T03:24:55.151256] [FLK_MGR] Running jobs: ['89249c56fa4d544dcc2ccd9e8ff1dde4']
[0m[2025-01-19T03:24:55.151264] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T03:24:55.151279] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T03:28:55.174741] [SCALING] Scaling started.
[0m[2025-01-19T03:28:55.174859] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T03:28:55.188212] [SCALING] Scaling finished.
[0m[2025-01-19T03:28:55.188256] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:28:55.206616] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:28:55.222392] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T03:28:55.242943] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 0 replica.
[0m[2025-01-19T03:28:55.257108] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T03:28:55.270440] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T03:28:55.284470] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T03:28:55.297415] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T03:28:55.311216] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T03:28:55.332936] [POD_MGR] Pod flink-jobmanager-7d7c784b74-tjnbj deleted
[0m[2025-01-19T03:28:57.267175] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:28:59.243152] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:28:59.243224] Reloading playbook: application/kafka
[0m[2025-01-19T03:29:05.298343] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T03:29:46.373845] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T03:29:46.374104] [EXPERIMENT] Run 4 completed. Start: 1737257009, End: 1737257386
[0m[2025-01-19T03:29:46.374110] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T03:29:56.375093] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-19T03:29:58.311079] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:30:00.237699] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:30:00.237877] [SCALING] Setting up experiment.


[0m[2025-01-19T03:30:00.237889] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:30:00.242903] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:30:00.259076] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T03:30:00.276401] [SCALING] Statefulset name to scale : flink-32000m-16384
[0m[2025-01-19T03:30:00.286938] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 1 replica.
[0m[2025-01-19T03:31:15.373032] [FLK_MGR] Running job.
[0m[2025-01-19T03:31:15.373150] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T03:31:15.755299] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-cn8v5
[0m[2025-01-19T03:31:19.833935] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 621c6baa5218bff2b919d8a765c0c4cf

[0m[2025-01-19T03:31:19.833985] [FLK_MGR] Running job id: 621c6baa5218bff2b919d8a765c0c4cf
[0m[2025-01-19T03:31:19.833991] [FLK_MGR] Getting job info.
[0m[2025-01-19T03:31:19.850944] [FLK_MGR] Job plan response: {"plan":{"jid":"621c6baa5218bff2b919d8a765c0c4cf","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T03:31:19.851082] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T03:31:20.225107] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-cn8v5
[0m[2025-01-19T03:31:21.653221] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 03:31:18 : 621c6baa5218bff2b919d8a765c0c4cf : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T03:31:21.653279] [FLK_MGR] Running jobs: ['621c6baa5218bff2b919d8a765c0c4cf']
[0m[2025-01-19T03:31:21.653287] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T03:31:21.653299] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T03:35:21.676719] [SCALING] Scaling started.
[0m[2025-01-19T03:35:21.676772] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T03:35:21.688771] [SCALING] Scaling finished.
[0m[2025-01-19T03:35:21.688805] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:35:21.706412] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:35:21.721568] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T03:35:21.742057] [STS_MGR] StatefulSet flink-32000m-16384 scaled to 0 replica.
[0m[2025-01-19T03:35:21.757589] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T03:35:21.770708] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T03:35:21.784225] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T03:35:21.797272] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T03:35:21.810230] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T03:35:21.842346] [POD_MGR] Pod flink-jobmanager-7d7c784b74-cn8v5 deleted
[0m[2025-01-19T03:35:23.759466] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:35:25.732560] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:35:25.732647] Reloading playbook: application/kafka
[0m[2025-01-19T03:35:31.807023] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T03:36:12.821744] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T03:36:12.822014] [EXPERIMENT] Run 5 completed. Start: 1737257396, End: 1737257772
[0m[2025-01-19T03:36:12.822022] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T03:36:25.107546] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-19T03:36:25.107629] [RESOURCE_E] Running experiment with 32000m cores and 32768 memory.
[0m[2025-01-19T03:36:32.411862] Playbook /app/playbooks/application/flink.yaml with tag create executed successfully.
[0m[2025-01-19T03:36:32.411955] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-19T03:36:34.296969] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:36:36.189450] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:36:36.189546] [SCALING] Setting up experiment.


[0m[2025-01-19T03:36:36.189557] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:36:36.194914] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:36:36.212266] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T03:36:36.230018] [SCALING] Statefulset name to scale : flink-32000m-32768
[0m[2025-01-19T03:36:36.240958] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 1 replica.
[0m[2025-01-19T03:37:51.325565] [FLK_MGR] Running job.
[0m[2025-01-19T03:37:51.325627] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T03:37:51.711277] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-4xh2x
[0m[2025-01-19T03:37:55.766984] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a23465b13a6195521771aa06124efa45

[0m[2025-01-19T03:37:55.767042] [FLK_MGR] Running job id: a23465b13a6195521771aa06124efa45
[0m[2025-01-19T03:37:55.767052] [FLK_MGR] Getting job info.
[0m[2025-01-19T03:37:55.784542] [FLK_MGR] Job plan response: {"plan":{"jid":"a23465b13a6195521771aa06124efa45","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T03:37:55.784693] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T03:37:56.175425] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-4xh2x
[0m[2025-01-19T03:37:57.608120] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 03:37:54 : a23465b13a6195521771aa06124efa45 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T03:37:57.608178] [FLK_MGR] Running jobs: ['a23465b13a6195521771aa06124efa45']
[0m[2025-01-19T03:37:57.608186] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T03:37:57.608199] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T03:41:57.630576] [SCALING] Scaling started.
[0m[2025-01-19T03:41:57.630680] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T03:41:57.645036] [SCALING] Scaling finished.
[0m[2025-01-19T03:41:57.645156] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:41:57.664405] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:41:57.683435] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T03:41:57.705913] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 0 replica.
[0m[2025-01-19T03:41:57.721771] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T03:41:57.735160] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T03:41:57.748322] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T03:41:57.760888] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T03:41:57.773902] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T03:41:57.808843] [POD_MGR] Pod flink-jobmanager-7d7c784b74-4xh2x deleted
[0m[2025-01-19T03:41:59.731126] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:42:01.731055] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:42:01.731137] Reloading playbook: application/kafka
[0m[2025-01-19T03:42:07.705872] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T03:42:48.705447] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T03:42:48.705763] [EXPERIMENT] Run 1 completed. Start: 1737257792, End: 1737258168
[0m[2025-01-19T03:42:48.705770] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T03:42:58.706789] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-19T03:43:00.622946] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:43:02.544182] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:43:02.544268] [SCALING] Setting up experiment.


[0m[2025-01-19T03:43:02.544278] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:43:02.549856] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:43:02.565891] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T03:43:02.582658] [SCALING] Statefulset name to scale : flink-32000m-32768
[0m[2025-01-19T03:43:02.593938] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 1 replica.
[0m[2025-01-19T03:44:17.680051] [FLK_MGR] Running job.
[0m[2025-01-19T03:44:17.680144] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T03:44:19.520971] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-7lkg4
[0m[2025-01-19T03:44:23.597231] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID af40e692f0e80e8b1875a7b2da972410

[0m[2025-01-19T03:44:23.597274] [FLK_MGR] Running job id: af40e692f0e80e8b1875a7b2da972410
[0m[2025-01-19T03:44:23.597281] [FLK_MGR] Getting job info.
[0m[2025-01-19T03:44:23.612827] [FLK_MGR] Job plan response: {"plan":{"jid":"af40e692f0e80e8b1875a7b2da972410","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T03:44:23.612956] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T03:44:23.993456] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-7lkg4
[0m[2025-01-19T03:44:25.429209] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 03:44:22 : af40e692f0e80e8b1875a7b2da972410 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T03:44:25.429263] [FLK_MGR] Running jobs: ['af40e692f0e80e8b1875a7b2da972410']
[0m[2025-01-19T03:44:25.429272] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T03:44:25.429285] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T03:48:25.451724] [SCALING] Scaling started.
[0m[2025-01-19T03:48:25.451833] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T03:48:25.465496] [SCALING] Scaling finished.
[0m[2025-01-19T03:48:25.465522] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:48:25.486099] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:48:25.503627] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T03:48:25.525014] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 0 replica.
[0m[2025-01-19T03:48:25.541101] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T03:48:25.555578] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T03:48:25.571102] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T03:48:25.584956] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T03:48:25.598570] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T03:48:25.622882] [POD_MGR] Pod flink-jobmanager-7d7c784b74-7lkg4 deleted
[0m[2025-01-19T03:48:27.584970] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:48:29.496364] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:48:29.496448] Reloading playbook: application/kafka
[0m[2025-01-19T03:48:35.527519] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T03:49:16.564939] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T03:49:16.565149] [EXPERIMENT] Run 2 completed. Start: 1737258178, End: 1737258556
[0m[2025-01-19T03:49:16.565157] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T03:49:26.566063] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-19T03:49:28.510213] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:49:30.436281] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:49:30.436475] [SCALING] Setting up experiment.


[0m[2025-01-19T03:49:30.436522] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:49:30.442027] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:49:30.458887] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T03:49:30.474751] [SCALING] Statefulset name to scale : flink-32000m-32768
[0m[2025-01-19T03:49:30.484541] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 1 replica.
[0m[2025-01-19T03:50:45.570115] [FLK_MGR] Running job.
[0m[2025-01-19T03:50:45.570208] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T03:50:45.958837] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-pdj52
[0m[2025-01-19T03:50:50.033382] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 1ddd25ee07a638d6f0188ba581a05926

[0m[2025-01-19T03:50:50.033430] [FLK_MGR] Running job id: 1ddd25ee07a638d6f0188ba581a05926
[0m[2025-01-19T03:50:50.033437] [FLK_MGR] Getting job info.
[0m[2025-01-19T03:50:50.051393] [FLK_MGR] Job plan response: {"plan":{"jid":"1ddd25ee07a638d6f0188ba581a05926","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T03:50:50.051572] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T03:50:50.449236] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-pdj52
[0m[2025-01-19T03:50:51.887779] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 03:50:49 : 1ddd25ee07a638d6f0188ba581a05926 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T03:50:51.887839] [FLK_MGR] Running jobs: ['1ddd25ee07a638d6f0188ba581a05926']
[0m[2025-01-19T03:50:51.887846] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T03:50:51.887859] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T03:54:51.910373] [SCALING] Scaling started.
[0m[2025-01-19T03:54:51.910478] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T03:54:51.924019] [SCALING] Scaling finished.
[0m[2025-01-19T03:54:51.924045] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:54:51.942608] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:54:51.958824] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T03:54:51.979354] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 0 replica.
[0m[2025-01-19T03:54:51.994257] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T03:54:52.009611] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T03:54:52.022813] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T03:54:52.036598] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T03:54:52.049509] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T03:54:52.085983] [POD_MGR] Pod flink-jobmanager-7d7c784b74-pdj52 deleted
[0m[2025-01-19T03:54:54.019473] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:54:55.992109] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T03:54:55.992212] Reloading playbook: application/kafka
[0m[2025-01-19T03:55:02.030606] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T03:55:42.990881] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T03:55:42.991106] [EXPERIMENT] Run 3 completed. Start: 1737258566, End: 1737258942
[0m[2025-01-19T03:55:42.991113] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T03:55:52.992106] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-19T03:55:54.937445] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:55:56.853814] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T03:55:56.853904] [SCALING] Setting up experiment.


[0m[2025-01-19T03:55:56.853915] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T03:55:56.858938] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T03:55:56.875805] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T03:55:56.899247] [SCALING] Statefulset name to scale : flink-32000m-32768
[0m[2025-01-19T03:55:56.912291] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 1 replica.
[0m[2025-01-19T03:57:11.999167] [FLK_MGR] Running job.
[0m[2025-01-19T03:57:11.999260] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T03:57:12.394391] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-jl5zf
[0m[2025-01-19T03:57:16.432320] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 566ac1a610ff24d53ee3c6fa9cabf8bd

[0m[2025-01-19T03:57:16.432380] [FLK_MGR] Running job id: 566ac1a610ff24d53ee3c6fa9cabf8bd
[0m[2025-01-19T03:57:16.432390] [FLK_MGR] Getting job info.
[0m[2025-01-19T03:57:16.450320] [FLK_MGR] Job plan response: {"plan":{"jid":"566ac1a610ff24d53ee3c6fa9cabf8bd","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T03:57:16.450488] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T03:57:16.835378] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-jl5zf
[0m[2025-01-19T03:57:18.286131] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 03:57:15 : 566ac1a610ff24d53ee3c6fa9cabf8bd : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T03:57:18.286189] [FLK_MGR] Running jobs: ['566ac1a610ff24d53ee3c6fa9cabf8bd']
[0m[2025-01-19T03:57:18.286197] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T03:57:18.286210] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T04:01:18.308717] [SCALING] Scaling started.
[0m[2025-01-19T04:01:18.308833] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T04:01:18.324449] [SCALING] Scaling finished.
[0m[2025-01-19T04:01:18.324477] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T04:01:18.343156] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T04:01:18.360910] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T04:01:18.383966] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 0 replica.
[0m[2025-01-19T04:01:18.400889] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T04:01:18.415368] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T04:01:18.428835] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T04:01:18.443016] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T04:01:18.455109] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T04:01:18.476996] [POD_MGR] Pod flink-jobmanager-7d7c784b74-jl5zf deleted
[0m[2025-01-19T04:01:20.412810] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T04:01:22.391938] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T04:01:22.392031] Reloading playbook: application/kafka
[0m[2025-01-19T04:01:28.306380] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T04:02:09.268425] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T04:02:09.268709] [EXPERIMENT] Run 4 completed. Start: 1737258952, End: 1737259329
[0m[2025-01-19T04:02:09.268715] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T04:02:19.269705] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-19T04:02:21.186365] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T04:02:23.123042] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-19T04:02:23.123132] [SCALING] Setting up experiment.


[0m[2025-01-19T04:02:23.123144] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T04:02:23.128826] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T04:02:23.145540] [SCALING] First node: virtual-158-0-2

[0m[2025-01-19T04:02:23.163917] [SCALING] Statefulset name to scale : flink-32000m-32768
[0m[2025-01-19T04:02:23.174558] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 1 replica.
[0m[2025-01-19T04:03:38.262204] [FLK_MGR] Running job.
[0m[2025-01-19T04:03:38.262299] [FLK_MGR] Starting job with 1 parallelism.
[0m[2025-01-19T04:03:38.645854] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 1'] on pod flink-jobmanager-7d7c784b74-c4hjr
[0m[2025-01-19T04:03:42.728079] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 561f46e6c42a74ba566c52a60bf932d9

[0m[2025-01-19T04:03:42.728129] [FLK_MGR] Running job id: 561f46e6c42a74ba566c52a60bf932d9
[0m[2025-01-19T04:03:42.728138] [FLK_MGR] Getting job info.
[0m[2025-01-19T04:03:42.744874] [FLK_MGR] Job plan response: {"plan":{"jid":"561f46e6c42a74ba566c52a60bf932d9","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"FORWARD","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":1,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-19T04:03:42.745010] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-19T04:03:43.117342] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-c4hjr
[0m[2025-01-19T04:03:44.541444] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
19.01.2025 04:03:41 : 561f46e6c42a74ba566c52a60bf932d9 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-19T04:03:44.541511] [FLK_MGR] Running jobs: ['561f46e6c42a74ba566c52a60bf932d9']
[0m[2025-01-19T04:03:44.541520] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-19T04:03:44.541533] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-19T04:07:44.566897] [SCALING] Scaling started.
[0m[2025-01-19T04:07:44.567015] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-19T04:07:44.579384] [SCALING] Scaling finished.
[0m[2025-01-19T04:07:44.579410] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-19T04:07:44.597813] [NODE_MGR] Resetting state labels.
[0m[2025-01-19T04:07:44.614470] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-19T04:07:44.638071] [STS_MGR] StatefulSet flink-32000m-32768 scaled to 0 replica.
[0m[2025-01-19T04:07:44.656258] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-19T04:07:44.671259] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-19T04:07:44.684073] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-19T04:07:44.697747] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-19T04:07:44.712562] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-19T04:07:44.743650] [POD_MGR] Pod flink-jobmanager-7d7c784b74-c4hjr deleted
[0m[2025-01-19T04:07:46.666509] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T04:07:48.707090] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-19T04:07:48.707179] Reloading playbook: application/kafka
[0m[2025-01-19T04:07:54.761901] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-19T04:08:35.759560] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-19T04:08:35.759818] [EXPERIMENT] Run 5 completed. Start: 1737259339, End: 1737259715
[0m[2025-01-19T04:08:35.759825] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-19T04:08:48.032961] Playbook /app/playbooks/application/flink.yaml with tag delete executed successfully.
[0m[2025-01-19T04:08:48.033314] [FSM] Run phase complete, transitioning to finishing.
[0m[2025-01-19T04:08:48.033615] [FSM] Finish phase started.
[0m[2025-01-19T04:08:48.033635] [FSM] State is States.FINISHING
[0m[2025-01-19T04:08:48.033848] FolderManager initialized with base path: /experiment-volume. Date: None
