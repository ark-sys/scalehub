[0m[2025-01-17T08:24:50.978880] [CLIENT] Received payload b'{"command": "START", "configs": "[\\"{\\\\n    \\\\\\"scalehub.inventory\\\\\\": \\\\\\"/app/conf/hosts\\\\\\",\\\\n    \\\\\\"scalehub.playbook\\\\\\": \\\\\\"/app/playbooks\\\\\\",\\\\n    \\\\\\"scalehub.experiments\\\\\\": \\\\\\"/app/experiments-data\\\\\\",\\\\n    \\\\\\"scalehub.debug_level\\\\\\": \\\\\\"3\\\\\\",\\\\n    \\\\\\"experiment.chaos.enable\\\\\\": \\\\\\"false\\\\\\",\\\\n    \\\\\\"experiment.chaos.affected_nodes_percentage\\\\\\": \\\\\\"70\\\\\\",\\\\n    \\\\\\"experiment.chaos.delay_latency_ms\\\\\\": \\\\\\"50\\\\\\",\\\\n    \\\\\\"experiment.chaos.delay_jitter_ms\\\\\\": \\\\\\"0\\\\\\",\\\\n    \\\\\\"experiment.chaos.delay_correlation\\\\\\": \\\\\\"0\\\\\\",\\\\n    \\\\\\"experiment.chaos.bandwidth_rate_mbps\\\\\\": \\\\\\"100\\\\\\",\\\\n    \\\\\\"experiment.chaos.bandwidth_limit\\\\\\": \\\\\\"10000\\\\\\",\\\\n    \\\\\\"experiment.chaos.bandwidth_buffer\\\\\\": \\\\\\"1000\\\\\\",\\\\n    \\\\\\"experiment.flink.checkpoint_interval_ms\\\\\\": \\\\\\"4000\\\\\\",\\\\n    \\\\\\"experiment.flink.window_size_ms\\\\\\": \\\\\\"1000\\\\\\",\\\\n    \\\\\\"experiment.flink.fibonacci_value\\\\\\": \\\\\\"18\\\\\\",\\\\n    \\\\\\"experiment.name\\\\\\": \\\\\\"Join\\\\\\",\\\\n    \\\\\\"experiment.job_file\\\\\\": \\\\\\"myjoin-transscale-all.jar\\\\\\",\\\\n    \\\\\\"experiment.task_name\\\\\\": \\\\\\"TumblingEventTimeWindows\\\\\\",\\\\n    \\\\\\"experiment.output_skip_s\\\\\\": \\\\\\"60\\\\\\",\\\\n    \\\\\\"experiment.output_stats\\\\\\": \\\\\\"true\\\\\\",\\\\n    \\\\\\"experiment.output_plot\\\\\\": \\\\\\"true\\\\\\",\\\\n    \\\\\\"experiment.broker_mqtt_host\\\\\\": \\\\\\"ingress.scalehub.local\\\\\\",\\\\n    \\\\\\"experiment.broker_mqtt_port\\\\\\": \\\\\\"30001\\\\\\",\\\\n    \\\\\\"experiment.kafka_partitions\\\\\\": \\\\\\"1000\\\\\\",\\\\n    \\\\\\"experiment.first_node\\\\\\": \\\\\\"grid5000\\\\\\",\\\\n    \\\\\\"experiment.unchained_tasks\\\\\\": \\\\\\"true\\\\\\",\\\\n    \\\\\\"experiment.type\\\\\\": \\\\\\"simple\\\\\\",\\\\n    \\\\\\"experiment.runs\\\\\\": \\\\\\"5\\\\\\",\\\\n    \\\\\\"experiment.comment\\\\\\": \\\\\\"\\\\\\\\\\\\\\"4 nodes: 2 BM + 2 VMS\\\\\\\\\\\\\\"\\\\\\",\\\\n    \\\\\\"experiment.scaling.strategy_path\\\\\\": \\\\\\"/app/conf/experiment/strategy/mix_node_bm_vms.yaml\\\\\\",\\\\n    \\\\\\"experiment.scaling.max_parallelism\\\\\\": 52,\\\\n    \\\\\\"experiment.scaling.interval_scaling_s\\\\\\": 240,\\\\n    \\\\\\"experiment.generators.generators\\\\\\": \\\\\\"generator1, generator2\\\\\\",\\\\n    \\\\\\"experiment.generators\\\\\\": [\\\\n        {\\\\n            \\\\\\"name\\\\\\": \\\\\\"generator1\\\\\\",\\\\n            \\\\\\"type\\\\\\": \\\\\\"theodolite-lg\\\\\\",\\\\n            \\\\\\"topic\\\\\\": \\\\\\"input-topic1\\\\\\",\\\\n            \\\\\\"num_sensors\\\\\\": 175000,\\\\n            \\\\\\"interval_ms\\\\\\": 1000,\\\\n            \\\\\\"replicas\\\\\\": 30,\\\\n            \\\\\\"value\\\\\\": 9001\\\\n        },\\\\n        {\\\\n            \\\\\\"name\\\\\\": \\\\\\"generator2\\\\\\",\\\\n            \\\\\\"type\\\\\\": \\\\\\"theodolite-lg\\\\\\",\\\\n            \\\\\\"topic\\\\\\": \\\\\\"input-topic2\\\\\\",\\\\n            \\\\\\"num_sensors\\\\\\": 175000,\\\\n            \\\\\\"interval_ms\\\\\\": 1000,\\\\n            \\\\\\"replicas\\\\\\": 30,\\\\n            \\\\\\"value\\\\\\": 9001\\\\n        }\\\\n    ],\\\\n    \\\\\\"experiment.scaling.steps\\\\\\": [\\\\n        {\\\\n            \\\\\\"node\\\\\\": \\\\\\"grid5000\\\\\\",\\\\n            \\\\\\"taskmanager\\\\\\": [\\\\n                {\\\\n                    \\\\\\"number\\\\\\": 52,\\\\n                    \\\\\\"type\\\\\\": \\\\\\"l\\\\\\",\\\\n                    \\\\\\"method\\\\\\": \\\\\\"block\\\\\\"\\\\n                }\\\\n            ]\\\\n        },\\\\n        {\\\\n            \\\\\\"node\\\\\\": \\\\\\"grid5000\\\\\\",\\\\n            \\\\\\"taskmanager\\\\\\": [\\\\n                {\\\\n                    \\\\\\"number\\\\\\": 52,\\\\n                    \\\\\\"type\\\\\\": \\\\\\"l\\\\\\",\\\\n                    \\\\\\"method\\\\\\": \\\\\\"block\\\\\\"\\\\n                }\\\\n            ]\\\\n        },\\\\n        {\\\\n            \\\\\\"node\\\\\\": \\\\\\"vm_grid5000\\\\\\",\\\\n            \\\\\\"type\\\\\\": \\\\\\"small\\\\\\",\\\\n            \\\\\\"taskmanager\\\\\\": [\\\\n                {\\\\n                    \\\\\\"number\\\\\\": 2,\\\\n                    \\\\\\"type\\\\\\": \\\\\\"m\\\\\\",\\\\n                    \\\\\\"method\\\\\\": \\\\\\"block\\\\\\"\\\\n                }\\\\n            ]\\\\n        },\\\\n        {\\\\n            \\\\\\"node\\\\\\": \\\\\\"vm_grid5000\\\\\\",\\\\n            \\\\\\"type\\\\\\": \\\\\\"small\\\\\\",\\\\n            \\\\\\"taskmanager\\\\\\": [\\\\n                {\\\\n                    \\\\\\"number\\\\\\": 2,\\\\n                    \\\\\\"type\\\\\\": \\\\\\"m\\\\\\",\\\\n                    \\\\\\"method\\\\\\": \\\\\\"block\\\\\\"\\\\n                }\\\\n            ]\\\\n        }\\\\n    ]\\\\n}\\", \\"{\\\\n    \\\\\\"scalehub.inventory\\\\\\": \\\\\\"/app/conf/hosts\\\\\\",\\\\n    \\\\\\"scalehub.playbook\\\\\\": \\\\\\"/app/playbooks\\\\\\",\\\\n    \\\\\\"scalehub.experiments\\\\\\": \\\\\\"/app/experiments-data\\\\\\",\\\\n    \\\\\\"scalehub.debug_level\\\\\\": \\\\\\"3\\\\\\",\\\\n    \\\\\\"experiment.chaos.enable\\\\\\": \\\\\\"false\\\\\\",\\\\n    \\\\\\"experiment.chaos.affected_nodes_percentage\\\\\\": \\\\\\"70\\\\\\",\\\\n    \\\\\\"experiment.chaos.delay_latency_ms\\\\\\": \\\\\\"50\\\\\\",\\\\n    \\\\\\"experiment.chaos.delay_jitter_ms\\\\\\": \\\\\\"0\\\\\\",\\\\n    \\\\\\"experiment.chaos.delay_correlation\\\\\\": \\\\\\"0\\\\\\",\\\\n    \\\\\\"experiment.chaos.bandwidth_rate_mbps\\\\\\": \\\\\\"100\\\\\\",\\\\n    \\\\\\"experiment.chaos.bandwidth_limit\\\\\\": \\\\\\"10000\\\\\\",\\\\n    \\\\\\"experiment.chaos.bandwidth_buffer\\\\\\": \\\\\\"1000\\\\\\",\\\\n    \\\\\\"experiment.flink.checkpoint_interval_ms\\\\\\": \\\\\\"4000\\\\\\",\\\\n    \\\\\\"experiment.flink.window_size_ms\\\\\\": \\\\\\"1000\\\\\\",\\\\n    \\\\\\"experiment.flink.fibonacci_value\\\\\\": \\\\\\"18\\\\\\",\\\\n    \\\\\\"experiment.name\\\\\\": \\\\\\"Join\\\\\\",\\\\n    \\\\\\"experiment.job_file\\\\\\": \\\\\\"myjoin-transscale-all.jar\\\\\\",\\\\n    \\\\\\"experiment.task_name\\\\\\": \\\\\\"TumblingEventTimeWindows\\\\\\",\\\\n    \\\\\\"experiment.output_skip_s\\\\\\": \\\\\\"60\\\\\\",\\\\n    \\\\\\"experiment.output_stats\\\\\\": \\\\\\"true\\\\\\",\\\\n    \\\\\\"experiment.output_plot\\\\\\": \\\\\\"true\\\\\\",\\\\n    \\\\\\"experiment.broker_mqtt_host\\\\\\": \\\\\\"ingress.scalehub.local\\\\\\",\\\\n    \\\\\\"experiment.broker_mqtt_port\\\\\\": \\\\\\"30001\\\\\\",\\\\n    \\\\\\"experiment.kafka_partitions\\\\\\": \\\\\\"1000\\\\\\",\\\\n    \\\\\\"experiment.first_node\\\\\\": \\\\\\"grid5000\\\\\\",\\\\n    \\\\\\"experiment.unchained_tasks\\\\\\": \\\\\\"true\\\\\\",\\\\n    \\\\\\"experiment.type\\\\\\": \\\\\\"simple\\\\\\",\\\\n    \\\\\\"experiment.runs\\\\\\": \\\\\\"5\\\\\\",\\\\n    \\\\\\"experiment.comment\\\\\\": \\\\\\"\\\\\\\\\\\\\\"4 nodes with 1 small taskmanager each.\\\\\\\\\\\\\\"\\\\\\",\\\\n    \\\\\\"experiment.scaling.strategy_path\\\\\\": \\\\\\"/app/conf/experiment/strategy/multi_node_vms.yaml\\\\\\",\\\\n    \\\\\\"experiment.scaling.max_parallelism\\\\\\": 1,\\\\n    \\\\\\"experiment.scaling.interval_scaling_s\\\\\\": 240,\\\\n    \\\\\\"experiment.generators.generators\\\\\\": \\\\\\"generator1, generator2\\\\\\",\\\\n    \\\\\\"experiment.generators\\\\\\": [\\\\n        {\\\\n            \\\\\\"name\\\\\\": \\\\\\"generator1\\\\\\",\\\\n            \\\\\\"type\\\\\\": \\\\\\"theodolite-lg\\\\\\",\\\\n            \\\\\\"topic\\\\\\": \\\\\\"input-topic1\\\\\\",\\\\n            \\\\\\"num_sensors\\\\\\": 175000,\\\\n            \\\\\\"interval_ms\\\\\\": 1000,\\\\n            \\\\\\"replicas\\\\\\": 15,\\\\n            \\\\\\"value\\\\\\": 9001\\\\n        },\\\\n        {\\\\n            \\\\\\"name\\\\\\": \\\\\\"generator2\\\\\\",\\\\n            \\\\\\"type\\\\\\": \\\\\\"theodolite-lg\\\\\\",\\\\n            \\\\\\"topic\\\\\\": \\\\\\"input-topic2\\\\\\",\\\\n            \\\\\\"num_sensors\\\\\\": 175000,\\\\n            \\\\\\"interval_ms\\\\\\": 1000,\\\\n            \\\\\\"replicas\\\\\\": 15,\\\\n            \\\\\\"value\\\\\\": 9001\\\\n        }\\\\n    ],\\\\n    \\\\\\"experiment.scaling.steps\\\\\\": [\\\\n        {\\\\n            \\\\\\"node\\\\\\": \\\\\\"vm_grid5000\\\\\\",\\\\n            \\\\\\"type\\\\\\": \\\\\\"small\\\\\\",\\\\n            \\\\\\"taskmanager\\\\\\": [\\\\n                {\\\\n                    \\\\\\"number\\\\\\": 2,\\\\n                    \\\\\\"type\\\\\\": \\\\\\"m\\\\\\",\\\\n                    \\\\\\"method\\\\\\": \\\\\\"block\\\\\\"\\\\n                }\\\\n            ]\\\\n        },\\\\n        {\\\\n            \\\\\\"node\\\\\\": \\\\\\"vm_grid5000\\\\\\",\\\\n            \\\\\\"type\\\\\\": \\\\\\"small\\\\\\",\\\\n            \\\\\\"taskmanager\\\\\\": [\\\\n                {\\\\n                    \\\\\\"number\\\\\\": 2,\\\\n                    \\\\\\"type\\\\\\": \\\\\\"m\\\\\\",\\\\n                    \\\\\\"method\\\\\\": \\\\\\"block\\\\\\"\\\\n                }\\\\n            ]\\\\n        },\\\\n        {\\\\n            \\\\\\"node\\\\\\": \\\\\\"vm_grid5000\\\\\\",\\\\n            \\\\\\"type\\\\\\": \\\\\\"small\\\\\\",\\\\n            \\\\\\"taskmanager\\\\\\": [\\\\n                {\\\\n                    \\\\\\"number\\\\\\": 2,\\\\n                    \\\\\\"type\\\\\\": \\\\\\"m\\\\\\",\\\\n                    \\\\\\"method\\\\\\": \\\\\\"block\\\\\\"\\\\n                }\\\\n            ]\\\\n        },\\\\n        {\\\\n            \\\\\\"node\\\\\\": \\\\\\"vm_grid5000\\\\\\",\\\\n            \\\\\\"type\\\\\\": \\\\\\"small\\\\\\",\\\\n            \\\\\\"taskmanager\\\\\\": [\\\\n                {\\\\n                    \\\\\\"number\\\\\\": 2,\\\\n                    \\\\\\"type\\\\\\": \\\\\\"m\\\\\\",\\\\n                    \\\\\\"method\\\\\\": \\\\\\"block\\\\\\"\\\\n                }\\\\n            ]\\\\n        }\\\\n    ]\\\\n}\\"]"}'. Current state: States.IDLE.
[0m[2025-01-17T08:24:50.979085] [CLIENT] Received config: ["{\n    \"scalehub.inventory\": \"/app/conf/hosts\",\n    \"scalehub.playbook\": \"/app/playbooks\",\n    \"scalehub.experiments\": \"/app/experiments-data\",\n    \"scalehub.debug_level\": \"3\",\n    \"experiment.chaos.enable\": \"false\",\n    \"experiment.chaos.affected_nodes_percentage\": \"70\",\n    \"experiment.chaos.delay_latency_ms\": \"50\",\n    \"experiment.chaos.delay_jitter_ms\": \"0\",\n    \"experiment.chaos.delay_correlation\": \"0\",\n    \"experiment.chaos.bandwidth_rate_mbps\": \"100\",\n    \"experiment.chaos.bandwidth_limit\": \"10000\",\n    \"experiment.chaos.bandwidth_buffer\": \"1000\",\n    \"experiment.flink.checkpoint_interval_ms\": \"4000\",\n    \"experiment.flink.window_size_ms\": \"1000\",\n    \"experiment.flink.fibonacci_value\": \"18\",\n    \"experiment.name\": \"Join\",\n    \"experiment.job_file\": \"myjoin-transscale-all.jar\",\n    \"experiment.task_name\": \"TumblingEventTimeWindows\",\n    \"experiment.output_skip_s\": \"60\",\n    \"experiment.output_stats\": \"true\",\n    \"experiment.output_plot\": \"true\",\n    \"experiment.broker_mqtt_host\": \"ingress.scalehub.local\",\n    \"experiment.broker_mqtt_port\": \"30001\",\n    \"experiment.kafka_partitions\": \"1000\",\n    \"experiment.first_node\": \"grid5000\",\n    \"experiment.unchained_tasks\": \"true\",\n    \"experiment.type\": \"simple\",\n    \"experiment.runs\": \"5\",\n    \"experiment.comment\": \"\\\"4 nodes: 2 BM + 2 VMS\\\"\",\n    \"experiment.scaling.strategy_path\": \"/app/conf/experiment/strategy/mix_node_bm_vms.yaml\",\n    \"experiment.scaling.max_parallelism\": 52,\n    \"experiment.scaling.interval_scaling_s\": 240,\n    \"experiment.generators.generators\": \"generator1, generator2\",\n    \"experiment.generators\": [\n        {\n            \"name\": \"generator1\",\n            \"type\": \"theodolite-lg\",\n            \"topic\": \"input-topic1\",\n            \"num_sensors\": 175000,\n            \"interval_ms\": 1000,\n            \"replicas\": 30,\n            \"value\": 9001\n        },\n        {\n            \"name\": \"generator2\",\n            \"type\": \"theodolite-lg\",\n            \"topic\": \"input-topic2\",\n            \"num_sensors\": 175000,\n            \"interval_ms\": 1000,\n            \"replicas\": 30,\n            \"value\": 9001\n        }\n    ],\n    \"experiment.scaling.steps\": [\n        {\n            \"node\": \"grid5000\",\n            \"taskmanager\": [\n                {\n                    \"number\": 52,\n                    \"type\": \"l\",\n                    \"method\": \"block\"\n                }\n            ]\n        },\n        {\n            \"node\": \"grid5000\",\n            \"taskmanager\": [\n                {\n                    \"number\": 52,\n                    \"type\": \"l\",\n                    \"method\": \"block\"\n                }\n            ]\n        },\n        {\n            \"node\": \"vm_grid5000\",\n            \"type\": \"small\",\n            \"taskmanager\": [\n                {\n                    \"number\": 2,\n                    \"type\": \"m\",\n                    \"method\": \"block\"\n                }\n            ]\n        },\n        {\n            \"node\": \"vm_grid5000\",\n            \"type\": \"small\",\n            \"taskmanager\": [\n                {\n                    \"number\": 2,\n                    \"type\": \"m\",\n                    \"method\": \"block\"\n                }\n            ]\n        }\n    ]\n}", "{\n    \"scalehub.inventory\": \"/app/conf/hosts\",\n    \"scalehub.playbook\": \"/app/playbooks\",\n    \"scalehub.experiments\": \"/app/experiments-data\",\n    \"scalehub.debug_level\": \"3\",\n    \"experiment.chaos.enable\": \"false\",\n    \"experiment.chaos.affected_nodes_percentage\": \"70\",\n    \"experiment.chaos.delay_latency_ms\": \"50\",\n    \"experiment.chaos.delay_jitter_ms\": \"0\",\n    \"experiment.chaos.delay_correlation\": \"0\",\n    \"experiment.chaos.bandwidth_rate_mbps\": \"100\",\n    \"experiment.chaos.bandwidth_limit\": \"10000\",\n    \"experiment.chaos.bandwidth_buffer\": \"1000\",\n    \"experiment.flink.checkpoint_interval_ms\": \"4000\",\n    \"experiment.flink.window_size_ms\": \"1000\",\n    \"experiment.flink.fibonacci_value\": \"18\",\n    \"experiment.name\": \"Join\",\n    \"experiment.job_file\": \"myjoin-transscale-all.jar\",\n    \"experiment.task_name\": \"TumblingEventTimeWindows\",\n    \"experiment.output_skip_s\": \"60\",\n    \"experiment.output_stats\": \"true\",\n    \"experiment.output_plot\": \"true\",\n    \"experiment.broker_mqtt_host\": \"ingress.scalehub.local\",\n    \"experiment.broker_mqtt_port\": \"30001\",\n    \"experiment.kafka_partitions\": \"1000\",\n    \"experiment.first_node\": \"grid5000\",\n    \"experiment.unchained_tasks\": \"true\",\n    \"experiment.type\": \"simple\",\n    \"experiment.runs\": \"5\",\n    \"experiment.comment\": \"\\\"4 nodes with 1 small taskmanager each.\\\"\",\n    \"experiment.scaling.strategy_path\": \"/app/conf/experiment/strategy/multi_node_vms.yaml\",\n    \"experiment.scaling.max_parallelism\": 1,\n    \"experiment.scaling.interval_scaling_s\": 240,\n    \"experiment.generators.generators\": \"generator1, generator2\",\n    \"experiment.generators\": [\n        {\n            \"name\": \"generator1\",\n            \"type\": \"theodolite-lg\",\n            \"topic\": \"input-topic1\",\n            \"num_sensors\": 175000,\n            \"interval_ms\": 1000,\n            \"replicas\": 15,\n            \"value\": 9001\n        },\n        {\n            \"name\": \"generator2\",\n            \"type\": \"theodolite-lg\",\n            \"topic\": \"input-topic2\",\n            \"num_sensors\": 175000,\n            \"interval_ms\": 1000,\n            \"replicas\": 15,\n            \"value\": 9001\n        }\n    ],\n    \"experiment.scaling.steps\": [\n        {\n            \"node\": \"vm_grid5000\",\n            \"type\": \"small\",\n            \"taskmanager\": [\n                {\n                    \"number\": 2,\n                    \"type\": \"m\",\n                    \"method\": \"block\"\n                }\n            ]\n        },\n        {\n            \"node\": \"vm_grid5000\",\n            \"type\": \"small\",\n            \"taskmanager\": [\n                {\n                    \"number\": 2,\n                    \"type\": \"m\",\n                    \"method\": \"block\"\n                }\n            ]\n        },\n        {\n            \"node\": \"vm_grid5000\",\n            \"type\": \"small\",\n            \"taskmanager\": [\n                {\n                    \"number\": 2,\n                    \"type\": \"m\",\n                    \"method\": \"block\"\n                }\n            ]\n        },\n        {\n            \"node\": \"vm_grid5000\",\n            \"type\": \"small\",\n            \"taskmanager\": [\n                {\n                    \"number\": 2,\n                    \"type\": \"m\",\n                    \"method\": \"block\"\n                }\n            ]\n        }\n    ]\n}"]
[0m[2025-01-17T08:24:50.979511] [FSM] Setting configs. Found 2 configs in sequence.
[0m[2025-01-17T08:24:50.979886] [FSM] Start phase with experiment: simple
[0m[2025-01-17T08:24:50.979927] [FSM] State is States.STARTING
[0m[2025-01-17T08:24:50.980054] [FSM] Creating experiment instance of type: simple
[0;93m[2025-01-17T08:24:50.980142] [WARNING] Error loading kubeconfig from ENV: Invalid kube-config file. No configuration found.[0m
[0;93m[2025-01-17T08:24:50.980151] [WARNING] Trying incluster config instead.[0m
[0m[2025-01-17T08:24:50.980982] [EXPERIMENT] Starting experiment.
[0m[2025-01-17T08:24:50.981562] [THRD] Starting thread.
[0m[2025-01-17T08:24:50.981583] [EXPERIMENT] =================================== Starting run 1 ===================================
[0m[2025-01-17T08:24:50.982178] [FSM] FSM startup complete, transitioning to running.
[0m[2025-01-17T08:24:50.982316] [FSM] Run phase started.
[0m[2025-01-17T08:24:50.982511] [FSM] State is States.RUNNING
[0m[2025-01-17T08:24:50.983533] [EXPERIMENT] Running experiment.
[0m[2025-01-17T08:24:50.983740] [CLIENT] Received payload b''. Current state: States.RUNNING.
[0m[2025-01-17T08:24:52.892967] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-17T08:24:54.750946] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-17T08:24:54.751013] [SCALING] Setting up experiment.


[0m[2025-01-17T08:24:54.751026] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-17T08:24:54.759612] [NODE_MGR] Resetting state labels.
[0m[2025-01-17T08:24:54.771197] [SCALING] First node: paradoxe-7.rennes.grid5000.fr

[0m[2025-01-17T08:24:54.787701] [SCALING] Statefulset name to scale : flink-taskmanager-l
[0m[2025-01-17T08:24:54.798339] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 52 replica.
[0m[2025-01-17T08:24:59.806570] [FLK_MGR] Running job.
[0m[2025-01-17T08:24:59.806596] [FLK_MGR] Starting job with 52 parallelism.
[0m[2025-01-17T08:25:00.362672] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 52'] on pod flink-jobmanager-7d7c784b74-t4jbx
[0m[2025-01-17T08:25:05.138865] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 9e564af56c3a261c4190fd49ccd8dd41

[0m[2025-01-17T08:25:05.139052] [FLK_MGR] Running job id: 9e564af56c3a261c4190fd49ccd8dd41
[0m[2025-01-17T08:25:05.139066] [FLK_MGR] Getting job info.
[0m[2025-01-17T08:25:05.157177] [FLK_MGR] Job plan response: {"plan":{"jid":"9e564af56c3a261c4190fd49ccd8dd41","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":52,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T08:25:05.157344] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T08:25:05.702976] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-t4jbx
[0m[2025-01-17T08:25:07.141649] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 08:25:04 : 9e564af56c3a261c4190fd49ccd8dd41 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T08:25:07.141892] [FLK_MGR] Running jobs: ['9e564af56c3a261c4190fd49ccd8dd41']
[0m[2025-01-17T08:25:07.141904] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T08:25:07.141918] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-17T08:29:07.165972] [SCALING] Scaling started.
[0m[2025-01-17T08:29:07.166107] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-17T08:29:07.186121] [SCALING] Next node: paradoxe-8.rennes.grid5000.fr

[0m[2025-01-17T08:29:07.196614] =========================================================== Step 1 ===========================================================
[0m[2025-01-17T08:29:07.196631] [SCALING] Scaling on node : grid5000
[0m[2025-01-17T08:29:07.196675] [SCALING] Adding 52 replicas of l taskmanager.
[0m[2025-01-17T08:29:07.201333] [SCALING] Statefulset name to scale : flink-taskmanager-l
[0m[2025-01-17T08:29:07.210637] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 52, 'flink-taskmanager-m': 0, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T08:29:07.220068] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 104 replica.
[0m[2025-01-17T08:29:12.238171] [SCALING] ************************************ Adding 104 replicas ************************************
[0m[2025-01-17T08:29:12.238207] [FLK_MGR] Running job.
[0m[2025-01-17T08:29:12.238212] [FLK_MGR] Rescaling job to 104.
[0m[2025-01-17T08:29:13.067341] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d 9e564af56c3a261c4190fd49ccd8dd41'] on pod flink-jobmanager-7d7c784b74-t4jbx
[0m[2025-01-17T08:29:17.153764] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-9e564a-2bce735bce3d
[0m[2025-01-17T08:29:36.864537] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-9e564a-2bce735bce3d -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:104;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-t4jbx
[0m[2025-01-17T08:29:40.029120] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 104.
[0m[2025-01-17T08:29:40.029163] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:104;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 104
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID 23dd862a6f1b9044ebb9b2db8ed25035

[0m[2025-01-17T08:29:40.029190] [FLK_MGR] Running job id: 23dd862a6f1b9044ebb9b2db8ed25035
[0m[2025-01-17T08:29:40.029200] [FLK_MGR] Getting job info.
[0m[2025-01-17T08:29:40.037731] [FLK_MGR] Job plan response: {"plan":{"jid":"23dd862a6f1b9044ebb9b2db8ed25035","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":104,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T08:29:40.037881] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T08:29:40.857100] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-t4jbx
[0m[2025-01-17T08:29:42.577100] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 08:29:39 : 23dd862a6f1b9044ebb9b2db8ed25035 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T08:29:42.577167] [FLK_MGR] Running jobs: ['23dd862a6f1b9044ebb9b2db8ed25035']
[0m[2025-01-17T08:29:42.577175] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T08:29:42.585900] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T08:33:42.609724] [SCALING] Scaling step on node paradoxe-8.rennes.grid5000.fr finished. Marking node as full.
[0m[2025-01-17T08:33:47.642525] [SCALING] Next node: virtual-158-0-10

[0m[2025-01-17T08:33:47.652539] =========================================================== Step 2 ===========================================================
[0m[2025-01-17T08:33:47.652560] [SCALING] Scaling on node : vm_grid5000
[0m[2025-01-17T08:33:47.652570] [SCALING] Adding 2 replicas of m taskmanager.
[0m[2025-01-17T08:33:47.656899] [SCALING] Statefulset name to scale : flink-taskmanager-m
[0m[2025-01-17T08:33:47.665589] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 104, 'flink-taskmanager-m': 0, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T08:33:47.676352] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 2 replica.
[0m[2025-01-17T08:33:52.695195] [SCALING] ************************************ Adding 106 replicas ************************************
[0m[2025-01-17T08:33:52.695219] [FLK_MGR] Running job.
[0m[2025-01-17T08:33:52.695225] [FLK_MGR] Rescaling job to 106.
[0m[2025-01-17T08:33:53.431721] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d 23dd862a6f1b9044ebb9b2db8ed25035'] on pod flink-jobmanager-7d7c784b74-t4jbx
[0m[2025-01-17T08:33:59.516409] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-23dd86-3319c9cfb143
[0m[2025-01-17T08:34:19.187219] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-23dd86-3319c9cfb143 -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:106;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-t4jbx
[0m[2025-01-17T08:34:22.161783] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 106.
[0m[2025-01-17T08:34:22.161820] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:106;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 106
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID a26fcdf4aae05a3fa778846147466881

[0m[2025-01-17T08:34:22.161838] [FLK_MGR] Running job id: a26fcdf4aae05a3fa778846147466881
[0m[2025-01-17T08:34:22.161845] [FLK_MGR] Getting job info.
[0m[2025-01-17T08:34:22.169989] [FLK_MGR] Job plan response: {"plan":{"jid":"a26fcdf4aae05a3fa778846147466881","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":106,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T08:34:22.170146] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T08:34:22.898072] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-t4jbx
[0m[2025-01-17T08:34:24.481182] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 08:34:21 : a26fcdf4aae05a3fa778846147466881 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T08:34:24.481246] [FLK_MGR] Running jobs: ['a26fcdf4aae05a3fa778846147466881']
[0m[2025-01-17T08:34:24.481253] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T08:34:24.502347] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T08:38:24.527825] [SCALING] Scaling step on node virtual-158-0-10 finished. Marking node as full.
[0m[2025-01-17T08:38:29.560965] [SCALING] Next node: virtual-158-0-11

[0m[2025-01-17T08:38:29.571718] =========================================================== Step 3 ===========================================================
[0m[2025-01-17T08:38:29.571734] [SCALING] Scaling on node : vm_grid5000
[0m[2025-01-17T08:38:29.571742] [SCALING] Adding 2 replicas of m taskmanager.
[0m[2025-01-17T08:38:29.577179] [SCALING] Statefulset name to scale : flink-taskmanager-m
[0m[2025-01-17T08:38:29.585974] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 104, 'flink-taskmanager-m': 2, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T08:38:29.594876] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 4 replica.
[0m[2025-01-17T08:38:34.613923] [SCALING] ************************************ Adding 108 replicas ************************************
[0m[2025-01-17T08:38:34.613948] [FLK_MGR] Running job.
[0m[2025-01-17T08:38:34.613953] [FLK_MGR] Rescaling job to 108.
[0m[2025-01-17T08:38:35.392028] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d a26fcdf4aae05a3fa778846147466881'] on pod flink-jobmanager-7d7c784b74-t4jbx
[0m[2025-01-17T08:38:38.145147] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-a26fcd-71402ee34d45
[0m[2025-01-17T08:38:57.838380] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-a26fcd-71402ee34d45 -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:108;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-t4jbx
[0m[2025-01-17T08:39:00.760372] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 108.
[0m[2025-01-17T08:39:00.760421] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:108;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 108
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID 839adfca7f59d4a95d1b64fc8c57a3f8

[0m[2025-01-17T08:39:00.760448] [FLK_MGR] Running job id: 839adfca7f59d4a95d1b64fc8c57a3f8
[0m[2025-01-17T08:39:00.760457] [FLK_MGR] Getting job info.
[0m[2025-01-17T08:39:00.868699] [FLK_MGR] Job plan response: {"plan":{"jid":"839adfca7f59d4a95d1b64fc8c57a3f8","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":108,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T08:39:00.868909] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T08:39:01.606612] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-t4jbx
[0m[2025-01-17T08:39:03.189560] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 08:39:00 : 839adfca7f59d4a95d1b64fc8c57a3f8 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T08:39:03.189628] [FLK_MGR] Running jobs: ['839adfca7f59d4a95d1b64fc8c57a3f8']
[0m[2025-01-17T08:39:03.189636] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T08:39:03.196427] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T08:43:03.220458] [SCALING] Scaling step on node virtual-158-0-11 finished. Marking node as full.
[0m[2025-01-17T08:43:08.233450] [SCALING] Scaling finished.
[0m[2025-01-17T08:43:08.233509] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-17T08:43:08.285167] [NODE_MGR] Resetting state labels.
[0m[2025-01-17T08:43:08.334037] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-17T08:43:08.389612] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-17T08:43:18.413811] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-17T08:43:23.436271] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-17T08:43:23.451766] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-17T08:43:23.465454] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-17T08:43:23.497772] [POD_MGR] Pod flink-jobmanager-7d7c784b74-t4jbx deleted
[0m[2025-01-17T08:43:25.333927] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-17T08:43:27.204038] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-17T08:43:27.204109] Reloading playbook: application/kafka
[0m[2025-01-17T08:43:33.133302] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-17T08:44:14.088355] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-17T08:44:14.088530] [EXPERIMENT] Run 1 completed. Start: 1737102290, End: 1737103454
[0m[2025-01-17T08:44:14.088537] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-17T08:44:24.089534] [EXPERIMENT] =================================== Starting run 2 ===================================
[0m[2025-01-17T08:44:25.978402] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-17T08:44:27.853061] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-17T08:44:27.853140] [SCALING] Setting up experiment.


[0m[2025-01-17T08:44:27.853154] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-17T08:44:27.857918] [NODE_MGR] Resetting state labels.
[0m[2025-01-17T08:44:27.868641] [SCALING] First node: paradoxe-7.rennes.grid5000.fr

[0m[2025-01-17T08:44:27.883177] [SCALING] Statefulset name to scale : flink-taskmanager-l
[0m[2025-01-17T08:44:27.892182] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 52 replica.
[0m[2025-01-17T08:44:32.901835] [FLK_MGR] Running job.
[0m[2025-01-17T08:44:32.901863] [FLK_MGR] Starting job with 52 parallelism.
[0m[2025-01-17T08:44:33.497921] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 52'] on pod flink-jobmanager-7d7c784b74-lkk8p
[0m[2025-01-17T08:44:37.518618] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID 5c3ca68ee0fce7f2a026d12ae915bf3a

[0m[2025-01-17T08:44:37.518662] [FLK_MGR] Running job id: 5c3ca68ee0fce7f2a026d12ae915bf3a
[0m[2025-01-17T08:44:37.518674] [FLK_MGR] Getting job info.
[0m[2025-01-17T08:44:37.529901] [FLK_MGR] Job plan response: {"plan":{"jid":"5c3ca68ee0fce7f2a026d12ae915bf3a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":52,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T08:44:37.530055] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T08:44:38.100736] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-lkk8p
[0m[2025-01-17T08:44:39.538018] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 08:44:36 : 5c3ca68ee0fce7f2a026d12ae915bf3a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T08:44:39.538071] [FLK_MGR] Running jobs: ['5c3ca68ee0fce7f2a026d12ae915bf3a']
[0m[2025-01-17T08:44:39.538078] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T08:44:39.538086] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-17T08:48:39.561905] [SCALING] Scaling started.
[0m[2025-01-17T08:48:39.562015] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-17T08:48:39.581956] [SCALING] Next node: paradoxe-8.rennes.grid5000.fr

[0m[2025-01-17T08:48:39.592069] =========================================================== Step 1 ===========================================================
[0m[2025-01-17T08:48:39.592085] [SCALING] Scaling on node : grid5000
[0m[2025-01-17T08:48:39.592096] [SCALING] Adding 52 replicas of l taskmanager.
[0m[2025-01-17T08:48:39.596470] [SCALING] Statefulset name to scale : flink-taskmanager-l
[0m[2025-01-17T08:48:39.605477] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 52, 'flink-taskmanager-m': 0, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T08:48:39.615040] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 104 replica.
[0m[2025-01-17T08:48:44.637750] [SCALING] ************************************ Adding 104 replicas ************************************
[0m[2025-01-17T08:48:44.637781] [FLK_MGR] Running job.
[0m[2025-01-17T08:48:44.637788] [FLK_MGR] Rescaling job to 104.
[0m[2025-01-17T08:48:45.318975] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d 5c3ca68ee0fce7f2a026d12ae915bf3a'] on pod flink-jobmanager-7d7c784b74-lkk8p
[0m[2025-01-17T08:48:49.387622] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-5c3ca6-68e338782358
[0m[2025-01-17T08:49:09.090862] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-5c3ca6-68e338782358 -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:104;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-lkk8p
[0m[2025-01-17T08:49:12.163430] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 104.
[0m[2025-01-17T08:49:12.163469] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:104;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 104
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID b7aac492f2b4fa7c677a56023f7e9770

[0m[2025-01-17T08:49:12.163487] [FLK_MGR] Running job id: b7aac492f2b4fa7c677a56023f7e9770
[0m[2025-01-17T08:49:12.163494] [FLK_MGR] Getting job info.
[0m[2025-01-17T08:49:12.208406] [FLK_MGR] Job plan response: {"plan":{"jid":"b7aac492f2b4fa7c677a56023f7e9770","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":104,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T08:49:12.208590] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T08:49:13.036573] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-lkk8p
[0m[2025-01-17T08:49:14.600492] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 08:49:11 : b7aac492f2b4fa7c677a56023f7e9770 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T08:49:14.600557] [FLK_MGR] Running jobs: ['b7aac492f2b4fa7c677a56023f7e9770']
[0m[2025-01-17T08:49:14.600565] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T08:49:14.608494] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T08:53:14.631300] [SCALING] Scaling step on node paradoxe-8.rennes.grid5000.fr finished. Marking node as full.
[0m[2025-01-17T08:53:19.665501] [SCALING] Next node: virtual-158-0-10

[0m[2025-01-17T08:53:19.675396] =========================================================== Step 2 ===========================================================
[0m[2025-01-17T08:53:19.675417] [SCALING] Scaling on node : vm_grid5000
[0m[2025-01-17T08:53:19.675426] [SCALING] Adding 2 replicas of m taskmanager.
[0m[2025-01-17T08:53:19.679326] [SCALING] Statefulset name to scale : flink-taskmanager-m
[0m[2025-01-17T08:53:19.687671] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 104, 'flink-taskmanager-m': 0, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T08:53:19.697068] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 2 replica.
[0m[2025-01-17T08:53:24.716545] [SCALING] ************************************ Adding 106 replicas ************************************
[0m[2025-01-17T08:53:24.716570] [FLK_MGR] Running job.
[0m[2025-01-17T08:53:24.716575] [FLK_MGR] Rescaling job to 106.
[0m[2025-01-17T08:53:25.407178] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d b7aac492f2b4fa7c677a56023f7e9770'] on pod flink-jobmanager-7d7c784b74-lkk8p
[0m[2025-01-17T08:53:28.164933] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-b7aac4-343dad119f23
[0m[2025-01-17T08:53:47.859633] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-b7aac4-343dad119f23 -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:106;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-lkk8p
[0m[2025-01-17T08:53:50.866964] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 106.
[0m[2025-01-17T08:53:50.866998] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:106;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 106
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID c5242d580e527621766dbbf3e175c788

[0m[2025-01-17T08:53:50.867015] [FLK_MGR] Running job id: c5242d580e527621766dbbf3e175c788
[0m[2025-01-17T08:53:50.867021] [FLK_MGR] Getting job info.
[0m[2025-01-17T08:53:50.977396] [FLK_MGR] Job plan response: {"plan":{"jid":"c5242d580e527621766dbbf3e175c788","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":106,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T08:53:50.977577] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T08:53:51.791111] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-lkk8p
[0m[2025-01-17T08:53:53.441530] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 08:53:50 : c5242d580e527621766dbbf3e175c788 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T08:53:53.441597] [FLK_MGR] Running jobs: ['c5242d580e527621766dbbf3e175c788']
[0m[2025-01-17T08:53:53.441605] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T08:53:53.448713] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T08:57:53.473528] [SCALING] Scaling step on node virtual-158-0-10 finished. Marking node as full.
[0m[2025-01-17T08:57:58.506328] [SCALING] Next node: virtual-158-0-11

[0m[2025-01-17T08:57:58.517298] =========================================================== Step 3 ===========================================================
[0m[2025-01-17T08:57:58.517314] [SCALING] Scaling on node : vm_grid5000
[0m[2025-01-17T08:57:58.517323] [SCALING] Adding 2 replicas of m taskmanager.
[0m[2025-01-17T08:57:58.521832] [SCALING] Statefulset name to scale : flink-taskmanager-m
[0m[2025-01-17T08:57:58.531682] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 104, 'flink-taskmanager-m': 2, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T08:57:58.540867] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 4 replica.
[0m[2025-01-17T08:58:03.559212] [SCALING] ************************************ Adding 108 replicas ************************************
[0m[2025-01-17T08:58:03.559238] [FLK_MGR] Running job.
[0m[2025-01-17T08:58:03.559243] [FLK_MGR] Rescaling job to 108.
[0m[2025-01-17T08:58:04.257133] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d c5242d580e527621766dbbf3e175c788'] on pod flink-jobmanager-7d7c784b74-lkk8p
[0m[2025-01-17T08:58:08.310472] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-c5242d-9160e7399e0a
[0m[2025-01-17T08:58:28.004170] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-c5242d-9160e7399e0a -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:108;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-lkk8p
[0m[2025-01-17T08:58:30.848609] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 108.
[0m[2025-01-17T08:58:30.848649] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:108;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 108
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID cd1a95c1797b9caf5865ea9379574d90

[0m[2025-01-17T08:58:30.848680] [FLK_MGR] Running job id: cd1a95c1797b9caf5865ea9379574d90
[0m[2025-01-17T08:58:30.848692] [FLK_MGR] Getting job info.
[0m[2025-01-17T08:58:30.954437] [FLK_MGR] Job plan response: {"plan":{"jid":"cd1a95c1797b9caf5865ea9379574d90","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":108,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T08:58:30.954595] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T08:58:31.750793] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-lkk8p
[0m[2025-01-17T08:58:33.441440] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 08:58:30 : cd1a95c1797b9caf5865ea9379574d90 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T08:58:33.441518] [FLK_MGR] Running jobs: ['cd1a95c1797b9caf5865ea9379574d90']
[0m[2025-01-17T08:58:33.441528] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T08:58:33.448546] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T09:02:33.472932] [SCALING] Scaling step on node virtual-158-0-11 finished. Marking node as full.
[0m[2025-01-17T09:02:38.485462] [SCALING] Scaling finished.
[0m[2025-01-17T09:02:38.485556] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-17T09:02:38.538033] [NODE_MGR] Resetting state labels.
[0m[2025-01-17T09:02:38.588222] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-17T09:02:38.606802] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-17T09:02:48.631867] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-17T09:02:53.655698] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-17T09:02:53.668827] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-17T09:02:53.681359] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-17T09:02:53.704332] [POD_MGR] Pod flink-jobmanager-7d7c784b74-lkk8p deleted
[0m[2025-01-17T09:02:55.560622] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-17T09:02:57.457181] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-17T09:02:57.457305] Reloading playbook: application/kafka
[0m[2025-01-17T09:03:03.441484] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-17T09:03:49.364003] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-17T09:03:49.364303] [EXPERIMENT] Run 2 completed. Start: 1737103464, End: 1737104629
[0m[2025-01-17T09:03:49.364311] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-17T09:03:59.365386] [EXPERIMENT] =================================== Starting run 3 ===================================
[0m[2025-01-17T09:04:01.220863] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-17T09:04:03.116750] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-17T09:04:03.116953] [SCALING] Setting up experiment.


[0m[2025-01-17T09:04:03.117055] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-17T09:04:03.122323] [NODE_MGR] Resetting state labels.
[0m[2025-01-17T09:04:03.139326] [SCALING] First node: paradoxe-7.rennes.grid5000.fr

[0m[2025-01-17T09:04:03.156987] [SCALING] Statefulset name to scale : flink-taskmanager-l
[0m[2025-01-17T09:04:03.167317] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 52 replica.
[0m[2025-01-17T09:04:08.176704] [FLK_MGR] Running job.
[0m[2025-01-17T09:04:08.176731] [FLK_MGR] Starting job with 52 parallelism.
[0m[2025-01-17T09:04:08.754948] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 52'] on pod flink-jobmanager-7d7c784b74-p5qrs
[0m[2025-01-17T09:04:12.898513] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID a3dfc90a705e5d93a900d87f7f632ddc

[0m[2025-01-17T09:04:12.898557] [FLK_MGR] Running job id: a3dfc90a705e5d93a900d87f7f632ddc
[0m[2025-01-17T09:04:12.898564] [FLK_MGR] Getting job info.
[0m[2025-01-17T09:04:12.915699] [FLK_MGR] Job plan response: {"plan":{"jid":"a3dfc90a705e5d93a900d87f7f632ddc","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":52,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T09:04:12.915828] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T09:04:13.476155] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-p5qrs
[0m[2025-01-17T09:04:14.898844] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 09:04:11 : a3dfc90a705e5d93a900d87f7f632ddc : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T09:04:14.898899] [FLK_MGR] Running jobs: ['a3dfc90a705e5d93a900d87f7f632ddc']
[0m[2025-01-17T09:04:14.898906] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T09:04:14.898912] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-17T09:08:14.922053] [SCALING] Scaling started.
[0m[2025-01-17T09:08:14.922110] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-17T09:08:14.943884] [SCALING] Next node: paradoxe-8.rennes.grid5000.fr

[0m[2025-01-17T09:08:14.955915] =========================================================== Step 1 ===========================================================
[0m[2025-01-17T09:08:14.955938] [SCALING] Scaling on node : grid5000
[0m[2025-01-17T09:08:14.955951] [SCALING] Adding 52 replicas of l taskmanager.
[0m[2025-01-17T09:08:14.960960] [SCALING] Statefulset name to scale : flink-taskmanager-l
[0m[2025-01-17T09:08:14.970269] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 52, 'flink-taskmanager-m': 0, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T09:08:14.979799] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 104 replica.
[0m[2025-01-17T09:08:19.999181] [SCALING] ************************************ Adding 104 replicas ************************************
[0m[2025-01-17T09:08:19.999210] [FLK_MGR] Running job.
[0m[2025-01-17T09:08:19.999216] [FLK_MGR] Rescaling job to 104.
[0m[2025-01-17T09:08:20.676170] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d a3dfc90a705e5d93a900d87f7f632ddc'] on pod flink-jobmanager-7d7c784b74-p5qrs
[0m[2025-01-17T09:08:26.771332] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-a3dfc9-2dda445eea40
[0m[2025-01-17T09:08:46.515988] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-a3dfc9-2dda445eea40 -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:104;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-p5qrs
[0m[2025-01-17T09:08:49.624909] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 104.
[0m[2025-01-17T09:08:49.624948] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:104;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 104
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID 0d7fbf878b7d3982b02624c703194f52

[0m[2025-01-17T09:08:49.624969] [FLK_MGR] Running job id: 0d7fbf878b7d3982b02624c703194f52
[0m[2025-01-17T09:08:49.624975] [FLK_MGR] Getting job info.
[0m[2025-01-17T09:08:49.633245] [FLK_MGR] Job plan response: {"plan":{"jid":"0d7fbf878b7d3982b02624c703194f52","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":104,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T09:08:49.633419] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T09:08:50.371179] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-p5qrs
[0m[2025-01-17T09:08:52.298222] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 09:08:49 : 0d7fbf878b7d3982b02624c703194f52 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T09:08:52.298291] [FLK_MGR] Running jobs: ['0d7fbf878b7d3982b02624c703194f52']
[0m[2025-01-17T09:08:52.298299] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T09:08:52.311105] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T09:12:52.334800] [SCALING] Scaling step on node paradoxe-8.rennes.grid5000.fr finished. Marking node as full.
[0m[2025-01-17T09:12:57.367633] [SCALING] Next node: virtual-158-0-10

[0m[2025-01-17T09:12:57.377743] =========================================================== Step 2 ===========================================================
[0m[2025-01-17T09:12:57.377762] [SCALING] Scaling on node : vm_grid5000
[0m[2025-01-17T09:12:57.377772] [SCALING] Adding 2 replicas of m taskmanager.
[0m[2025-01-17T09:12:57.383369] [SCALING] Statefulset name to scale : flink-taskmanager-m
[0m[2025-01-17T09:12:57.392381] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 104, 'flink-taskmanager-m': 0, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T09:12:57.402356] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 2 replica.
[0m[2025-01-17T09:13:02.423138] [SCALING] ************************************ Adding 106 replicas ************************************
[0m[2025-01-17T09:13:02.423167] [FLK_MGR] Running job.
[0m[2025-01-17T09:13:02.423174] [FLK_MGR] Rescaling job to 106.
[0m[2025-01-17T09:13:03.110867] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d 0d7fbf878b7d3982b02624c703194f52'] on pod flink-jobmanager-7d7c784b74-p5qrs
[0m[2025-01-17T09:13:05.929864] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-0d7fbf-657deaf61388
[0m[2025-01-17T09:13:25.734470] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-0d7fbf-657deaf61388 -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:106;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-p5qrs
[0m[2025-01-17T09:13:28.646583] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 106.
[0m[2025-01-17T09:13:28.646618] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:106;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 106
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID 8fe5f7d8d937f245fa040723ec5d6727

[0m[2025-01-17T09:13:28.646635] [FLK_MGR] Running job id: 8fe5f7d8d937f245fa040723ec5d6727
[0m[2025-01-17T09:13:28.646641] [FLK_MGR] Getting job info.
[0m[2025-01-17T09:13:28.747848] [FLK_MGR] Job plan response: {"plan":{"jid":"8fe5f7d8d937f245fa040723ec5d6727","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":106,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T09:13:28.748037] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T09:13:29.809144] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-p5qrs
[0m[2025-01-17T09:13:31.390198] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 09:13:28 : 8fe5f7d8d937f245fa040723ec5d6727 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T09:13:31.390270] [FLK_MGR] Running jobs: ['8fe5f7d8d937f245fa040723ec5d6727']
[0m[2025-01-17T09:13:31.390278] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T09:13:31.398803] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T09:17:31.422297] [SCALING] Scaling step on node virtual-158-0-10 finished. Marking node as full.
[0m[2025-01-17T09:17:36.458695] [SCALING] Next node: virtual-158-0-11

[0m[2025-01-17T09:17:36.471272] =========================================================== Step 3 ===========================================================
[0m[2025-01-17T09:17:36.471300] [SCALING] Scaling on node : vm_grid5000
[0m[2025-01-17T09:17:36.471317] [SCALING] Adding 2 replicas of m taskmanager.
[0m[2025-01-17T09:17:36.476673] [SCALING] Statefulset name to scale : flink-taskmanager-m
[0m[2025-01-17T09:17:36.485900] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 104, 'flink-taskmanager-m': 2, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T09:17:36.495322] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 4 replica.
[0m[2025-01-17T09:17:41.513328] [SCALING] ************************************ Adding 108 replicas ************************************
[0m[2025-01-17T09:17:41.513364] [FLK_MGR] Running job.
[0m[2025-01-17T09:17:41.513370] [FLK_MGR] Rescaling job to 108.
[0m[2025-01-17T09:17:42.234167] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d 8fe5f7d8d937f245fa040723ec5d6727'] on pod flink-jobmanager-7d7c784b74-p5qrs
[0m[2025-01-17T09:17:45.002855] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-8fe5f7-98c68a0c6203
[0m[2025-01-17T09:18:04.768510] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-8fe5f7-98c68a0c6203 -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:108;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-p5qrs
[0m[2025-01-17T09:18:07.557168] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 108.
[0m[2025-01-17T09:18:07.557204] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:108;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 108
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID dd672f2095491e9b15e9c1cba5db2c7c

[0m[2025-01-17T09:18:07.557222] [FLK_MGR] Running job id: dd672f2095491e9b15e9c1cba5db2c7c
[0m[2025-01-17T09:18:07.557228] [FLK_MGR] Getting job info.
[0m[2025-01-17T09:18:07.659924] [FLK_MGR] Job plan response: {"plan":{"jid":"dd672f2095491e9b15e9c1cba5db2c7c","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":108,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T09:18:07.660080] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T09:18:08.395399] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-p5qrs
[0m[2025-01-17T09:18:09.920419] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 09:18:07 : dd672f2095491e9b15e9c1cba5db2c7c : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T09:18:09.920502] [FLK_MGR] Running jobs: ['dd672f2095491e9b15e9c1cba5db2c7c']
[0m[2025-01-17T09:18:09.920512] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T09:18:09.929896] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T09:22:09.953589] [SCALING] Scaling step on node virtual-158-0-11 finished. Marking node as full.
[0m[2025-01-17T09:22:14.965957] [SCALING] Scaling finished.
[0m[2025-01-17T09:22:14.966023] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-17T09:22:15.020944] [NODE_MGR] Resetting state labels.
[0m[2025-01-17T09:22:15.072896] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-17T09:22:15.090867] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-17T09:22:20.110793] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-17T09:22:25.132375] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-17T09:22:25.145601] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-17T09:22:25.160835] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-17T09:22:25.183745] [POD_MGR] Pod flink-jobmanager-7d7c784b74-p5qrs deleted
[0m[2025-01-17T09:22:27.050885] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-17T09:22:28.944256] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-17T09:22:28.944321] Reloading playbook: application/kafka
[0m[2025-01-17T09:22:34.837781] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-17T09:23:20.776713] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-17T09:23:20.776874] [EXPERIMENT] Run 3 completed. Start: 1737104639, End: 1737105800
[0m[2025-01-17T09:23:20.776880] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-17T09:23:30.777955] [EXPERIMENT] =================================== Starting run 4 ===================================
[0m[2025-01-17T09:23:32.664427] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-17T09:23:34.550447] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-17T09:23:34.550515] [SCALING] Setting up experiment.


[0m[2025-01-17T09:23:34.550523] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-17T09:23:34.556534] [NODE_MGR] Resetting state labels.
[0m[2025-01-17T09:23:34.571795] [SCALING] First node: paradoxe-7.rennes.grid5000.fr

[0m[2025-01-17T09:23:34.587884] [SCALING] Statefulset name to scale : flink-taskmanager-l
[0m[2025-01-17T09:23:34.597168] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 52 replica.
[0m[2025-01-17T09:23:39.607755] [FLK_MGR] Running job.
[0m[2025-01-17T09:23:39.607787] [FLK_MGR] Starting job with 52 parallelism.
[0m[2025-01-17T09:23:40.190171] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 52'] on pod flink-jobmanager-7d7c784b74-sb6bg
[0m[2025-01-17T09:23:44.339997] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID bab118190391ca6b56b927db46b542cb

[0m[2025-01-17T09:23:44.340094] [FLK_MGR] Running job id: bab118190391ca6b56b927db46b542cb
[0m[2025-01-17T09:23:44.340108] [FLK_MGR] Getting job info.
[0m[2025-01-17T09:23:44.357037] [FLK_MGR] Job plan response: {"plan":{"jid":"bab118190391ca6b56b927db46b542cb","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":52,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T09:23:44.357337] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T09:23:44.905961] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sb6bg
[0m[2025-01-17T09:23:46.346041] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 09:23:43 : bab118190391ca6b56b927db46b542cb : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T09:23:46.346094] [FLK_MGR] Running jobs: ['bab118190391ca6b56b927db46b542cb']
[0m[2025-01-17T09:23:46.346100] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T09:23:46.346107] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-17T09:27:46.370157] [SCALING] Scaling started.
[0m[2025-01-17T09:27:46.370213] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-17T09:27:46.392080] [SCALING] Next node: paradoxe-8.rennes.grid5000.fr

[0m[2025-01-17T09:27:46.403538] =========================================================== Step 1 ===========================================================
[0m[2025-01-17T09:27:46.403556] [SCALING] Scaling on node : grid5000
[0m[2025-01-17T09:27:46.403568] [SCALING] Adding 52 replicas of l taskmanager.
[0m[2025-01-17T09:27:46.408584] [SCALING] Statefulset name to scale : flink-taskmanager-l
[0m[2025-01-17T09:27:46.417774] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 52, 'flink-taskmanager-m': 0, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T09:27:46.428257] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 104 replica.
[0m[2025-01-17T09:27:51.448770] [SCALING] ************************************ Adding 104 replicas ************************************
[0m[2025-01-17T09:27:51.448799] [FLK_MGR] Running job.
[0m[2025-01-17T09:27:51.448804] [FLK_MGR] Rescaling job to 104.
[0m[2025-01-17T09:27:52.126318] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d bab118190391ca6b56b927db46b542cb'] on pod flink-jobmanager-7d7c784b74-sb6bg
[0m[2025-01-17T09:27:56.202436] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-bab118-3c0659b40722
[0m[2025-01-17T09:28:15.935638] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-bab118-3c0659b40722 -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:104;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-sb6bg
[0m[2025-01-17T09:28:19.043488] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 104.
[0m[2025-01-17T09:28:19.043527] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:104;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 104
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID c57886e65bcd7c715ee20d350a8d3ec4

[0m[2025-01-17T09:28:19.043546] [FLK_MGR] Running job id: c57886e65bcd7c715ee20d350a8d3ec4
[0m[2025-01-17T09:28:19.043555] [FLK_MGR] Getting job info.
[0m[2025-01-17T09:28:19.108378] [FLK_MGR] Job plan response: {"plan":{"jid":"c57886e65bcd7c715ee20d350a8d3ec4","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":104,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T09:28:19.108541] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T09:28:19.839497] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sb6bg
[0m[2025-01-17T09:28:21.551676] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 09:28:18 : c57886e65bcd7c715ee20d350a8d3ec4 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T09:28:21.551744] [FLK_MGR] Running jobs: ['c57886e65bcd7c715ee20d350a8d3ec4']
[0m[2025-01-17T09:28:21.551752] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T09:28:21.559801] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T09:32:21.583781] [SCALING] Scaling step on node paradoxe-8.rennes.grid5000.fr finished. Marking node as full.
[0m[2025-01-17T09:32:26.617386] [SCALING] Next node: virtual-158-0-10

[0m[2025-01-17T09:32:26.628208] =========================================================== Step 2 ===========================================================
[0m[2025-01-17T09:32:26.628232] [SCALING] Scaling on node : vm_grid5000
[0m[2025-01-17T09:32:26.628242] [SCALING] Adding 2 replicas of m taskmanager.
[0m[2025-01-17T09:32:26.633252] [SCALING] Statefulset name to scale : flink-taskmanager-m
[0m[2025-01-17T09:32:26.642611] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 104, 'flink-taskmanager-m': 0, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T09:32:26.652390] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 2 replica.
[0m[2025-01-17T09:32:31.671176] [SCALING] ************************************ Adding 106 replicas ************************************
[0m[2025-01-17T09:32:31.671201] [FLK_MGR] Running job.
[0m[2025-01-17T09:32:31.671206] [FLK_MGR] Rescaling job to 106.
[0m[2025-01-17T09:32:32.345310] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d c57886e65bcd7c715ee20d350a8d3ec4'] on pod flink-jobmanager-7d7c784b74-sb6bg
[0m[2025-01-17T09:32:36.400868] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-c57886-3973a15c1291
[0m[2025-01-17T09:32:56.147421] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-c57886-3973a15c1291 -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:106;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-sb6bg
[0m[2025-01-17T09:32:59.060795] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 106.
[0m[2025-01-17T09:32:59.060832] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:106;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 106
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID 5ddf95c408a7eedf2ac383173a4e05d0

[0m[2025-01-17T09:32:59.060856] [FLK_MGR] Running job id: 5ddf95c408a7eedf2ac383173a4e05d0
[0m[2025-01-17T09:32:59.060867] [FLK_MGR] Getting job info.
[0m[2025-01-17T09:32:59.138850] [FLK_MGR] Job plan response: {"plan":{"jid":"5ddf95c408a7eedf2ac383173a4e05d0","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":106,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T09:32:59.139047] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T09:32:59.918643] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sb6bg
[0m[2025-01-17T09:33:01.442744] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 09:32:58 : 5ddf95c408a7eedf2ac383173a4e05d0 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T09:33:01.442810] [FLK_MGR] Running jobs: ['5ddf95c408a7eedf2ac383173a4e05d0']
[0m[2025-01-17T09:33:01.442818] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T09:33:01.450127] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T09:37:01.475180] [SCALING] Scaling step on node virtual-158-0-10 finished. Marking node as full.
[0m[2025-01-17T09:37:06.510157] [SCALING] Next node: virtual-158-0-11

[0m[2025-01-17T09:37:06.519647] =========================================================== Step 3 ===========================================================
[0m[2025-01-17T09:37:06.519665] [SCALING] Scaling on node : vm_grid5000
[0m[2025-01-17T09:37:06.519675] [SCALING] Adding 2 replicas of m taskmanager.
[0m[2025-01-17T09:37:06.524194] [SCALING] Statefulset name to scale : flink-taskmanager-m
[0m[2025-01-17T09:37:06.532993] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 104, 'flink-taskmanager-m': 2, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T09:37:06.541841] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 4 replica.
[0m[2025-01-17T09:37:11.559240] [SCALING] ************************************ Adding 108 replicas ************************************
[0m[2025-01-17T09:37:11.559264] [FLK_MGR] Running job.
[0m[2025-01-17T09:37:11.559269] [FLK_MGR] Rescaling job to 108.
[0m[2025-01-17T09:37:12.271440] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d 5ddf95c408a7eedf2ac383173a4e05d0'] on pod flink-jobmanager-7d7c784b74-sb6bg
[0m[2025-01-17T09:37:18.317163] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-5ddf95-293334c94bc4
[0m[2025-01-17T09:37:38.094129] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-5ddf95-293334c94bc4 -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:108;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-sb6bg
[0m[2025-01-17T09:37:41.054170] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 108.
[0m[2025-01-17T09:37:41.054213] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:108;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 108
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID 1c3aa73f20978d8e0da92645d83c62af

[0m[2025-01-17T09:37:41.054233] [FLK_MGR] Running job id: 1c3aa73f20978d8e0da92645d83c62af
[0m[2025-01-17T09:37:41.054239] [FLK_MGR] Getting job info.
[0m[2025-01-17T09:37:41.134043] [FLK_MGR] Job plan response: {"plan":{"jid":"1c3aa73f20978d8e0da92645d83c62af","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":108,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T09:37:41.134419] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T09:37:41.965934] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-sb6bg
[0m[2025-01-17T09:37:43.552140] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 09:37:40 : 1c3aa73f20978d8e0da92645d83c62af : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T09:37:43.552212] [FLK_MGR] Running jobs: ['1c3aa73f20978d8e0da92645d83c62af']
[0m[2025-01-17T09:37:43.552222] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T09:37:43.560003] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T09:41:43.584260] [SCALING] Scaling step on node virtual-158-0-11 finished. Marking node as full.
[0m[2025-01-17T09:41:48.595967] [SCALING] Scaling finished.
[0m[2025-01-17T09:41:48.596029] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-17T09:41:48.647538] [NODE_MGR] Resetting state labels.
[0m[2025-01-17T09:41:48.698749] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-17T09:41:48.718374] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-17T09:41:58.742104] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-17T09:42:03.762575] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-17T09:42:03.774434] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-17T09:42:03.786193] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-17T09:42:03.805294] [POD_MGR] Pod flink-jobmanager-7d7c784b74-sb6bg deleted
[0m[2025-01-17T09:42:05.703261] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-17T09:42:07.569701] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-17T09:42:07.569768] Reloading playbook: application/kafka
[0m[2025-01-17T09:42:13.421243] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-17T09:43:19.351162] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-17T09:43:19.351339] [EXPERIMENT] Run 4 completed. Start: 1737105810, End: 1737106999
[0m[2025-01-17T09:43:19.351348] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-17T09:43:29.352440] [EXPERIMENT] =================================== Starting run 5 ===================================
[0m[2025-01-17T09:43:31.221782] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-17T09:43:33.072485] Playbook /app/playbooks/application/load_generators.yaml with tag create executed successfully.
[0m[2025-01-17T09:43:33.072552] [SCALING] Setting up experiment.


[0m[2025-01-17T09:43:33.072562] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-17T09:43:33.077840] [NODE_MGR] Resetting state labels.
[0m[2025-01-17T09:43:33.090289] [SCALING] First node: paradoxe-7.rennes.grid5000.fr

[0m[2025-01-17T09:43:33.106661] [SCALING] Statefulset name to scale : flink-taskmanager-l
[0m[2025-01-17T09:43:33.116555] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 52 replica.
[0m[2025-01-17T09:43:38.126115] [FLK_MGR] Running job.
[0m[2025-01-17T09:43:38.126142] [FLK_MGR] Starting job with 52 parallelism.
[0m[2025-01-17T09:43:38.678206] [POD_MGR] Running command ['/bin/sh', '-c', 'flink run -d -j /tmp/jobs/myjoin-transscale-all.jar --start_par 52'] on pod flink-jobmanager-7d7c784b74-vjl69
[0m[2025-01-17T09:43:42.746351] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Job has been submitted with JobID fffe55adbb4202a950fc56379f0b859a

[0m[2025-01-17T09:43:42.746400] [FLK_MGR] Running job id: fffe55adbb4202a950fc56379f0b859a
[0m[2025-01-17T09:43:42.746408] [FLK_MGR] Getting job info.
[0m[2025-01-17T09:43:42.765507] [FLK_MGR] Job plan response: {"plan":{"jid":"fffe55adbb4202a950fc56379f0b859a","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":52,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T09:43:42.765740] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T09:43:43.329943] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-vjl69
[0m[2025-01-17T09:43:44.768873] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 09:43:41 : fffe55adbb4202a950fc56379f0b859a : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T09:43:44.768924] [FLK_MGR] Running jobs: ['fffe55adbb4202a950fc56379f0b859a']
[0m[2025-01-17T09:43:44.768931] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T09:43:44.768937] [SCALING] First iteration after setup, just waiting...
[0m[2025-01-17T09:47:44.792122] [SCALING] Scaling started.
[0m[2025-01-17T09:47:44.792179] [SCALING] First node and first taskmanager already scaled, mark node as full. Continue to next step.

[0m[2025-01-17T09:47:44.812334] [SCALING] Next node: paradoxe-8.rennes.grid5000.fr

[0m[2025-01-17T09:47:44.822959] =========================================================== Step 1 ===========================================================
[0m[2025-01-17T09:47:44.822975] [SCALING] Scaling on node : grid5000
[0m[2025-01-17T09:47:44.822988] [SCALING] Adding 52 replicas of l taskmanager.
[0m[2025-01-17T09:47:44.828059] [SCALING] Statefulset name to scale : flink-taskmanager-l
[0m[2025-01-17T09:47:44.838440] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 52, 'flink-taskmanager-m': 0, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T09:47:44.848777] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 104 replica.
[0m[2025-01-17T09:47:49.868367] [SCALING] ************************************ Adding 104 replicas ************************************
[0m[2025-01-17T09:47:49.868395] [FLK_MGR] Running job.
[0m[2025-01-17T09:47:49.868400] [FLK_MGR] Rescaling job to 104.
[0m[2025-01-17T09:47:50.622206] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d fffe55adbb4202a950fc56379f0b859a'] on pod flink-jobmanager-7d7c784b74-vjl69
[0m[2025-01-17T09:47:53.422960] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-fffe55-bdd987e5f21e
[0m[2025-01-17T09:48:13.095516] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-fffe55-bdd987e5f21e -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:104;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-vjl69
[0m[2025-01-17T09:48:16.223653] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 104.
[0m[2025-01-17T09:48:16.223695] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:104;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 104
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID 8a00e04a72acd94f24b7383cbce754e6

[0m[2025-01-17T09:48:16.223717] [FLK_MGR] Running job id: 8a00e04a72acd94f24b7383cbce754e6
[0m[2025-01-17T09:48:16.223724] [FLK_MGR] Getting job info.
[0m[2025-01-17T09:48:16.231271] [FLK_MGR] Job plan response: {"plan":{"jid":"8a00e04a72acd94f24b7383cbce754e6","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":104,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T09:48:16.231444] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T09:48:17.062413] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-vjl69
[0m[2025-01-17T09:48:18.654299] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 09:48:15 : 8a00e04a72acd94f24b7383cbce754e6 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T09:48:18.654366] [FLK_MGR] Running jobs: ['8a00e04a72acd94f24b7383cbce754e6']
[0m[2025-01-17T09:48:18.654374] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T09:48:18.662117] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T09:52:18.685153] [SCALING] Scaling step on node paradoxe-8.rennes.grid5000.fr finished. Marking node as full.
[0m[2025-01-17T09:52:23.719204] [SCALING] Next node: virtual-158-0-10

[0m[2025-01-17T09:52:23.730414] =========================================================== Step 2 ===========================================================
[0m[2025-01-17T09:52:23.730431] [SCALING] Scaling on node : vm_grid5000
[0m[2025-01-17T09:52:23.730440] [SCALING] Adding 2 replicas of m taskmanager.
[0m[2025-01-17T09:52:23.735213] [SCALING] Statefulset name to scale : flink-taskmanager-m
[0m[2025-01-17T09:52:23.744602] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 104, 'flink-taskmanager-m': 0, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T09:52:23.754441] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 2 replica.
[0m[2025-01-17T09:52:28.774526] [SCALING] ************************************ Adding 106 replicas ************************************
[0m[2025-01-17T09:52:28.774554] [FLK_MGR] Running job.
[0m[2025-01-17T09:52:28.774560] [FLK_MGR] Rescaling job to 106.
[0m[2025-01-17T09:52:29.528918] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d 8a00e04a72acd94f24b7383cbce754e6'] on pod flink-jobmanager-7d7c784b74-vjl69
[0m[2025-01-17T09:52:31.616709] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-8a00e0-d17a20fa0620
[0m[2025-01-17T09:52:51.303824] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-8a00e0-d17a20fa0620 -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:106;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-vjl69
[0m[2025-01-17T09:52:54.222716] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 106.
[0m[2025-01-17T09:52:54.222752] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:106;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 106
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID 095a198f84c6ec3713a06897b859ba83

[0m[2025-01-17T09:52:54.222770] [FLK_MGR] Running job id: 095a198f84c6ec3713a06897b859ba83
[0m[2025-01-17T09:52:54.222779] [FLK_MGR] Getting job info.
[0m[2025-01-17T09:52:54.336796] [FLK_MGR] Job plan response: {"plan":{"jid":"095a198f84c6ec3713a06897b859ba83","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":106,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T09:52:54.336966] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T09:52:55.066071] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-vjl69
[0m[2025-01-17T09:52:56.599846] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 09:52:54 : 095a198f84c6ec3713a06897b859ba83 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T09:52:56.599913] [FLK_MGR] Running jobs: ['095a198f84c6ec3713a06897b859ba83']
[0m[2025-01-17T09:52:56.599920] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T09:52:56.607295] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T09:56:56.630849] [SCALING] Scaling step on node virtual-158-0-10 finished. Marking node as full.
[0m[2025-01-17T09:57:01.661791] [SCALING] Next node: virtual-158-0-11

[0m[2025-01-17T09:57:01.672309] =========================================================== Step 3 ===========================================================
[0m[2025-01-17T09:57:01.672333] [SCALING] Scaling on node : vm_grid5000
[0m[2025-01-17T09:57:01.672344] [SCALING] Adding 2 replicas of m taskmanager.
[0m[2025-01-17T09:57:01.676741] [SCALING] Statefulset name to scale : flink-taskmanager-m
[0m[2025-01-17T09:57:01.688377] [SCALING] Current taskmanagers count: {'flink-taskmanager-l': 104, 'flink-taskmanager-m': 2, 'flink-taskmanager-s': 0, 'flink-taskmanager-xl': 0, 'flink-taskmanager-xxl': 0}
[0m[2025-01-17T09:57:01.698569] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 4 replica.
[0m[2025-01-17T09:57:06.716910] [SCALING] ************************************ Adding 108 replicas ************************************
[0m[2025-01-17T09:57:06.716946] [FLK_MGR] Running job.
[0m[2025-01-17T09:57:06.716952] [FLK_MGR] Rescaling job to 108.
[0m[2025-01-17T09:57:07.465001] [POD_MGR] Running command ['/bin/sh', '-c', 'flink stop -p -d 095a198f84c6ec3713a06897b859ba83'] on pod flink-jobmanager-7d7c784b74-vjl69
[0m[2025-01-17T09:57:11.535815] [FLK_MGR] Savepoint path: s3://flink-bucket/savepoints/savepoint-095a19-a210c6a61e30
[0m[2025-01-17T09:57:31.236155] [POD_MGR] Running command ['/bin/sh', '-c', "flink run -d -s s3://flink-bucket/savepoints/savepoint-095a19-a210c6a61e30 -j /tmp/jobs/myjoin-transscale-all.jar --parmap 'Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:108;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1'"] on pod flink-jobmanager-7d7c784b74-vjl69
[0m[2025-01-17T09:57:34.155756] [FLK_MGR] Operator TumblingEventTimeWindows rescaled to 108.
[0m[2025-01-17T09:57:34.155804] [FLK_MGR] Job run response: ERROR StatusLogger Reconfiguration failed: No configuration found for '37f8bb67' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for '34e9fd99' at 'null' in 'null'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator (file:/opt/flink/lib/flink-dist-1.20.0.jar) to field java.util.Collections$UnmodifiableMap.m
WARNING: Please consider reporting this to the maintainers of org.apache.flink.streaming.runtime.translators.DataStreamV2SinkTransformationTranslator
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
KAFKA_BOOTSTRAP_SERVERS: kafka-service.kafka.svc.cluster.local:9092
SCHEMA_REGISTRY_URL: http://schema-registry-service.kafka.svc.cluster.local:8081
KAFKA_INPUT_TOPIC1: input-topic1
KAFKA_INPUT_TOPIC2: input-topic2
JOB_WINDOW_SIZE: 1000
CHECKPOINTING: true
FIB_INPUT: 18
Starting JoinApplication.
Sink__Sink:1;Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks:108;Timestamps/Watermarks+-_Map:1;Source__Source1:1;Source__Source2:1
Sink__Sink --> 1
Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks --> 108
Timestamps/Watermarks+-_Map --> 1
Source__Source1 --> 1
Source__Source2 --> 1
Job has been submitted with JobID 34f7d958cc47f2c5e772902fc51b3971

[0m[2025-01-17T09:57:34.155828] [FLK_MGR] Running job id: 34f7d958cc47f2c5e772902fc51b3971
[0m[2025-01-17T09:57:34.155834] [FLK_MGR] Getting job info.
[0m[2025-01-17T09:57:34.242151] [FLK_MGR] Job plan response: {"plan":{"jid":"34f7d958cc47f2c5e772902fc51b3971","name":"myjoin-transscale-0.0.1","type":"STREAMING","nodes":[{"id":"41a95396e613c9f62f1da16142d5ddd2","parallelism":1,"operator":"","operator_strategy":"","description":"Sink: Sink<br/>","inputs":[{"num":0,"id":"32f0ffe0b6f0b990239bb81cec28b9d8","ship_strategy":"REBALANCE","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"32f0ffe0b6f0b990239bb81cec28b9d8","parallelism":108,"operator":"","operator_strategy":"","description":"Window(TumblingEventTimeWindows(1000), EventTimeTrigger, TimeEvictor, CoGroupWindowFunction)<br/>+- Timestamps/Watermarks<br/>","inputs":[{"num":0,"id":"31ec045e3401e87fc7879b43d8e8625d","ship_strategy":"HASH","exchange":"pipelined_bounded"},{"num":1,"id":"e926317ddf99720773e3c7f4f412c3d7","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"31ec045e3401e87fc7879b43d8e8625d","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"dca33db40b2f8f122636cd5297c0c511","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"dca33db40b2f8f122636cd5297c0c511","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source1<br/>","optimizer_properties":{}},{"id":"e926317ddf99720773e3c7f4f412c3d7","parallelism":1,"operator":"","operator_strategy":"","description":"Timestamps/Watermarks<br/>+- Map<br/>","inputs":[{"num":0,"id":"9c7327831b3b5b4ae2c580979f474a9c","ship_strategy":"HASH","exchange":"pipelined_bounded"}],"optimizer_properties":{}},{"id":"9c7327831b3b5b4ae2c580979f474a9c","parallelism":1,"operator":"","operator_strategy":"","description":"Source: Source2<br/>","optimizer_properties":{}}]}}
[0m[2025-01-17T09:57:34.242311] [FLK_MGR] Current operator names: dict_keys(['Sink__Sink', 'Window(TumblingEventTimeWindows(1000),_EventTimeTrigger,_TimeEvictor,_CoGroupWindowFunction)+-_Timestamps/Watermarks', 'Timestamps/Watermarks+-_Map', 'Source__Source1', 'Source__Source2'])
[0m[2025-01-17T09:57:34.963897] [POD_MGR] Running command ['/bin/sh', '-c', 'flink list -r 2>/dev/null'] on pod flink-jobmanager-7d7c784b74-vjl69
[0m[2025-01-17T09:57:36.491916] [FLK_MGR] Running jobs: Waiting for response...
------------------ Running/Restarting Jobs -------------------
17.01.2025 09:57:33 : 34f7d958cc47f2c5e772902fc51b3971 : myjoin-transscale-0.0.1 (RUNNING)
--------------------------------------------------------------
[0m[2025-01-17T09:57:36.491986] [FLK_MGR] Running jobs: ['34f7d958cc47f2c5e772902fc51b3971']
[0m[2025-01-17T09:57:36.491995] [FLK_MGR] Total jobs cancelled: 0
[0m[2025-01-17T09:57:36.499022] [SCALING] Monitoring interval: for 240 seconds
[0m[2025-01-17T10:01:36.523721] [SCALING] Scaling step on node virtual-158-0-11 finished. Marking node as full.
[0m[2025-01-17T10:01:41.536504] [SCALING] Scaling finished.
[0m[2025-01-17T10:01:41.536769] [NODE_MGR] Resetting scaling labels to unschedulable.
[0m[2025-01-17T10:01:41.594465] [NODE_MGR] Resetting state labels.
[0m[2025-01-17T10:01:41.643844] [STS_MGR] Resetting taskmanagers.
[0m[2025-01-17T10:01:41.662170] [STS_MGR] StatefulSet flink-taskmanager-l scaled to 0 replica.
[0m[2025-01-17T10:01:51.687014] [STS_MGR] StatefulSet flink-taskmanager-m scaled to 0 replica.
[0m[2025-01-17T10:01:56.707322] [STS_MGR] StatefulSet flink-taskmanager-s scaled to 0 replica.
[0m[2025-01-17T10:01:56.720136] [STS_MGR] StatefulSet flink-taskmanager-xl scaled to 0 replica.
[0m[2025-01-17T10:01:56.732408] [STS_MGR] StatefulSet flink-taskmanager-xxl scaled to 0 replica.
[0m[2025-01-17T10:01:56.752096] [POD_MGR] Pod flink-jobmanager-7d7c784b74-vjl69 deleted
[0m[2025-01-17T10:01:58.647372] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-17T10:02:00.574826] Playbook /app/playbooks/application/load_generators.yaml with tag delete executed successfully.
[0m[2025-01-17T10:02:00.574896] Reloading playbook: application/kafka
[0m[2025-01-17T10:02:06.540634] Playbook /app/playbooks/application/kafka.yaml with tag delete executed successfully.
[0m[2025-01-17T10:02:52.482983] Playbook /app/playbooks/application/kafka.yaml with tag create executed successfully.
[0m[2025-01-17T10:02:52.483150] [EXPERIMENT] Run 5 completed. Start: 1737107009, End: 1737108172
[0m[2025-01-17T10:02:52.483157] [EXPERIMENT] Sleeping for 10 seconds before next run.
[0m[2025-01-17T10:03:02.484737] [FSM] Run phase complete, transitioning to finishing.
[0m[2025-01-17T10:03:02.485287] [FSM] Finish phase started.
[0m[2025-01-17T10:03:02.485316] [FSM] State is States.FINISHING
[0m[2025-01-17T10:03:02.485773] FolderManager initialized with base path: /experiment-volume. Date: None
