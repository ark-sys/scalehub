#!/usr/bin/env python3
import argparse
from time import sleep

from src.Client import Client, Playbooks
from src.G5k import G5k
from src.Platform import Platform
from utils.Config import Config
from utils.Defaults import DefaultKeys as Key, DefaultValues as Value
from utils.KubernetesManager import KubernetesManager
from utils.Logger import Logger


# Build cluster and install dependencies
def provision(config: Config):
    platform_type = config.get_str(Key.Platform.type)
    match platform_type:
        case "Grid5000":
            # Initiate oarsub request
            log.info("Reserving...")
            p: Platform = G5k(config, log)

            inventory = p.setup()

            # Dump list of requested nodes to file
            with open(config.get_str(Key.Scalehub.inventory), "w") as f:
                f.write(inventory)

            # Setup cluster with kubernetes
            p: Playbooks = Playbooks()
            kubernetes_type = (
                f"cluster-setup.{config.get_str(Key.Platform.kubernetes_type)}"
            )
            return p.run_playbook(kubernetes_type, config=config)

        case _:
            log.error(f"Provision is not implemented for platform {platform_type}")


# Destroy cluster
def destroy(config: Config):
    platform_type = config.get_str(Key.Platform.type)
    match platform_type:
        case "Grid5000":
            # Initiate oardel request
            p: Platform = G5k(config, log)
            return p.destroy()
        case _:
            log.error(f"Destroy is not implemented for platform {platform_type}")


# Execute tasks with "deploy" tag for a given playbook
def deploy(playbook, config: Config):
    log.info(f"Executing deployment tasks in playbook : {playbook} ...")
    p: Playbooks = Playbooks()
    tag = "create"
    if playbook == "load_generators":
        for lg_config in config.get(Key.Experiment.Generators.generators):
            load_generator_params = {
                "lg_name": lg_config["name"],
                "lg_topic": lg_config["topic"],
                "lg_numsensors": int(lg_config["num_sensors"]),
                "lg_intervalms": int(lg_config["interval_ms"]),
                "lg_replicas": int(lg_config["replicas"]),
                "lg_value": int(lg_config["value"]),
            }
            p.run_playbook(
                playbook,
                config=config,
                tag=tag,
                extra_vars=load_generator_params,
            )
    else:
        return p.run_playbook(playbook, config=config, tag=tag)


# Execute tasks with "delete" tag for a given playbook
def delete(playbook, config: Config):
    log.info(f"Executing deletion tasks in playbook : {playbook} ...")
    p: Playbooks = Playbooks()
    tag = "delete"
    if playbook == "load_generators":
        for lg_config in config.get(Key.Experiment.Generators.generators):
            load_generator_params = {
                "lg_name": lg_config["name"],
                "lg_topic": lg_config["topic"],
                "lg_numsensors": int(lg_config["num_sensors"]),
                "lg_intervalms": int(lg_config["interval_ms"]),
                "lg_replicas": int(lg_config["replicas"]),
                "lg_value": int(lg_config["value"]),
            }
            p.run_playbook(
                playbook,
                config=config,
                tag=tag,
                extra_vars=load_generator_params,
            )
    else:
        return p.run_playbook(playbook, config=config, tag=tag)


# Delete and re-deploy 'playbook' parameter
def reload(playbook, config: Config):
    # Delete running playbook
    delete(playbook, config)
    # Give some time for tasks to execute
    sleep(5)
    # Deploy again playbook
    deploy(playbook, config)


def experiment(action, config: Config):
    e: Client = Client(log, config)
    match action:
        case "start":
            e.start()
        case "stop":
            e.stop()
        case "clean":
            e.clean()
        case "check":
            e.check()
        case _:
            log.error(f"Action {action} is not implemented for command 'experiment'.")


# Get tokens for minio and kubernetes dashboard
def tokens():
    k: KubernetesManager = KubernetesManager(log)

    # Retrieve token for minio console
    minio_console_token = k.get_token("console-sa-secret", "minio-operator")
    kubernetes_dashboard_token = k.get_token("admin-user", "kubernetes-dashboard")

    # Print tokens in a readable format and easy to copy-paste
    log.info(f"Minio Console Token : \n{minio_console_token}\n\n")
    log.info(f"Kubernetes Dashboard Token : \n{kubernetes_dashboard_token}\n\n")


# Quick action commands
def run(action, action_type, config: Config):
    log.debug(f"Running action {action} ...")
    k: KubernetesManager = KubernetesManager(log)
    p: Playbooks = Playbooks()
    match action:
        case "job":
            return k.execute_command_on_pod(
                deployment_name="flink-jobmanager",
                command=f"flink run -d -j /tmp/jobs/{config.get_str(Key.Experiment.job_file)}",
            )
        case "chaos":
            # Check if chaos has to be created or deleted
            match action_type:
                case "create":
                    experiment = {
                        "run_experiment": "true",
                    }
                    p.run_playbook(
                        "chaos",
                        config=config,
                        tag=["experiment"],
                        extra_vars=experiment,
                    )
                case "delete":
                    experiment = {
                        "delete_experiment": "true",
                    }
                    p.run_playbook(
                        "chaos",
                        config=config,
                        tag=["experiment"],
                        extra_vars=experiment,
                    )
                case _:
                    log.warning(f"default case, nothing happened")

        case "clean":

            # Delete load generators
            delete("load_generators", config)
            # Restart Flink
            reload("flink", config)
            # Remove chaos
            run("chaos", "delete", config)

        case "test":
            pass
        case _:
            log.error(f"Action {action} is not implemented.")


def sync_experiment_data(config: Config):
    log.info("Syncing experiment data...")
    p: Platform = G5k(config, log, verbose=False)
    p.sync_data()


# Export data for a given date
@DeprecationWarning
def export(config: Config, exp_path: str, action_type=None):
    log.info("Exporting...")
    #
    # def get_timestamp_from_log(path):
    #     # Verify that a log file exists for the chosen experiment
    #     log_path = os.path.join(path, "exp_log.txt")
    #     if not os.path.exists(log_path):
    #         log.error("Log file for experiment not found.")
    #         exit(1)
    #     else:
    #         # Verify if experiment executed correctly by checking start and end timestamps
    #         try:
    #             with open(log_path, "r") as log_file:
    #                 logs = log_file.read()
    #
    #             start_match = re.search(r"Experiment start at : (\d+)", logs)
    #             end_match = re.search(r"Experiment end at : (\d+)", logs)
    #             if start_match and end_match:
    #                 start_timestamp = int(start_match.group(1))
    #                 end_timestamp = int(end_match.group(1))
    #                 return start_timestamp, end_timestamp
    #             else:
    #                 log.error("Log file is incomplete: missing timestamp.")
    #                 exit(1)
    #         except FileNotFoundError:
    #             log.error("Log file not found.")
    #             return 0, 0
    #
    # # Build full path from exp_path name
    # # exp_path should be 'DD-MM-YYYY/N' where or 'DD-MM-YYYY' :
    # #   DD-MM-YYYY is the date of the experiments
    # #   N is the number of the experiment
    #
    # # Define regular expression patterns for 'DD-MM-YYYY' and 'DD-MM-YYYY/N' formats
    # exact_format_pattern = r"^\d{2}-\d{2}-\d{4}$"
    # with_integer_pattern = r"^\d{2}-\d{2}-\d{4}/(\d+)$"
    #
    # # Try to match the 'DD-MM-YYYY' format
    # exact_match = re.match(exact_format_pattern, exp_path)
    # # If it doesn't match the exact format, try the 'DD-MM-YYYY/N' format
    # with_integer_match = re.match(with_integer_pattern, exp_path)
    #
    # if exact_match:
    #     base_exp_path = os.path.join(config.get_str(Key.Scalehub.experiments), exp_path)
    #     log.info(f"Exporting experiments for {base_exp_path}.")
    #     # Iterate through each experiment folder of the base exp path
    #     for exp in os.listdir(base_exp_path):
    #         full_exp_path = os.path.join(base_exp_path, exp)
    #         # Retrieve timestamps from logs
    #         start_ts, end_ts = get_timestamp_from_log(full_exp_path)
    #         data: ExperimentData = ExperimentData(
    #             log=log,
    #             exp_path=full_exp_path,
    #             start_ts=start_ts,
    #             end_ts=end_ts,
    #         )
    #         match action_type:
    #             case "stats":
    #                 # If stats, only generate stats.csv with mean throughputs, parallelism and transscale predictions
    #                 # This options requires a joined_outputs.csv file containing throughput and parallelism data
    #                 data.eval_stats(
    #                     skip_duration=config.get_int(Key.Experiment.output_skip_s)
    #                 )
    #             case "plot":
    #                 # If plot, only generate a plot.png
    #                 # This options requires a stats.csv file
    #                 stats, _ = data.eval_stats(
    #                     skip_duration=config.get_int(Key.Experiment.output_skip_s)
    #                 )
    #                 data.eval_plot(stats)
    #             case _:
    #                 # Default option is to retrieve experiment data from DataBase and save it in a joined_output.csv for stats and plot generation
    #                 data.export_experiment_data()
    # elif with_integer_match:
    #     log.info(f"Exporting {exp_path} experiment.")
    #     full_exp_path = os.path.join(config.get_str(Key.Scalehub.experiments), exp_path)
    #     # Retrieve timestamps from logs
    #     start_ts, end_ts = get_timestamp_from_log(full_exp_path)
    #     data: ExperimentData = ExperimentData(
    #         log=log, exp_path=full_exp_path, start_ts=start_ts, end_ts=end_ts
    #     )
    #     match action_type:
    #         case "stats":
    #             # If stats, only generate stats.csv with mean throughputs, parallelism and transscale predictions
    #             # This options requires a joined_outputs.csv file containing throughput and parallelism data
    #             data.eval_stats(
    #                 skip_duration=config.get_int(Key.Experiment.output_skip_s)
    #             )
    #         case "plot":
    #             # If plot, only generate a plot.png
    #             # This options requires a stats.csv file
    #             stats, _ = data.eval_stats(
    #                 skip_duration=config.get_int(Key.Experiment.output_skip_s)
    #             )
    #             data.eval_plot(stats)
    #         case _:
    #             # Default option is to retrieve experiment data from DataBase and save it in a joined_output.csv for stats and plot generation
    #             data.export_experiment_data()
    # else:
    #     log.error("Error during export.")


def main(log: Logger):
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(dest="command")

    parser.add_argument(
        "-c",
        "--conf",
        dest="conf_file",
        action="store",
        default=Value.conf_path,
        help="Specify a custom path for the configuration file of scalehub.",
    )
    # Provision command
    subparsers.add_parser(
        "provision", help="Provision platform specified in conf/scalehub.conf"
    )

    # Destroy command
    subparsers.add_parser(
        "destroy", help="Destroy platform specified in conf/scalehub.conf"
    )

    # Deploy command
    deploy_parser = subparsers.add_parser(
        "deploy", help="Executes deploy tasks of provided playbook."
    )
    deploy_parser.add_argument("playbook", help="Name of the playbook.")

    # Delete command
    delete_parser = subparsers.add_parser(
        "delete", help="Executes delete tasks of provided playbook."
    )
    delete_parser.add_argument("playbook", help="Name of the playbook.")

    # Reload command
    reload_parser = subparsers.add_parser(
        "reload", help="Executes reload tasks of provided playbook."
    )
    reload_parser.add_argument("playbook", help="Name of the playbook.")

    # Experiment command
    experiment_parser = subparsers.add_parser(
        "experiment", help="Executes experiment tasks."
    )
    experiment_parser.add_argument("action", help="Name of the action.")

    # Tokens command
    subparsers.add_parser(
        "tokens", help="Get tokens for minio and kubernetes dashboard"
    )

    # Sync command
    subparsers.add_parser("sync", help="Sync experiment data from remote to local")

    # Run command
    run_parser = subparsers.add_parser("run", help="Run action.")
    run_parser.add_argument(
        "action", help="Specify the action to be run. {job | transscale | chaos}"
    )
    run_parser.add_argument(
        "type",
        help="Specify if {create | delete} action should be run. Only for 'chaos', 'transscale' and 'job' actions. Default is 'create'.",
        nargs="?",
        default="create",
    )

    # Reservation time command
    subparsers.add_parser("reservation_time", help="Get remaining reservation time")

    # Export command
    export_subparser = subparsers.add_parser("export", help="Export data")
    export_subparser.add_argument(
        "date", help="Provide experiment path in format 'DD-MM-YYYY/N'"
    )
    export_subparser.add_argument(
        "type",
        help="Choose what to export between 'stats', 'plot' or 'all'",
        nargs="?",
        default=None,
    )

    # Parse command line arguments
    args = parser.parse_args()

    # Parse configuration file values
    configuration_file = args.conf_file

    # Store configuration file values in Config struct
    config = Config(log, configuration_file)

    if args.command == "provision":
        provision(config)
    elif args.command == "deploy":
        deploy(args.playbook, config)
    elif args.command == "delete":
        delete(args.playbook, config)
    elif args.command == "reload":
        reload(args.playbook, config)
    elif args.command == "destroy":
        destroy(config)
    elif args.command == "experiment":
        action = args.action
        experiment(action, config)
    elif args.command == "tokens":
        tokens()
    elif args.command == "sync":
        sync_experiment_data(config)
    elif args.command == "run":
        action = args.action
        type = args.type
        run(action, type, config)
    elif args.command == "export":
        date = args.date
        type = args.type
    else:
        parser.print_help()


if __name__ == "__main__":
    log = Logger()
    main(log)
