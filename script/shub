#!/usr/bin/env python3
import argparse

# import argcomplete
import json
import os.path
import re

from src.Experiment import Experiment, ExperimentData
from src.G5k import G5k
from src.Platform import Platform
from src.Playbooks import Playbooks
from src.Plotter import Plotter
from src.utils.Config import Config
from src.utils.Defaults import ConfigKeys as Key, DefaultValues as Value
from src.utils.Logger import Logger
from src.utils.Misc import Misc

# Build cluster and install dependencies
def provision(config: Config):
    platform_type = config.get_str(Key.TYPE)
    match platform_type:
        case "Grid5000":
            # Initiate oarsub request
            log.info("Reserving...")
            p: Platform = G5k(config, log)
            inventory = p.setup()

            # Dump list of requested nodes to file
            with open(config.get_str(Key.INVENTORY_PATH), "w") as f:
                json.dump(inventory, f, ensure_ascii=False, indent=4)

            # Setup cluster with docker, k3s and appropriate labels
            play: Playbooks = Playbooks()
            return play.deploy("cluster-setup")
        case _:
            log.error(f"Provision is not implemented for platform {platform_type}")


# Destroy cluster
def destroy(config: Config):
    platform_type = config.get_str(Key.TYPE)
    match platform_type:
        case "Grid5000":
            # Initiate oardel request
            p: Platform = G5k(config, log)
            return p.destroy()
        case _:
            log.error(f"Destroy is not implemented for platform {platform_type}")


# Execute tasks with "deploy" tag for a given playbook
def deploy(playbook, config: Config):
    log.info(f"Executing deployment tasks in playbook : {playbook} ...")
    p: Playbooks = Playbooks()
    if playbook == "load_generators":
        for lg_config in config.parse_load_generators():
            p.deploy(
                playbook,
                lg_name=lg_config["name"],
                lg_topic=lg_config["topic"],
                lg_numsensors=int(lg_config["num_sensors"]),
                lg_intervalms=int(lg_config["interval_ms"]),
                lg_replicas=int(lg_config["replicas"]),
                lg_value=int(lg_config["value"]),
            )
    elif playbook == "transscale":
        p.deploy(
            playbook,
            job_file=config.get_str(Key.JOB),
            task_name=config.get_str(Key.TASK),
            max_parallelism=config.get_int(Key.TRANSCCALE_PAR),
            warmup=config.get_int(Key.TRANSSCALE_WARMUP),
            interval=config.get_int(Key.TRANSSCALE_INTERVAL),
        )
    else:
        return p.deploy(
            playbook,
            job_file=config.get_str(Key.JOB),
            task_name=config.get_str(Key.TASK),
        )


# Execute tasks with "delete" tag for a given playbook
def delete(playbook, config: Config):
    log.info(f"Executing deletion tasks in playbook : {playbook} ...")
    p: Playbooks = Playbooks()
    if playbook == "load_generators":
        for lg_config in config.parse_load_generators():
            p.delete(
                playbook,
                lg_name=lg_config["name"],
                lg_topic=lg_config["topic"],
                lg_numsensors=int(lg_config["num_sensors"]),
                lg_intervalms=int(lg_config["interval_ms"]),
                lg_replicas=int(lg_config["replicas"]),
            )
    else:
        return p.delete(playbook, job_file=config.get_str(Key.JOB))


# Quick action commands
def run(action, config):
    log.info(f"Running action {action} ...")
    m: Misc = Misc(log)
    match action:
        case "job":
            return m.run_command(
                pod_name="flink-jobmanager",
                command=f"flink run -d -j /tmp/jobs/{config.get_str(Key.JOB)}",
            )
        case "transscale":
            e: Experiment = Experiment(config, log)
            e.transscale_only_run()
        case "experiment":
            e: Experiment = Experiment(config, log)
            e.full_run()
        case _:
            log.error(f"Action {action} is not implemented.")


# Export data for a given date
def export(config: Config, exp_path: str):
    log.info("Exporting...")
    # Generate full path from provided path name
    # exp_path should be 'DD-MM-YYYY/N' where :
    #   DD-MM-YYYY is the date of the experiments
    #   N is the number of the experiment
    full_exp_path = os.path.join(config.get_str(Key.EXPERIMENTS_DATA_PATH), exp_path)

    # Verify that a log file exists for the chosen experiment
    log_path = os.path.join(full_exp_path, "exp_log.txt")
    if not os.path.exists(log_path):
        log.error("Log file for experiment not found.")
        exit(1)
    else:
        # Verify if experiment executed correctly by checking start and end timestamps
        with open(log_path, "r") as log_file:
            logs = log_file.read()

        start_match = re.search(r"Experiment start at : (\d+)", logs)
        end_match = re.search(r"Experiment end at : (\d+)", logs)
        if start_match and end_match:
            start_timestamp = int(start_match.group(1))
            end_timestamp = int(end_match.group(1))
            data: ExperimentData = ExperimentData(
                log=log,
                exp_path=full_exp_path,
                start_ts=start_timestamp,
                end_ts=end_timestamp,
                db_url=config.get_str(Key.DB_URL),
            )
            data.export_experiment_data()
            stats, _ = data.eval_stats(
                skip_duration=config.get_int(Key.DATA_SKIP_DURATION)
            )
            if config.get_bool(Key.DATA_OUTPUT_PLOT):
                data.eval_plot(stats)
        else:
            log.error("Log file is incomplete: missing timestamp.")


# Generate plots for an experiment
def plot(config: Config):
    log.info("Starting plotter.")
    p: Plotter = Plotter(config, log)


def main(log: Logger):
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(dest="command")

    parser.add_argument(
        "-c",
        "--conf",
        dest="conf_file",
        action="store",
        default=Value.System.CONF_PATH,
        help="Specify a custom path for the configuration file of scalehub.",
    )
    # Provision command
    subparsers.add_parser(
        "provision", help="Provision platform specified in conf/scalehub.conf"
    )

    # Destroy command
    subparsers.add_parser(
        "destroy", help="Destroy platform specified in conf/scalehub.conf"
    )

    # Deploy command
    deploy_parser = subparsers.add_parser(
        "deploy", help="Executes deploy tasks of provided playbook."
    )
    deploy_parser.add_argument("playbook", help="Name of the playbook.")

    # Delete command
    delete_parser = subparsers.add_parser(
        "delete", help="Executes delete tasks of provided playbook."
    )
    delete_parser.add_argument("playbook", help="Name of the playbook.")

    # Run command
    run_parser = subparsers.add_parser("run", help="Run action.")
    run_parser.add_argument(
        "action", help="Specify the action to be run. {job | transscale}"
    )

    # Export command
    export_subparser = subparsers.add_parser("export", help="Export data")
    export_subparser.add_argument(
        "experiment", help="Provide experiment path in format 'DD-MM-YYYY/N'"
    )

    # Plot command
    subparsers.add_parser("plot", help="Starts interactive data plotter.")

    # Parse command line arguments
    args = parser.parse_args()

    # Parse configuration file values
    configuration_file = args.conf_file

    # Store configuration file values in Config struct
    config = Config(log, configuration_file)

    if args.command == "provision":
        provision(config)
    elif args.command == "deploy":
        deploy(args.playbook, config)
    elif args.command == "delete":
        delete(args.playbook, config)
    elif args.command == "destroy":
        destroy(config)
    elif args.command == "run":
        run(args.action, config)
    elif args.command == "export":
        export(config, args.experiment)
    elif args.command == "plot":
        plot(config)
    else:
        parser.print_help()


if __name__ == "__main__":
    log = Logger()
    main(log)
