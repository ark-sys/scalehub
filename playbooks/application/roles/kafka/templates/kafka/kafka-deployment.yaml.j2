---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: kafka
spec:
  serviceName: kafka-service
  replicas: 3
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      nodeSelector:
        node-role.kubernetes.io/worker: producer
      initContainers:
        - name: cleanup
          image: alpine:3.20
          command: [ "sh", "-c", "rm -rf /kafka/data/*" ]
          volumeMounts:
            - name: data
              mountPath: /kafka/data
        - name: configure-broker-id
          image: alpine:3.20
          command:
            - sh
            - -c
            - |
              NODE_ID=$(echo $HOSTNAME | grep -o '[0-9]*$')
              echo "node.id=$NODE_ID" >> /etc/kafka/server.properties
          volumeMounts:
            - name: kafka-config
              mountPath: /etc/kafka
          env:
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
      containers:
        - name: kafka
          image: "{{kafka_image}}:{{kafka_tag}}"
          env:
            #            - name: KAFKA_NODE_ID
            #              valueFrom:
            #                fieldRef:
            #                  fieldPath: metadata.name
            - name: HOSTNAME_COMMAND
              value: hostname
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://:9092"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://_{HOSTNAME_COMMAND}.kafka-service.kafka.svc.cluster.local:9092"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "PLAINTEXT:PLAINTEXT"
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: zookeeper-service.kafka:2181
            - name: KAFKA_CREATE_TOPICS
              value: "ad-events:{{ partitions }}:3,input-topic1:{{ partitions }}:3,input-topic2:{{ partitions }}:3"
            - name: KAFKA_LOG_RETENTION_BYTES
              value: "1073741824"
            - name: KAFKA_LOG_CLEANER_ENABLE
              value: "true"
            - name: KAFKA_LOG_SEGMENT_BYTES
              value: "536870912"
            - name: KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS
              value: "5000"
            - name: KAFKA_LOG_RETENTION_MS
              value: "10000"
            - name: KAFKA_LOG_CLEANUP_POLICY
              value: "delete"
            - name: KAFKA_LOG_DIRS
              value: "/kafka/data"
            - name: KAFKA_JMX_OPTS
              value: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=5555"
            - name: JMX_PORT
              value: "5555"
            - name: KAFKA_PROCESS_ROLES
              value: "broker"

          ports:
            - containerPort: 5555
              name: jmx
              protocol: TCP
          volumeMounts:
            - name: data
              mountPath: /kafka/data
            - name: kafka-config
              mountPath: /etc/kafka
          resources:
            limits:
              memory: 4Gi
              cpu: 1000m
        - name: prometheus-jmx-exporter
          image: "{{jmx_image}}:{{jmx_tag}}"
          command:
            - java
            - -XX:+UnlockExperimentalVMOptions
            - -XX:+UseCGroupMemoryLimitForHeap
            - -XX:MaxRAMFraction=1
            - -XshowSettings:vm
            - -jar
            - jmx_prometheus_httpserver.jar
            - "5556"
            - /etc/jmx-config/jmx-kafka-prometheus.yml
          ports:
            - containerPort: 5556
              name: metrics
          volumeMounts:
            - name: jmx-config
              mountPath: /etc/jmx-config
      volumes:
        - name: data
          hostPath:
            path: /tmp/experiment-data/kafka
        - name: jmx-config
          configMap:
            name: jmx-configmap
        - name: kafka-config
          emptyDir: { }