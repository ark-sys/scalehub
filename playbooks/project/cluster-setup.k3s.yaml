---
- name: Common setup for both workers and controller
  hosts: control, workers, storage
  become: true
  gather_facts: true
  tags: [ always ]
  tasks:
    - name: Install python3-apt
      shell:
        cmd: apt-get install -y python3-apt
    - name: Install required system packages
      ansible.builtin.apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - lsb-release
          - gnupg
          - ncdu # Disk usage monitoring
        state: latest
        update_cache: true

    - name: Add Docker GPG apt Key
      ansible.builtin.apt_key:
        url: "https://download.docker.com/linux/{{ ansible_distribution | lower }}/gpg"
        state: present

    - name: Add Docker Repository
      ansible.builtin.apt_repository:
        repo: "deb https://download.docker.com/linux/{{ ansible_distribution | lower }} {{ ansible_distribution_release }} stable"
        state: present
        filename: docker

    - name: Update apt and install docker-ce
      ansible.builtin.apt:
        name:
          - docker-ce
          - docker-ce-cli
          - containerd.io
        state: latest
        update_cache: true
    - name: Create Docker daemon configuration file with size limits for the logging
      ansible.builtin.copy:
        content: |
          {
            "log-driver": "local",
            "log-opts": {
              "max-size": "200m"
            }
          }
        dest: /etc/docker/daemon.json

    - name: Restart Docker service
      ansible.builtin.service:
        name: docker
        state: restarted
    - name: Disable node exporter
      ansible.builtin.service:
        name: prometheus-node-exporter
        state: stopped
        enabled: false
    - name: Create /etc/rancher/k3s
      ansible.builtin.file:
        path: /etc/rancher/k3s
        state: directory
        mode: "0755"
        recurse: yes
    - name: Create tmp folder for flink checkpoints
      ansible.builtin.file:
        path: /tmp/experiment-data/
        state: directory
        mode: "0777"

- name: Install K3S and setup kubeconfig
  hosts: control
  become: true
  gather_facts: false
  tags: [ always ]
  tasks:
    - name: Install k3s on controller
      environment:
        INSTALL_K3S_EXEC: --disable=traefik
        INSTALL_K3S_VERSION: v1.28.3+k3s2
      shell:
        cmd: "curl -sfL https://get.k3s.io | sh -s -"
    - name: Get kubeconfig from controller
      ansible.builtin.shell:
        cmd: cat /etc/rancher/k3s/k3s.yaml
      register: kubeconfig_content
    - name: Replace localhost with control node IP address
      set_fact:
        kubeconfig_content: "{{ kubeconfig_content.stdout | replace('127.0.0.1', hostvars[groups['control'][0]]['ansible_default_ipv4']['address']) }}"
    - name: Save kubeconfig to localhost
      delegate_to: localhost
      ansible.builtin.copy:
        content: "{{ kubeconfig_content }}"
        dest: "{{ kubeconfig_path }}"
        mode: '644'

- name: Install K3S on worker nodes
  hosts: workers, storage
  become: true
  gather_facts: false
  tags: [ always ]
  tasks:
    - name: Get node token from controller for workers hosts
      delegate_to: "{{ groups['control'][0] }}"
      shell: "cat /var/lib/rancher/k3s/server/node-token"
      register: node_token
    - name: Install k3s on workers and storage
      environment:
        K3S_URL: "https://{{ hostvars[groups['control'][0]]['ansible_default_ipv4']['address'] }}:6443"
        K3S_TOKEN: "{{ node_token.stdout }}"
        INSTALL_K3S_VERSION: v1.28.3+k3s2
      shell:
        cmd: "curl -sfL https://get.k3s.io | sh -s -"

- name: Post-install configuration - Label worker nodes
  hosts: localhost
  gather_facts: false
  tags: [ always ]
  tasks:
    - name: Wait for all k3s nodes to be ready
      shell: kubectl wait --for=condition=Ready nodes --all --timeout=600s
    - name: Create monitoring namespace
      kubernetes.core.k8s:
        name: monitoring
        api_version: v1
        kind: Namespace
        state: present
    - name: Retrieve worker nodes from inventory
      set_fact:
        worker_hosts: "{{ groups['workers'] }}"
    - name: Retrieve control node from inventory
      set_fact:
        control_host: "{{ groups['control'][0] }}"
    - name: Retrieve storage node from inventory
      set_fact:
        storage_host: "{{ groups['storage'][0] }}"

    - name: Define total_nodes variable
      set_fact:
        total_nodes: "{{ worker_hosts | length | int }}"

    - name: Calculate number of producer nodes
      set_fact:
        producer_nodes: "{{ (total_nodes | int * 3 / 10) | round | int }}"

    - name: Calculate number of consumer nodes
      set_fact:
        consumer_nodes: "{{ total_nodes | int - producer_nodes | int }}"

    - name: Slice worker_hosts list
      set_fact:
        producer_hosts: "{{ worker_hosts[:producer_nodes | int] }}"
        consumer_hosts: "{{ worker_hosts[producer_nodes | int:] }}"

    - name: Label nodes based on node count
      block:
        - name: Label nodes as worker-producer
          command:
            cmd: "kubectl label nodes {{ item }} --overwrite node-role.kubernetes.io/worker='producer' node-role.kubernetes.io/producer=''"
          with_items:
            - "{{ producer_hosts }}"

        - name: Label nodes as worker-consumer
          command:
            cmd: "kubectl label nodes {{ item }} --overwrite node-role.kubernetes.io/worker='consumer' node-role.kubernetes.io/consumer=''"
          with_items:
            - "{{ consumer_hosts }}"
      when: total_nodes | int >= 3

    - name: Label all nodes as worker-producer and worker-consumer
      command:
        cmd: "kubectl label nodes {{ item }} --overwrite node-role.kubernetes.io/worker='producer' node-role.kubernetes.io/producer='' node-role.kubernetes.io/consumer=''"
      with_items:
        - "{{ worker_hosts }}"
      when: total_nodes | int < 3

    - name: Label control node
      command:
        cmd: "kubectl label nodes {{ control_host }} --overwrite node-role.kubernetes.io/control-plane=true"
    - name: Label storage node
      command:
        cmd: "kubectl label nodes {{ storage_host }} --overwrite node-role.kubernetes.io/storage=true node-role.kubernetes.io/scalehub-storage=true"

    - name: Randomly select a consumer node
      set_fact:
        random_consumer_node: "{{ consumer_hosts | random(seed=42) }}"
    - name: Label a random consumer node with autoscaling
      command:
        cmd: "kubectl label node {{ random_consumer_node }} --overwrite node-role.kubernetes.io/autoscaling='SCHEDULABLE'"
