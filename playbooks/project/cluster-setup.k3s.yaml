---
- name: Common setup for both workers and controller
  hosts: control, workers
  become: true
  gather_facts: true
  tags: [ always ]
  tasks:
    - name: Install python3-apt
      shell:
        cmd: apt-get install -y python3-apt
    - name: Install required system packages
      ansible.builtin.apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - lsb-release
          - gnupg
          - ncdu # Disk usage monitoring
        state: latest
        update_cache: true

    - name: Add Docker GPG apt Key
      ansible.builtin.apt_key:
        url: "https://download.docker.com/linux/{{ ansible_distribution | lower }}/gpg"
        state: present

    - name: Add Docker Repository
      ansible.builtin.apt_repository:
        repo: "deb https://download.docker.com/linux/{{ ansible_distribution | lower }} {{ ansible_distribution_release }} stable"
        state: present
        filename: docker

    - name: Update apt and install docker-ce
      ansible.builtin.apt:
        name:
          - docker-ce
          - docker-ce-cli
          - containerd.io
        state: latest
        update_cache: true

    - name: Create Docker daemon configuration file with size limits for the logging
      ansible.builtin.copy:
        content: |
          {
            "log-driver": "local",
            "log-opts": {
              "max-size": "200m"
            }
          }
        dest: /etc/docker/daemon.json

    - name: Restart Docker service
      ansible.builtin.service:
        name: docker
        state: restarted

    - name: Create /etc/rancher/k3s
      shell:
        cmd: mkdir -p /etc/rancher/k3s
    - name: Disable node exporter
      ansible.builtin.service:
        name: prometheus-node-exporter
        state: stopped
        enabled: false
    - name: Create tmp folder for experiment
      ansible.builtin.file:
        path: /tmp/experiment-data
        state: directory
        mode: "0777"
    - name: Create tmp folder for flink
      ansible.builtin.file:
        path: /tmp/experiment-data/flink/tmp
        state: directory
        mode: "0777"
    - name: Create tmp folder for flink checkpoints
      ansible.builtin.file:
        path: /tmp/experiment-data/flink/checkpoints
        state: directory
        mode: "0777"


- name: Install K3S and post-install config
  hosts: control
  become: true
  gather_facts: false
  tags: [ always ]
  tasks:
    - name: Install k3s on controller
      environment:
        INSTALL_K3S_EXEC: --disable=traefik --disable=local-storage
        INSTALL_K3S_VERSION: v1.25.11+k3s1
      shell:
        cmd: "curl -sfL https://get.k3s.io | sh -s -"

    - name: Get node token
      tags: [ always ]
      ansible.builtin.shell:
        cmd: sudo cat /var/lib/rancher/k3s/server/token
      register: NODE_TOKEN

    - name: "Create Dummy Host for saving *global* variable"
      tags: [ always ]
      add_host:
        name: "CONTROLLER_DETAILS"
        token: "{{ NODE_TOKEN.stdout }}"
        controller_ip: "{{ ansible_default_ipv4.address }}"

    - ansible.builtin.fetch:
        src: /etc/rancher/k3s/k3s.yaml
        dest: "{{ kubeconfig_path }}"
        flat: true

- name: Setup Workers
  hosts: workers
  become: true
  gather_facts: false
  strategy: free
  tags: [ always ]
  tasks:
    - name: Install k3s on workers
      environment:
        K3S_URL: https://{{ hostvars['CONTROLLER_DETAILS']['controller_ip'] }}:6443
        K3S_TOKEN: "{{ hostvars['CONTROLLER_DETAILS']['token'] }}"
        #        INSTALL_K3S_EXEC: --docker
        INSTALL_K3S_VERSION: v1.25.11+k3s1
      shell:
        cmd: curl -sfL https://get.k3s.io | sh -s -

- name: Post-install configuration - kubeconfig
  hosts: localhost
  gather_facts: false
  connection: local
  tags:
    - kubeconfig
    - always
  tasks:
    - name: Patch kubeconfig - Set controller IP
      ansible.builtin.lineinfile:
        path: "{{ kubeconfig_path }}"
        regexp: 127.0.0.1:6443
        line: "    server: https://{{ hostvars['CONTROLLER_DETAILS']['controller_ip'] }}:6443"

    - name: Patch kubeconfig- Rename cluster
      ansible.builtin.replace:
        path: "{{ kubeconfig_path }}"
        regexp: default
        replace: scalehub-cluster

    - name: Set correct chmod on kubeconfig
      ansible.builtin.file:
        path: "{{ kubeconfig_path }}"
        mode: "0600"
    - name: Wait for all k3s nodes to be ready
      shell: kubectl wait --for=condition=Ready nodes --all --timeout=600s
      register: nodes_ready
    - debug: var=nodes_ready.stdout_lines

- name: Post-install configuration - Label worker nodes
  hosts: localhost
  gather_facts: false
  tags: [ always ]
  tasks:
    - name: Retrieve worker nodes from inventory
      set_fact:
        worker_hosts: "{{ groups['workers'] }}"
    - name: Retrieve control node from inventory
      set_fact:
        control_host: "{{ groups['control'][0] }}"

    - name: Define total_nodes variable
      set_fact:
        total_nodes: "{{ worker_hosts | length | int }}"

    - name: Calculate number of producer nodes
      set_fact:
        producer_nodes: "{{ (total_nodes | int * 3 / 10) | round | int }}"

    - name: Calculate number of consumer nodes
      set_fact:
        consumer_nodes: "{{ total_nodes | int - producer_nodes | int }}"

    - name: Slice worker_hosts list
      set_fact:
        producer_hosts: "{{ worker_hosts[:producer_nodes | int] }}"
        consumer_hosts: "{{ worker_hosts[producer_nodes | int:] }}"

    - name: Label nodes based on node count
      block:
        - name: Label nodes as worker-producer
          command:
            cmd: "kubectl label nodes {{ item }} --overwrite node-role.kubernetes.io/worker='producer' node-role.kubernetes.io/producer=''"
          with_items:
            - "{{ producer_hosts }}"

        - name: Label nodes as worker-consumer
          command:
            cmd: "kubectl label nodes {{ item }} --overwrite node-role.kubernetes.io/worker='consumer' node-role.kubernetes.io/consumer=''"
          with_items:
            - "{{ consumer_hosts }}"
      when: total_nodes | int >= 3

    - name: Label all nodes as worker-producer and worker-consumer
      command:
        cmd: "kubectl label nodes {{ item }} --overwrite node-role.kubernetes.io/worker='producer' node-role.kubernetes.io/producer='' node-role.kubernetes.io/consumer=''"
      with_items:
        - "{{ worker_hosts }}"
      when: total_nodes | int < 3

    - name: Label control node
      command:
        cmd: "kubectl label nodes {{ control_host }} --overwrite node-role.kubernetes.io/control-plane=true"

    - name: Randomly select a consumer node
      set_fact:
        random_consumer_node: "{{ consumer_hosts | random(seed=42) }}"
    - name: Label a random consumer node with autoscaling
      command:
        cmd: "kubectl label node {{ random_consumer_node }} --overwrite node-role.kubernetes.io/autoscaling='SCHEDULABLE'"
    # Todo: this part should be parameterizable
    # Setup NFS
    - name: Setup NFS
      block:
        - name: Install NFS Storage provisioner
          kubernetes.core.helm:
            name: csi-driver-nfs
            chart_ref: "csi-driver-nfs"
            chart_version: 4.1.0
            chart_repo_url: https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts
            release_namespace: csi-driver-nfs
            create_namespace: true
            wait: true
          register: csi_driver
        - name: Deploy NFS Storage
          kubernetes.core.k8s:
            state: present
            definition:
              apiVersion: storage.k8s.io/v1
              kind: StorageClass
              metadata:
                name: nfs-csi
              provisioner: nfs.csi.k8s.io
              parameters:
                server: "{{ nfs_server_address }}"
                share: "{{ nfs_share }}/scalehub-pvc"
                subDir: "${pvc.metadata.namespace}-${pvc.metadata.name}"
              volumeBindingMode: Immediate
              mountOptions:
                - nconnect=16

